{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marco-siino/eloquent2024/blob/main/ELOQUENT_2024_Task_2_Hallucigen_Mistral7B_MSiino.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ubSCVmmlBKX"
      },
      "source": [
        "Installing dependencies. You might need to tweak the CMAKE_ARGS for the `llama-cpp-python` pip package."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CKL68Itp9Bm-",
        "outputId": "c56a07a6-de08-4edc-e88a-3f1fd3fc42b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting llama-cpp-python>=0.1.79\n",
            "  Downloading llama_cpp_python-0.2.71.tar.gz (48.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.4/48.4 MB\u001b[0m \u001b[31m206.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting typing-extensions>=4.5.0 (from llama-cpp-python>=0.1.79)\n",
            "  Downloading typing_extensions-4.11.0-py3-none-any.whl (34 kB)\n",
            "Collecting numpy>=1.20.0 (from llama-cpp-python>=0.1.79)\n",
            "  Downloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m320.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting diskcache>=5.6.1 (from llama-cpp-python>=0.1.79)\n",
            "  Downloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m234.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jinja2>=2.11.3 (from llama-cpp-python>=0.1.79)\n",
            "  Downloading jinja2-3.1.4-py3-none-any.whl (133 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.3/133.3 kB\u001b[0m \u001b[31m329.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting MarkupSafe>=2.0 (from jinja2>=2.11.3->llama-cpp-python>=0.1.79)\n",
            "  Downloading MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
            "Building wheels for collected packages: llama-cpp-python\n",
            "  Building wheel for llama-cpp-python (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for llama-cpp-python: filename=llama_cpp_python-0.2.71-cp310-cp310-linux_x86_64.whl size=55332522 sha256=15b2e8a86ee262e2d37ec3c6536840a87ce93f17251b39c5bd215f1cfa7dd5b6\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-zeokkhh8/wheels/5d/35/d3/b4ab42b4528cc5e1f9b1469c4b4076de51e2f3ceb50506b424\n",
            "Successfully built llama-cpp-python\n",
            "Installing collected packages: typing-extensions, numpy, MarkupSafe, diskcache, jinja2, llama-cpp-python\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.11.0\n",
            "    Uninstalling typing_extensions-4.11.0:\n",
            "      Successfully uninstalled typing_extensions-4.11.0\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.25.2\n",
            "    Uninstalling numpy-1.25.2:\n",
            "      Successfully uninstalled numpy-1.25.2\n",
            "  Attempting uninstall: MarkupSafe\n",
            "    Found existing installation: MarkupSafe 2.1.5\n",
            "    Uninstalling MarkupSafe-2.1.5:\n",
            "      Successfully uninstalled MarkupSafe-2.1.5\n",
            "  Attempting uninstall: jinja2\n",
            "    Found existing installation: Jinja2 3.1.3\n",
            "    Uninstalling Jinja2-3.1.3:\n",
            "      Successfully uninstalled Jinja2-3.1.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torch 2.2.1+cu121 requires nvidia-cublas-cu12==12.1.3.1; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.2.1+cu121 requires nvidia-cuda-cupti-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.2.1+cu121 requires nvidia-cuda-nvrtc-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.2.1+cu121 requires nvidia-cuda-runtime-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.2.1+cu121 requires nvidia-cudnn-cu12==8.9.2.26; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.2.1+cu121 requires nvidia-cufft-cu12==11.0.2.54; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.2.1+cu121 requires nvidia-curand-cu12==10.3.2.106; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.2.1+cu121 requires nvidia-cusolver-cu12==11.4.5.107; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.2.1+cu121 requires nvidia-cusparse-cu12==12.1.0.106; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.2.1+cu121 requires nvidia-nccl-cu12==2.19.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.2.1+cu121 requires nvidia-nvtx-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed MarkupSafe-2.1.5 diskcache-5.6.3 jinja2-3.1.4 llama-cpp-python-0.2.71 numpy-1.26.4 typing-extensions-4.11.0\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (0.20.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (3.14.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.66.4)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.11.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (24.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2024.2.2)\n",
            "Collecting datasets\n",
            "  Downloading datasets-2.19.1-py3-none-any.whl (542 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m542.0/542.0 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.14.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.0.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.4)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<=2024.3.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.5)\n",
            "Collecting huggingface-hub>=0.21.2 (from datasets)\n",
            "  Downloading huggingface_hub-0.23.0-py3-none-any.whl (401 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m401.2/401.2 kB\u001b[0m \u001b[31m41.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.2->datasets) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Installing collected packages: xxhash, dill, multiprocess, huggingface-hub, datasets\n",
            "  Attempting uninstall: huggingface-hub\n",
            "    Found existing installation: huggingface-hub 0.20.3\n",
            "    Uninstalling huggingface-hub-0.20.3:\n",
            "      Successfully uninstalled huggingface-hub-0.20.3\n",
            "Successfully installed datasets-2.19.1 dill-0.3.8 huggingface-hub-0.23.0 multiprocess-0.70.16 xxhash-3.4.1\n",
            "Collecting deep-translator\n",
            "  Downloading deep_translator-1.11.4-py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.3/42.3 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: beautifulsoup4<5.0.0,>=4.9.1 in /usr/local/lib/python3.10/dist-packages (from deep-translator) (4.12.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from deep-translator) (2.31.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4<5.0.0,>=4.9.1->deep-translator) (2.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.23.0->deep-translator) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.23.0->deep-translator) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.23.0->deep-translator) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.23.0->deep-translator) (2024.2.2)\n",
            "Installing collected packages: deep-translator\n",
            "Successfully installed deep-translator-1.11.4\n"
          ]
        }
      ],
      "source": [
        "# GPU llama-cpp-python; Starting from version llama-cpp-python==0.1.79, it supports GGUF\n",
        "!CMAKE_ARGS=\"-DLLAMA_CUBLAS=on \" pip install 'llama-cpp-python>=0.1.79' --force-reinstall --upgrade --no-cache-dir\n",
        "# For download the models\n",
        "!pip install huggingface_hub\n",
        "!pip install datasets\n",
        "!pip install -U deep-translator\n",
        "\n",
        "import datasets\n",
        "from datasets import load_dataset\n",
        "from deep_translator import GoogleTranslator\n",
        "import json\n",
        "import re\n",
        "import random\n",
        "import numpy as np\n",
        "import tqdm.notebook as tqdm\n",
        "\n",
        "# Seed to shuffle the json training set.\n",
        "seed_value = 42\n",
        "random.seed(seed_value)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M2ns57iDlBKa"
      },
      "source": [
        "Downloading an instruction-finetuned Mistral model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uDMqQmBfAhYO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "b681ea880f56420eacb3fc0366dc65b6",
            "da972865bee547b6998fcc38e88165dc",
            "5b19be7f8ae645c6a264d794091d6940",
            "2f04869e637542018dee1995a3fca139",
            "858936563e4442b0a0bc168a9b30d3dc",
            "7de4cf1cfff847c39b30876b4ef2d1e4",
            "800e8c46c9ae4a118168b9e0ed9bd453",
            "ea0a151eec96406281bfcfa3a70245bf",
            "cec3fa17191843d089bf40785a6de01b",
            "a7dbe5f4d8614b1992e8a1bf66783ef3",
            "0e0454888c0647f4a0ecf54b19488707"
          ]
        },
        "outputId": "698051f5-af54-490a-e268-10e8ced580ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "mistral-7b-instruct-v0.2.Q6_K.gguf:   0%|          | 0.00/5.94G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b681ea880f56420eacb3fc0366dc65b6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "llama_model_loader: loaded meta data with 24 key-value pairs and 291 tensors from /root/.cache/huggingface/hub/models--TheBloke--Mistral-7B-Instruct-v0.2-GGUF/snapshots/3a6fbf4a41a1d52e415a4958cde6856d34b2db93/mistral-7b-instruct-v0.2.Q6_K.gguf (version GGUF V3 (latest))\n",
            "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
            "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
            "llama_model_loader: - kv   1:                               general.name str              = mistralai_mistral-7b-instruct-v0.2\n",
            "llama_model_loader: - kv   2:                       llama.context_length u32              = 32768\n",
            "llama_model_loader: - kv   3:                     llama.embedding_length u32              = 4096\n",
            "llama_model_loader: - kv   4:                          llama.block_count u32              = 32\n",
            "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 14336\n",
            "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n",
            "llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 32\n",
            "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 8\n",
            "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
            "llama_model_loader: - kv  10:                       llama.rope.freq_base f32              = 1000000.000000\n",
            "llama_model_loader: - kv  11:                          general.file_type u32              = 18\n",
            "llama_model_loader: - kv  12:                       tokenizer.ggml.model str              = llama\n",
            "llama_model_loader: - kv  13:                      tokenizer.ggml.tokens arr[str,32000]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
            "llama_model_loader: - kv  14:                      tokenizer.ggml.scores arr[f32,32000]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
            "llama_model_loader: - kv  15:                  tokenizer.ggml.token_type arr[i32,32000]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
            "llama_model_loader: - kv  16:                tokenizer.ggml.bos_token_id u32              = 1\n",
            "llama_model_loader: - kv  17:                tokenizer.ggml.eos_token_id u32              = 2\n",
            "llama_model_loader: - kv  18:            tokenizer.ggml.unknown_token_id u32              = 0\n",
            "llama_model_loader: - kv  19:            tokenizer.ggml.padding_token_id u32              = 0\n",
            "llama_model_loader: - kv  20:               tokenizer.ggml.add_bos_token bool             = true\n",
            "llama_model_loader: - kv  21:               tokenizer.ggml.add_eos_token bool             = false\n",
            "llama_model_loader: - kv  22:                    tokenizer.chat_template str              = {{ bos_token }}{% for message in mess...\n",
            "llama_model_loader: - kv  23:               general.quantization_version u32              = 2\n",
            "llama_model_loader: - type  f32:   65 tensors\n",
            "llama_model_loader: - type q6_K:  226 tensors\n",
            "llm_load_vocab: special tokens definition check successful ( 259/32000 ).\n",
            "llm_load_print_meta: format           = GGUF V3 (latest)\n",
            "llm_load_print_meta: arch             = llama\n",
            "llm_load_print_meta: vocab type       = SPM\n",
            "llm_load_print_meta: n_vocab          = 32000\n",
            "llm_load_print_meta: n_merges         = 0\n",
            "llm_load_print_meta: n_ctx_train      = 32768\n",
            "llm_load_print_meta: n_embd           = 4096\n",
            "llm_load_print_meta: n_head           = 32\n",
            "llm_load_print_meta: n_head_kv        = 8\n",
            "llm_load_print_meta: n_layer          = 32\n",
            "llm_load_print_meta: n_rot            = 128\n",
            "llm_load_print_meta: n_embd_head_k    = 128\n",
            "llm_load_print_meta: n_embd_head_v    = 128\n",
            "llm_load_print_meta: n_gqa            = 4\n",
            "llm_load_print_meta: n_embd_k_gqa     = 1024\n",
            "llm_load_print_meta: n_embd_v_gqa     = 1024\n",
            "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
            "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
            "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
            "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
            "llm_load_print_meta: f_logit_scale    = 0.0e+00\n",
            "llm_load_print_meta: n_ff             = 14336\n",
            "llm_load_print_meta: n_expert         = 0\n",
            "llm_load_print_meta: n_expert_used    = 0\n",
            "llm_load_print_meta: causal attn      = 1\n",
            "llm_load_print_meta: pooling type     = 0\n",
            "llm_load_print_meta: rope type        = 0\n",
            "llm_load_print_meta: rope scaling     = linear\n",
            "llm_load_print_meta: freq_base_train  = 1000000.0\n",
            "llm_load_print_meta: freq_scale_train = 1\n",
            "llm_load_print_meta: n_yarn_orig_ctx  = 32768\n",
            "llm_load_print_meta: rope_finetuned   = unknown\n",
            "llm_load_print_meta: ssm_d_conv       = 0\n",
            "llm_load_print_meta: ssm_d_inner      = 0\n",
            "llm_load_print_meta: ssm_d_state      = 0\n",
            "llm_load_print_meta: ssm_dt_rank      = 0\n",
            "llm_load_print_meta: model type       = 8B\n",
            "llm_load_print_meta: model ftype      = Q6_K\n",
            "llm_load_print_meta: model params     = 7.24 B\n",
            "llm_load_print_meta: model size       = 5.53 GiB (6.56 BPW) \n",
            "llm_load_print_meta: general.name     = mistralai_mistral-7b-instruct-v0.2\n",
            "llm_load_print_meta: BOS token        = 1 '<s>'\n",
            "llm_load_print_meta: EOS token        = 2 '</s>'\n",
            "llm_load_print_meta: UNK token        = 0 '<unk>'\n",
            "llm_load_print_meta: PAD token        = 0 '<unk>'\n",
            "llm_load_print_meta: LF token         = 13 '<0x0A>'\n",
            "llm_load_tensors: ggml ctx size =    0.30 MiB\n",
            "llm_load_tensors: offloading 32 repeating layers to GPU\n",
            "llm_load_tensors: offloaded 32/33 layers to GPU\n",
            "llm_load_tensors:        CPU buffer size =  5666.09 MiB\n",
            "llm_load_tensors:      CUDA0 buffer size =  5461.00 MiB\n",
            "...................................................................................................\n",
            "llama_new_context_with_model: n_ctx      = 8192\n",
            "llama_new_context_with_model: n_batch    = 800\n",
            "llama_new_context_with_model: n_ubatch   = 512\n",
            "llama_new_context_with_model: flash_attn = 0\n",
            "llama_new_context_with_model: freq_base  = 1000000.0\n",
            "llama_new_context_with_model: freq_scale = 1\n",
            "llama_kv_cache_init:      CUDA0 KV buffer size =  1024.00 MiB\n",
            "llama_new_context_with_model: KV self size  = 1024.00 MiB, K (f16):  512.00 MiB, V (f16):  512.00 MiB\n",
            "llama_new_context_with_model:  CUDA_Host  output buffer size =     0.12 MiB\n",
            "llama_new_context_with_model:      CUDA0 compute buffer size =   560.00 MiB\n",
            "llama_new_context_with_model:  CUDA_Host compute buffer size =    24.01 MiB\n",
            "llama_new_context_with_model: graph nodes  = 1030\n",
            "llama_new_context_with_model: graph splits = 4\n",
            "AVX = 1 | AVX_VNNI = 0 | AVX2 = 1 | AVX512 = 1 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | MATMUL_INT8 = 0 | LLAMAFILE = 1 | \n",
            "Model metadata: {'tokenizer.chat_template': \"{{ bos_token }}{% for message in messages %}{% if (message['role'] == 'user') != (loop.index0 % 2 == 0) %}{{ raise_exception('Conversation roles must alternate user/assistant/user/assistant/...') }}{% endif %}{% if message['role'] == 'user' %}{{ '[INST] ' + message['content'] + ' [/INST]' }}{% elif message['role'] == 'assistant' %}{{ message['content'] + eos_token}}{% else %}{{ raise_exception('Only user and assistant roles are supported!') }}{% endif %}{% endfor %}\", 'tokenizer.ggml.add_eos_token': 'false', 'tokenizer.ggml.padding_token_id': '0', 'tokenizer.ggml.unknown_token_id': '0', 'tokenizer.ggml.eos_token_id': '2', 'general.architecture': 'llama', 'llama.rope.freq_base': '1000000.000000', 'llama.context_length': '32768', 'general.name': 'mistralai_mistral-7b-instruct-v0.2', 'tokenizer.ggml.add_bos_token': 'true', 'llama.embedding_length': '4096', 'llama.feed_forward_length': '14336', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'llama.rope.dimension_count': '128', 'tokenizer.ggml.bos_token_id': '1', 'llama.attention.head_count': '32', 'llama.block_count': '32', 'llama.attention.head_count_kv': '8', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'llama', 'general.file_type': '18'}\n",
            "Guessed chat format: mistral-instruct\n"
          ]
        }
      ],
      "source": [
        "from huggingface_hub import hf_hub_download\n",
        "\n",
        "model_name_or_path = \"TheBloke/Mistral-7B-Instruct-v0.2-GGUF\"\n",
        "model_basename = \"mistral-7b-instruct-v0.2.Q6_K.gguf\"\n",
        "\n",
        "model_path = hf_hub_download(repo_id=model_name_or_path, filename=model_basename)\n",
        "\n",
        "# This config has been tested on an RTX 3080 (VRAM of 16GB).\n",
        "# you might need to tweak with respect to your hardware.\n",
        "from llama_cpp import Llama\n",
        "lcpp_llm = Llama(\n",
        "    model_path=model_path,\n",
        "    n_threads=4, #16, # CPU cores\n",
        "    n_batch=800, #8000, # Should be between 1 and n_ctx, consider the amount of VRAM in your GPU.\n",
        "    n_gpu_layers=32, # Change this value based on your model and your GPU VRAM pool.\n",
        "    n_ctx=8192, # Context window\n",
        "    logits_all=True\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download the dataset for the three subtasks."
      ],
      "metadata": {
        "id": "jeXgLOpd4ztp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Subtask 1.\n",
        "!wget 'https://raw.githubusercontent.com/marco-siino/EXIST2024/main/dataset/EXIST2023_test_clean.json'\n",
        "!wget 'https://raw.githubusercontent.com/marco-siino/EXIST2024/main/dataset/EXIST2024_training.json'\n",
        "!wget 'https://raw.githubusercontent.com/marco-siino/EXIST2024/main/dataset/EXIST2024_training_task1_gold_hard.json'\n",
        "\n",
        "\n",
        "train_path = 'EXIST2024_training.json'\n",
        "train_gold_path = 'EXIST2024_training_task1_gold_hard.json'\n",
        "test_path = 'EXIST2023_test_clean.json'"
      ],
      "metadata": {
        "id": "fKaC_tQ-2xbI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ec4e285-3568-4b6e-eb61-42327b44c6fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-05-09 13:46:46--  https://raw.githubusercontent.com/marco-siino/EXIST2024/main/dataset/EXIST2023_test_clean.json\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2143912 (2.0M) [text/plain]\n",
            "Saving to: ‘EXIST2023_test_clean.json’\n",
            "\n",
            "EXIST2023_test_clea 100%[===================>]   2.04M  --.-KB/s    in 0.008s  \n",
            "\n",
            "2024-05-09 13:46:47 (245 MB/s) - ‘EXIST2023_test_clean.json’ saved [2143912/2143912]\n",
            "\n",
            "--2024-05-09 13:46:47--  https://raw.githubusercontent.com/marco-siino/EXIST2024/main/dataset/EXIST2024_training.json\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 9397366 (9.0M) [text/plain]\n",
            "Saving to: ‘EXIST2024_training.json’\n",
            "\n",
            "EXIST2024_training. 100%[===================>]   8.96M  --.-KB/s    in 0.03s   \n",
            "\n",
            "2024-05-09 13:46:48 (319 MB/s) - ‘EXIST2024_training.json’ saved [9397366/9397366]\n",
            "\n",
            "--2024-05-09 13:46:48--  https://raw.githubusercontent.com/marco-siino/EXIST2024/main/dataset/EXIST2024_training_task1_gold_hard.json\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 433241 (423K) [text/plain]\n",
            "Saving to: ‘EXIST2024_training_task1_gold_hard.json’\n",
            "\n",
            "EXIST2024_training_ 100%[===================>] 423.09K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2024-05-09 13:46:48 (79.0 MB/s) - ‘EXIST2024_training_task1_gold_hard.json’ saved [433241/433241]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create few-shot samples from training set."
      ],
      "metadata": {
        "id": "fHPX3E0PCJ9q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " prompt_context = \"[INST] Is the following TWEET sexist, in any form, or does it describe situations in which such discrimination occurs (i.e., it is sexist itself, describes a sexist situation or criticizes a sexist behaviour)? Reply only with YES or NO.\\n\"\n"
      ],
      "metadata": {
        "id": "zafRW5vU6y1n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(train_path, 'r') as istr:\n",
        "    train_1_json = json.load(istr)\n",
        "  #print(train_1_json[0])\n",
        "\n",
        "# Convert the dictionary keys into a list\n",
        "keys_list = list(train_1_json.keys())\n",
        "\n",
        "# Shuffle the list\n",
        "random.shuffle(keys_list)\n",
        "\n",
        "# Create a new dictionary with shuffled keys\n",
        "train_1_json = {key: train_1_json[key] for key in keys_list}"
      ],
      "metadata": {
        "id": "lsmWAy7VoXuP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_few_shot_samples_run1(train_1_json,nr_samples):\n",
        "\n",
        "  nr_few_shot_samples = nr_samples\n",
        "\n",
        "  few_shot_counter = 0\n",
        "\n",
        "  few_shot_samples = ''\n",
        "\n",
        "  with open(train_gold_path, 'r') as istr:\n",
        "    train_gold_json = json.load(istr)\n",
        "  indexed_data = {entry[\"id\"]: entry for entry in train_gold_json}\n",
        "\n",
        "  for key, value in train_1_json.items():\n",
        "\n",
        "    if few_shot_counter == nr_few_shot_samples:\n",
        "      break\n",
        "    try:\n",
        "      label = indexed_data[key]['value']\n",
        "    except:\n",
        "      continue\n",
        "\n",
        "    few_shot_counter+=1\n",
        "    tweet = train_1_json[key]['tweet']\n",
        "    print(train_1_json[key]['tweet'] + ' // ' + label)\n",
        "    if train_1_json[key]['lang']=='es':\n",
        "      tweet = GoogleTranslator(source='es', target='en').translate(train_1_json[key]['tweet'])\n",
        "\n",
        "    few_shot_samples += '<s>'+prompt_context+\"TWEET:\"+tweet + ' [/INST] \\n ' + label + \"\\n</s> \\n\\n \"\n",
        "\n",
        "    if few_shot_counter == nr_few_shot_samples:\n",
        "        break\n",
        "\n",
        "  return few_shot_samples"
      ],
      "metadata": {
        "id": "99ag8gav51mC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_few_shot_samples_run2(train_1_json,nr_samples):\n",
        "\n",
        "  nr_few_shot_samples = nr_samples\n",
        "\n",
        "  few_shot_counter = 0\n",
        "\n",
        "  few_shot_samples = ''\n",
        "\n",
        "  with open(train_gold_path, 'r') as istr:\n",
        "    train_gold_json = json.load(istr)\n",
        "  indexed_data = {entry[\"id\"]: entry for entry in train_gold_json}\n",
        "  #print(indexed_data['100001'])\n",
        "\n",
        "  for key, value in train_1_json.items():\n",
        "\n",
        "    if few_shot_counter == nr_few_shot_samples:\n",
        "      break\n",
        "    try:\n",
        "      label = indexed_data[key]['value']\n",
        "    except:\n",
        "      continue\n",
        "\n",
        "    few_shot_counter+=1\n",
        "    tweet = train_1_json[key]['tweet']\n",
        "    print(train_1_json[key]['tweet'] + ' // ' + label)\n",
        "    if train_1_json[key]['lang']=='es':\n",
        "      tweet = GoogleTranslator(source='es', target='en').translate(train_1_json[key]['tweet'])\n",
        "\n",
        "    few_shot_samples += prompt_context+\"TWEET:\"+tweet + ' [/INST] \\n ' + label + \"\\n \\n\\n \"\n",
        "\n",
        "    if few_shot_counter == nr_few_shot_samples:\n",
        "        break\n",
        "\n",
        "  return few_shot_samples"
      ],
      "metadata": {
        "id": "oNuu3aAhZxYA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "few_shot_samples_run1 = create_few_shot_samples_run1(train_1_json,10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o8IaDH-7GmrN",
        "outputId": "bf0507a9-efff-44f6-c781-851d706a6692"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "@JackelineWB @JohnMAckerman @lopezobrador_ tu eres el absurdo, o sea Loret si tiene derecho de violar la privacidad de personas civiles?? // NO\n",
            "Yo me pregunto si que haya fortunas genera acaso un techo de cristal o algo por el estilo. Cada vez hay más ricos, y a quien le moleste lo heredado, que analice si padece de envidia. https://t.co/oesBZ03sdh // NO\n",
            "No te vistas así*No uses minifalta*No se saques selfie*No salgas sola* Parecés una puta*Vos lo habrás mirado*Estás provocandoAh ! y que deprimente lo de Fablet. El señor que nos dice qué tenemos que hacer para que no nos violen. // YES\n",
            "@Russtophocles1 Girls don’t count as reply guys , call me sexist but I always love compliments from da gals. Even if they are horny posting😂😂 but if you’re mean I will cry // YES\n",
            "Siempre he pensado esto de todos los abogados ... Jajaja Bueno mi cuñado NO es así, me sorprende porque es el estereotipo perfecto! Costeño, ebrio y abogado https://t.co/YH6AjDlElH // NO\n",
            "Es algo relacionado con la identidad de género y la expresión de género. Me gusta skk seguros de su identidad como chicos pero amando usar vestidos, solo que para llegar a esa parte tienen que pasar por problemas de descubrimiento, y es aquí donde Chuuya ayuda a Dazai 🤍. // NO\n",
            "You want to be a strong and empowered woman? Then grow a spine strong enough to look at your own sins and shortcomings square in the eye and be willing to face them head on. Only weak women blame men for everything. // YES\n",
            "Maldito amor romantico me dañaste sapoperro gonorrea // NO\n",
            "@ArcEng9154644 @pnjaban @MrAndyNgo @alankesslr @Claudio_Report To see these antifa people work so hard to destroy what they use and need would be amusing, but their beliefs and antics cause too much damage to the rest of society for me to consider them just clueless clowns. // NO\n",
            "🌵 El cine y las palomitas: un matrimonio forzado con final feliz... https://t.co/jf50mSjhwI // NO\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "few_shot_samples_run2 = create_few_shot_samples_run2(train_1_json,10)"
      ],
      "metadata": {
        "id": "fdVNwQQhaMlH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d59c76cb-8e57-4bec-a783-c5a601eec866"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "@JackelineWB @JohnMAckerman @lopezobrador_ tu eres el absurdo, o sea Loret si tiene derecho de violar la privacidad de personas civiles?? // NO\n",
            "Yo me pregunto si que haya fortunas genera acaso un techo de cristal o algo por el estilo. Cada vez hay más ricos, y a quien le moleste lo heredado, que analice si padece de envidia. https://t.co/oesBZ03sdh // NO\n",
            "No te vistas así*No uses minifalta*No se saques selfie*No salgas sola* Parecés una puta*Vos lo habrás mirado*Estás provocandoAh ! y que deprimente lo de Fablet. El señor que nos dice qué tenemos que hacer para que no nos violen. // YES\n",
            "@Russtophocles1 Girls don’t count as reply guys , call me sexist but I always love compliments from da gals. Even if they are horny posting😂😂 but if you’re mean I will cry // YES\n",
            "Siempre he pensado esto de todos los abogados ... Jajaja Bueno mi cuñado NO es así, me sorprende porque es el estereotipo perfecto! Costeño, ebrio y abogado https://t.co/YH6AjDlElH // NO\n",
            "Es algo relacionado con la identidad de género y la expresión de género. Me gusta skk seguros de su identidad como chicos pero amando usar vestidos, solo que para llegar a esa parte tienen que pasar por problemas de descubrimiento, y es aquí donde Chuuya ayuda a Dazai 🤍. // NO\n",
            "You want to be a strong and empowered woman? Then grow a spine strong enough to look at your own sins and shortcomings square in the eye and be willing to face them head on. Only weak women blame men for everything. // YES\n",
            "Maldito amor romantico me dañaste sapoperro gonorrea // NO\n",
            "@ArcEng9154644 @pnjaban @MrAndyNgo @alankesslr @Claudio_Report To see these antifa people work so hard to destroy what they use and need would be amusing, but their beliefs and antics cause too much damage to the rest of society for me to consider them just clueless clowns. // NO\n",
            "🌵 El cine y las palomitas: un matrimonio forzado con final feliz... https://t.co/jf50mSjhwI // NO\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(few_shot_samples_run1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6WHgxqxAxcu1",
        "outputId": "ef9d702a-67ea-4a08-b89f-dc0c46d34f26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s>[INST] Is the following TWEET sexist, in any form, or does it describe situations in which such discrimination occurs (i.e., it is sexist itself, describes a sexist situation or criticizes a sexist behaviour)? Reply only with YES or NO.\n",
            "TWEET:@JackelineWB @JohnMAckerman @lopezobrador_ you are absurd, that is, Loret has the right to violate the privacy of civilians?? [/INST] \n",
            " NO\n",
            "</s> \n",
            "\n",
            " <s>[INST] Is the following TWEET sexist, in any form, or does it describe situations in which such discrimination occurs (i.e., it is sexist itself, describes a sexist situation or criticizes a sexist behaviour)? Reply only with YES or NO.\n",
            "TWEET:I wonder if the fact that there are fortunes generates a glass ceiling or something like that. There are more and more rich people, and anyone who is bothered by what they inherited should analyze whether they suffer from envy. https://t.co/oesBZ03sdh [/INST] \n",
            " NO\n",
            "</s> \n",
            "\n",
            " <s>[INST] Is the following TWEET sexist, in any form, or does it describe situations in which such discrimination occurs (i.e., it is sexist itself, describes a sexist situation or criticizes a sexist behaviour)? Reply only with YES or NO.\n",
            "TWEET:Don't dress like that*Don't wear a mini skirt*Don't take a selfie*Don't go out alone* You look like a whore*You must have seen it*You're provokingAh! and how depressing about Fablet. The man who tells us what we have to do so that they do not rape us. [/INST] \n",
            " YES\n",
            "</s> \n",
            "\n",
            " <s>[INST] Is the following TWEET sexist, in any form, or does it describe situations in which such discrimination occurs (i.e., it is sexist itself, describes a sexist situation or criticizes a sexist behaviour)? Reply only with YES or NO.\n",
            "TWEET:@Russtophocles1 Girls don’t count as reply guys , call me sexist but I always love compliments from da gals. Even if they are horny posting😂😂 but if you’re mean I will cry [/INST] \n",
            " YES\n",
            "</s> \n",
            "\n",
            " <s>[INST] Is the following TWEET sexist, in any form, or does it describe situations in which such discrimination occurs (i.e., it is sexist itself, describes a sexist situation or criticizes a sexist behaviour)? Reply only with YES or NO.\n",
            "TWEET:I have always thought this about all lawyers... Hahaha Well my brother-in-law is NOT like that, it surprises me because he is the perfect stereotype! Costeño, drunk and lawyer https://t.co/YH6AjDlElH [/INST] \n",
            " NO\n",
            "</s> \n",
            "\n",
            " <s>[INST] Is the following TWEET sexist, in any form, or does it describe situations in which such discrimination occurs (i.e., it is sexist itself, describes a sexist situation or criticizes a sexist behaviour)? Reply only with YES or NO.\n",
            "TWEET:It's something related to gender identity and gender expression. I like skk sure of their identity as boys but loving to wear dresses, only to get to that part they have to go through discovery problems, and this is where Chuuya helps Dazai 🤍. [/INST] \n",
            " NO\n",
            "</s> \n",
            "\n",
            " <s>[INST] Is the following TWEET sexist, in any form, or does it describe situations in which such discrimination occurs (i.e., it is sexist itself, describes a sexist situation or criticizes a sexist behaviour)? Reply only with YES or NO.\n",
            "TWEET:You want to be a strong and empowered woman? Then grow a spine strong enough to look at your own sins and shortcomings square in the eye and be willing to face them head on. Only weak women blame men for everything. [/INST] \n",
            " YES\n",
            "</s> \n",
            "\n",
            " <s>[INST] Is the following TWEET sexist, in any form, or does it describe situations in which such discrimination occurs (i.e., it is sexist itself, describes a sexist situation or criticizes a sexist behaviour)? Reply only with YES or NO.\n",
            "TWEET:Damn romantic love, you hurt me toadstool gonorrhea [/INST] \n",
            " NO\n",
            "</s> \n",
            "\n",
            " <s>[INST] Is the following TWEET sexist, in any form, or does it describe situations in which such discrimination occurs (i.e., it is sexist itself, describes a sexist situation or criticizes a sexist behaviour)? Reply only with YES or NO.\n",
            "TWEET:@ArcEng9154644 @pnjaban @MrAndyNgo @alankesslr @Claudio_Report To see these antifa people work so hard to destroy what they use and need would be amusing, but their beliefs and antics cause too much damage to the rest of society for me to consider them just clueless clowns. [/INST] \n",
            " NO\n",
            "</s> \n",
            "\n",
            " <s>[INST] Is the following TWEET sexist, in any form, or does it describe situations in which such discrimination occurs (i.e., it is sexist itself, describes a sexist situation or criticizes a sexist behaviour)? Reply only with YES or NO.\n",
            "TWEET:🌵 Cinema and popcorn: a forced marriage with a happy ending... https://t.co/jf50mSjhwI [/INST] \n",
            " NO\n",
            "</s> \n",
            "\n",
            " \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(few_shot_samples_run2)"
      ],
      "metadata": {
        "id": "HSfwZXX5aXSE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad646b4f-5b68-411a-c34c-0d5016793af9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INST] Is the following TWEET sexist, in any form, or does it describe situations in which such discrimination occurs (i.e., it is sexist itself, describes a sexist situation or criticizes a sexist behaviour)? Reply only with YES or NO.\n",
            "TWEET:@JackelineWB @JohnMAckerman @lopezobrador_ you are absurd, that is, Loret has the right to violate the privacy of civilians?? [/INST] \n",
            " NO\n",
            " \n",
            "\n",
            " [INST] Is the following TWEET sexist, in any form, or does it describe situations in which such discrimination occurs (i.e., it is sexist itself, describes a sexist situation or criticizes a sexist behaviour)? Reply only with YES or NO.\n",
            "TWEET:I wonder if the fact that there are fortunes generates a glass ceiling or something like that. There are more and more rich people, and anyone who is bothered by what they inherited should analyze whether they suffer from envy. https://t.co/oesBZ03sdh [/INST] \n",
            " NO\n",
            " \n",
            "\n",
            " [INST] Is the following TWEET sexist, in any form, or does it describe situations in which such discrimination occurs (i.e., it is sexist itself, describes a sexist situation or criticizes a sexist behaviour)? Reply only with YES or NO.\n",
            "TWEET:Don't dress like that*Don't wear a mini skirt*Don't take a selfie*Don't go out alone* You look like a whore*You must have seen it*You're provokingAh! and how depressing about Fablet. The man who tells us what we have to do so that they do not rape us. [/INST] \n",
            " YES\n",
            " \n",
            "\n",
            " [INST] Is the following TWEET sexist, in any form, or does it describe situations in which such discrimination occurs (i.e., it is sexist itself, describes a sexist situation or criticizes a sexist behaviour)? Reply only with YES or NO.\n",
            "TWEET:@Russtophocles1 Girls don’t count as reply guys , call me sexist but I always love compliments from da gals. Even if they are horny posting😂😂 but if you’re mean I will cry [/INST] \n",
            " YES\n",
            " \n",
            "\n",
            " [INST] Is the following TWEET sexist, in any form, or does it describe situations in which such discrimination occurs (i.e., it is sexist itself, describes a sexist situation or criticizes a sexist behaviour)? Reply only with YES or NO.\n",
            "TWEET:I have always thought this about all lawyers... Hahaha Well my brother-in-law is NOT like that, it surprises me because he is the perfect stereotype! Costeño, drunk and lawyer https://t.co/YH6AjDlElH [/INST] \n",
            " NO\n",
            " \n",
            "\n",
            " [INST] Is the following TWEET sexist, in any form, or does it describe situations in which such discrimination occurs (i.e., it is sexist itself, describes a sexist situation or criticizes a sexist behaviour)? Reply only with YES or NO.\n",
            "TWEET:It's something related to gender identity and gender expression. I like skk sure of their identity as boys but loving to wear dresses, only to get to that part they have to go through discovery problems, and this is where Chuuya helps Dazai 🤍. [/INST] \n",
            " NO\n",
            " \n",
            "\n",
            " [INST] Is the following TWEET sexist, in any form, or does it describe situations in which such discrimination occurs (i.e., it is sexist itself, describes a sexist situation or criticizes a sexist behaviour)? Reply only with YES or NO.\n",
            "TWEET:You want to be a strong and empowered woman? Then grow a spine strong enough to look at your own sins and shortcomings square in the eye and be willing to face them head on. Only weak women blame men for everything. [/INST] \n",
            " YES\n",
            " \n",
            "\n",
            " [INST] Is the following TWEET sexist, in any form, or does it describe situations in which such discrimination occurs (i.e., it is sexist itself, describes a sexist situation or criticizes a sexist behaviour)? Reply only with YES or NO.\n",
            "TWEET:Damn romantic love, you hurt me toadstool gonorrhea [/INST] \n",
            " NO\n",
            " \n",
            "\n",
            " [INST] Is the following TWEET sexist, in any form, or does it describe situations in which such discrimination occurs (i.e., it is sexist itself, describes a sexist situation or criticizes a sexist behaviour)? Reply only with YES or NO.\n",
            "TWEET:@ArcEng9154644 @pnjaban @MrAndyNgo @alankesslr @Claudio_Report To see these antifa people work so hard to destroy what they use and need would be amusing, but their beliefs and antics cause too much damage to the rest of society for me to consider them just clueless clowns. [/INST] \n",
            " NO\n",
            " \n",
            "\n",
            " [INST] Is the following TWEET sexist, in any form, or does it describe situations in which such discrimination occurs (i.e., it is sexist itself, describes a sexist situation or criticizes a sexist behaviour)? Reply only with YES or NO.\n",
            "TWEET:🌵 Cinema and popcorn: a forced marriage with a happy ending... https://t.co/jf50mSjhwI [/INST] \n",
            " NO\n",
            " \n",
            "\n",
            " \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run!"
      ],
      "metadata": {
        "id": "r6Cqo0JqotN9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UKo1-X5OvT4b",
        "outputId": "e522815f-4735-4240-a553-cb2f28e9ec77"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.31 ms /    16 runs   (    0.71 ms per token,  1415.05 tokens per second)\n",
            "llama_print_timings: prompt eval time =   43991.62 ms /    31 tokens ( 1419.08 ms per token,     0.70 tokens per second)\n",
            "llama_print_timings:        eval time =    1781.28 ms /    15 runs   (  118.75 ms per token,     8.42 tokens per second)\n",
            "llama_print_timings:       total time =    2919.85 ms /    46 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Eurogamer_es All gamergate from development to game forums, classic in the world of video games.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.94 ms /    16 runs   (    0.56 ms per token,  1789.51 tokens per second)\n",
            "llama_print_timings: prompt eval time =     522.03 ms /    32 tokens (   16.31 ms per token,    61.30 tokens per second)\n",
            "llama_print_timings:        eval time =    1484.48 ms /    15 runs   (   98.97 ms per token,    10.10 tokens per second)\n",
            "llama_print_timings:       total time =    2144.45 ms /    47 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@ArCaNgEl__23 @Benzenazi Man, it's not comparable, look at Gamergate.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.12 ms /    16 runs   (    0.57 ms per token,  1754.19 tokens per second)\n",
            "llama_print_timings: prompt eval time =     537.64 ms /    24 tokens (   22.40 ms per token,    44.64 tokens per second)\n",
            "llama_print_timings:        eval time =    1515.20 ms /    15 runs   (  101.01 ms per token,     9.90 tokens per second)\n",
            "llama_print_timings:       total time =    2172.92 ms /    39 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "I'm looking for companies involved in gamergate for etc etc to buy all their products\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.50 ms /    16 runs   (    0.59 ms per token,  1685.10 tokens per second)\n",
            "llama_print_timings: prompt eval time =     263.12 ms /    75 tokens (    3.51 ms per token,   285.05 tokens per second)\n",
            "llama_print_timings:        eval time =    1477.56 ms /    15 runs   (   98.50 ms per token,    10.15 tokens per second)\n",
            "llama_print_timings:       total time =    2022.20 ms /    90 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@jordirico First it was the internet, then the gamergate, the manosphere and its extreme misogyny without the platforms lifting a finger, the incel-murders, the extreme right capitalizing on hate, the mimicry of these ideas with those of a respectable debate and finally here we are\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.48 ms /    16 runs   (    0.72 ms per token,  1393.97 tokens per second)\n",
            "llama_print_timings: prompt eval time =     745.91 ms /    28 tokens (   26.64 ms per token,    37.54 tokens per second)\n",
            "llama_print_timings:        eval time =    1878.44 ms /    15 runs   (  125.23 ms per token,     7.99 tokens per second)\n",
            "llama_print_timings:       total time =    2852.18 ms /    43 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@AlonsoQuijano12 I was involved in gamergate, so unfortunately I know too much 😭\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.64 ms /    16 runs   (    0.54 ms per token,  1852.07 tokens per second)\n",
            "llama_print_timings: prompt eval time =     725.38 ms /    29 tokens (   25.01 ms per token,    39.98 tokens per second)\n",
            "llama_print_timings:        eval time =    1492.63 ms /    15 runs   (   99.51 ms per token,    10.05 tokens per second)\n",
            "llama_print_timings:       total time =    2360.49 ms /    44 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@MrSandman1954 @AKN4710 Gamergate screwed the internet forever.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.18 ms /    16 runs   (    0.57 ms per token,  1742.92 tokens per second)\n",
            "llama_print_timings: prompt eval time =     271.37 ms /   102 tokens (    2.66 ms per token,   375.87 tokens per second)\n",
            "llama_print_timings:        eval time =    1528.22 ms /    15 runs   (  101.88 ms per token,     9.82 tokens per second)\n",
            "llama_print_timings:       total time =    2137.94 ms /   117 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@grupoeldeber @grupoeldeber It would be good if they also said that it was in CANADA🇨🇦 the first country where it was reported that G∆y couples who adopted children abused them in 2008. How selective are they with the crap they publish, right? https://t.co/GPAmLOfcY9 https://t.co/f36aAmxq35\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.51 ms /    16 runs   (    0.66 ms per token,  1522.50 tokens per second)\n",
            "llama_print_timings: prompt eval time =     256.40 ms /    40 tokens (    6.41 ms per token,   156.01 tokens per second)\n",
            "llama_print_timings:        eval time =    1669.54 ms /    15 runs   (  111.30 ms per token,     8.98 tokens per second)\n",
            "llama_print_timings:       total time =    2100.23 ms /    55 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "They, very close together and more alone than ever. The consequences of everything. Mozambique. https://t.co/5nVGTb3Ua3\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.94 ms /    16 runs   (    0.56 ms per token,  1790.71 tokens per second)\n",
            "llama_print_timings: prompt eval time =     518.24 ms /    32 tokens (   16.19 ms per token,    61.75 tokens per second)\n",
            "llama_print_timings:        eval time =    1478.20 ms /    15 runs   (   98.55 ms per token,    10.15 tokens per second)\n",
            "llama_print_timings:       total time =    2137.94 ms /    47 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "DC Children's Hospital Harassed Over Trans Youth Serviceshttps://t.co/RrEtZ5TDDM\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.27 ms /    16 runs   (    0.58 ms per token,  1726.00 tokens per second)\n",
            "llama_print_timings: prompt eval time =     236.29 ms /    45 tokens (    5.25 ms per token,   190.44 tokens per second)\n",
            "llama_print_timings:        eval time =    1473.25 ms /    15 runs   (   98.22 ms per token,    10.18 tokens per second)\n",
            "llama_print_timings:       total time =    1881.19 ms /    60 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "20mins deep into BeReal and I have never felt so pressured to take my phone nope I don't want to feel harassed I say goodbye 🫡\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.01 ms /    16 runs   (    0.63 ms per token,  1598.40 tokens per second)\n",
            "llama_print_timings: prompt eval time =     240.02 ms /    61 tokens (    3.93 ms per token,   254.14 tokens per second)\n",
            "llama_print_timings:        eval time =    1537.04 ms /    15 runs   (  102.47 ms per token,     9.76 tokens per second)\n",
            "llama_print_timings:       total time =    1994.20 ms /    76 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Anthony Fauci, the leading US infectious disease expert, noted in August 2022 that he had received death threats and that his family was routinely exposed to harassment. https://t.co/EerbO2Px5j\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.23 ms /    16 runs   (    0.64 ms per token,  1564.33 tokens per second)\n",
            "llama_print_timings: prompt eval time =     636.59 ms /    28 tokens (   22.74 ms per token,    43.98 tokens per second)\n",
            "llama_print_timings:        eval time =    1699.15 ms /    15 runs   (  113.28 ms per token,     8.83 tokens per second)\n",
            "llama_print_timings:       total time =    2494.10 ms /    43 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@dimplerrylover I know but literally the girl was being harassed like how can she smile like that\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      14.67 ms /    16 runs   (    0.92 ms per token,  1090.59 tokens per second)\n",
            "llama_print_timings: prompt eval time =     330.59 ms /    85 tokens (    3.89 ms per token,   257.12 tokens per second)\n",
            "llama_print_timings:        eval time =    1720.85 ms /    15 runs   (  114.72 ms per token,     8.72 tokens per second)\n",
            "llama_print_timings:       total time =    2362.82 ms /   100 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@marcela_ruge @_Lamanada_ @Mitocondria1311 @karinin7986 @julibmoya @MissPoirot07 @Adrianaruiz17 @DiaAnimales @marcevalenciar @MONYRODRIGUEZOF Marce do you have daviplata?\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.54 ms /    16 runs   (    0.60 ms per token,  1676.62 tokens per second)\n",
            "llama_print_timings: prompt eval time =     248.08 ms /    64 tokens (    3.88 ms per token,   257.98 tokens per second)\n",
            "llama_print_timings:        eval time =    1507.13 ms /    15 runs   (  100.48 ms per token,     9.95 tokens per second)\n",
            "llama_print_timings:       total time =    1985.24 ms /    79 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "About to see the grand premiere of #Jauría based on the case of #LaManada @anasofihg @RobertoBeck90 @elteatrocdmx #teatromexicano https://t.co/N5Uke18ikQ\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.23 ms /    16 runs   (    0.64 ms per token,  1564.33 tokens per second)\n",
            "llama_print_timings: prompt eval time =     255.93 ms /    64 tokens (    4.00 ms per token,   250.07 tokens per second)\n",
            "llama_print_timings:        eval time =    1470.43 ms /    15 runs   (   98.03 ms per token,    10.20 tokens per second)\n",
            "llama_print_timings:       total time =    1955.22 ms /    79 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "What a bastard our uncle Pablo is with his little jokes. How comfortable we are on the cool grass... mybestfriends #doglove #theyneverabandon #lodaneverythingchangedenada https://t.co/4x20oe7V8D\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.62 ms /    16 runs   (    0.73 ms per token,  1376.34 tokens per second)\n",
            "llama_print_timings: prompt eval time =     266.03 ms /    75 tokens (    3.55 ms per token,   281.92 tokens per second)\n",
            "llama_print_timings:        eval time =    1846.07 ms /    15 runs   (  123.07 ms per token,     8.13 tokens per second)\n",
            "llama_print_timings:       total time =    2402.28 ms /    90 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@noebermudez_13 @ldacr And we are already looking forward to filling the stands with you everywhere again!!! @LaManada_CR And now distribute balls left and right except to those who gather balls 🥺🤣🤣🤣🤣#VAMOSLEONAS #SOMOSLAMANADA\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.28 ms /    16 runs   (    0.58 ms per token,  1725.07 tokens per second)\n",
            "llama_print_timings: prompt eval time =     306.34 ms /   116 tokens (    2.64 ms per token,   378.67 tokens per second)\n",
            "llama_print_timings:        eval time =    1586.29 ms /    15 runs   (  105.75 ms per token,     9.46 tokens per second)\n",
            "llama_print_timings:       total time =    2264.95 ms /   131 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "#TBT: María Rosa, Gregorio Polanco and Ysabel Verás, back in October 2016, during one of the Kermés held for the team's fundraising. The Pack is tradition, family, unity and joy!🥎🐺🥎🐺#TBT #Auuuuu#LaManada#LobosFansClub#LobosSoftbolClub https://t.co/LwSL4npanZ\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.79 ms /    16 runs   (    0.55 ms per token,  1820.66 tokens per second)\n",
            "llama_print_timings: prompt eval time =     388.22 ms /   129 tokens (    3.01 ms per token,   332.29 tokens per second)\n",
            "llama_print_timings:        eval time =    1546.21 ms /    15 runs   (  103.08 ms per token,     9.70 tokens per second)\n",
            "llama_print_timings:       total time =    2338.96 ms /   144 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "AUGUST 9 Find out everything! 🎙 You can watch the entire segment of 'El Bla, Bla, Bla' with HÉCTOR JOAQUÍN in the #Podcasts section of the LaMusica app. 📲#HectorJoaquin #LaManada #ElBlaBlaBla #LaMusica @la_musica @zeta93fm https://t.co/ZDZM4Qs1zx https://t.co/zqMjKMgN4r\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.90 ms /    16 runs   (    0.62 ms per token,  1616.32 tokens per second)\n",
            "llama_print_timings: prompt eval time =     278.74 ms /    88 tokens (    3.17 ms per token,   315.71 tokens per second)\n",
            "llama_print_timings:        eval time =    1564.55 ms /    15 runs   (  104.30 ms per token,     9.59 tokens per second)\n",
            "llama_print_timings:       total time =    2130.29 ms /   103 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Fistroman1 @ElioGatsby Without proof?? What was it in public? What did we all see, what are you telling me? Don't mix churras with merinas. What from now until you come to me with the metoo and the notallmen there is little left and I don't feel like it end up really arguing, I see it coming.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.06 ms /    16 runs   (    0.63 ms per token,  1590.93 tokens per second)\n",
            "llama_print_timings: prompt eval time =     276.48 ms /    83 tokens (    3.33 ms per token,   300.21 tokens per second)\n",
            "llama_print_timings:        eval time =    1570.84 ms /    15 runs   (  104.72 ms per token,     9.55 tokens per second)\n",
            "llama_print_timings:       total time =    2125.13 ms /    98 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@EstefaniaVeloz ...With the legal process, not to set a person on fire (I don't even know who they are in this case). There are women who are victims but there are also corrupt, violent and victimizers. The #MeToo movement has already fulfilled its mission. What's next? How to advance without it being a weapon of whim?\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.26 ms /    16 runs   (    0.64 ms per token,  1560.06 tokens per second)\n",
            "llama_print_timings: prompt eval time =     299.01 ms /    97 tokens (    3.08 ms per token,   324.40 tokens per second)\n",
            "llama_print_timings:        eval time =    1464.31 ms /    15 runs   (   97.62 ms per token,    10.24 tokens per second)\n",
            "llama_print_timings:       total time =    2077.06 ms /   112 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@robertoantoniow @JessicaLBedoya Both of you are fired, because you are adults and it is a consensual and transactional relationship. Let them not invent a \"MeToo\" later, because it is not. A couple of thieves and liars. They even had people fired for the investigation. I well remember the level of power with which that UGLY footprint came 🤮\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.43 ms /    16 runs   (    0.65 ms per token,  1534.18 tokens per second)\n",
            "llama_print_timings: prompt eval time =     275.32 ms /    88 tokens (    3.13 ms per token,   319.63 tokens per second)\n",
            "llama_print_timings:        eval time =    1699.98 ms /    15 runs   (  113.33 ms per token,     8.82 tokens per second)\n",
            "llama_print_timings:       total time =    2287.58 ms /   103 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@geeksterilia From the Olivia who is climbing on bricks for being a director. The video of the call to Shia is like that, all condescending to MY weakness. For this, according to her, she asked Shia to get out of her hair because well, I mean, And then nothing. The girl pretending https://t.co/t9zCKx1IDs\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.38 ms /    16 runs   (    0.59 ms per token,  1705.58 tokens per second)\n",
            "llama_print_timings: prompt eval time =     706.46 ms /    23 tokens (   30.72 ms per token,    32.56 tokens per second)\n",
            "llama_print_timings:        eval time =    1469.57 ms /    15 runs   (   97.97 ms per token,    10.21 tokens per second)\n",
            "llama_print_timings:       total time =    2327.89 ms /    38 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@jaurxm If you want, tell me some and I'll put them in\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.16 ms /    16 runs   (    0.57 ms per token,  1746.53 tokens per second)\n",
            "llama_print_timings: prompt eval time =     233.31 ms /    40 tokens (    5.83 ms per token,   171.44 tokens per second)\n",
            "llama_print_timings:        eval time =    1536.58 ms /    15 runs   (  102.44 ms per token,     9.76 tokens per second)\n",
            "llama_print_timings:       total time =    1931.73 ms /    55 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Aracely54051891 We started another #Metoo movement like you... it wouldn't work, it's only from man to woman\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.04 ms /    16 runs   (    0.57 ms per token,  1769.91 tokens per second)\n",
            "llama_print_timings: prompt eval time =     598.90 ms /    23 tokens (   26.04 ms per token,    38.40 tokens per second)\n",
            "llama_print_timings:        eval time =    1473.50 ms /    15 runs   (   98.23 ms per token,    10.18 tokens per second)\n",
            "llama_print_timings:       total time =    2186.76 ms /    38 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@SherryWimbleton mgtow people and masculinism should not be compatible\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.65 ms /    16 runs   (    0.60 ms per token,  1657.17 tokens per second)\n",
            "llama_print_timings: prompt eval time =     232.69 ms /    37 tokens (    6.29 ms per token,   159.01 tokens per second)\n",
            "llama_print_timings:        eval time =    1604.01 ms /    15 runs   (  106.93 ms per token,     9.35 tokens per second)\n",
            "llama_print_timings:       total time =    1992.69 ms /    52 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@al_andr0 @maxveram @turttle_cathyun Maybe if you look at his account clearly in a mgtow\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.97 ms /    16 runs   (    0.62 ms per token,  1604.01 tokens per second)\n",
            "llama_print_timings: prompt eval time =     261.48 ms /    51 tokens (    5.13 ms per token,   195.04 tokens per second)\n",
            "llama_print_timings:        eval time =    1671.12 ms /    15 runs   (  111.41 ms per token,     8.98 tokens per second)\n",
            "llama_print_timings:       total time =    2233.97 ms /    66 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@RechazoChileno @MGTOW_Chilensis It is true, they were told but they did not listen, now they should ask for forgiveness and ask that we not have any more misfortunes\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.87 ms /    16 runs   (    0.62 ms per token,  1620.75 tokens per second)\n",
            "llama_print_timings: prompt eval time =     255.58 ms /    62 tokens (    4.12 ms per token,   242.59 tokens per second)\n",
            "llama_print_timings:        eval time =    1636.99 ms /    15 runs   (  109.13 ms per token,     9.16 tokens per second)\n",
            "llama_print_timings:       total time =    2104.68 ms /    77 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Sexists, misogynists, mgtow and other crowd that swarms the world, you are just like the feminazis, bitter beings loaded with bad experiences who only know how to cry and clench your little fists, don't you see it?\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.79 ms /    16 runs   (    0.61 ms per token,  1634.82 tokens per second)\n",
            "llama_print_timings: prompt eval time =     380.61 ms /   191 tokens (    1.99 ms per token,   501.82 tokens per second)\n",
            "llama_print_timings:        eval time =    1463.45 ms /    15 runs   (   97.56 ms per token,    10.25 tokens per second)\n",
            "llama_print_timings:       total time =    2422.83 ms /   206 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@ArmezHL @Incognito_archi @AntonioMiraflo1 @HellNoveno @tradhusbando @poiu2525 @mund_ola @CaraBM6T0W @Lewdowl1 @die100000 @infer_oficial @Lukas_snob_22 @terminat2_HL @marketfarid @DieJn200519 @grisasexual @MasculinismoLi1 @AliadesAllType @HellDecimoMgtow Let's see if I understand, he is not mgtow, and he has girlfriend, therefore she is not a redpiler? I don't see the punch line, nor the spice. https://t.co/mdNjGe5YKg\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.28 ms /    16 runs   (    0.70 ms per token,  1418.57 tokens per second)\n",
            "llama_print_timings: prompt eval time =     276.12 ms /    73 tokens (    3.78 ms per token,   264.38 tokens per second)\n",
            "llama_print_timings:        eval time =    1794.80 ms /    15 runs   (  119.65 ms per token,     8.36 tokens per second)\n",
            "llama_print_timings:       total time =    2506.89 ms /    88 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "I saw this image on an MGTOW profile and the comment he made didn't seem interesting to me, but the image did. What do you think of these terms? \"Love bombing\" and \"caspering\" seem stupid to me xd https://t.co/Dl04HWqDnd\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.37 ms /    16 runs   (    0.59 ms per token,  1707.76 tokens per second)\n",
            "llama_print_timings: prompt eval time =     258.00 ms /    49 tokens (    5.27 ms per token,   189.92 tokens per second)\n",
            "llama_print_timings:        eval time =    1550.42 ms /    15 runs   (  103.36 ms per token,     9.67 tokens per second)\n",
            "llama_print_timings:       total time =    1985.97 ms /    64 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "It is equally obvious that it is a microaggression that becomes a funny anecdote more than anything, but I would like to have a name for that type of experiences, because it happens a lot!!!\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.43 ms /    16 runs   (    0.59 ms per token,  1696.71 tokens per second)\n",
            "llama_print_timings: prompt eval time =     254.79 ms /    43 tokens (    5.93 ms per token,   168.77 tokens per second)\n",
            "llama_print_timings:        eval time =    1536.81 ms /    15 runs   (  102.45 ms per token,     9.76 tokens per second)\n",
            "llama_print_timings:       total time =    1954.63 ms /    58 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Oh Boy...Now #MicroAggression is attacking @NotiJuan because he exposed it in a video where you can see what he did and now he denies it.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      12.03 ms /    16 runs   (    0.75 ms per token,  1330.34 tokens per second)\n",
            "llama_print_timings: prompt eval time =     290.97 ms /    79 tokens (    3.68 ms per token,   271.50 tokens per second)\n",
            "llama_print_timings:        eval time =    1802.42 ms /    15 runs   (  120.16 ms per token,     8.32 tokens per second)\n",
            "llama_print_timings:       total time =    2549.76 ms /    94 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@tere_marinovic Rejection advertisers, we urge you not to use the expression “like garlic” to reinforce something bad. The AAJ (Association of Garlic Lovers) declares itself in a state of alert and vigilance in the face of this microaggression to its interests. There are millions of votes at stake.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.59 ms /    16 runs   (    0.60 ms per token,  1667.88 tokens per second)\n",
            "llama_print_timings: prompt eval time =     253.94 ms /    43 tokens (    5.91 ms per token,   169.33 tokens per second)\n",
            "llama_print_timings:        eval time =    1539.67 ms /    15 runs   (  102.64 ms per token,     9.74 tokens per second)\n",
            "llama_print_timings:       total time =    1964.38 ms /    58 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "(And yes, I do believe that it can be used as a form of microaggression - like almost everything - but I also think that that generalization is not very brilliant.)\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.65 ms /    16 runs   (    0.67 ms per token,  1502.35 tokens per second)\n",
            "llama_print_timings: prompt eval time =     272.66 ms /    71 tokens (    3.84 ms per token,   260.40 tokens per second)\n",
            "llama_print_timings:        eval time =    1487.11 ms /    15 runs   (   99.14 ms per token,    10.09 tokens per second)\n",
            "llama_print_timings:       total time =    2011.43 ms /    86 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@_Agnosthesia_ Did you completely miss the part about his workplace ostracizing him after disclosing to the director that he was a queer man? Passive coldness is still discrimination. This is called microaggression. Would you like to be treated as inconvenient for existing?\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.26 ms /    16 runs   (    0.58 ms per token,  1727.30 tokens per second)\n",
            "llama_print_timings: prompt eval time =     290.72 ms /   113 tokens (    2.57 ms per token,   388.69 tokens per second)\n",
            "llama_print_timings:        eval time =    1524.98 ms /    15 runs   (  101.67 ms per token,     9.84 tokens per second)\n",
            "llama_print_timings:       total time =    2176.94 ms /   128 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@sweetsparklesw @_samuel0014 @AcademiaUpdates @ALEXANDERACHA It is microaggression after microaggression that makes homophobia noticeable. The academy chased a group of drag girls because they did not want to dance in men's clothing. Tell me that's not homophobia? They took Dennis out of the closet so forcefully that even Danna Paola cried. That's not homophobia?\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.93 ms /    16 runs   (    0.62 ms per token,  1611.60 tokens per second)\n",
            "llama_print_timings: prompt eval time =     278.57 ms /    73 tokens (    3.82 ms per token,   262.05 tokens per second)\n",
            "llama_print_timings:        eval time =    1563.11 ms /    15 runs   (  104.21 ms per token,     9.60 tokens per second)\n",
            "llama_print_timings:       total time =    2085.67 ms /    88 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Celia_Alejandra Yaaaaa I get it! Of course, I still think that may be a stereotype. I don't know if I would have read it as misogyny because for me it is more like micro-machismo but I understand that it may be an outdated stereotype.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.89 ms /    16 runs   (    0.56 ms per token,  1799.57 tokens per second)\n",
            "llama_print_timings: prompt eval time =     738.63 ms /    31 tokens (   23.83 ms per token,    41.97 tokens per second)\n",
            "llama_print_timings:        eval time =    1594.65 ms /    15 runs   (  106.31 ms per token,     9.41 tokens per second)\n",
            "llama_print_timings:       total time =    2466.36 ms /    46 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Now they call “micromachismo” the fact of being a gentleman. Those feminists are getting more and more stupid.\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.80 ms /    16 runs   (    0.61 ms per token,  1632.15 tokens per second)\n",
            "llama_print_timings: prompt eval time =     260.55 ms /    42 tokens (    6.20 ms per token,   161.20 tokens per second)\n",
            "llama_print_timings:        eval time =    1721.47 ms /    15 runs   (  114.76 ms per token,     8.71 tokens per second)\n",
            "llama_print_timings:       total time =    2230.58 ms /    57 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Cormillot did not realize it but he made visible something that is not talked about much: the last intact bastion of the purest micromachismo are the offices.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.60 ms /    16 runs   (    0.60 ms per token,  1665.97 tokens per second)\n",
            "llama_print_timings: prompt eval time =     246.24 ms /    48 tokens (    5.13 ms per token,   194.93 tokens per second)\n",
            "llama_print_timings:        eval time =    1664.22 ms /    15 runs   (  110.95 ms per token,     9.01 tokens per second)\n",
            "llama_print_timings:       total time =    2086.45 ms /    63 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Today in micromachismo in my friend \"How do you not like to cook, your boyfriend already knows?\" I don't know whether to laugh or ask him if everything is okay at his house.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.72 ms /    16 runs   (    0.61 ms per token,  1646.60 tokens per second)\n",
            "llama_print_timings: prompt eval time =     264.74 ms /    73 tokens (    3.63 ms per token,   275.75 tokens per second)\n",
            "llama_print_timings:        eval time =    1575.50 ms /    15 runs   (  105.03 ms per token,     9.52 tokens per second)\n",
            "llama_print_timings:       total time =    2085.69 ms /    88 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "When a woman denounces sexism because she had consensual sex with a guy who didn't call her again, she is taking the issue to a superficial point. I am aware of what micromachismo is and I would never defend it, but you don't kill an ant with a grenade.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.08 ms /    16 runs   (    0.63 ms per token,  1586.67 tokens per second)\n",
            "llama_print_timings: prompt eval time =     244.88 ms /    55 tokens (    4.45 ms per token,   224.60 tokens per second)\n",
            "llama_print_timings:        eval time =    1649.85 ms /    15 runs   (  109.99 ms per token,     9.09 tokens per second)\n",
            "llama_print_timings:       total time =    2094.73 ms /    70 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@VirginiaG68 You haven't missed much. We remain dedicated to microfascism, micromachismo and aesthetic violence against fat women, prosthetics and mastectomies. #TeamFacha\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.27 ms /    16 runs   (    0.58 ms per token,  1725.81 tokens per second)\n",
            "llama_print_timings: prompt eval time =     298.67 ms /    89 tokens (    3.36 ms per token,   297.99 tokens per second)\n",
            "llama_print_timings:        eval time =    1470.66 ms /    15 runs   (   98.04 ms per token,    10.20 tokens per second)\n",
            "llama_print_timings:       total time =    2189.92 ms /   104 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@eneksei @Olad_20 @Mariiaa98_ @skeifer You speak of misogyny in the face of a generalization to justify, immediately afterwards, the generalization in a man's complaint about notallmen. In fact, the good old Skiner affects men and women and occurs quite a bit in the narcissistic profiles cited by the gentleman.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.14 ms /    16 runs   (    0.57 ms per token,  1750.16 tokens per second)\n",
            "llama_print_timings: prompt eval time =     238.74 ms /    44 tokens (    5.43 ms per token,   184.30 tokens per second)\n",
            "llama_print_timings:        eval time =    1562.23 ms /    15 runs   (  104.15 ms per token,     9.60 tokens per second)\n",
            "llama_print_timings:       total time =    1967.20 ms /    59 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@ruthi___ @corleoneRMCF @claudiiwiss_ Leave it, the poor thing doesn't matter any more. This err that errs with notallmen\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.48 ms /    16 runs   (    0.59 ms per token,  1687.23 tokens per second)\n",
            "llama_print_timings: prompt eval time =     253.82 ms /    65 tokens (    3.90 ms per token,   256.09 tokens per second)\n",
            "llama_print_timings:        eval time =    1565.08 ms /    15 runs   (  104.34 ms per token,     9.58 tokens per second)\n",
            "llama_print_timings:       total time =    2048.55 ms /    80 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Which of you was responsible for teaching your uncle Mario to use Twitter? He just tweets pure nonsense, take away his Wi-Fi, he just goes around giving others grief with his \"very necessary\" #NotAllMen comment https://t.co/ 9griMRzSvF\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.34 ms /    16 runs   (    0.71 ms per token,  1411.18 tokens per second)\n",
            "llama_print_timings: prompt eval time =     256.99 ms /    41 tokens (    6.27 ms per token,   159.54 tokens per second)\n",
            "llama_print_timings:        eval time =    1817.99 ms /    15 runs   (  121.20 ms per token,     8.25 tokens per second)\n",
            "llama_print_timings:       total time =    2268.62 ms /    56 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@CNDH @YndiraSandoval what's going on here? Someone explain please!! #NotAllMen? Does the debtor not exercise economic violence?\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.23 ms /    16 runs   (    0.51 ms per token,  1942.93 tokens per second)\n",
            "llama_print_timings: prompt eval time =     253.65 ms /    36 tokens (    7.05 ms per token,   141.93 tokens per second)\n",
            "llama_print_timings:        eval time =    1539.61 ms /    15 runs   (  102.64 ms per token,     9.74 tokens per second)\n",
            "llama_print_timings:       total time =    1937.89 ms /    51 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@PenaGariel @ribbonLP imagine if a tweet bothers you 😭😭😭😭😭#Notallmen😭😭😭😭\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.67 ms /    16 runs   (    0.54 ms per token,  1846.51 tokens per second)\n",
            "llama_print_timings: prompt eval time =     235.81 ms /    42 tokens (    5.61 ms per token,   178.11 tokens per second)\n",
            "llama_print_timings:        eval time =    1565.93 ms /    15 runs   (  104.40 ms per token,     9.58 tokens per second)\n",
            "llama_print_timings:       total time =    1961.97 ms /    57 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@tincho_mg I consider you among the healthy ones! don't wear notallmen, if the suit doesn't fit, don't wear it hahaha\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.84 ms /    16 runs   (    0.55 ms per token,  1809.34 tokens per second)\n",
            "llama_print_timings: prompt eval time =     240.52 ms /    35 tokens (    6.87 ms per token,   145.52 tokens per second)\n",
            "llama_print_timings:        eval time =    1651.15 ms /    15 runs   (  110.08 ms per token,     9.08 tokens per second)\n",
            "llama_print_timings:       total time =    2031.22 ms /    50 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "I shouted fuck the patriarchy surrounded by swifties, the best night of my life https://t.co/ek6OIan1kg\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.97 ms /    16 runs   (    0.69 ms per token,  1458.79 tokens per second)\n",
            "llama_print_timings: prompt eval time =     706.19 ms /    29 tokens (   24.35 ms per token,    41.07 tokens per second)\n",
            "llama_print_timings:        eval time =    1850.12 ms /    15 runs   (  123.34 ms per token,     8.11 tokens per second)\n",
            "llama_print_timings:       total time =    2717.27 ms /    44 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "I love that Mov said Fuck the patriarchy and Meli taught us man jumping, which by the way is really fun.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.09 ms /    16 runs   (    0.63 ms per token,  1585.26 tokens per second)\n",
            "llama_print_timings: prompt eval time =     272.51 ms /    78 tokens (    3.49 ms per token,   286.22 tokens per second)\n",
            "llama_print_timings:        eval time =    1512.74 ms /    15 runs   (  100.85 ms per token,     9.92 tokens per second)\n",
            "llama_print_timings:       total time =    2057.39 ms /    93 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@pau_army_bts A clear example of the deep-rooted machismo that exists in society, because if the situation were that men bought an album of their favs and we women bought the chips, they would criticize us the same 🤬 as Dr. Swift said fuck the patriarchy, my silver my decision\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.38 ms /    16 runs   (    0.59 ms per token,  1706.67 tokens per second)\n",
            "llama_print_timings: prompt eval time =     258.20 ms /    49 tokens (    5.27 ms per token,   189.77 tokens per second)\n",
            "llama_print_timings:        eval time =    1531.12 ms /    15 runs   (  102.07 ms per token,     9.80 tokens per second)\n",
            "llama_print_timings:       total time =    1964.18 ms /    64 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "I don't want to fuck the patriarchy, I'm tired of the fact that for you penetration is synonymous with humiliation and submission, how deeply violent and phallocentric that conception is.\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.27 ms /    16 runs   (    0.58 ms per token,  1726.56 tokens per second)\n",
            "llama_print_timings: prompt eval time =     657.43 ms /    28 tokens (   23.48 ms per token,    42.59 tokens per second)\n",
            "llama_print_timings:        eval time =    1547.80 ms /    15 runs   (  103.19 ms per token,     9.69 tokens per second)\n",
            "llama_print_timings:       total time =    2330.88 ms /    43 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Every day that passes I understand more the “FUCK THE PATRIARCHY” of all too well\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.64 ms /    16 runs   (    0.60 ms per token,  1659.58 tokens per second)\n",
            "llama_print_timings: prompt eval time =     263.07 ms /    46 tokens (    5.72 ms per token,   174.86 tokens per second)\n",
            "llama_print_timings:        eval time =    1706.15 ms /    15 runs   (  113.74 ms per token,     8.79 tokens per second)\n",
            "llama_print_timings:       total time =    2244.62 ms /    61 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Patriarchy, Patriarcat, Patriarchy. #Patriarchy, #Patriarcat, #Patriarchy. https://t.co/5tfxatw9UF\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.06 ms /    16 runs   (    0.57 ms per token,  1765.03 tokens per second)\n",
            "llama_print_timings: prompt eval time =     275.19 ms /   108 tokens (    2.55 ms per token,   392.45 tokens per second)\n",
            "llama_print_timings:        eval time =    1508.43 ms /    15 runs   (  100.56 ms per token,     9.94 tokens per second)\n",
            "llama_print_timings:       total time =    2117.95 ms /   123 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Register to vote: https://t.co/yIjQtrHynP#vote #womensequityday #womensrights #equity #womensday #amandagorman #poem Register to vote: https://t.co/ctcNYGtXz8#vote #equidaddelamujer #equidad #rechosdelamujer #diadelamujer #amardagorman #poem\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.31 ms /    16 runs   (    0.64 ms per token,  1551.59 tokens per second)\n",
            "llama_print_timings: prompt eval time =     280.48 ms /    80 tokens (    3.51 ms per token,   285.23 tokens per second)\n",
            "llama_print_timings:        eval time =    1579.18 ms /    15 runs   (  105.28 ms per token,     9.50 tokens per second)\n",
            "llama_print_timings:       total time =    2140.26 ms /    95 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "This Women's Day in South Africa @Kantar always stands firm in supporting the global issue of equal work between genders. Here's a reminder of International Women's Day in a message from our Middle East &amp; Africa. #WomensDay #GenderEquity…https://t.co/Ma28HYaKuT\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      13.93 ms /    16 runs   (    0.87 ms per token,  1148.44 tokens per second)\n",
            "llama_print_timings: prompt eval time =     283.64 ms /    74 tokens (    3.83 ms per token,   260.90 tokens per second)\n",
            "llama_print_timings:        eval time =    1829.71 ms /    15 runs   (  121.98 ms per token,     8.20 tokens per second)\n",
            "llama_print_timings:       total time =    2553.85 ms /    89 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Confiedance #teambuilding #directselling #motivation #nation #republicday #facebook #instagramposts #leadership #WomensDay https://t.co/nCfC6qLB03 https://t.co/LppDv6dylJ\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.84 ms /    16 runs   (    0.55 ms per token,  1810.57 tokens per second)\n",
            "llama_print_timings: prompt eval time =     739.92 ms /    31 tokens (   23.87 ms per token,    41.90 tokens per second)\n",
            "llama_print_timings:        eval time =    1468.47 ms /    15 runs   (   97.90 ms per token,    10.21 tokens per second)\n",
            "llama_print_timings:       total time =    2334.75 ms /    46 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@nissanza Single Cab#NewNissanNavara #MadeForYourJourney#womensday\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.33 ms /    16 runs   (    0.58 ms per token,  1715.63 tokens per second)\n",
            "llama_print_timings: prompt eval time =     315.22 ms /   122 tokens (    2.58 ms per token,   387.03 tokens per second)\n",
            "llama_print_timings:        eval time =    1535.89 ms /    15 runs   (  102.39 ms per token,     9.77 tokens per second)\n",
            "llama_print_timings:       total time =    2231.36 ms /   137 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "THE VENETIAN Resort | Las Vegas https://t.co/mERvhR7U2Z #NFTs #NFTCommunity #Cryptocomnft #crofam #NBA #WNBA #NYC #California #Crypto #UK #Houston #Calabasas #NewYork #Japan #Stocks #SouthKorea #Milan #ART #Investing # WomensDay #420 https://t.co/PclFsmCT68\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.85 ms /    16 runs   (    0.62 ms per token,  1625.19 tokens per second)\n",
            "llama_print_timings: prompt eval time =     292.41 ms /   128 tokens (    2.28 ms per token,   437.74 tokens per second)\n",
            "llama_print_timings:        eval time =    1565.89 ms /    15 runs   (  104.39 ms per token,     9.58 tokens per second)\n",
            "llama_print_timings:       total time =    2246.46 ms /   143 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "https://t.co/Zd3eFZFbq1We are ONE with the universeAlways forever, always#DiaInternacionalDeLosPueblosIndigenas #PueblosOriginarios#sanaYdespierta 🌟 #09Ago#Health #IndigenousDay #FelizMartesAtodos#IndigenousWomen #ALaTarde #cosmovision #WomensDay #women #tuesdayvibe https://t. co/B84EbKlpKq\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.95 ms /    16 runs   (    0.68 ms per token,  1461.85 tokens per second)\n",
            "llama_print_timings: prompt eval time =     269.96 ms /    60 tokens (    4.50 ms per token,   222.25 tokens per second)\n",
            "llama_print_timings:        eval time =    1658.43 ms /    15 runs   (  110.56 ms per token,     9.04 tokens per second)\n",
            "llama_print_timings:       total time =    2263.67 ms /    75 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "No. No. 1000x No. #WomensRights #WomensRights #WomensRights #WomensRightsAreHumanRights https://t.co/VawqXrPS6o\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.90 ms /    16 runs   (    0.56 ms per token,  1797.55 tokens per second)\n",
            "llama_print_timings: prompt eval time =     270.46 ms /    78 tokens (    3.47 ms per token,   288.40 tokens per second)\n",
            "llama_print_timings:        eval time =    1494.41 ms /    15 runs   (   99.63 ms per token,    10.04 tokens per second)\n",
            "llama_print_timings:       total time =    2029.14 ms /    93 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Putin hands over power, you can't with Ukraine and you can't with Russia #RusiavsUkraina #Rusia https://t.co/4jKJPQGAG4 #IranProtests2022 #WomensRights #RusiaVsUkraina\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.68 ms /    16 runs   (    0.60 ms per token,  1653.40 tokens per second)\n",
            "llama_print_timings: prompt eval time =     297.85 ms /   128 tokens (    2.33 ms per token,   429.75 tokens per second)\n",
            "llama_print_timings:        eval time =    1545.60 ms /    15 runs   (  103.04 ms per token,     9.70 tokens per second)\n",
            "llama_print_timings:       total time =    2233.88 ms /   143 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "DURADRY - EXCESSIVE PERSPIRATION &amp; ODOR CONTROLhttps://t.co/LpqaZa1JCG #wellness #Health #fitness #healthy #healthy #selfcare #Trending #TrendingNow #lifestyle #yoga #beauty #women #WomensRights #workouts #skincare #weightloss #lifedrawing #organic #natural #HealthyFood https://t.co/0IJJaqKWOX\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.48 ms /    16 runs   (    0.59 ms per token,  1687.41 tokens per second)\n",
            "llama_print_timings: prompt eval time =     267.85 ms /   103 tokens (    2.60 ms per token,   384.55 tokens per second)\n",
            "llama_print_timings:        eval time =    1570.17 ms /    15 runs   (  104.68 ms per token,     9.55 tokens per second)\n",
            "llama_print_timings:       total time =    2170.43 ms /   118 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@emonioycambio @Nievessebastia1 So between naïf and vindictive💪The 80-year-old lady doing her exercises with her churros...#ArteDeMujeres #WomensArt#Globalwomen#WomensRights#WomensRightsAreHumanRights#LetJulieSwim https://t.co/y31wclW1ZR\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.38 ms /    16 runs   (    0.59 ms per token,  1706.48 tokens per second)\n",
            "llama_print_timings: prompt eval time =     283.67 ms /    86 tokens (    3.30 ms per token,   303.17 tokens per second)\n",
            "llama_print_timings:        eval time =    1505.97 ms /    15 runs   (  100.40 ms per token,     9.96 tokens per second)\n",
            "llama_print_timings:       total time =    2116.17 ms /   101 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "“There are two paths you can take, yours and the one that others choose for you” Enola 🦋#lasniñasCAN #enolaholmes #alone #laciudaddelasdiosas #womensrights #fightlikeagirl 💜💪🏻 https://t.co/YrtOgJ67qg\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.52 ms /    16 runs   (    0.60 ms per token,  1680.32 tokens per second)\n",
            "llama_print_timings: prompt eval time =     273.49 ms /    92 tokens (    2.97 ms per token,   336.39 tokens per second)\n",
            "llama_print_timings:        eval time =    1597.44 ms /    15 runs   (  106.50 ms per token,     9.39 tokens per second)\n",
            "llama_print_timings:       total time =    2176.30 ms /   107 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "https://t.co/eBQis5NnaO👈@purocuentomarce 👈Women's equality and empowerment is one of the 17 Sustainable Development Goals.#MujeresFuertes #women #WomensRights #education https://t.co/lgLa3Z6t4Z\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.37 ms /    16 runs   (    0.59 ms per token,  1708.49 tokens per second)\n",
            "llama_print_timings: prompt eval time =     242.84 ms /    52 tokens (    4.67 ms per token,   214.14 tokens per second)\n",
            "llama_print_timings:        eval time =    1535.50 ms /    15 runs   (  102.37 ms per token,     9.77 tokens per second)\n",
            "llama_print_timings:       total time =    1974.46 ms /    67 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Come on, friends. Let's help a young champion for whom there are no yositecreo funds.#AnimoaEugenia https://t.co/b6uJ67turr\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      12.05 ms /    16 runs   (    0.75 ms per token,  1327.36 tokens per second)\n",
            "llama_print_timings: prompt eval time =     261.10 ms /    57 tokens (    4.58 ms per token,   218.30 tokens per second)\n",
            "llama_print_timings:        eval time =    1857.00 ms /    15 runs   (  123.80 ms per token,     8.08 tokens per second)\n",
            "llama_print_timings:       total time =    2470.87 ms /    72 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "#yositeI think what Wednesday is this? Believe without evidence, send men to prison for just being men? I believe that a male collective should be formed that fights at least for equality as the constitutions of the countries surely dictate.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.68 ms /    16 runs   (    0.61 ms per token,  1652.55 tokens per second)\n",
            "llama_print_timings: prompt eval time =     273.88 ms /    67 tokens (    4.09 ms per token,   244.63 tokens per second)\n",
            "llama_print_timings:        eval time =    1545.08 ms /    15 runs   (  103.01 ms per token,     9.71 tokens per second)\n",
            "llama_print_timings:       total time =    2039.08 ms /    82 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@mariomojc Well, it is true that judging is up to the judge, but the reality is harsher than the case of a comedian because hundreds of women who report being raped are judged every day on networks, in society and in justice. #I do believe you\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.28 ms /    16 runs   (    0.58 ms per token,  1724.88 tokens per second)\n",
            "llama_print_timings: prompt eval time =     250.91 ms /    52 tokens (    4.83 ms per token,   207.24 tokens per second)\n",
            "llama_print_timings:        eval time =    1660.62 ms /    15 runs   (  110.71 ms per token,     9.03 tokens per second)\n",
            "llama_print_timings:       total time =    2093.66 ms /    67 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "We won't let them take the girl. #YoSiTeCreo #ASIEsTortura #JusticiaPorCoiris https://t.co/PCbKw732PM\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.96 ms /    16 runs   (    0.62 ms per token,  1606.59 tokens per second)\n",
            "llama_print_timings: prompt eval time =     244.25 ms /    42 tokens (    5.82 ms per token,   171.96 tokens per second)\n",
            "llama_print_timings:        eval time =    1723.06 ms /    15 runs   (  114.87 ms per token,     8.71 tokens per second)\n",
            "llama_print_timings:       total time =    2143.09 ms /    57 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "How elegant it is... Without saying anything, just pressing play... Inside the video. #YoSiTeCreo #InElNombreDeRocio12\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.94 ms /    16 runs   (    0.62 ms per token,  1609.33 tokens per second)\n",
            "llama_print_timings: prompt eval time =     297.62 ms /   110 tokens (    2.71 ms per token,   369.60 tokens per second)\n",
            "llama_print_timings:        eval time =    1528.41 ms /    15 runs   (  101.89 ms per token,     9.81 tokens per second)\n",
            "llama_print_timings:       total time =    2180.38 ms /   125 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@JairoDurn16 @CorreAlexandra @ICBFColombia @VivianaVargasVi @yositecreo__ @cristinaplazasm @afectoenlinea @RedPaPaz @DianaLuzBornac1 @Solaris144 @conciliador70 @episcopadocol You find them for “current news”. If you share an email with me I can send them to you right now….\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.46 ms /    16 runs   (    0.59 ms per token,  1692.05 tokens per second)\n",
            "llama_print_timings: prompt eval time =     262.19 ms /    50 tokens (    5.24 ms per token,   190.70 tokens per second)\n",
            "llama_print_timings:        eval time =    1599.95 ms /    15 runs   (  106.66 ms per token,     9.38 tokens per second)\n",
            "llama_print_timings:       total time =    2039.02 ms /    65 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@biobio But it's true. This thing about women having to be given edoacios is an undeserved privilege. But equal or better workers than men. We don't have to receive charity!!\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.40 ms /    16 runs   (    0.59 ms per token,  1702.13 tokens per second)\n",
            "llama_print_timings: prompt eval time =     532.33 ms /    32 tokens (   16.64 ms per token,    60.11 tokens per second)\n",
            "llama_print_timings:        eval time =    1637.06 ms /    15 runs   (  109.14 ms per token,     9.16 tokens per second)\n",
            "llama_print_timings:       total time =    2310.60 ms /    47 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "You have to make women tremble with pleasure... Right? https://t.co/jJTEOY0tU9\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.67 ms /    16 runs   (    0.60 ms per token,  1655.12 tokens per second)\n",
            "llama_print_timings: prompt eval time =     249.64 ms /    34 tokens (    7.34 ms per token,   136.20 tokens per second)\n",
            "llama_print_timings:        eval time =    1616.88 ms /    15 runs   (  107.79 ms per token,     9.28 tokens per second)\n",
            "llama_print_timings:       total time =    2068.76 ms /    49 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "To know what women are interested in, you have to talk to a champion https://t.co/nQz4lyXY3d\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.36 ms /    16 runs   (    0.58 ms per token,  1709.40 tokens per second)\n",
            "llama_print_timings: prompt eval time =     261.76 ms /    59 tokens (    4.44 ms per token,   225.39 tokens per second)\n",
            "llama_print_timings:        eval time =    1629.38 ms /    15 runs   (  108.63 ms per token,     9.21 tokens per second)\n",
            "llama_print_timings:       total time =    2089.01 ms /    74 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@JoseMAcevedo Women have to be applauded for everything like a retarded seal so as not to look like an oppressive male; These acts should have legal consequences, that they should be put in jail so that they learn to respect.\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.59 ms /    16 runs   (    0.54 ms per token,  1861.98 tokens per second)\n",
            "llama_print_timings: prompt eval time =     240.35 ms /    35 tokens (    6.87 ms per token,   145.62 tokens per second)\n",
            "llama_print_timings:        eval time =    1498.84 ms /    15 runs   (   99.92 ms per token,    10.01 tokens per second)\n",
            "llama_print_timings:       total time =    1883.82 ms /    50 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "HAHAHAHAHA WOMEN SHOULD BE AFRAID https://t.co/60TBOUEYRg\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.76 ms /    16 runs   (    0.61 ms per token,  1639.51 tokens per second)\n",
            "llama_print_timings: prompt eval time =     261.14 ms /    81 tokens (    3.22 ms per token,   310.18 tokens per second)\n",
            "llama_print_timings:        eval time =    1534.76 ms /    15 runs   (  102.32 ms per token,     9.77 tokens per second)\n",
            "llama_print_timings:       total time =    2059.09 ms /    96 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Its_too_cold Isn't it indirectly saying that if a guy doesn't respect women it's because he hasn't touched them, isn't it indirectly saying that to respect women you have to first be able to touch them? It is better to focus on the resentment of some incels than on their celibacy itself\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.21 ms /    16 runs   (    0.64 ms per token,  1566.78 tokens per second)\n",
            "llama_print_timings: prompt eval time =     272.38 ms /    62 tokens (    4.39 ms per token,   227.63 tokens per second)\n",
            "llama_print_timings:        eval time =    1640.90 ms /    15 runs   (  109.39 ms per token,     9.14 tokens per second)\n",
            "llama_print_timings:       total time =    2240.98 ms /    77 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@SIEBELIS @T13 God, if these people of approval are all mentally ill, temptation is called to abuse someone, that is not temptation clown, one thing is that you get excited by x people and another is that you fall into that supposed temptation\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.15 ms /    16 runs   (    0.57 ms per token,  1749.02 tokens per second)\n",
            "llama_print_timings: prompt eval time =     286.54 ms /    84 tokens (    3.41 ms per token,   293.16 tokens per second)\n",
            "llama_print_timings:        eval time =    1565.45 ms /    15 runs   (  104.36 ms per token,     9.58 tokens per second)\n",
            "llama_print_timings:       total time =    2125.46 ms /    99 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@rsgarc Thanks for sharing. I had to go through something similar and, yes, as soon as I started giving shit, it was over, when I was 11 years old. Judo helped me. Now... the same thing happened to me, I started abusing one. I cut him off as soon as I realized my shitty attitude. I hope he forgives me.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.51 ms /    16 runs   (    0.59 ms per token,  1683.15 tokens per second)\n",
            "llama_print_timings: prompt eval time =     285.95 ms /    77 tokens (    3.71 ms per token,   269.28 tokens per second)\n",
            "llama_print_timings:        eval time =    1524.46 ms /    15 runs   (  101.63 ms per token,     9.84 tokens per second)\n",
            "llama_print_timings:       total time =    2063.47 ms /    92 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Jagarciar14 @_AlexMico for abusing a five-year-old girl when he was 17, claims that the young woman has flatly denied in a letter sent to the Efe agency. If we publish the news, we will do it in full, if it is not manipulation and that is very ugly\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.54 ms /    16 runs   (    0.66 ms per token,  1517.45 tokens per second)\n",
            "llama_print_timings: prompt eval time =     248.15 ms /    36 tokens (    6.89 ms per token,   145.07 tokens per second)\n",
            "llama_print_timings:        eval time =    1757.11 ms /    15 runs   (  117.14 ms per token,     8.54 tokens per second)\n",
            "llama_print_timings:       total time =    2220.12 ms /    51 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Juana56973095 @PatriotaSlater Alejandro Vega to prison for abusing the Chilean army.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.91 ms /    16 runs   (    0.62 ms per token,  1614.53 tokens per second)\n",
            "llama_print_timings: prompt eval time =     253.18 ms /    56 tokens (    4.52 ms per token,   221.19 tokens per second)\n",
            "llama_print_timings:        eval time =    1494.18 ms /    15 runs   (   99.61 ms per token,    10.04 tokens per second)\n",
            "llama_print_timings:       total time =    1938.47 ms /    71 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "#RecuentodelasemanaMP Man sentenced to 16 years in prison for sexually abusing his daughter in Yaracuy https://t.co/rXIXm20GQr #29Ago\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.35 ms /    16 runs   (    0.58 ms per token,  1711.41 tokens per second)\n",
            "llama_print_timings: prompt eval time =     277.15 ms /    87 tokens (    3.19 ms per token,   313.91 tokens per second)\n",
            "llama_print_timings:        eval time =    1640.92 ms /    15 runs   (  109.39 ms per token,     9.14 tokens per second)\n",
            "llama_print_timings:       total time =    2196.71 ms /   102 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@TucitaRules_ Yes, because she also later says that she is leaving with another guy and makes the insinuation that they abused her again... Either she is simply too weak to walk on the street or she is simply the most permissible victim in the world: I mean when a woman doesn't want to, scratch, kick, bite or something, she doesn't.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.45 ms /    16 runs   (    0.59 ms per token,  1692.94 tokens per second)\n",
            "llama_print_timings: prompt eval time =     244.30 ms /    50 tokens (    4.89 ms per token,   204.67 tokens per second)\n",
            "llama_print_timings:        eval time =    1509.56 ms /    15 runs   (  100.64 ms per token,     9.94 tokens per second)\n",
            "llama_print_timings:       total time =    1928.53 ms /    65 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@marthaperaltae I come to remind you that #TaxReform is an abuse of the people's pockets. Don't justify it with the story of sugar and then promote the legality of coca\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.20 ms /    16 runs   (    0.70 ms per token,  1428.19 tokens per second)\n",
            "llama_print_timings: prompt eval time =     253.31 ms /    44 tokens (    5.76 ms per token,   173.70 tokens per second)\n",
            "llama_print_timings:        eval time =    1763.96 ms /    15 runs   (  117.60 ms per token,     8.50 tokens per second)\n",
            "llama_print_timings:       total time =    2282.38 ms /    59 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@EAristeguieta @cruzmaldonado2 Prisoners have to blame the tococo and his police henchmen, for being complicit in this abuse.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.77 ms /    16 runs   (    0.61 ms per token,  1638.50 tokens per second)\n",
            "llama_print_timings: prompt eval time =     276.41 ms /    70 tokens (    3.95 ms per token,   253.25 tokens per second)\n",
            "llama_print_timings:        eval time =    1555.47 ms /    15 runs   (  103.70 ms per token,     9.64 tokens per second)\n",
            "llama_print_timings:       total time =    2066.55 ms /    85 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@jccay81 @MariettoPonce He uses and abuses power to relieve his trauma, he enjoys being greeted and thanked. Poverty grows, and jobs decrease, inflation rises and food becomes more expensive, he is grateful for what? Is its popularity fair? Does he believe it?\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.48 ms /    16 runs   (    0.59 ms per token,  1687.59 tokens per second)\n",
            "llama_print_timings: prompt eval time =     293.06 ms /    83 tokens (    3.53 ms per token,   283.22 tokens per second)\n",
            "llama_print_timings:        eval time =    1566.01 ms /    15 runs   (  104.40 ms per token,     9.58 tokens per second)\n",
            "llama_print_timings:       total time =    2128.79 ms /    98 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@GuaroAtravesado @TarekWiliamSaab The @TareckPSUV likes these types of procedures, police excesses. In a country with separation of powers and real justice, these police officers are brought to the attention of the prosecution for abuse. They want to solve everything in a bad way, with blows and with improper procedures.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      13.23 ms /    16 runs   (    0.83 ms per token,  1209.56 tokens per second)\n",
            "llama_print_timings: prompt eval time =     246.33 ms /    35 tokens (    7.04 ms per token,   142.09 tokens per second)\n",
            "llama_print_timings:        eval time =    1614.06 ms /    15 runs   (  107.60 ms per token,     9.29 tokens per second)\n",
            "llama_print_timings:       total time =    2072.86 ms /    50 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "They investigate a man in Tulancingo for aggravated sexual abuse https://t.co/1Fcx2lqr9g\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.33 ms /    16 runs   (    0.65 ms per token,  1548.44 tokens per second)\n",
            "llama_print_timings: prompt eval time =     255.31 ms /    60 tokens (    4.26 ms per token,   235.01 tokens per second)\n",
            "llama_print_timings:        eval time =    1551.06 ms /    15 runs   (  103.40 ms per token,     9.67 tokens per second)\n",
            "llama_print_timings:       total time =    2015.27 ms /    75 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "What's up, they're telling you that you indirectly or directly defended a woman who psychologically, physically and sexually abused a person and you give the speech about OH BUT THE MEN??? Dude no one is talking about them now\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.92 ms /    16 runs   (    0.56 ms per token,  1793.32 tokens per second)\n",
            "llama_print_timings: prompt eval time =     242.44 ms /    39 tokens (    6.22 ms per token,   160.87 tokens per second)\n",
            "llama_print_timings:        eval time =    1496.08 ms /    15 runs   (   99.74 ms per token,    10.03 tokens per second)\n",
            "llama_print_timings:       total time =    1880.97 ms /    54 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Hello August; I promise to move forward with determination and patience... I decree that every positive action will bear fruit so that the doors to new opportunities are effectively opened.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.46 ms /    16 runs   (    0.59 ms per token,  1692.23 tokens per second)\n",
            "llama_print_timings: prompt eval time =     634.50 ms /    28 tokens (   22.66 ms per token,    44.13 tokens per second)\n",
            "llama_print_timings:        eval time =    1634.64 ms /    15 runs   (  108.98 ms per token,     9.18 tokens per second)\n",
            "llama_print_timings:       total time =    2402.28 ms /    43 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Making my bed, the first positive action of the day😊Let's have a nice day my people!\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.22 ms /    16 runs   (    0.58 ms per token,  1734.79 tokens per second)\n",
            "llama_print_timings: prompt eval time =     255.56 ms /    47 tokens (    5.44 ms per token,   183.91 tokens per second)\n",
            "llama_print_timings:        eval time =    1638.79 ms /    15 runs   (  109.25 ms per token,     9.15 tokens per second)\n",
            "llama_print_timings:       total time =    2064.14 ms /    62 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@MXESTADIOS Why do many people have to detract from some positive action? Why are we like this? Or that the person is bad, or that my team is better? let it be\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.73 ms /    16 runs   (    0.61 ms per token,  1644.74 tokens per second)\n",
            "llama_print_timings: prompt eval time =     269.65 ms /    73 tokens (    3.69 ms per token,   270.72 tokens per second)\n",
            "llama_print_timings:        eval time =    1509.79 ms /    15 runs   (  100.65 ms per token,     9.94 tokens per second)\n",
            "llama_print_timings:       total time =    2012.83 ms /    88 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "national judiciary: Call positive action for discrimination. They economically discriminate against #women and #men for life for being #CivilGuard. Their professional career and retirement have to be recognized in salaries and remunerations like police officers… https://t. co/ShDiXpJf6z\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.03 ms /    16 runs   (    0.69 ms per token,  1450.59 tokens per second)\n",
            "llama_print_timings: prompt eval time =     287.66 ms /    74 tokens (    3.89 ms per token,   257.25 tokens per second)\n",
            "llama_print_timings:        eval time =    1737.97 ms /    15 runs   (  115.86 ms per token,     8.63 tokens per second)\n",
            "llama_print_timings:       total time =    2285.71 ms /    89 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@SebasDrummer This rating is a shame, an analysis of the causes would be good... However, good news does not make headlines, please look for it, it would be a positive action for the benefit of the entire country! Here is one: https://t. co/NMR0oFwIrJ\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.68 ms /    16 runs   (    0.61 ms per token,  1652.38 tokens per second)\n",
            "llama_print_timings: prompt eval time =     260.20 ms /    47 tokens (    5.54 ms per token,   180.63 tokens per second)\n",
            "llama_print_timings:        eval time =    1566.73 ms /    15 runs   (  104.45 ms per token,     9.57 tokens per second)\n",
            "llama_print_timings:       total time =    1996.63 ms /    62 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "The #QuitoConsensus is an agreement between countries to adopt positive action measures and necessary mechanisms, including legislative reforms and budget allocations, to guarantee the participation of women in public positions and political representation\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.55 ms /    16 runs   (    0.60 ms per token,  1675.04 tokens per second)\n",
            "llama_print_timings: prompt eval time =     276.77 ms /    72 tokens (    3.84 ms per token,   260.14 tokens per second)\n",
            "llama_print_timings:        eval time =    1566.68 ms /    15 runs   (  104.45 ms per token,     9.57 tokens per second)\n",
            "llama_print_timings:       total time =    2084.18 ms /    87 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@EdgarSanchezSV Let the Law be the one that imposes Freedom or Prison! IN THIS COUNTRY YOU CAN NO LONGER DEFAME PEOPLE, YOU SHOULD NOT HARASS WOMEN, AND YOU SHOULD NOT THREATEN OTHERS!\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.80 ms /    16 runs   (    0.55 ms per token,  1817.36 tokens per second)\n",
            "llama_print_timings: prompt eval time =     580.60 ms /    22 tokens (   26.39 ms per token,    37.89 tokens per second)\n",
            "llama_print_timings:        eval time =    1489.58 ms /    15 runs   (   99.31 ms per token,    10.07 tokens per second)\n",
            "llama_print_timings:       total time =    2178.53 ms /    37 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "I just followed a Draven bot, I'm going to sexually harass him\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.32 ms /    16 runs   (    0.65 ms per token,  1550.39 tokens per second)\n",
            "llama_print_timings: prompt eval time =     289.80 ms /    72 tokens (    4.02 ms per token,   248.45 tokens per second)\n",
            "llama_print_timings:        eval time =    1724.41 ms /    15 runs   (  114.96 ms per token,     8.70 tokens per second)\n",
            "llama_print_timings:       total time =    2385.61 ms /    87 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Liberalize In other words; ABORTION IS a right, specifically A SEXUAL RIGHT, regardless of who is going to do it and their reasons. What IS NOT A RIGHT is to criticize, insult, harass, etc., someone for deciding about their own life, which does NOT affect yours.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.07 ms /    16 runs   (    0.63 ms per token,  1589.04 tokens per second)\n",
            "llama_print_timings: prompt eval time =     255.05 ms /    62 tokens (    4.11 ms per token,   243.09 tokens per second)\n",
            "llama_print_timings:        eval time =    1520.36 ms /    15 runs   (  101.36 ms per token,     9.87 tokens per second)\n",
            "llama_print_timings:       total time =    1980.54 ms /    77 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "You think you have the right to harass my boyfriend just for being a woman, I think everyone here agrees that being of any sex doesn't make you better than anyone else. #feminist #bullying https://t.co/DbUPc9s0Uz\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.05 ms /    16 runs   (    0.57 ms per token,  1767.57 tokens per second)\n",
            "llama_print_timings: prompt eval time =     277.59 ms /    67 tokens (    4.14 ms per token,   241.36 tokens per second)\n",
            "llama_print_timings:        eval time =    1499.41 ms /    15 runs   (   99.96 ms per token,    10.00 tokens per second)\n",
            "llama_print_timings:       total time =    1996.93 ms /    82 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@FanboydeJinx But don't give them the pleasure of letting this affect you. Also what did you expect? If they start harassing it is obvious that they are going to gain the block, that's what it's for and you don't have to feel guilty.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.62 ms /    16 runs   (    0.66 ms per token,  1507.30 tokens per second)\n",
            "llama_print_timings: prompt eval time =     237.94 ms /    43 tokens (    5.53 ms per token,   180.72 tokens per second)\n",
            "llama_print_timings:        eval time =    1695.18 ms /    15 runs   (  113.01 ms per token,     8.85 tokens per second)\n",
            "llama_print_timings:       total time =    2118.50 ms /    58 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Congratulations, I haven't harassed an aunt for doing eyeliner in 19 years https://t.co/O05Pogd1mV\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.77 ms /    16 runs   (    0.61 ms per token,  1637.16 tokens per second)\n",
            "llama_print_timings: prompt eval time =     265.28 ms /    51 tokens (    5.20 ms per token,   192.25 tokens per second)\n",
            "llama_print_timings:        eval time =    1480.47 ms /    15 runs   (   98.70 ms per token,    10.13 tokens per second)\n",
            "llama_print_timings:       total time =    1921.96 ms /    66 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Claudit09685351 This is not the first time, a complaint was made with email included to the head of dideco for sexual harassment and they did not take it into account...\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.36 ms /    16 runs   (    0.59 ms per token,  1708.67 tokens per second)\n",
            "llama_print_timings: prompt eval time =     270.53 ms /    78 tokens (    3.47 ms per token,   288.33 tokens per second)\n",
            "llama_print_timings:        eval time =    1479.41 ms /    15 runs   (   98.63 ms per token,    10.14 tokens per second)\n",
            "llama_print_timings:       total time =    1992.87 ms /    93 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "It is urgent to implement a culture of prevention against workplace sexual harassment. Sexual harassment not only causes serious harm to the victim but also affects the productivity of the company. These are not isolated events, there is a system that allows this to happen. #stopacoso https ://t.co/2d5aJ5C7HU\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.56 ms /    16 runs   (    0.60 ms per token,  1673.82 tokens per second)\n",
            "llama_print_timings: prompt eval time =     269.21 ms /    71 tokens (    3.79 ms per token,   263.73 tokens per second)\n",
            "llama_print_timings:        eval time =    1494.83 ms /    15 runs   (   99.66 ms per token,    10.03 tokens per second)\n",
            "llama_print_timings:       total time =    1989.20 ms /    86 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "⚠️TW//Sexual harassment\"The silence that fills Volkov and Foster's patrol car has already become its natural environment. No one speaks, no one even deigns to say a word. Volkov because he has nothing to say (and prefers the calm down rather than force a conversation\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      12.16 ms /    16 runs   (    0.76 ms per token,  1316.33 tokens per second)\n",
            "llama_print_timings: prompt eval time =     268.15 ms /    59 tokens (    4.54 ms per token,   220.03 tokens per second)\n",
            "llama_print_timings:        eval time =    1790.98 ms /    15 runs   (  119.40 ms per token,     8.38 tokens per second)\n",
            "llama_print_timings:       total time =    2291.66 ms /    74 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "🔴 Michoacán School Director is reported for sexual harassment https://t.co/iB2NvDCpIV #morelia #michoacán #pátzcuaro #uruapan #apatzingán #huiramba\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.43 ms /    16 runs   (    0.59 ms per token,  1697.25 tokens per second)\n",
            "llama_print_timings: prompt eval time =     284.16 ms /    81 tokens (    3.51 ms per token,   285.05 tokens per second)\n",
            "llama_print_timings:        eval time =    1534.19 ms /    15 runs   (  102.28 ms per token,     9.78 tokens per second)\n",
            "llama_print_timings:       total time =    2078.23 ms /    96 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@David34213465 @Jiobbit A lot of text to conclude nothing. Let me explain to you, it is sexual harassment when you make advances or comments of a sexual nature to a person without their consent, trust is a non-determining factor, they can even be best friends and still do not consent to that type of\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.63 ms /    16 runs   (    0.60 ms per token,  1660.61 tokens per second)\n",
            "llama_print_timings: prompt eval time =     280.94 ms /    86 tokens (    3.27 ms per token,   306.11 tokens per second)\n",
            "llama_print_timings:        eval time =    1530.85 ms /    15 runs   (  102.06 ms per token,     9.80 tokens per second)\n",
            "llama_print_timings:       total time =    2079.29 ms /   101 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Law 21,369, which regulates sexual harassment, violence and gender discrimination on higher education campuses; It came into effect on September 15, 2021 and marks one year for an implementation that confirms the UAHC's commitment to these standards in its culture https://t.co/qYDHtlgXuK\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.55 ms /    16 runs   (    0.60 ms per token,  1674.52 tokens per second)\n",
            "llama_print_timings: prompt eval time =     241.81 ms /    53 tokens (    4.56 ms per token,   219.18 tokens per second)\n",
            "llama_print_timings:        eval time =    1511.80 ms /    15 runs   (  100.79 ms per token,     9.92 tokens per second)\n",
            "llama_print_timings:       total time =    1934.88 ms /    68 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Onlyboy_2 Be careful because the customer can sue the store because his employee harassed him or touched him in a sexual way.... The employee was courteously helpful and attentive,... Leaving work will be different.....\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.71 ms /    16 runs   (    0.67 ms per token,  1493.79 tokens per second)\n",
            "llama_print_timings: prompt eval time =     250.24 ms /    33 tokens (    7.58 ms per token,   131.87 tokens per second)\n",
            "llama_print_timings:        eval time =    1872.78 ms /    15 runs   (  124.85 ms per token,     8.01 tokens per second)\n",
            "llama_print_timings:       total time =    2289.20 ms /    48 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Sexual harassment in the workplace by the boss and other employees https://t.co/90mnbZjwwD\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.39 ms /    16 runs   (    0.65 ms per token,  1539.20 tokens per second)\n",
            "llama_print_timings: prompt eval time =     290.31 ms /    80 tokens (    3.63 ms per token,   275.57 tokens per second)\n",
            "llama_print_timings:        eval time =    1570.75 ms /    15 runs   (  104.72 ms per token,     9.55 tokens per second)\n",
            "llama_print_timings:       total time =    2114.62 ms /    95 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@DaMoralesDel @realmalpa4ever Hey, that's okay... Or maybe @Matador000 has already recanted for her harassment of Duque⁉️🤔 I haven't seen Glutona @smilelalis do it either. https://t.co/kqnwuk7cS4\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.82 ms /    16 runs   (    0.61 ms per token,  1628.66 tokens per second)\n",
            "llama_print_timings: prompt eval time =     248.40 ms /    58 tokens (    4.28 ms per token,   233.50 tokens per second)\n",
            "llama_print_timings:        eval time =    1541.72 ms /    15 runs   (  102.78 ms per token,     9.73 tokens per second)\n",
            "llama_print_timings:       total time =    1983.81 ms /    73 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "lazy people who want to live dependent on other people's children, better the famous people who respect the privacy and safety of their children in this horrible world full of child harassment and pedophilia https://t.co/FfqqDBFWnv\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.27 ms /    16 runs   (    0.58 ms per token,  1726.18 tokens per second)\n",
            "llama_print_timings: prompt eval time =     241.00 ms /    57 tokens (    4.23 ms per token,   236.51 tokens per second)\n",
            "llama_print_timings:        eval time =    1492.07 ms /    15 runs   (   99.47 ms per token,    10.05 tokens per second)\n",
            "llama_print_timings:       total time =    1931.47 ms /    72 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@cantaletica How much I testified in a case of harassment of a friend of his, his reaction was to make comments like “that's why they rape them” “that's why they kill them” ☹️\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.73 ms /    16 runs   (    0.67 ms per token,  1491.42 tokens per second)\n",
            "llama_print_timings: prompt eval time =     284.22 ms /    74 tokens (    3.84 ms per token,   260.36 tokens per second)\n",
            "llama_print_timings:        eval time =    1690.04 ms /    15 runs   (  112.67 ms per token,     8.88 tokens per second)\n",
            "llama_print_timings:       total time =    2356.41 ms /    89 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "#BailaViniJr#ApagonAlChiringuito@RonyVargasV, come on coward, speak out against racism and harassment of one of the best players in the world or continue supporting #PedrerolMafioso! https://t.co/TRrijhy8Qb\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.50 ms /    16 runs   (    0.59 ms per token,  1683.50 tokens per second)\n",
            "llama_print_timings: prompt eval time =     282.04 ms /    70 tokens (    4.03 ms per token,   248.19 tokens per second)\n",
            "llama_print_timings:        eval time =    1622.56 ms /    15 runs   (  108.17 ms per token,     9.24 tokens per second)\n",
            "llama_print_timings:       total time =    2134.83 ms /    85 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@elperiodico They call it liquid love, you are the worst, bad approach to everything, more unhappiness, empty people in search of permanent satisfaction, chasing the chimera all your fucking life... Good business for selling smokes, psychologists and pharmacists, go ahead and everyone go catch the wind\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.68 ms /    16 runs   (    0.61 ms per token,  1652.55 tokens per second)\n",
            "llama_print_timings: prompt eval time =     349.67 ms /   149 tokens (    2.35 ms per token,   426.11 tokens per second)\n",
            "llama_print_timings:        eval time =    1606.79 ms /    15 runs   (  107.12 ms per token,     9.34 tokens per second)\n",
            "llama_print_timings:       total time =    2413.26 ms /   164 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "KATIA MIRANDA👉 \"Fascinus V\" and \"Amor liquido\" both from the series visual labyrinths, works of art that you can find in our Í𝗔 𝗩𝗜𝗥𝗧𝗨𝗔𝗟! https://t.co/lozR3uKMXs or write to WhatsApp: 4579-9170 #ElAttico #Guatemala #KatiaMiranda #Lienzo #Obrasdearte https://t.co/ptNGLG60yK\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.02 ms /    16 runs   (    0.56 ms per token,  1773.25 tokens per second)\n",
            "llama_print_timings: prompt eval time =     234.11 ms /    33 tokens (    7.09 ms per token,   140.96 tokens per second)\n",
            "llama_print_timings:        eval time =    1721.47 ms /    15 runs   (  114.76 ms per token,     8.71 tokens per second)\n",
            "llama_print_timings:       total time =    2098.77 ms /    48 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "THIS, you feel out of place in this world of liquid love. https://t.co/DFfeslUgIZ\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.26 ms /    16 runs   (    0.58 ms per token,  1728.24 tokens per second)\n",
            "llama_print_timings: prompt eval time =     286.82 ms /    85 tokens (    3.37 ms per token,   296.35 tokens per second)\n",
            "llama_print_timings:        eval time =    1560.29 ms /    15 runs   (  104.02 ms per token,     9.61 tokens per second)\n",
            "llama_print_timings:       total time =    2111.87 ms /   100 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Not even giving ass is binding, stop writing nonsense that love is not chosen, it is only given, whether they give ass or not, whether they suck it or not, whether they allow themselves to be spit on or not.Liquid Love, Zygmunt Bauman, 2022. https:/ /t.co/y4CCxrbZyd\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.67 ms /    16 runs   (    0.60 ms per token,  1655.12 tokens per second)\n",
            "llama_print_timings: prompt eval time =     736.35 ms /    31 tokens (   23.75 ms per token,    42.10 tokens per second)\n",
            "llama_print_timings:        eval time =    1503.03 ms /    15 runs   (  100.20 ms per token,     9.98 tokens per second)\n",
            "llama_print_timings:       total time =    2370.75 ms /    46 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "I want to read \"Liquid Love\" https://t.co/UR7csNUQ0g #skoob\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.78 ms /    16 runs   (    0.61 ms per token,  1635.66 tokens per second)\n",
            "llama_print_timings: prompt eval time =     254.38 ms /    71 tokens (    3.58 ms per token,   279.11 tokens per second)\n",
            "llama_print_timings:        eval time =    1535.58 ms /    15 runs   (  102.37 ms per token,     9.77 tokens per second)\n",
            "llama_print_timings:       total time =    2037.22 ms /    86 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "If you want to think a little more about this you can research \"liquid love\" and \"liquid modernity\" by sociologist Zygmunt Bauman; I also drew some conclusions from the book psychology and economics by Raymundo Campos and from research by neuroscientist Dar Meshi.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.74 ms /    16 runs   (    0.67 ms per token,  1489.34 tokens per second)\n",
            "llama_print_timings: prompt eval time =     703.83 ms /    28 tokens (   25.14 ms per token,    39.78 tokens per second)\n",
            "llama_print_timings:        eval time =    1856.42 ms /    15 runs   (  123.76 ms per token,     8.08 tokens per second)\n",
            "llama_print_timings:       total time =    2757.93 ms /    43 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "going to drama plot to look for recommendations of dramas that make me agonize over romantic love, good night\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.41 ms /    16 runs   (    0.59 ms per token,  1700.86 tokens per second)\n",
            "llama_print_timings: prompt eval time =     267.30 ms /    60 tokens (    4.45 ms per token,   224.47 tokens per second)\n",
            "llama_print_timings:        eval time =    1485.12 ms /    15 runs   (   99.01 ms per token,    10.10 tokens per second)\n",
            "llama_print_timings:       total time =    1963.84 ms /    75 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Is it more natural to behave like Romeo and Juliet, paradigms of the myth of romantic love? Or like the promiscuous Casanova and Don Juan Tenorio? 🤔https://t.co/8kT545EsLM\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       7.99 ms /    16 runs   (    0.50 ms per token,  2002.50 tokens per second)\n",
            "llama_print_timings: prompt eval time =     652.84 ms /    26 tokens (   25.11 ms per token,    39.83 tokens per second)\n",
            "llama_print_timings:        eval time =    1574.13 ms /    15 runs   (  104.94 ms per token,     9.53 tokens per second)\n",
            "llama_print_timings:       total time =    2340.73 ms /    41 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "nonono revived romantic love 😭 https://t.co/AhbPO81rCB\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.65 ms /    16 runs   (    0.60 ms per token,  1658.72 tokens per second)\n",
            "llama_print_timings: prompt eval time =     274.64 ms /    81 tokens (    3.39 ms per token,   294.93 tokens per second)\n",
            "llama_print_timings:        eval time =    1490.54 ms /    15 runs   (   99.37 ms per token,    10.06 tokens per second)\n",
            "llama_print_timings:       total time =    2046.61 ms /    96 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "«The loneliness and obligatory solipsistic air of #ConcepciónArenal also has good visual moments, such as the scenes in the forest with her dog and under the northern rain, or her epiphany on the balcony in Madrid, which links potential romantic love, + https ://t.co/dlpAXhqjlk\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.71 ms /    16 runs   (    0.54 ms per token,  1838.02 tokens per second)\n",
            "llama_print_timings: prompt eval time =     869.78 ms /    27 tokens (   32.21 ms per token,    31.04 tokens per second)\n",
            "llama_print_timings:        eval time =    1477.31 ms /    15 runs   (   98.49 ms per token,    10.15 tokens per second)\n",
            "llama_print_timings:       total time =    2514.32 ms /    42 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "And without romantic love taking over the relationship https://t.co/kNxs0hfszH\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.75 ms /    16 runs   (    0.55 ms per token,  1827.74 tokens per second)\n",
            "llama_print_timings: prompt eval time =     673.90 ms /    29 tokens (   23.24 ms per token,    43.03 tokens per second)\n",
            "llama_print_timings:        eval time =    1476.74 ms /    15 runs   (   98.45 ms per token,    10.16 tokens per second)\n",
            "llama_print_timings:       total time =    2275.66 ms /    44 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "the only one that makes romantic love work https://t.co/HdLlXoG5UW\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.73 ms /    16 runs   (    0.61 ms per token,  1644.91 tokens per second)\n",
            "llama_print_timings: prompt eval time =     257.09 ms /    72 tokens (    3.57 ms per token,   280.06 tokens per second)\n",
            "llama_print_timings:        eval time =    1564.50 ms /    15 runs   (  104.30 ms per token,     9.59 tokens per second)\n",
            "llama_print_timings:       total time =    2054.53 ms /    87 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "The elimination of sexist language and androcentrism is fundamental for the construction of a law with a gender perspective. #sinperspectivadegeneronohayjusticia #LeyMicaela #feminist lawyers #lawyers https://t.co/VPg05tMvcc\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.24 ms /    16 runs   (    0.64 ms per token,  1562.50 tokens per second)\n",
            "llama_print_timings: prompt eval time =     258.58 ms /    70 tokens (    3.69 ms per token,   270.71 tokens per second)\n",
            "llama_print_timings:        eval time =    1682.19 ms /    15 runs   (  112.15 ms per token,     8.92 tokens per second)\n",
            "llama_print_timings:       total time =    2182.49 ms /    85 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Generally when there is cultural appropriation of these mystical/philosophical themes there is a tendency to adapt that to the androcentrism of the West. Something that, for example, happens in the Luke saga in Star Wars, where the Jedi issue seems only a matter for gentlemen.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.01 ms /    16 runs   (    0.56 ms per token,  1775.41 tokens per second)\n",
            "llama_print_timings: prompt eval time =     255.69 ms /    33 tokens (    7.75 ms per token,   129.06 tokens per second)\n",
            "llama_print_timings:        eval time =    1673.18 ms /    15 runs   (  111.55 ms per token,     8.96 tokens per second)\n",
            "llama_print_timings:       total time =    2060.21 ms /    48 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "*Feigns surprise*Androcentrism is still valid in the discipline, unfortunately. The fight continues✊🏼💜\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.05 ms /    16 runs   (    0.57 ms per token,  1766.98 tokens per second)\n",
            "llama_print_timings: prompt eval time =     601.70 ms /    23 tokens (   26.16 ms per token,    38.22 tokens per second)\n",
            "llama_print_timings:        eval time =    1568.11 ms /    15 runs   (  104.54 ms per token,     9.57 tokens per second)\n",
            "llama_print_timings:       total time =    2280.36 ms /    38 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "It is unacceptable that women are labeled bitches for facing androcentrism\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.01 ms /    16 runs   (    0.56 ms per token,  1776.40 tokens per second)\n",
            "llama_print_timings: prompt eval time =     238.34 ms /    41 tokens (    5.81 ms per token,   172.02 tokens per second)\n",
            "llama_print_timings:        eval time =    1544.17 ms /    15 runs   (  102.94 ms per token,     9.71 tokens per second)\n",
            "llama_print_timings:       total time =    1941.12 ms /    56 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@gerardotc In these cases, as in so many others, the punishment always goes in the same direction. #Androcentrism #Misogyny\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.71 ms /    16 runs   (    0.67 ms per token,  1493.79 tokens per second)\n",
            "llama_print_timings: prompt eval time =     243.07 ms /    51 tokens (    4.77 ms per token,   209.82 tokens per second)\n",
            "llama_print_timings:        eval time =    1710.21 ms /    15 runs   (  114.01 ms per token,     8.77 tokens per second)\n",
            "llama_print_timings:       total time =    2144.04 ms /    66 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Jose Manuel, don't give me a shitty explanation for a situation of real equality when all you are is a sexist saying sexist things, I can smell androcentrism from 8 kilometers away.\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.63 ms /    16 runs   (    0.60 ms per token,  1660.61 tokens per second)\n",
            "llama_print_timings: prompt eval time =     279.42 ms /    84 tokens (    3.33 ms per token,   300.62 tokens per second)\n",
            "llama_print_timings:        eval time =    1462.66 ms /    15 runs   (   97.51 ms per token,    10.26 tokens per second)\n",
            "llama_print_timings:       total time =    2010.02 ms /    99 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@A_Aguinaga @congresoperu @PedroCastillo YOU ​​GO AND GIVE A CONFERENCE HOW TO KILL WOMEN BY STERILIZATIONS AND HOW TO AVOID POVERTY BY ELIMINATING UNBORN CHILDREN. YOU ARE THE WORST PERUVIAN\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.33 ms /    16 runs   (    0.58 ms per token,  1714.90 tokens per second)\n",
            "llama_print_timings: prompt eval time =     269.74 ms /    77 tokens (    3.50 ms per token,   285.46 tokens per second)\n",
            "llama_print_timings:        eval time =    1433.52 ms /    15 runs   (   95.57 ms per token,    10.46 tokens per second)\n",
            "llama_print_timings:       total time =    1958.87 ms /    92 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@lamabe_05 La Mabe Mabelita: Go to kidnap, murder women, go to sell public positions, go to destroy health, education and security, go to have debt bonds and pay interest when the country's risk rises, go to steal the iess.LET'S DO WHAT LASSO SAYS!\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      12.13 ms /    16 runs   (    0.76 ms per token,  1319.37 tokens per second)\n",
            "llama_print_timings: prompt eval time =     636.23 ms /   424 tokens (    1.50 ms per token,   666.43 tokens per second)\n",
            "llama_print_timings:        eval time =    1811.24 ms /    15 runs   (  120.75 ms per token,     8.28 tokens per second)\n",
            "llama_print_timings:       total time =    3676.06 ms /   439 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@abrilprimavera2 @Veva_leo @bolboreta_7 @beloki_ana @luismi754 @Joanna_S___ @yosoyasin @Ana81548224 @2Royma @Juania37281458 @Circe_______7 @IN100S0_2 @MireReedus @_BrujaAveria @Marimar66842849 @Anitawer2 @Amer9 30249141 @cargadodebalas @Angela17673286 @srtmatorra @AUSSIESYDNEY62 @Jennife46975531 @MdtValeria @Shane7019 @pepiquintanah @lagunadonosol @Dolores92662996 @PaUrdi7 @2021Felina @srtanyi @BeaGonzo @garciapeino @ARlunaris @parequeaclara @DolceFa81306422 @VetaPino @Merilin86445959 @Rosaros81600671 @Pili_Fleitas @encarter76 @Luna5003576 9 @CarmoMariela @xasminmoda @GUS85218471 @christianMHB1 @elReydelchoriso @laguna_donoso @mappaxxe @ChristianMarioH And in Prison should continue, but since the evidence does not seem sufficient, then out on the street. Abusing, raping and murdering women comes very cheap. #SUPPORT5A\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.60 ms /    16 runs   (    0.60 ms per token,  1667.54 tokens per second)\n",
            "llama_print_timings: prompt eval time =     277.19 ms /    74 tokens (    3.75 ms per token,   266.96 tokens per second)\n",
            "llama_print_timings:        eval time =    1691.24 ms /    15 runs   (  112.75 ms per token,     8.87 tokens per second)\n",
            "llama_print_timings:       total time =    2206.22 ms /    89 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@RicardoMeb Secretary Ricardo Mejía in the morning you said that the case of Debanhi Escobar Basaldua will be brought to the FGR and we do not see this happening. We demand justice in this case as long as nothing is done, crime finds it easy to kidnap and murder women.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.82 ms /    16 runs   (    0.61 ms per token,  1629.99 tokens per second)\n",
            "llama_print_timings: prompt eval time =     291.13 ms /    83 tokens (    3.51 ms per token,   285.09 tokens per second)\n",
            "llama_print_timings:        eval time =    1509.33 ms /    15 runs   (  100.62 ms per token,     9.94 tokens per second)\n",
            "llama_print_timings:       total time =    2064.49 ms /    98 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@pedrodlop1 @vox_es Hahahaha hahahahahahajananajjajajajja PUERTO DE SANTAMARIA 2. Although you are right, murdering women and children throughout Spain was most unconstitutional, they should have only murdered in Basque countries. Guillotine, dog dead...\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.40 ms /    16 runs   (    0.65 ms per token,  1538.91 tokens per second)\n",
            "llama_print_timings: prompt eval time =     232.67 ms /    36 tokens (    6.46 ms per token,   154.72 tokens per second)\n",
            "llama_print_timings:        eval time =    1530.91 ms /    15 runs   (  102.06 ms per token,     9.80 tokens per second)\n",
            "llama_print_timings:       total time =    1907.11 ms /    51 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@real_Jepri @hugoesc31475407 Murdering women who knew and thought differently was Heresy\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.74 ms /    16 runs   (    0.73 ms per token,  1363.33 tokens per second)\n",
            "llama_print_timings: prompt eval time =     260.31 ms /    47 tokens (    5.54 ms per token,   180.56 tokens per second)\n",
            "llama_print_timings:        eval time =    1809.82 ms /    15 runs   (  120.65 ms per token,     8.29 tokens per second)\n",
            "llama_print_timings:       total time =    2273.35 ms /    62 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "A person with a mask passed by and I turned to see her because she looked attractive and it turned out that she was my ex, the sociologist, my God, why are you doing this to me?\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.83 ms /    16 runs   (    0.55 ms per token,  1812.42 tokens per second)\n",
            "llama_print_timings: prompt eval time =     245.05 ms /    34 tokens (    7.21 ms per token,   138.75 tokens per second)\n",
            "llama_print_timings:        eval time =    1532.88 ms /    15 runs   (  102.19 ms per token,     9.79 tokens per second)\n",
            "llama_print_timings:       total time =    1913.07 ms /    49 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@fuedicho FRIDA LAHLO, she was attractive, MEXICAN race ⭐👍🐾💜\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.84 ms /    16 runs   (    0.61 ms per token,  1626.18 tokens per second)\n",
            "llama_print_timings: prompt eval time =     254.76 ms /    57 tokens (    4.47 ms per token,   223.74 tokens per second)\n",
            "llama_print_timings:        eval time =    1587.68 ms /    15 runs   (  105.85 ms per token,     9.45 tokens per second)\n",
            "llama_print_timings:       total time =    2031.71 ms /    72 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@SperoniIris \".. about atomic energy in our country and the possibilities of creating electrical energy in isolated and low-population places.\" That is why electricity generated by nuclear energy is not attractive for private \"suppliers\": It restricts business ; obvious\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.04 ms /    16 runs   (    0.57 ms per token,  1769.13 tokens per second)\n",
            "llama_print_timings: prompt eval time =     244.21 ms /    36 tokens (    6.78 ms per token,   147.41 tokens per second)\n",
            "llama_print_timings:        eval time =    1695.63 ms /    15 runs   (  113.04 ms per token,     8.85 tokens per second)\n",
            "llama_print_timings:       total time =    2078.75 ms /    51 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Mercenary_Ignis Not bad... She's attractive, but they haven't spoken once.Pass... At least for the moment.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.89 ms /    16 runs   (    0.74 ms per token,  1345.90 tokens per second)\n",
            "llama_print_timings: prompt eval time =     263.53 ms /    53 tokens (    4.97 ms per token,   201.11 tokens per second)\n",
            "llama_print_timings:        eval time =    1755.22 ms /    15 runs   (  117.01 ms per token,     8.55 tokens per second)\n",
            "llama_print_timings:       total time =    2230.84 ms /    68 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Manchester United makes the hiring of Casemiro official: The Brazilian player will be an attractive card for Manchester United who is in crisis Manchester United has made... https://t.co/5NtTYVuZqd\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.28 ms /    16 runs   (    0.58 ms per token,  1724.51 tokens per second)\n",
            "llama_print_timings: prompt eval time =     247.58 ms /    44 tokens (    5.63 ms per token,   177.72 tokens per second)\n",
            "llama_print_timings:        eval time =    1578.91 ms /    15 runs   (  105.26 ms per token,     9.50 tokens per second)\n",
            "llama_print_timings:       total time =    1978.07 ms /    59 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "How beautiful. Are we going to do carpentry? At least make it attractive like the pottery in ghost. https://t.co/vXzwo2AkJr\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.03 ms /    16 runs   (    0.56 ms per token,  1771.48 tokens per second)\n",
            "llama_print_timings: prompt eval time =     257.02 ms /    42 tokens (    6.12 ms per token,   163.41 tokens per second)\n",
            "llama_print_timings:        eval time =    1562.11 ms /    15 runs   (  104.14 ms per token,     9.60 tokens per second)\n",
            "llama_print_timings:       total time =    1964.60 ms /    57 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "He only opens his mouth to say stupid things and embarrass all Peruvians. So they opened his cage.😡 https://t.co/RqmgOVImk6\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.08 ms /    16 runs   (    0.69 ms per token,  1443.78 tokens per second)\n",
            "llama_print_timings: prompt eval time =     246.20 ms /    54 tokens (    4.56 ms per token,   219.33 tokens per second)\n",
            "llama_print_timings:        eval time =    1607.72 ms /    15 runs   (  107.18 ms per token,     9.33 tokens per second)\n",
            "llama_print_timings:       total time =    2045.37 ms /    69 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@josecarmelopaz @MAVEDRO @CarlRamirezA Someday you will be ashamed of how you tried to justify your idolatry, let's wait for God's time\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.68 ms /    16 runs   (    0.61 ms per token,  1652.21 tokens per second)\n",
            "llama_print_timings: prompt eval time =     264.72 ms /    42 tokens (    6.30 ms per token,   158.66 tokens per second)\n",
            "llama_print_timings:        eval time =    1646.47 ms /    15 runs   (  109.76 ms per token,     9.11 tokens per second)\n",
            "llama_print_timings:       total time =    2152.24 ms /    57 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@exitosape Hahahaha instead of shaming, take out your claws, iden feline injured, that's how criminals are, they consider themselves offended\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.71 ms /    16 runs   (    0.61 ms per token,  1647.45 tokens per second)\n",
            "llama_print_timings: prompt eval time =     281.88 ms /    96 tokens (    2.94 ms per token,   340.58 tokens per second)\n",
            "llama_print_timings:        eval time =    1527.35 ms /    15 runs   (  101.82 ms per token,     9.82 tokens per second)\n",
            "llama_print_timings:       total time =    2110.19 ms /   111 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "They/Them (2022), another from the Blumhouse factory that is disguised as a slasher and a tribute to Friday the 13th including Kevin Bacon but which is an LGBTQIA+ pamphlet that would embarrass the community itself. The turd of the year. #movies #cinema #news #streaming https://t.co/b0wqKvcvPQ\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.12 ms /    16 runs   (    0.57 ms per token,  1753.62 tokens per second)\n",
            "llama_print_timings: prompt eval time =     725.33 ms /    30 tokens (   24.18 ms per token,    41.36 tokens per second)\n",
            "llama_print_timings:        eval time =    1548.60 ms /    15 runs   (  103.24 ms per token,     9.69 tokens per second)\n",
            "llama_print_timings:       total time =    2399.57 ms /    45 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "How we miss the previous first lady. She never gave cause for criticism. The crazy woman now only serves to embarrass Colombians\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.77 ms /    16 runs   (    0.74 ms per token,  1359.27 tokens per second)\n",
            "llama_print_timings: prompt eval time =     263.20 ms /    71 tokens (    3.71 ms per token,   269.76 tokens per second)\n",
            "llama_print_timings:        eval time =    1820.98 ms /    15 runs   (  121.40 ms per token,     8.24 tokens per second)\n",
            "llama_print_timings:       total time =    2459.74 ms /    86 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Xuxipc Fortunately, not all of us from Madrid are sympathizers of Miss IDA who acts as P d M with absurdities, nonsense, falsehoods and demagoguery, she is characterized because common sense is archived no one knows where and this is enough to embarrass some people from Madrid .\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.32 ms /    16 runs   (    0.58 ms per token,  1717.29 tokens per second)\n",
            "llama_print_timings: prompt eval time =     297.02 ms /   122 tokens (    2.43 ms per token,   410.75 tokens per second)\n",
            "llama_print_timings:        eval time =    1579.19 ms /    15 runs   (  105.28 ms per token,     9.50 tokens per second)\n",
            "llama_print_timings:       total time =    2250.52 ms /   137 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Zee made a joke and sneezed but then Nunew ignored Zee and said :🐱: \"I'll keep eating\" then Z got embarrassed and said 🐺: \"that hurts\" (which NN ignored his joke) and NN said 🐱: \"I'm just joking\" . It's so fucking cute.#VaminoxZeeNuNew#ZeeNuNew #ซนซน https://t.co/Dxua7DVMy6\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.55 ms /    16 runs   (    0.60 ms per token,  1674.52 tokens per second)\n",
            "llama_print_timings: prompt eval time =     259.37 ms /    84 tokens (    3.09 ms per token,   323.86 tokens per second)\n",
            "llama_print_timings:        eval time =    1629.84 ms /    15 runs   (  108.66 ms per token,     9.20 tokens per second)\n",
            "llama_print_timings:       total time =    2172.37 ms /    99 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@DIRECTVGOMXThe militancy of journalism transcends https://t.co/KB1U5GwEiZ FALSE information about Lula in DirectGoNews (Somos Latino América) embarrassed even the presenter, by comparing the \"persecution\" of Lula with Crist style: CLEPTOCRACIA@DIRECTVGO\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.84 ms /    16 runs   (    0.68 ms per token,  1476.56 tokens per second)\n",
            "llama_print_timings: prompt eval time =     278.45 ms /    77 tokens (    3.62 ms per token,   276.53 tokens per second)\n",
            "llama_print_timings:        eval time =    1717.04 ms /    15 runs   (  114.47 ms per token,     8.74 tokens per second)\n",
            "llama_print_timings:       total time =    2255.05 ms /    92 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@vladiskld I just broke my cell phone in anger. Salomón Villada (Ferxxo, Feid) embarrassed me in front of my family. My children are crying, scared by my anger as I walk around the room shaking. I can't stand this, call the police because I'm about to do something crazy.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.59 ms /    16 runs   (    0.60 ms per token,  1668.93 tokens per second)\n",
            "llama_print_timings: prompt eval time =     279.28 ms /    88 tokens (    3.17 ms per token,   315.09 tokens per second)\n",
            "llama_print_timings:        eval time =    1475.44 ms /    15 runs   (   98.36 ms per token,    10.17 tokens per second)\n",
            "llama_print_timings:       total time =    2020.92 ms /   103 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@SuperSecretario @Angelovenami End the patriarchal imposition of \"like a mother...\" I am a mother, I had a wonderful father and my old lady lives! Perhaps she never wanted to be a mother, or being the mother of a Peronist embarrassed her so much that she allied herself with her murderers. Mirta has a dead gay son + for her the same death!\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.50 ms /    16 runs   (    0.59 ms per token,  1684.03 tokens per second)\n",
            "llama_print_timings: prompt eval time =     283.37 ms /    98 tokens (    2.89 ms per token,   345.84 tokens per second)\n",
            "llama_print_timings:        eval time =    1660.00 ms /    15 runs   (  110.67 ms per token,     9.04 tokens per second)\n",
            "llama_print_timings:       total time =    2237.37 ms /   113 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@ElsaKekita @vivicanosaok It's Garbage. He blocked me because I told him the same thing..And that he always had MILEI who accompanied the F. From the book..👍..And BERNI. Last night I was laughing with the latter and it made me sick. I was waiting for the next program and he embarrassed me how he seduces him .. (Not as a journalist??) .. 👍\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.94 ms /    16 runs   (    0.62 ms per token,  1610.14 tokens per second)\n",
            "llama_print_timings: prompt eval time =     245.20 ms /    50 tokens (    4.90 ms per token,   203.91 tokens per second)\n",
            "llama_print_timings:        eval time =    1466.88 ms /    15 runs   (   97.79 ms per token,    10.23 tokens per second)\n",
            "llama_print_timings:       total time =    1886.82 ms /    65 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@palomaSnchez What if you told him that the secret is in the #Pack? Why do I imagine that she embarrassed you that a little girl without malice dreams of what you achieved in a humiliating way?\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.88 ms /    16 runs   (    0.62 ms per token,  1619.11 tokens per second)\n",
            "llama_print_timings: prompt eval time =     287.42 ms /    79 tokens (    3.64 ms per token,   274.86 tokens per second)\n",
            "llama_print_timings:        eval time =    1495.69 ms /    15 runs   (   99.71 ms per token,    10.03 tokens per second)\n",
            "llama_print_timings:       total time =    2177.37 ms /    94 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@SergioGaTorres What respect and tolerance you have, majete, stoning, whipping women, treating them like scum, executing gays and lesbians or slaughtering lambs with knives without slaughterhouses and without putting them to sleep, it's fabulous then, isn't it? Go shit on the road.\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.88 ms /    16 runs   (    0.62 ms per token,  1618.61 tokens per second)\n",
            "llama_print_timings: prompt eval time =     262.85 ms /    60 tokens (    4.38 ms per token,   228.26 tokens per second)\n",
            "llama_print_timings:        eval time =    1491.90 ms /    15 runs   (   99.46 ms per token,    10.05 tokens per second)\n",
            "llama_print_timings:       total time =    1953.05 ms /    75 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Is there a plan to dismember the Islamic states? So they will stop whipping women and hanging homosexuals, very good for both groups and congratulations to those who are promoting these plans https://t.co/5nCJy0JPiz\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.12 ms /    16 runs   (    0.57 ms per token,  1755.16 tokens per second)\n",
            "llama_print_timings: prompt eval time =     258.47 ms /    63 tokens (    4.10 ms per token,   243.74 tokens per second)\n",
            "llama_print_timings:        eval time =    1593.02 ms /    15 runs   (  106.20 ms per token,     9.42 tokens per second)\n",
            "llama_print_timings:       total time =    2048.89 ms /    78 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@judit_sinhache The one who doesn't like children or families is Pablo, or parks, or grandparents. Except for spanking women, he doesn't like anything. https://t.co/H0MgXqh4dR\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.43 ms /    16 runs   (    0.71 ms per token,  1399.46 tokens per second)\n",
            "llama_print_timings: prompt eval time =     252.98 ms /    36 tokens (    7.03 ms per token,   142.31 tokens per second)\n",
            "llama_print_timings:        eval time =    1727.21 ms /    15 runs   (  115.15 ms per token,     8.68 tokens per second)\n",
            "llama_print_timings:       total time =    2202.48 ms /    51 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Well, yours likes to spank women and his bosom friend loves to insult them... https://t.co/Hvmoxw9ejv\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.96 ms /    16 runs   (    0.56 ms per token,  1786.51 tokens per second)\n",
            "llama_print_timings: prompt eval time =     289.12 ms /    90 tokens (    3.21 ms per token,   311.29 tokens per second)\n",
            "llama_print_timings:        eval time =    1457.49 ms /    15 runs   (   97.17 ms per token,    10.29 tokens per second)\n",
            "llama_print_timings:       total time =    2021.86 ms /   105 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@SXTrece @Caputcomunismo @NoaGresiva Where do the Podemitas talk about having the cheapest electricity in Europe? 🤔🤔You were only talking about how with you in the government the electricity bill would go down and you have tripled it 😂😂😂😂It was another joke between colleagues, like the thing about spanking women 😭😭😭😭😭\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.45 ms /    16 runs   (    0.59 ms per token,  1692.41 tokens per second)\n",
            "llama_print_timings: prompt eval time =     266.54 ms /    64 tokens (    4.16 ms per token,   240.12 tokens per second)\n",
            "llama_print_timings:        eval time =    1547.58 ms /    15 runs   (  103.17 ms per token,     9.69 tokens per second)\n",
            "llama_print_timings:       total time =    2020.69 ms /    79 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@pvallin Ahmmmm…I don't know🤔🤔?? Can we??, well no, those are more about whipping women until they bleed...Bildu maybe?? Refining his old style of shot in the back of the head could very well be one of them\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.98 ms /    16 runs   (    0.62 ms per token,  1602.89 tokens per second)\n",
            "llama_print_timings: prompt eval time =     262.13 ms /    81 tokens (    3.24 ms per token,   309.00 tokens per second)\n",
            "llama_print_timings:        eval time =    1580.49 ms /    15 runs   (  105.37 ms per token,     9.49 tokens per second)\n",
            "llama_print_timings:       total time =    2098.71 ms /    96 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Great @borjateran touching on functional diversity and copyrights that are being forgotten. The 🏖️ is the space with the most diversity that exists but we must not forget the invisible barriers and those self-inflicted by many due to posting. #Livedejavivir https://t.co/UAr3Fcnn4S\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.95 ms /    16 runs   (    0.62 ms per token,  1608.04 tokens per second)\n",
            "llama_print_timings: prompt eval time =     262.82 ms /    50 tokens (    5.26 ms per token,   190.24 tokens per second)\n",
            "llama_print_timings:        eval time =    1550.56 ms /    15 runs   (  103.37 ms per token,     9.67 tokens per second)\n",
            "llama_print_timings:       total time =    2078.51 ms /    65 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "I think it's the first time we've used Peter in the city. Yes, there are invisible barriers to prevent us from going for a walk. https://t.co/lav9LGGS7U\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.91 ms /    16 runs   (    0.56 ms per token,  1795.74 tokens per second)\n",
            "llama_print_timings: prompt eval time =     262.35 ms /    77 tokens (    3.41 ms per token,   293.50 tokens per second)\n",
            "llama_print_timings:        eval time =    1609.21 ms /    15 runs   (  107.28 ms per token,     9.32 tokens per second)\n",
            "llama_print_timings:       total time =    2111.54 ms /    92 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@reseteo1234 Obviously, Meloni is just another case. There are millions of \"Melonis\". And \"Obamas\" too. The funny thing is that they are perceived as an \"example\", as an \"advance\". Invisible barriers have always existed, but they are only invisible to the eyes of an idiot.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.88 ms /    16 runs   (    0.56 ms per token,  1801.19 tokens per second)\n",
            "llama_print_timings: prompt eval time =     565.57 ms /    21 tokens (   26.93 ms per token,    37.13 tokens per second)\n",
            "llama_print_timings:        eval time =    1466.39 ms /    15 runs   (   97.76 ms per token,    10.23 tokens per second)\n",
            "llama_print_timings:       total time =    2137.84 ms /    36 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Sometimes we are stuck with invisible barriers created by our own mind.- David Villa\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.43 ms /    16 runs   (    0.59 ms per token,  1697.25 tokens per second)\n",
            "llama_print_timings: prompt eval time =     232.72 ms /    34 tokens (    6.84 ms per token,   146.10 tokens per second)\n",
            "llama_print_timings:        eval time =    1545.57 ms /    15 runs   (  103.04 ms per token,     9.71 tokens per second)\n",
            "llama_print_timings:       total time =    1917.88 ms /    49 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Invisible Barriers to Healthcare - Derek Prince - https://t.co/laLkgAhfL3 via @YouTube\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.35 ms /    16 runs   (    0.65 ms per token,  1546.49 tokens per second)\n",
            "llama_print_timings: prompt eval time =     278.63 ms /    72 tokens (    3.87 ms per token,   258.40 tokens per second)\n",
            "llama_print_timings:        eval time =    1536.73 ms /    15 runs   (  102.45 ms per token,     9.76 tokens per second)\n",
            "llama_print_timings:       total time =    2167.78 ms /    87 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "\"Women encounter invisible barriers that range from being a minority and not being within formal and informal networks of power\" -@RaquelLagunas_, @pnud Live: https://t.co/S7tdVTptbP https://t.co /Eu84YGVGSj\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.49 ms /    16 runs   (    0.59 ms per token,  1686.52 tokens per second)\n",
            "llama_print_timings: prompt eval time =     262.73 ms /    54 tokens (    4.87 ms per token,   205.54 tokens per second)\n",
            "llama_print_timings:        eval time =    1569.56 ms /    15 runs   (  104.64 ms per token,     9.56 tokens per second)\n",
            "llama_print_timings:       total time =    2009.75 ms /    69 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "If a fat girl uploads photos in a bikini it is \"Body positivity 🥰😍♥️\" but if a thin girl does the same it is \"promoting ED and harmful standards.\" Hypocrites fr.\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.56 ms /    16 runs   (    0.60 ms per token,  1674.34 tokens per second)\n",
            "llama_print_timings: prompt eval time =     267.12 ms /    57 tokens (    4.69 ms per token,   213.39 tokens per second)\n",
            "llama_print_timings:        eval time =    1531.48 ms /    15 runs   (  102.10 ms per token,     9.79 tokens per second)\n",
            "llama_print_timings:       total time =    1999.55 ms /    72 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@taamaraalvarado the body positivity that you talk about and promote so much, where is it? This is also body shaming. If a man says “I saw her tits and I stopped liking her” what would happen?\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       4.08 ms /     5 runs   (    0.82 ms per token,  1224.89 tokens per second)\n",
            "llama_print_timings: prompt eval time =     278.04 ms /    83 tokens (    3.35 ms per token,   298.52 tokens per second)\n",
            "llama_print_timings:        eval time =     449.62 ms /     4 runs   (  112.40 ms per token,     8.90 tokens per second)\n",
            "llama_print_timings:       total time =    1110.91 ms /    87 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@ArteMapacheArt a lot of noise against fatphobia, but it's good that they discriminate against a cripple. what's happening? Can't you let people remember that body positivity isn't just for fat buttery hamburgers who suffer from cardiac arrest? I spit on your intolerance 🖕\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.75 ms /    16 runs   (    0.61 ms per token,  1641.36 tokens per second)\n",
            "llama_print_timings: prompt eval time =     230.94 ms /    54 tokens (    4.28 ms per token,   233.82 tokens per second)\n",
            "llama_print_timings:        eval time =    1484.74 ms /    15 runs   (   98.98 ms per token,    10.10 tokens per second)\n",
            "llama_print_timings:       total time =    1896.30 ms /    69 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Body positivity until it is with very thin bodies. He doesn't have a TCA but if he did the worst thing you could do is comment on his body https://t.co/XWGO9CwS81\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.83 ms /    16 runs   (    0.55 ms per token,  1811.80 tokens per second)\n",
            "llama_print_timings: prompt eval time =     573.00 ms /    24 tokens (   23.87 ms per token,    41.89 tokens per second)\n",
            "llama_print_timings:        eval time =    1561.06 ms /    15 runs   (  104.07 ms per token,     9.61 tokens per second)\n",
            "llama_print_timings:       total time =    2246.17 ms /    39 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "It seems to me that much of the body positivity movement is pure toxic positivism.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       3.04 ms /     5 runs   (    0.61 ms per token,  1642.04 tokens per second)\n",
            "llama_print_timings: prompt eval time =     250.31 ms /    61 tokens (    4.10 ms per token,   243.69 tokens per second)\n",
            "llama_print_timings:        eval time =     438.03 ms /     4 runs   (  109.51 ms per token,     9.13 tokens per second)\n",
            "llama_print_timings:       total time =     837.96 ms /    65 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "This is what today's feminism creates, like the stupidity of body positivity... etc., a weak, glass society prepared for nothing because they are offended and feel bad about everything. https://t.co/gjQnP1wjKa\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.84 ms /    16 runs   (    0.55 ms per token,  1809.55 tokens per second)\n",
            "llama_print_timings: prompt eval time =     394.88 ms /    16 tokens (   24.68 ms per token,    40.52 tokens per second)\n",
            "llama_print_timings:        eval time =    1608.55 ms /    15 runs   (  107.24 ms per token,     9.33 tokens per second)\n",
            "llama_print_timings:       total time =    2101.96 ms /    31 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "wishing to move so I could go in panties\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.28 ms /    16 runs   (    0.58 ms per token,  1724.32 tokens per second)\n",
            "llama_print_timings: prompt eval time =     282.36 ms /    91 tokens (    3.10 ms per token,   322.29 tokens per second)\n",
            "llama_print_timings:        eval time =    1621.17 ms /    15 runs   (  108.08 ms per token,     9.25 tokens per second)\n",
            "llama_print_timings:       total time =    2175.49 ms /   106 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@CamelliaRosse @1971mame @maria_patino @sonsolesonega Hahahahaha super professional hahahahaha the roundabout that changes more minds than panties. The one who prefers to make a fool of herself than to work honestly. I study journalism to lie on a network where they don't let them give their opinion freely.\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.90 ms /    16 runs   (    0.56 ms per token,  1796.95 tokens per second)\n",
            "llama_print_timings: prompt eval time =     237.33 ms /    43 tokens (    5.52 ms per token,   181.19 tokens per second)\n",
            "llama_print_timings:        eval time =    1651.97 ms /    15 runs   (  110.13 ms per token,     9.08 tokens per second)\n",
            "llama_print_timings:       total time =    2040.03 ms /    58 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "CantabriaHumor is not running out of panties because they don't dry, apparently https://t.co/r4Zd0kRQgF\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.10 ms /    16 runs   (    0.57 ms per token,  1758.05 tokens per second)\n",
            "llama_print_timings: prompt eval time =     249.16 ms /    45 tokens (    5.54 ms per token,   180.61 tokens per second)\n",
            "llama_print_timings:        eval time =    1518.24 ms /    15 runs   (  101.22 ms per token,     9.88 tokens per second)\n",
            "llama_print_timings:       total time =    1920.69 ms /    60 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Can you stop calling being a shitty transphobe a mistake? that you have not tripped on the panties stall, you have broadcast a podcast aware of the hate speech that the guest has\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      14.64 ms /    16 runs   (    0.91 ms per token,  1093.12 tokens per second)\n",
            "llama_print_timings: prompt eval time =     260.68 ms /    45 tokens (    5.79 ms per token,   172.63 tokens per second)\n",
            "llama_print_timings:        eval time =    1836.32 ms /    15 runs   (  122.42 ms per token,     8.17 tokens per second)\n",
            "llama_print_timings:       total time =    2277.79 ms /    60 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Me: *I put on good panties because my period has already gone and I no longer stain* The period: https://t.co/wR0A00KmRu\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.30 ms /    16 runs   (    0.58 ms per token,  1719.69 tokens per second)\n",
            "llama_print_timings: prompt eval time =     269.87 ms /    64 tokens (    4.22 ms per token,   237.15 tokens per second)\n",
            "llama_print_timings:        eval time =    1477.65 ms /    15 runs   (   98.51 ms per token,    10.15 tokens per second)\n",
            "llama_print_timings:       total time =    1974.68 ms /    79 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Caliu_A Exactly. His shit is her money, not ours. If not, they'll even have to seize your panties or go to jail. Like any citizen. Aren't we all the same? Alas, let's take x ass\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.15 ms /    16 runs   (    0.57 ms per token,  1749.21 tokens per second)\n",
            "llama_print_timings: prompt eval time =     261.33 ms /    67 tokens (    3.90 ms per token,   256.38 tokens per second)\n",
            "llama_print_timings:        eval time =    1468.84 ms /    15 runs   (   97.92 ms per token,    10.21 tokens per second)\n",
            "llama_print_timings:       total time =    1942.20 ms /    82 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "International Report: Internet against climate change, isolation and the gender gap in the Great American #ChacoNews from #Chaco, #Tarija, #SantaCruz and #Bolivia| #ChacoReport https://t.co/SI7dCBKL0k\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.99 ms /    16 runs   (    0.62 ms per token,  1601.76 tokens per second)\n",
            "llama_print_timings: prompt eval time =     240.94 ms /    46 tokens (    5.24 ms per token,   190.92 tokens per second)\n",
            "llama_print_timings:        eval time =    1760.49 ms /    15 runs   (  117.37 ms per token,     8.52 tokens per second)\n",
            "llama_print_timings:       total time =    2189.28 ms /    61 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Happy day to the programmers and especially to the brave women programmers who have dared to enter a world with such a gender gap, so that the biases become less and less 💪🏻\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.55 ms /    16 runs   (    0.60 ms per token,  1675.74 tokens per second)\n",
            "llama_print_timings: prompt eval time =     283.41 ms /    93 tokens (    3.05 ms per token,   328.15 tokens per second)\n",
            "llama_print_timings:        eval time =    1483.67 ms /    15 runs   (   98.91 ms per token,    10.11 tokens per second)\n",
            "llama_print_timings:       total time =    2045.60 ms /   108 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "The gender gap does exist. The rate is higher in the lines of: microcredit, consumption and housing. It is incredible that women, who in most cases are in charge of the home economy, find themselves facing this policy of exclusion. Photo: @larepublica_co https://t.co/jkyVEOQiJD https://t.co/e10z5cwCdy\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.13 ms /    16 runs   (    0.57 ms per token,  1751.70 tokens per second)\n",
            "llama_print_timings: prompt eval time =     255.12 ms /    46 tokens (    5.55 ms per token,   180.31 tokens per second)\n",
            "llama_print_timings:        eval time =    1506.40 ms /    15 runs   (  100.43 ms per token,     9.96 tokens per second)\n",
            "llama_print_timings:       total time =    1915.34 ms /    61 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "From different shores we can also agree. Just as the previous points cause concern, I support continuing with public policies to close the gender gap, seeking greater labor participation and better income for #Women.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.95 ms /    16 runs   (    0.62 ms per token,  1608.85 tokens per second)\n",
            "llama_print_timings: prompt eval time =     254.39 ms /    62 tokens (    4.10 ms per token,   243.72 tokens per second)\n",
            "llama_print_timings:        eval time =    1714.66 ms /    15 runs   (  114.31 ms per token,     8.75 tokens per second)\n",
            "llama_print_timings:       total time =    2179.15 ms /    77 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Curiously, the gender gap in this issue is almost 100/100, but it seems not only to not matter, but it must be the right thing to do when progress is not funny. https://t.co/mbMfb6sOXT\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.25 ms /    16 runs   (    0.58 ms per token,  1730.29 tokens per second)\n",
            "llama_print_timings: prompt eval time =     293.57 ms /    84 tokens (    3.49 ms per token,   286.14 tokens per second)\n",
            "llama_print_timings:        eval time =    1625.84 ms /    15 runs   (  108.39 ms per token,     9.23 tokens per second)\n",
            "llama_print_timings:       total time =    2180.64 ms /    99 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "The gender gap in the technology sector is a reality in 2022... The percentage of #women specialized in #technology does not even reach 20%. 😞👉 https://t.co/TXeKXwlY7EVía: @nuevatribuna https://t.co/sklUUPfMJX\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.31 ms /    16 runs   (    0.58 ms per token,  1718.95 tokens per second)\n",
            "llama_print_timings: prompt eval time =     256.97 ms /    65 tokens (    3.95 ms per token,   252.95 tokens per second)\n",
            "llama_print_timings:        eval time =    1643.89 ms /    15 runs   (  109.59 ms per token,     9.12 tokens per second)\n",
            "llama_print_timings:       total time =    2112.71 ms /    80 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "At EDE Inclusive Employment we join the challenge of reducing the gender #DigitalGap with actions aimed at unemployed women: Introduction to computing and basic digital skills for employment, Social networks as a energizing tool,…https://t.co/82CVSVnzgR\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.47 ms /    16 runs   (    0.53 ms per token,  1889.47 tokens per second)\n",
            "llama_print_timings: prompt eval time =     240.48 ms /    34 tokens (    7.07 ms per token,   141.39 tokens per second)\n",
            "llama_print_timings:        eval time =    1520.88 ms /    15 runs   (  101.39 ms per token,     9.86 tokens per second)\n",
            "llama_print_timings:       total time =    1891.94 ms /    49 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Digital gender gap and the impact on eCommerce https://t.co/WlExxg2gKR #ecommerce\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.21 ms /    16 runs   (    0.58 ms per token,  1738.19 tokens per second)\n",
            "llama_print_timings: prompt eval time =     281.15 ms /    79 tokens (    3.56 ms per token,   280.99 tokens per second)\n",
            "llama_print_timings:        eval time =    1590.81 ms /    15 runs   (  106.05 ms per token,     9.43 tokens per second)\n",
            "llama_print_timings:       total time =    2113.56 ms /    94 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "📲 #TheCountryWeWant | More than 25% of Peruvian adolescents had to borrow a mobile device to access virtual classes, according to a Hiperderecho study. In the case of their male peers, the figure was 15%.https://t.co/yWDza7f8mN\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.37 ms /    16 runs   (    0.59 ms per token,  1707.94 tokens per second)\n",
            "llama_print_timings: prompt eval time =     272.36 ms /    77 tokens (    3.54 ms per token,   282.71 tokens per second)\n",
            "llama_print_timings:        eval time =    1508.16 ms /    15 runs   (  100.54 ms per token,     9.95 tokens per second)\n",
            "llama_print_timings:       total time =    2017.41 ms /    92 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Do you know what the digital gender gap is? There is a very low representation of women in the Internet world, so there is still a lot of work to do so that stereotypes in the digital world are defeated.https://t.co/US0tLovynG https://t.co/ GRJHBNaKjm\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.51 ms /    16 runs   (    0.72 ms per token,  1389.97 tokens per second)\n",
            "llama_print_timings: prompt eval time =     302.20 ms /    93 tokens (    3.25 ms per token,   307.74 tokens per second)\n",
            "llama_print_timings:        eval time =    1816.39 ms /    15 runs   (  121.09 ms per token,     8.26 tokens per second)\n",
            "llama_print_timings:       total time =    2612.37 ms /   108 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "#DesafíosPetroTIC “Change is with women,” says the government program of the new president of Colombia Gustavo Petro. But what are the challenges facing closing the digital gender gap? We tell you @MujeresTIC_Col &gt;&gt; https://t.co/6aUEN3iT6U https://t.co/LlKGYfSH1O\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.22 ms /    16 runs   (    0.58 ms per token,  1736.11 tokens per second)\n",
            "llama_print_timings: prompt eval time =     306.71 ms /   104 tokens (    2.95 ms per token,   339.08 tokens per second)\n",
            "llama_print_timings:        eval time =    1609.30 ms /    15 runs   (  107.29 ms per token,     9.32 tokens per second)\n",
            "llama_print_timings:       total time =    2234.44 ms /   119 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "📲 Do you need to learn digital tools for your entrepreneurship? We invite you to participate in the #TodasConectadas 👩🏻‍💻✨ Webinar led by @MinMujeryEG that will train you for free to reduce the digital gender gap🙌Sign up for 👉 https://t.co/uCGGPeQz9n https://t. co/ysSRuu8ZkB\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.56 ms /    16 runs   (    0.60 ms per token,  1672.94 tokens per second)\n",
            "llama_print_timings: prompt eval time =     259.17 ms /    60 tokens (    4.32 ms per token,   231.51 tokens per second)\n",
            "llama_print_timings:        eval time =    1534.71 ms /    15 runs   (  102.31 ms per token,     9.77 tokens per second)\n",
            "llama_print_timings:       total time =    1990.01 ms /    75 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "An alert that it raises is the large gap in the amounts of credit that are granted, to the detriment of women. Which has as one of the main causes the gender pay gap, which we must eradicate. There is no justification, only discrimination.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.30 ms /    16 runs   (    0.71 ms per token,  1415.55 tokens per second)\n",
            "llama_print_timings: prompt eval time =     293.20 ms /    84 tokens (    3.49 ms per token,   286.50 tokens per second)\n",
            "llama_print_timings:        eval time =    1711.88 ms /    15 runs   (  114.13 ms per token,     8.76 tokens per second)\n",
            "llama_print_timings:       total time =    2300.15 ms /    99 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Worry about the article that the @WSJ puts on the front page. The gender pay gap, a woman on average earns 30% less than a man doing EXACTLY the same thing. The issue with the note is that the study states that men earn twice as much right after leaving university. https://t.co/J5p4x3Ruz4\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.82 ms /    16 runs   (    0.61 ms per token,  1629.83 tokens per second)\n",
            "llama_print_timings: prompt eval time =     283.40 ms /    73 tokens (    3.88 ms per token,   257.59 tokens per second)\n",
            "llama_print_timings:        eval time =    1468.89 ms /    15 runs   (   97.93 ms per token,    10.21 tokens per second)\n",
            "llama_print_timings:       total time =    1990.09 ms /    88 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Vice President Karen Palma in an International Conversation within the framework of the celebration of the International Day of #EqualSalary. We reflect and share experiences around measures that contribute to reducing the gender wage gap.#SalaryTransparency♀️⚖️ https://t.co/DWe9EQpJzg\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.02 ms /    16 runs   (    0.63 ms per token,  1596.33 tokens per second)\n",
            "llama_print_timings: prompt eval time =     264.49 ms /    80 tokens (    3.31 ms per token,   302.47 tokens per second)\n",
            "llama_print_timings:        eval time =    1512.26 ms /    15 runs   (  100.82 ms per token,     9.92 tokens per second)\n",
            "llama_print_timings:       total time =    2043.38 ms /    95 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "In Quintana Roo, @LuisaAlcalde, head of the @STPS_mx mentioned that there is a wage gap of up to 18% and to combat this behavior a transparent message must be given, because it allows companies to identify the situation and change it.https://t .co/DLlh7Nn3Ff\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.94 ms /    16 runs   (    0.68 ms per token,  1463.06 tokens per second)\n",
            "llama_print_timings: prompt eval time =     269.91 ms /    67 tokens (    4.03 ms per token,   248.23 tokens per second)\n",
            "llama_print_timings:        eval time =    1775.20 ms /    15 runs   (  118.35 ms per token,     8.45 tokens per second)\n",
            "llama_print_timings:       total time =    2281.83 ms /    82 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "We must put an end to job insecurity. This implies a minimum living wage, a living and decent wage and job stability, a transition towards a more equitable pension system; reduce the gender pay gap. This will be the change. https://t.co/zsySfj5VCm\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.69 ms /    16 runs   (    0.54 ms per token,  1842.26 tokens per second)\n",
            "llama_print_timings: prompt eval time =     250.25 ms /    48 tokens (    5.21 ms per token,   191.81 tokens per second)\n",
            "llama_print_timings:        eval time =    1613.35 ms /    15 runs   (  107.56 ms per token,     9.30 tokens per second)\n",
            "llama_print_timings:       total time =    2035.79 ms /    63 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Concaem promotes reducing the gender wage gap and the state care systemhttps://t.co/CkKjrnNRHu https://t.co/MejPKo1255\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.79 ms /    16 runs   (    0.55 ms per token,  1819.84 tokens per second)\n",
            "llama_print_timings: prompt eval time =     561.75 ms /    32 tokens (   17.55 ms per token,    56.96 tokens per second)\n",
            "llama_print_timings:        eval time =    1609.11 ms /    15 runs   (  107.27 ms per token,     9.32 tokens per second)\n",
            "llama_print_timings:       total time =    2298.28 ms /    47 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Every time I see a player with a striking last name I think about the bullying that may have been done to him at school.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.63 ms /    16 runs   (    0.54 ms per token,  1853.78 tokens per second)\n",
            "llama_print_timings: prompt eval time =     238.92 ms /    42 tokens (    5.69 ms per token,   175.79 tokens per second)\n",
            "llama_print_timings:        eval time =    1506.80 ms /    15 runs   (  100.45 ms per token,     9.95 tokens per second)\n",
            "llama_print_timings:       total time =    1890.87 ms /    57 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@sboric Why are you bullying your shitty brother ❓😈😂😂 https://t.co/JG0OKIJIkB\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.98 ms /    16 runs   (    0.69 ms per token,  1456.53 tokens per second)\n",
            "llama_print_timings: prompt eval time =     290.34 ms /    87 tokens (    3.34 ms per token,   299.65 tokens per second)\n",
            "llama_print_timings:        eval time =    1725.63 ms /    15 runs   (  115.04 ms per token,     8.69 tokens per second)\n",
            "llama_print_timings:       total time =    2461.06 ms /   102 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@mery_soldier @bryanmozz98 @eldiariodedross It's like at school, if they bully you you should let them bully you, you can't defend yourself. Stop screwing around, if someone attacks you you have to respond in equal proportion. Whether at 7 years old or 40 years old, never leave anyone behind.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.45 ms /    16 runs   (    0.59 ms per token,  1693.12 tokens per second)\n",
            "llama_print_timings: prompt eval time =     260.11 ms /    53 tokens (    4.91 ms per token,   203.76 tokens per second)\n",
            "llama_print_timings:        eval time =    1518.12 ms /    15 runs   (  101.21 ms per token,     9.88 tokens per second)\n",
            "llama_print_timings:       total time =    1951.68 ms /    68 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@patyvasquez @taylorswift13 Hahaha, thank you very much 🥰 and yes, to be able to defend ourselves from the fourteen-year-olds who bully us seniors 😂\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.61 ms /    16 runs   (    0.60 ms per token,  1665.11 tokens per second)\n",
            "llama_print_timings: prompt eval time =     239.76 ms /    47 tokens (    5.10 ms per token,   196.03 tokens per second)\n",
            "llama_print_timings:        eval time =    1556.81 ms /    15 runs   (  103.79 ms per token,     9.64 tokens per second)\n",
            "llama_print_timings:       total time =    1953.42 ms /    62 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@YosiWright Everyone * bullies him because of how tall he is * Yose remembering that good things come in small packages: https://t.co/GcUzxEjqG6\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.43 ms /    16 runs   (    0.65 ms per token,  1534.77 tokens per second)\n",
            "llama_print_timings: prompt eval time =     276.58 ms /    87 tokens (    3.18 ms per token,   314.55 tokens per second)\n",
            "llama_print_timings:        eval time =    1649.99 ms /    15 runs   (  110.00 ms per token,     9.09 tokens per second)\n",
            "llama_print_timings:       total time =    2212.94 ms /   102 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "In the Colombian, this video came out. Last year, before arriving in Congress, @ISAZULETA assured in the middle of a council that citizens can call State officials \"MOUNTS.\" Today that she is a senator, she says that she is exposed to \"media bullying\" 🤣🤣🤣🤣🤣 https://t.co/vhAcaNGMKv\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.62 ms /    16 runs   (    0.54 ms per token,  1856.79 tokens per second)\n",
            "llama_print_timings: prompt eval time =     527.57 ms /    32 tokens (   16.49 ms per token,    60.66 tokens per second)\n",
            "llama_print_timings:        eval time =    1557.18 ms /    15 runs   (  103.81 ms per token,     9.63 tokens per second)\n",
            "llama_print_timings:       total time =    2215.14 ms /    47 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@fresitagooner First of all, you need hips to help you, and coincidentally I can do it~\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.91 ms /    16 runs   (    0.56 ms per token,  1796.54 tokens per second)\n",
            "llama_print_timings: prompt eval time =     235.18 ms /    39 tokens (    6.03 ms per token,   165.83 tokens per second)\n",
            "llama_print_timings:        eval time =    1503.24 ms /    15 runs   (  100.22 ms per token,     9.98 tokens per second)\n",
            "llama_print_timings:       total time =    1884.27 ms /    54 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Today a man decided to wear a cream suit with a pink shirt to move his hips and I couldn't think about anything else for the rest of the day.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.81 ms /    16 runs   (    0.55 ms per token,  1815.09 tokens per second)\n",
            "llama_print_timings: prompt eval time =     486.36 ms /    20 tokens (   24.32 ms per token,    41.12 tokens per second)\n",
            "llama_print_timings:        eval time =    1486.13 ms /    15 runs   (   99.08 ms per token,    10.09 tokens per second)\n",
            "llama_print_timings:       total time =    2076.44 ms /    35 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "That movement of hips with Karolg G in the background is very delicious\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.95 ms /    16 runs   (    0.68 ms per token,  1461.05 tokens per second)\n",
            "llama_print_timings: prompt eval time =     253.86 ms /    56 tokens (    4.53 ms per token,   220.59 tokens per second)\n",
            "llama_print_timings:        eval time =    1789.81 ms /    15 runs   (  119.32 ms per token,     8.38 tokens per second)\n",
            "llama_print_timings:       total time =    2256.66 ms /    71 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Vendetta1313_ Because they don't know that women's brains look for that prototype since it is indicative of good nutrition and health, just as a woman with wide hips is indicative of health and fertility.\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.42 ms /    16 runs   (    0.59 ms per token,  1697.97 tokens per second)\n",
            "llama_print_timings: prompt eval time =     283.34 ms /    67 tokens (    4.23 ms per token,   236.47 tokens per second)\n",
            "llama_print_timings:        eval time =    1521.23 ms /    15 runs   (  101.42 ms per token,     9.86 tokens per second)\n",
            "llama_print_timings:       total time =    2015.20 ms /    82 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "When I read that \"just to remind you that your boyfriend may be biting his coworker's hips and she laughs every time he does it\" it makes me angry because I imagine that situation and it's horrible 🤣🫣💆🏻 ‍♀️\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.33 ms /    16 runs   (    0.52 ms per token,  1921.23 tokens per second)\n",
            "llama_print_timings: prompt eval time =     712.33 ms /    29 tokens (   24.56 ms per token,    40.71 tokens per second)\n",
            "llama_print_timings:        eval time =    1479.89 ms /    15 runs   (   98.66 ms per token,    10.14 tokens per second)\n",
            "llama_print_timings:       total time =    2317.06 ms /    44 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Horseback riding you wanted momu then your hips hurt and you don't know why 😂😂😂😂\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.91 ms /    16 runs   (    0.56 ms per token,  1795.33 tokens per second)\n",
            "llama_print_timings: prompt eval time =     234.08 ms /    37 tokens (    6.33 ms per token,   158.07 tokens per second)\n",
            "llama_print_timings:        eval time =    1475.88 ms /    15 runs   (   98.39 ms per token,    10.16 tokens per second)\n",
            "llama_print_timings:       total time =    1852.94 ms /    52 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@jairocalixto sensei, did you ask the chacha?? https://t.co/BG8kdrOzOd\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.42 ms /    16 runs   (    0.65 ms per token,  1535.36 tokens per second)\n",
            "llama_print_timings: prompt eval time =     282.42 ms /    81 tokens (    3.49 ms per token,   286.80 tokens per second)\n",
            "llama_print_timings:        eval time =    1767.20 ms /    15 runs   (  117.81 ms per token,     8.49 tokens per second)\n",
            "llama_print_timings:       total time =    2471.48 ms /    96 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "It must have made her feel bad because she yelled at me that she wasn't anyone's chacha and that she wasn't going to empty other people's trash. (Ok) I asked her if she didn't mind the smell. She has responded to me, also shouting, that yes but out of pride she has not done it (Ok)\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.61 ms /    16 runs   (    0.54 ms per token,  1858.95 tokens per second)\n",
            "llama_print_timings: prompt eval time =     485.47 ms /    20 tokens (   24.27 ms per token,    41.20 tokens per second)\n",
            "llama_print_timings:        eval time =    1551.67 ms /    15 runs   (  103.44 ms per token,     9.67 tokens per second)\n",
            "llama_print_timings:       total time =    2143.00 ms /    35 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "I highly recommend the white chicken pizza at La Chacha😍😍😍\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.82 ms /    16 runs   (    0.55 ms per token,  1814.88 tokens per second)\n",
            "llama_print_timings: prompt eval time =     239.02 ms /    33 tokens (    7.24 ms per token,   138.06 tokens per second)\n",
            "llama_print_timings:        eval time =    1545.21 ms /    15 runs   (  103.01 ms per token,     9.71 tokens per second)\n",
            "llama_print_timings:       total time =    1927.60 ms /    48 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Dj_OnixIce @Bragi_Gunlod First stop calling her chacha! Ridiculous\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.76 ms /    16 runs   (    0.61 ms per token,  1639.01 tokens per second)\n",
            "llama_print_timings: prompt eval time =     638.97 ms /    24 tokens (   26.62 ms per token,    37.56 tokens per second)\n",
            "llama_print_timings:        eval time =    1601.21 ms /    15 runs   (  106.75 ms per token,     9.37 tokens per second)\n",
            "llama_print_timings:       total time =    2365.08 ms /    39 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@AydannaA Chacha really yes, that must be upside down over there.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.59 ms /    16 runs   (    0.54 ms per token,  1863.28 tokens per second)\n",
            "llama_print_timings: prompt eval time =     260.65 ms /    42 tokens (    6.21 ms per token,   161.13 tokens per second)\n",
            "llama_print_timings:        eval time =    1551.19 ms /    15 runs   (  103.41 ms per token,     9.67 tokens per second)\n",
            "llama_print_timings:       total time =    2032.40 ms /    57 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "I LOVE ✨✨chabuya👏👏 chacha 👏Chabuya👏 https://t.co/24KsX2CIHv\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.29 ms /    16 runs   (    0.58 ms per token,  1722.10 tokens per second)\n",
            "llama_print_timings: prompt eval time =     244.56 ms /    51 tokens (    4.80 ms per token,   208.54 tokens per second)\n",
            "llama_print_timings:        eval time =    1584.87 ms /    15 runs   (  105.66 ms per token,     9.46 tokens per second)\n",
            "llama_print_timings:       total time =    1998.79 ms /    66 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Oh guys, I was a fan of fixed gear when I was a girl, I even have a photo with some cool glasses and now my childhood was ruined in seconds https://t.co/NAlkI9ifBT\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.63 ms /    16 runs   (    0.60 ms per token,  1661.82 tokens per second)\n",
            "llama_print_timings: prompt eval time =     279.74 ms /    72 tokens (    3.89 ms per token,   257.38 tokens per second)\n",
            "llama_print_timings:        eval time =    1513.75 ms /    15 runs   (  100.92 ms per token,     9.91 tokens per second)\n",
            "llama_print_timings:       total time =    2020.33 ms /    87 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@mike93d @EnMexicoMagico Shut up, don bitterness, we're talking about the support of friends in the face of the girl's rejection, obviously it's a big deal to be told yes or no... That's the least of it😌\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.27 ms /    16 runs   (    0.64 ms per token,  1557.33 tokens per second)\n",
            "llama_print_timings: prompt eval time =     598.81 ms /    28 tokens (   21.39 ms per token,    46.76 tokens per second)\n",
            "llama_print_timings:        eval time =    1831.24 ms /    15 runs   (  122.08 ms per token,     8.19 tokens per second)\n",
            "llama_print_timings:       total time =    2579.12 ms /    43 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "The unattainable beautiful girl on my fb gave a lot of hearts to my story omg 💖\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.11 ms /    16 runs   (    0.51 ms per token,  1973.36 tokens per second)\n",
            "llama_print_timings: prompt eval time =     259.15 ms /    62 tokens (    4.18 ms per token,   239.25 tokens per second)\n",
            "llama_print_timings:        eval time =    1568.05 ms /    15 runs   (  104.54 ms per token,     9.57 tokens per second)\n",
            "llama_print_timings:       total time =    2022.57 ms /    77 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "A couple stopped next to me and he kept saying romantic things in my ear, they thought no one was listening to them but I was there with my ears very sharp until the girl said can we talk about this somewhere else? hahaha thanks sister because it even gave me cringe\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.53 ms /    16 runs   (    0.60 ms per token,  1678.91 tokens per second)\n",
            "llama_print_timings: prompt eval time =     255.40 ms /    54 tokens (    4.73 ms per token,   211.44 tokens per second)\n",
            "llama_print_timings:        eval time =    1485.81 ms /    15 runs   (   99.05 ms per token,    10.10 tokens per second)\n",
            "llama_print_timings:       total time =    1916.75 ms /    69 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "There was a girl who uploaded videos of how she gave gifts to her friend so that when she woke up from a coma she would see them and two hours ago she uploaded one saying goodbye to her :( I'm sad\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.30 ms /    16 runs   (    0.58 ms per token,  1720.06 tokens per second)\n",
            "llama_print_timings: prompt eval time =     275.51 ms /    81 tokens (    3.40 ms per token,   294.00 tokens per second)\n",
            "llama_print_timings:        eval time =    1523.17 ms /    15 runs   (  101.55 ms per token,     9.85 tokens per second)\n",
            "llama_print_timings:       total time =    2043.45 ms /    96 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Wow, I was really sad today and I went shopping for clothes. After 15 minutes the girl from the showroom sends me a message and she tells me if she could return the jacket I bought because she had already sold it and had forgotten to take it down from the coat rack🤦🏻‍♀️I'm just sad 🤷 🏻‍♀️\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.60 ms /    16 runs   (    0.66 ms per token,  1508.86 tokens per second)\n",
            "llama_print_timings: prompt eval time =     247.94 ms /    38 tokens (    6.52 ms per token,   153.26 tokens per second)\n",
            "llama_print_timings:        eval time =    1776.98 ms /    15 runs   (  118.47 ms per token,     8.44 tokens per second)\n",
            "llama_print_timings:       total time =    2194.52 ms /    53 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@patrigarx YES, she had so many tickets that the other girls could have gone with their boyfriends, and they still would have had left over\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.84 ms /    16 runs   (    0.55 ms per token,  1810.36 tokens per second)\n",
            "llama_print_timings: prompt eval time =     593.31 ms /    24 tokens (   24.72 ms per token,    40.45 tokens per second)\n",
            "llama_print_timings:        eval time =    1484.33 ms /    15 runs   (   98.96 ms per token,    10.11 tokens per second)\n",
            "llama_print_timings:       total time =    2195.16 ms /    39 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Seriously, girls, how ugly your boyfriends are, leave them and come with me!\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.68 ms /    16 runs   (    0.60 ms per token,  1653.06 tokens per second)\n",
            "llama_print_timings: prompt eval time =     251.89 ms /    58 tokens (    4.34 ms per token,   230.26 tokens per second)\n",
            "llama_print_timings:        eval time =    1557.14 ms /    15 runs   (  103.81 ms per token,     9.63 tokens per second)\n",
            "llama_print_timings:       total time =    1996.70 ms /    73 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "👏 👏👏Surely, except Papa and daddy 2, we will see them all....the desire and the plot can't help us, right girls? @milyundrama @vanesappantoja @doramatrica\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.00 ms /    16 runs   (    0.56 ms per token,  1777.98 tokens per second)\n",
            "llama_print_timings: prompt eval time =     505.90 ms /    20 tokens (   25.30 ms per token,    39.53 tokens per second)\n",
            "llama_print_timings:        eval time =    1440.27 ms /    15 runs   (   96.02 ms per token,    10.41 tokens per second)\n",
            "llama_print_timings:       total time =    2048.34 ms /    35 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Do girls whose eyes roll up when they smile know how perfect they are?\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      13.51 ms /    16 runs   (    0.84 ms per token,  1184.66 tokens per second)\n",
            "llama_print_timings: prompt eval time =     268.70 ms /    70 tokens (    3.84 ms per token,   260.51 tokens per second)\n",
            "llama_print_timings:        eval time =    1841.64 ms /    15 runs   (  122.78 ms per token,     8.14 tokens per second)\n",
            "llama_print_timings:       total time =    2480.29 ms /    85 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@SonicOne1769 @mateo1209 @orlando80020928 @Mastergabri1 @BigNewsOP Sanji trains his observation haki every day by detecting girls. She has the most advanced radar of the crew when it comes to women.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.13 ms /    16 runs   (    0.57 ms per token,  1752.66 tokens per second)\n",
            "llama_print_timings: prompt eval time =     251.20 ms /    35 tokens (    7.18 ms per token,   139.33 tokens per second)\n",
            "llama_print_timings:        eval time =    1614.52 ms /    15 runs   (  107.63 ms per token,     9.29 tokens per second)\n",
            "llama_print_timings:       total time =    2002.02 ms /    50 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Team of the doctor and the girls agree on one thing, fora Thomas fora Shay 🤝 #AFazenda14\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.07 ms /    16 runs   (    0.63 ms per token,  1588.72 tokens per second)\n",
            "llama_print_timings: prompt eval time =     380.59 ms /   134 tokens (    2.84 ms per token,   352.08 tokens per second)\n",
            "llama_print_timings:        eval time =    1632.33 ms /    15 runs   (  108.82 ms per token,     9.19 tokens per second)\n",
            "llama_print_timings:       total time =    2421.30 ms /   149 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "#104 c.showing their talent and popularity🔥#BTS #ARMY ✅️#JIN at the Korean Open Tennis Tournament🎾 Eugene Investment &amp; Securities 2022.New talent unlocked🔓🏅 ✅️#TAEHYUNG updated profile, BELLA📸with a great message behind \"Enough🚫 with cyberbullying\" (2.016💋)↘️ https://t.co/nNZIMmF6uF\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.22 ms /    16 runs   (    0.64 ms per token,  1565.25 tokens per second)\n",
            "llama_print_timings: prompt eval time =     250.79 ms /    57 tokens (    4.40 ms per token,   227.29 tokens per second)\n",
            "llama_print_timings:        eval time =    1522.53 ms /    15 runs   (  101.50 ms per token,     9.85 tokens per second)\n",
            "llama_print_timings:       total time =    1961.76 ms /    72 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "In MY point of view, there is more cyberbullying here on Twitter for @EVillegasV than anything else, for the issue of equal marriage. copy-past tweets 🫣 and it's disastrous....\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.63 ms /    16 runs   (    0.66 ms per token,  1504.75 tokens per second)\n",
            "llama_print_timings: prompt eval time =     274.77 ms /    78 tokens (    3.52 ms per token,   283.88 tokens per second)\n",
            "llama_print_timings:        eval time =    1687.93 ms /    15 runs   (  112.53 ms per token,     8.89 tokens per second)\n",
            "llama_print_timings:       total time =    2353.86 ms /    93 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@dekishira_ @mariocarreteroo okay but that mistake is called cyberbullying and surely the girl to whom you dedicated the thread right now is very screwed while the girl you are trying to defend, who will already be old enough to know how to publicly humiliate someone It's terrible, it will be so good\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.79 ms /    16 runs   (    0.55 ms per token,  1821.08 tokens per second)\n",
            "llama_print_timings: prompt eval time =     532.89 ms /    32 tokens (   16.65 ms per token,    60.05 tokens per second)\n",
            "llama_print_timings:        eval time =    1472.33 ms /    15 runs   (   98.16 ms per token,    10.19 tokens per second)\n",
            "llama_print_timings:       total time =    2136.24 ms /    47 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Freedom of expression faced 415 attacks, reveals report https://t.co/2zwmGXSO8F\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.54 ms /    16 runs   (    0.60 ms per token,  1678.03 tokens per second)\n",
            "llama_print_timings: prompt eval time =     266.27 ms /    98 tokens (    2.72 ms per token,   368.05 tokens per second)\n",
            "llama_print_timings:        eval time =    1499.99 ms /    15 runs   (  100.00 ms per token,    10.00 tokens per second)\n",
            "llama_print_timings:       total time =    2062.85 ms /   113 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "➡️New entry in #BlogDeBibliotecas by @educaciongob to present the latest issue of the Education Magazine, whose monograph is dedicated to #cyberbullying, an educational, social and health problem.👉Consult the blog and access the articles: https:/ /t.co/yUErf1e3T5 https://t.co/v4qXRz8vYZ\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.07 ms /    16 runs   (    0.69 ms per token,  1445.48 tokens per second)\n",
            "llama_print_timings: prompt eval time =     246.64 ms /    57 tokens (    4.33 ms per token,   231.11 tokens per second)\n",
            "llama_print_timings:        eval time =    1500.35 ms /    15 runs   (  100.02 ms per token,    10.00 tokens per second)\n",
            "llama_print_timings:       total time =    1929.65 ms /    72 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "DPO&amp;itlaw DTI News is available! https://t.co/cZ6gkmiT4p Thanks to @OfeTG @ricardmm @identidadrobada #cyberbullying #crime\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.34 ms /    16 runs   (    0.65 ms per token,  1547.69 tokens per second)\n",
            "llama_print_timings: prompt eval time =     251.69 ms /    38 tokens (    6.62 ms per token,   150.98 tokens per second)\n",
            "llama_print_timings:        eval time =    1684.28 ms /    15 runs   (  112.29 ms per token,     8.91 tokens per second)\n",
            "llama_print_timings:       total time =    2162.99 ms /    53 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Trans women DO NOT want to erase cisgender women and trans men are NOT traitors.https://t.co/RSuCOTFrYi\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.62 ms /    16 runs   (    0.60 ms per token,  1663.20 tokens per second)\n",
            "llama_print_timings: prompt eval time =     253.84 ms /    60 tokens (    4.23 ms per token,   236.37 tokens per second)\n",
            "llama_print_timings:        eval time =    1555.13 ms /    15 runs   (  103.68 ms per token,     9.65 tokens per second)\n",
            "llama_print_timings:       total time =    2012.31 ms /    75 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "There was constant poor attention from management to the area where I worked and the demands were maximum. They hired people to support us with a new menu, and this is not to exclude, but they were cisgender people who did not make me feel safe in collaboration. ...\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.78 ms /    16 runs   (    0.61 ms per token,  1636.33 tokens per second)\n",
            "llama_print_timings: prompt eval time =     256.83 ms /    48 tokens (    5.35 ms per token,   186.90 tokens per second)\n",
            "llama_print_timings:        eval time =    1519.64 ms /    15 runs   (  101.31 ms per token,     9.87 tokens per second)\n",
            "llama_print_timings:       total time =    1951.59 ms /    63 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "The survey item does not discriminate between men and women, but rather between cisgender and other identities. It's not that difficult. https://t.co/KDbSmStf4u\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      12.39 ms /    16 runs   (    0.77 ms per token,  1291.05 tokens per second)\n",
            "llama_print_timings: prompt eval time =     291.13 ms /    88 tokens (    3.31 ms per token,   302.27 tokens per second)\n",
            "llama_print_timings:        eval time =    1784.79 ms /    15 runs   (  118.99 ms per token,     8.40 tokens per second)\n",
            "llama_print_timings:       total time =    2553.44 ms /   103 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@pachusaenzcavia @Karenfiorellanv that means pigeonholing bad people only because they are cisgender 🤔is that also re? blaming others, victimizing yourself, eg: everyone is bad. Accept that you allowed everything they did to you and that you obviously chose wrong. learn from that, don't lock yourself in, they are all bad\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.25 ms /    16 runs   (    0.58 ms per token,  1728.98 tokens per second)\n",
            "llama_print_timings: prompt eval time =     259.90 ms /    57 tokens (    4.56 ms per token,   219.31 tokens per second)\n",
            "llama_print_timings:        eval time =    1533.15 ms /    15 runs   (  102.21 ms per token,     9.78 tokens per second)\n",
            "llama_print_timings:       total time =    1980.43 ms /    72 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Well nothing, literally having an anxiety attack because I have written that abortion is an experience that cisgender women go through when I wanted to say what NOT ONLY cisgender women go through or what AFAB people go through. How was your Friday?\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.75 ms /    16 runs   (    0.55 ms per token,  1827.94 tokens per second)\n",
            "llama_print_timings: prompt eval time =     247.36 ms /    36 tokens (    6.87 ms per token,   145.54 tokens per second)\n",
            "llama_print_timings:        eval time =    1656.19 ms /    15 runs   (  110.41 ms per token,     9.06 tokens per second)\n",
            "llama_print_timings:       total time =    2043.45 ms /    51 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@pedrovillakan Because I am cis and I am lesbian. Being Cisgender is identifying with the sex you were born with.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.74 ms /    16 runs   (    0.73 ms per token,  1362.51 tokens per second)\n",
            "llama_print_timings: prompt eval time =     291.51 ms /    89 tokens (    3.28 ms per token,   305.31 tokens per second)\n",
            "llama_print_timings:        eval time =    1856.03 ms /    15 runs   (  123.74 ms per token,     8.08 tokens per second)\n",
            "llama_print_timings:       total time =    2459.73 ms /   104 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "I remind you that we have a Co-education Congress with CLAVICO on October 1 and 2. If you've never come to one of our conferences, you don't know what you're missing. They are special conferences, sign up, you won't regret it. All the info at: https://t.co/OrA9tm0fi2\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.27 ms /    16 runs   (    0.58 ms per token,  1726.93 tokens per second)\n",
            "llama_print_timings: prompt eval time =     258.12 ms /    59 tokens (    4.37 ms per token,   228.58 tokens per second)\n",
            "llama_print_timings:        eval time =    1535.19 ms /    15 runs   (  102.35 ms per token,     9.77 tokens per second)\n",
            "llama_print_timings:       total time =    1985.68 ms /    74 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "You don't have to (transform) anything, you don't need to invent anything new, the solution is COEDUCATION, this is how you educate in equality 🙌🙌https://t.co/487EMu5ZAl\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.05 ms /    16 runs   (    0.63 ms per token,  1592.36 tokens per second)\n",
            "llama_print_timings: prompt eval time =     275.94 ms /    67 tokens (    4.12 ms per token,   242.81 tokens per second)\n",
            "llama_print_timings:        eval time =    1547.37 ms /    15 runs   (  103.16 ms per token,     9.69 tokens per second)\n",
            "llama_print_timings:       total time =    2042.76 ms /    82 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@IreneMontero That law is stupid. Do women who wantonly fuck with their partners, those who care for them, etc. say no? Submission is consented. What needs to be done is to educate in rebellion and feminism. Coeducation and not trans laws\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.99 ms /    16 runs   (    0.75 ms per token,  1334.78 tokens per second)\n",
            "llama_print_timings: prompt eval time =     277.43 ms /    80 tokens (    3.47 ms per token,   288.36 tokens per second)\n",
            "llama_print_timings:        eval time =    1846.65 ms /    15 runs   (  123.11 ms per token,     8.12 tokens per second)\n",
            "llama_print_timings:       total time =    2399.84 ms /    95 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "📅📅 Are you looking forward to a conference? In October the @IAMJunta 🚺🚺 organizes the third Andalusian congress of #Coeducation in #Cádiz📕📕 https://t.co/NBMq4PI8cw\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.87 ms /    16 runs   (    0.62 ms per token,  1621.24 tokens per second)\n",
            "llama_print_timings: prompt eval time =     267.73 ms /    60 tokens (    4.46 ms per token,   224.11 tokens per second)\n",
            "llama_print_timings:        eval time =    1519.64 ms /    15 runs   (  101.31 ms per token,     9.87 tokens per second)\n",
            "llama_print_timings:       total time =    1990.19 ms /    75 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Feminists will not remain silent. We do not allow you to pornify minors. Real coeducation now! We will continue to denounce the queer anti-feminist agendahttps://t.co/E6RiHRaIMb\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.77 ms /    16 runs   (    0.61 ms per token,  1637.67 tokens per second)\n",
            "llama_print_timings: prompt eval time =     261.30 ms /    51 tokens (    5.12 ms per token,   195.18 tokens per second)\n",
            "llama_print_timings:        eval time =    1487.07 ms /    15 runs   (   99.14 ms per token,    10.09 tokens per second)\n",
            "llama_print_timings:       total time =    1918.54 ms /    66 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "The workshop taught by Ana Magallanes on Coeducation to Prevent Sexist Violence begins 👀 @Gabifcom @unisevilla https://t.co/TAO6GvrOWm\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.73 ms /    16 runs   (    0.61 ms per token,  1643.89 tokens per second)\n",
            "llama_print_timings: prompt eval time =     274.03 ms /    75 tokens (    3.65 ms per token,   273.70 tokens per second)\n",
            "llama_print_timings:        eval time =    1581.32 ms /    15 runs   (  105.42 ms per token,     9.49 tokens per second)\n",
            "llama_print_timings:       total time =    2093.24 ms /    90 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@zarinagpenya @AntonCabrera3 @NarichiHimochi @picanteflipante Don't be ridiculous, you know what I mean, I gave some characteristics but there are more, and a muntiac can be differentiated from a dog. Just like a woman from a man.\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.71 ms /    16 runs   (    0.61 ms per token,  1647.62 tokens per second)\n",
            "llama_print_timings: prompt eval time =     299.45 ms /    92 tokens (    3.25 ms per token,   307.23 tokens per second)\n",
            "llama_print_timings:        eval time =    1483.26 ms /    15 runs   (   98.88 ms per token,    10.11 tokens per second)\n",
            "llama_print_timings:       total time =    2070.71 ms /   107 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "#Guatemala As @HBSsansalvador we join the @fundamyrnamack to honor Myrna Mack, as a woman who with her life gave voice to those who in silence cried out for justice, for a dignified life. #32yearsMyrnaMack Video from the Myrna Mack Foundation. https://t.co/F7ShB7m4FD\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.59 ms /    16 runs   (    0.60 ms per token,  1669.10 tokens per second)\n",
            "llama_print_timings: prompt eval time =     264.00 ms /    64 tokens (    4.13 ms per token,   242.42 tokens per second)\n",
            "llama_print_timings:        eval time =    1543.01 ms /    15 runs   (  102.87 ms per token,     9.72 tokens per second)\n",
            "llama_print_timings:       total time =    2012.59 ms /    79 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@LordVacant In fact... they have already confirmed that it is Girlhttps://t.co/fpmx3soAwb\"Nate Bihldorff, senior vice president of development and publishing at Nintendo, announced that the character identifies as a woman\"+\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.43 ms /    16 runs   (    0.59 ms per token,  1696.71 tokens per second)\n",
            "llama_print_timings: prompt eval time =     244.13 ms /    44 tokens (    5.55 ms per token,   180.23 tokens per second)\n",
            "llama_print_timings:        eval time =    1499.52 ms /    15 runs   (   99.97 ms per token,    10.00 tokens per second)\n",
            "llama_print_timings:       total time =    1899.32 ms /    59 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Many people perceive me as a strong, intelligent and determined woman...if they knew that today I cried just because my banana was green and tasted fucking ugly but I was very hungry.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.35 ms /    16 runs   (    0.58 ms per token,  1710.50 tokens per second)\n",
            "llama_print_timings: prompt eval time =     298.96 ms /    86 tokens (    3.48 ms per token,   287.66 tokens per second)\n",
            "llama_print_timings:        eval time =    1480.02 ms /    15 runs   (   98.67 ms per token,    10.13 tokens per second)\n",
            "llama_print_timings:       total time =    2069.54 ms /   101 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@RobertoMerken @Vulcano98263715 Roberto, you fall into the same thing again. You denigrate his arguments just for being a man and Opus Dei. Feminism is above all a philosophical idea, and as such an Opus Dei man has the same right to give his opinion as a radical feminist woman.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.54 ms /    16 runs   (    0.60 ms per token,  1677.50 tokens per second)\n",
            "llama_print_timings: prompt eval time =     260.12 ms /    65 tokens (    4.00 ms per token,   249.88 tokens per second)\n",
            "llama_print_timings:        eval time =    1541.26 ms /    15 runs   (  102.75 ms per token,     9.73 tokens per second)\n",
            "llama_print_timings:       total time =    2017.60 ms /    80 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "\"I would like to be known as an intelligent #woman, a brave woman, a loving woman, a woman who teaches by being.\" 🦸‍♀️-Maya Angelou#ReadingTuesday https://t.co/8zmnXjO2BC\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.71 ms /    16 runs   (    0.54 ms per token,  1836.97 tokens per second)\n",
            "llama_print_timings: prompt eval time =     566.69 ms /    23 tokens (   24.64 ms per token,    40.59 tokens per second)\n",
            "llama_print_timings:        eval time =    1504.98 ms /    15 runs   (  100.33 ms per token,     9.97 tokens per second)\n",
            "llama_print_timings:       total time =    2185.60 ms /    38 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "I'm like a little girl who needs a warm cup of colacao to sleep\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.90 ms /    16 runs   (    0.74 ms per token,  1344.88 tokens per second)\n",
            "llama_print_timings: prompt eval time =     233.20 ms /    37 tokens (    6.30 ms per token,   158.66 tokens per second)\n",
            "llama_print_timings:        eval time =    1717.13 ms /    15 runs   (  114.48 ms per token,     8.74 tokens per second)\n",
            "llama_print_timings:       total time =    2114.66 ms /    52 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@soonabineri and the remorse of N's 💩 seeing how a girl witnessed the baseness he did to her mom\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.56 ms /    16 runs   (    0.60 ms per token,  1674.17 tokens per second)\n",
            "llama_print_timings: prompt eval time =     281.36 ms /    75 tokens (    3.75 ms per token,   266.56 tokens per second)\n",
            "llama_print_timings:        eval time =    1518.54 ms /    15 runs   (  101.24 ms per token,     9.88 tokens per second)\n",
            "llama_print_timings:       total time =    2033.27 ms /    90 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "At 43 I will change many things (some of you already know my new resolutions). Because the important thing is the people, I promise to do better and I'm sorry for not being up to par with some people until now. Ah, tomorrow I plan to celebrate like a girl! #friends #family #next43\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.00 ms /    16 runs   (    0.62 ms per token,  1600.00 tokens per second)\n",
            "llama_print_timings: prompt eval time =     250.41 ms /    58 tokens (    4.32 ms per token,   231.62 tokens per second)\n",
            "llama_print_timings:        eval time =    1641.86 ms /    15 runs   (  109.46 ms per token,     9.14 tokens per second)\n",
            "llama_print_timings:       total time =    2093.48 ms /    73 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "When someone dies, I almost always hold back my tears, even though I know it shouldn't be done, I do it... But a year ago I couldn't do it, I cried like a girl and I had that horrible pain in my chest...\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.06 ms /    16 runs   (    0.63 ms per token,  1590.77 tokens per second)\n",
            "llama_print_timings: prompt eval time =     285.29 ms /    87 tokens (    3.28 ms per token,   304.95 tokens per second)\n",
            "llama_print_timings:        eval time =    1598.71 ms /    15 runs   (  106.58 ms per token,     9.38 tokens per second)\n",
            "llama_print_timings:       total time =    2151.31 ms /   102 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Metropoles @marcondesbrito They are pats of affection, they look at her like a child, they are pampering her, I don't know why there is so much evil in the human eye, has no one spanked their baby? It is not a lack of respect, but of Surely with this they will never celebrate that way again, people of bad living\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.99 ms /    16 runs   (    0.56 ms per token,  1779.16 tokens per second)\n",
            "llama_print_timings: prompt eval time =     699.79 ms /    28 tokens (   24.99 ms per token,    40.01 tokens per second)\n",
            "llama_print_timings:        eval time =    1526.33 ms /    15 runs   (  101.76 ms per token,     9.83 tokens per second)\n",
            "llama_print_timings:       total time =    2352.44 ms /    43 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "My sister's boss's family sees me as a little girl who doesn't pull any punches.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.98 ms /    16 runs   (    0.56 ms per token,  1780.94 tokens per second)\n",
            "llama_print_timings: prompt eval time =     714.38 ms /    29 tokens (   24.63 ms per token,    40.59 tokens per second)\n",
            "llama_print_timings:        eval time =    1527.75 ms /    15 runs   (  101.85 ms per token,     9.82 tokens per second)\n",
            "llama_print_timings:       total time =    2365.02 ms /    44 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@HizukiMiu how can I slack off?... miu bad, give yourself respect like a lady\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.69 ms /    16 runs   (    0.67 ms per token,  1496.87 tokens per second)\n",
            "llama_print_timings: prompt eval time =     236.88 ms /    35 tokens (    6.77 ms per token,   147.76 tokens per second)\n",
            "llama_print_timings:        eval time =    1860.26 ms /    15 runs   (  124.02 ms per token,     8.06 tokens per second)\n",
            "llama_print_timings:       total time =    2322.03 ms /    50 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "I just realized that I have people on social media who know me as an adult and serious lady, and I upload every story 🤦‍♀️\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.67 ms /    16 runs   (    0.60 ms per token,  1654.26 tokens per second)\n",
            "llama_print_timings: prompt eval time =     255.58 ms /    60 tokens (    4.26 ms per token,   234.76 tokens per second)\n",
            "llama_print_timings:        eval time =    1610.59 ms /    15 runs   (  107.37 ms per token,     9.31 tokens per second)\n",
            "llama_print_timings:       total time =    2056.41 ms /    75 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Sit like a Miss Shaoni... at this point you want to \"get attention\" but clearly there is only me in my house and that's how I felt like sitting down first. More comfortable https://t.co/uydR6sEebi\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.07 ms /    16 runs   (    0.57 ms per token,  1763.86 tokens per second)\n",
            "llama_print_timings: prompt eval time =     731.44 ms /    29 tokens (   25.22 ms per token,    39.65 tokens per second)\n",
            "llama_print_timings:        eval time =    1572.37 ms /    15 runs   (  104.82 ms per token,     9.54 tokens per second)\n",
            "llama_print_timings:       total time =    2428.01 ms /    44 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "I swear that today I ate the ice cream like a \"lady\" but I still got stains on it.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.88 ms /    16 runs   (    0.56 ms per token,  1801.40 tokens per second)\n",
            "llama_print_timings: prompt eval time =     245.08 ms /    50 tokens (    4.90 ms per token,   204.01 tokens per second)\n",
            "llama_print_timings:        eval time =    1643.04 ms /    15 runs   (  109.54 ms per token,     9.13 tokens per second)\n",
            "llama_print_timings:       total time =    2052.55 ms /    65 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@tomascasascm Haha. What innocence... \"Madam, stop charging 5 thousand a month, I will give you a thousand euros if you behave like a lady and stop sleeping with men.\"\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.03 ms /    16 runs   (    0.69 ms per token,  1450.98 tokens per second)\n",
            "llama_print_timings: prompt eval time =     249.54 ms /    40 tokens (    6.24 ms per token,   160.29 tokens per second)\n",
            "llama_print_timings:        eval time =    1861.98 ms /    15 runs   (  124.13 ms per token,     8.06 tokens per second)\n",
            "llama_print_timings:       total time =    2353.77 ms /    55 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "X: Kane you go to a fancy restaurant behave like a ladyAlso Kane: https://t.co/1FhO4HfWqN\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.17 ms /    16 runs   (    0.57 ms per token,  1744.44 tokens per second)\n",
            "llama_print_timings: prompt eval time =     271.12 ms /    69 tokens (    3.93 ms per token,   254.50 tokens per second)\n",
            "llama_print_timings:        eval time =    1517.59 ms /    15 runs   (  101.17 ms per token,     9.88 tokens per second)\n",
            "llama_print_timings:       total time =    1999.37 ms /    84 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Give Mexican cinema a chance and go see \"WHEN IT'S YOUNG\", a remake with our humor, a lot of reflection and emotions about youth, parents, old age, conciliation, opportunities, changes with the times and with a soundtrack and vintage films super pretty 🤩\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.56 ms /    16 runs   (    0.60 ms per token,  1672.77 tokens per second)\n",
            "llama_print_timings: prompt eval time =     260.21 ms /    54 tokens (    4.82 ms per token,   207.52 tokens per second)\n",
            "llama_print_timings:        eval time =    1545.32 ms /    15 runs   (  103.02 ms per token,     9.71 tokens per second)\n",
            "llama_print_timings:       total time =    1984.81 ms /    69 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "And although it seems that Chavismo is not to blame in this, the Peace Courts disappeared as best they could, which were effective instruments for conciliation between neighbors https://t.co/JMdgbaJNxM\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.44 ms /    16 runs   (    0.59 ms per token,  1694.74 tokens per second)\n",
            "llama_print_timings: prompt eval time =     261.24 ms /    58 tokens (    4.50 ms per token,   222.02 tokens per second)\n",
            "llama_print_timings:        eval time =    1455.36 ms /    15 runs   (   97.02 ms per token,    10.31 tokens per second)\n",
            "llama_print_timings:       total time =    1900.77 ms /    73 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "They support the solution of neighborhood conflicts with mediation and conciliation tables in the capital of Puebla 👬🏽🫱🏻‍🫲🏽 https://t.co/mGNmQ8POZe\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.72 ms /    16 runs   (    0.73 ms per token,  1364.72 tokens per second)\n",
            "llama_print_timings: prompt eval time =     256.22 ms /    68 tokens (    3.77 ms per token,   265.40 tokens per second)\n",
            "llama_print_timings:        eval time =    1871.35 ms /    15 runs   (  124.76 ms per token,     8.02 tokens per second)\n",
            "llama_print_timings:       total time =    2460.59 ms /    83 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "How important a good relationship with our labor conciliation authorities, the very good relations between the private sector and our authorities, bear fruit in harmony, work together, and always seeking to improve, congratulations to our president C Villaseñor!! https://t.co/e2PsLkxDrx\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.88 ms /    16 runs   (    0.62 ms per token,  1619.60 tokens per second)\n",
            "llama_print_timings: prompt eval time =     287.72 ms /    79 tokens (    3.64 ms per token,   274.57 tokens per second)\n",
            "llama_print_timings:        eval time =    1489.36 ms /    15 runs   (   99.29 ms per token,    10.07 tokens per second)\n",
            "llama_print_timings:       total time =    2030.52 ms /    94 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "I have always defended that people without children should be able to reconcile the same as those who do have them, but honestly the individualistic and selfish current that exists in the \"you have decided to have children, your reconciliation is not more important than mine\" bothers me a lot. . https://t.co/nhHR1Igt9S\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.84 ms /    16 runs   (    0.61 ms per token,  1626.51 tokens per second)\n",
            "llama_print_timings: prompt eval time =     281.32 ms /    89 tokens (    3.16 ms per token,   316.37 tokens per second)\n",
            "llama_print_timings:        eval time =    1523.63 ms /    15 runs   (  101.58 ms per token,     9.84 tokens per second)\n",
            "llama_print_timings:       total time =    2087.54 ms /   104 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Espeansa Welcome to Disney World.R-33 I usually do 10 guards a month and sometimes more. 190-200 hours per month on duty. My life as a sleepwalker and family conciliation, a myth. There will be someone who will say that I am rich.... Why continue... https://t.co/2SPpo0vi4L\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.12 ms /    16 runs   (    0.70 ms per token,  1438.46 tokens per second)\n",
            "llama_print_timings: prompt eval time =     275.62 ms /    82 tokens (    3.36 ms per token,   297.51 tokens per second)\n",
            "llama_print_timings:        eval time =    1811.81 ms /    15 runs   (  120.79 ms per token,     8.28 tokens per second)\n",
            "llama_print_timings:       total time =    2374.94 ms /    97 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "We are short of places in the public We are having difficulties in reconciling studies/work We are cheap labor during internships Today's vocational training needs the organization of the student body to ensure that it is at their service, and not the other way around. #YoSoyFP https:/ /t.co/qBfGOciPzT\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.38 ms /    16 runs   (    0.52 ms per token,  1908.85 tokens per second)\n",
            "llama_print_timings: prompt eval time =     741.10 ms /    31 tokens (   23.91 ms per token,    41.83 tokens per second)\n",
            "llama_print_timings:        eval time =    1493.97 ms /    15 runs   (   99.60 ms per token,    10.04 tokens per second)\n",
            "llama_print_timings:       total time =    2372.80 ms /    46 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "I wish you a quality of life such that you masturbate out of desire and not out of the need to fall asleep.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.46 ms /    16 runs   (    0.59 ms per token,  1690.44 tokens per second)\n",
            "llama_print_timings: prompt eval time =     277.19 ms /    80 tokens (    3.46 ms per token,   288.62 tokens per second)\n",
            "llama_print_timings:        eval time =    1542.25 ms /    15 runs   (  102.82 ms per token,     9.73 tokens per second)\n",
            "llama_print_timings:       total time =    2062.76 ms /    95 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@delosquesobran I'm going to record it: I have tried with \"white noise\" to fall asleep but nothing. With this I hope that by article #30 I will be well asleep...., or turning off the computer to watch something on \"Ñefla\" https ://t.co/kUGC0tWdqg\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.79 ms /    16 runs   (    0.61 ms per token,  1634.49 tokens per second)\n",
            "llama_print_timings: prompt eval time =     262.23 ms /    60 tokens (    4.37 ms per token,   228.81 tokens per second)\n",
            "llama_print_timings:        eval time =    1565.12 ms /    15 runs   (  104.34 ms per token,     9.58 tokens per second)\n",
            "llama_print_timings:       total time =    2021.24 ms /    75 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "I will not be the one to take a position against women's rights, however, as a single mother from the beginning of pregnancy, it would be advisable to think: How can families, single-parent mothers, try to reconcile and get their children forward?\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.44 ms /    16 runs   (    0.65 ms per token,  1533.30 tokens per second)\n",
            "llama_print_timings: prompt eval time =     242.51 ms /    45 tokens (    5.39 ms per token,   185.56 tokens per second)\n",
            "llama_print_timings:        eval time =    1905.23 ms /    15 runs   (  127.02 ms per token,     7.87 tokens per second)\n",
            "llama_print_timings:       total time =    2412.77 ms /    60 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Monica_Garcia_G Madam, as long as you don't assimilate the defeat of 4M, you won't be able to sleep, right?\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.54 ms /    16 runs   (    0.60 ms per token,  1676.45 tokens per second)\n",
            "llama_print_timings: prompt eval time =     256.78 ms /    62 tokens (    4.14 ms per token,   241.45 tokens per second)\n",
            "llama_print_timings:        eval time =    1459.71 ms /    15 runs   (   97.31 ms per token,    10.28 tokens per second)\n",
            "llama_print_timings:       total time =    1906.23 ms /    77 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Impossible to reconcile anything with Iran, it has brought shame on Argentina's foreign policy in recent years. The president of Iran questioned the Holocaust and said it still needs to be investigated - Infobae https://t.co/vQFTQNRrHS\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.53 ms /    16 runs   (    0.60 ms per token,  1678.73 tokens per second)\n",
            "llama_print_timings: prompt eval time =     278.39 ms /    81 tokens (    3.44 ms per token,   290.96 tokens per second)\n",
            "llama_print_timings:        eval time =    1512.55 ms /    15 runs   (  100.84 ms per token,     9.92 tokens per second)\n",
            "llama_print_timings:       total time =    2045.10 ms /    96 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "The relevant question is who gave the orders to the boys representing the Mayor's Office. Did they act like this on their own initiative? , which makes them complicit with the attackers or did they act on the instructions of a superior? In any case there is co-responsibility of @Bogota https://t.co/S9kkPtpa1X\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      12.06 ms /    16 runs   (    0.75 ms per token,  1326.48 tokens per second)\n",
            "llama_print_timings: prompt eval time =     294.74 ms /    84 tokens (    3.51 ms per token,   285.00 tokens per second)\n",
            "llama_print_timings:        eval time =    1787.01 ms /    15 runs   (  119.13 ms per token,     8.39 tokens per second)\n",
            "llama_print_timings:       total time =    2525.89 ms /    99 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "#SubTrabenMedios 🗞️ | Undersecretary @gboccardobosoni, in an interview with the Diario @elsurcl, highlights the principles that drive the #40Hours project related to more time for effective rest, economic responsibility and social co-responsibility. https://t.co/kIPizN9a22\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.52 ms /    16 runs   (    0.59 ms per token,  1681.03 tokens per second)\n",
            "llama_print_timings: prompt eval time =     260.95 ms /    48 tokens (    5.44 ms per token,   183.94 tokens per second)\n",
            "llama_print_timings:        eval time =    1512.10 ms /    15 runs   (  100.81 ms per token,     9.92 tokens per second)\n",
            "llama_print_timings:       total time =    1942.57 ms /    63 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "The big question remains how do we manage risks from co-responsibility? What happened between Friday and Saturday should not be the norm but the exception. https://t.co/kChpc4whDt\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.51 ms /    16 runs   (    0.59 ms per token,  1682.26 tokens per second)\n",
            "llama_print_timings: prompt eval time =     259.30 ms /    63 tokens (    4.12 ms per token,   242.96 tokens per second)\n",
            "llama_print_timings:        eval time =    1484.49 ms /    15 runs   (   98.97 ms per token,    10.10 tokens per second)\n",
            "llama_print_timings:       total time =    1940.70 ms /    78 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "and community, as well as to promote social and gender co-responsibility, so that women are not the ones who assume domestic and care work. In addition, job insecurity is prohibited. So let's participate actively and we will win. #Vote #Approve!\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.51 ms /    16 runs   (    0.59 ms per token,  1682.97 tokens per second)\n",
            "llama_print_timings: prompt eval time =     295.73 ms /    87 tokens (    3.40 ms per token,   294.19 tokens per second)\n",
            "llama_print_timings:        eval time =    1545.34 ms /    15 runs   (  103.02 ms per token,     9.71 tokens per second)\n",
            "llama_print_timings:       total time =    2101.92 ms /   102 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "📝 | Bill on Co-Responsibility in Parenting ✅ We share part of the rationale for the affirmative vote of our Senator @Carmensangui in yesterday's session 🔗 Full intervention: https://t.co/DYcVD74B0H https://t.co/ bdL7aSJ8c4\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.63 ms /    16 runs   (    0.60 ms per token,  1662.16 tokens per second)\n",
            "llama_print_timings: prompt eval time =     304.16 ms /   101 tokens (    3.01 ms per token,   332.06 tokens per second)\n",
            "llama_print_timings:        eval time =    1585.74 ms /    15 runs   (  105.72 ms per token,     9.46 tokens per second)\n",
            "llama_print_timings:       total time =    2188.92 ms /   116 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "👉Would you like to raise awareness among your company's staff about Equality?💡Are you interested in training on conciliation and co-responsibility? ⭐️Do you want to make your commitment to Equality visible?#PracticaLaIgualdad #MarcaLaDifferencehttps://t.co/UhbrwEd3Ip https:/ /t.co/T8j805fNT8\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.92 ms /    16 runs   (    0.62 ms per token,  1612.90 tokens per second)\n",
            "llama_print_timings: prompt eval time =     240.37 ms /    45 tokens (    5.34 ms per token,   187.22 tokens per second)\n",
            "llama_print_timings:        eval time =    1674.59 ms /    15 runs   (  111.64 ms per token,     8.96 tokens per second)\n",
            "llama_print_timings:       total time =    2078.60 ms /    60 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "The Summer Course 'Gender Violence' by @unirioja will address the objectification of the female body https://t.co/w2xRhR9096\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.05 ms /    16 runs   (    0.57 ms per token,  1768.54 tokens per second)\n",
            "llama_print_timings: prompt eval time =     258.26 ms /    41 tokens (    6.30 ms per token,   158.75 tokens per second)\n",
            "llama_print_timings:        eval time =    1625.31 ms /    15 runs   (  108.35 ms per token,     9.23 tokens per second)\n",
            "llama_print_timings:       total time =    2031.45 ms /    56 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@sofilopiccolo But The Patriarchy, the objectification of the female body and El Coso??? Haaaa there is money involved...freedom empower...Art!!!!\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.78 ms /    16 runs   (    0.55 ms per token,  1822.74 tokens per second)\n",
            "llama_print_timings: prompt eval time =     244.53 ms /    33 tokens (    7.41 ms per token,   134.96 tokens per second)\n",
            "llama_print_timings:        eval time =    1660.56 ms /    15 runs   (  110.70 ms per token,     9.03 tokens per second)\n",
            "llama_print_timings:       total time =    2034.94 ms /    48 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@AmarantaHankTw Before reading this book, it may help you to look up what the objectification of the female body means.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.46 ms /    16 runs   (    0.59 ms per token,  1690.80 tokens per second)\n",
            "llama_print_timings: prompt eval time =     271.83 ms /    66 tokens (    4.12 ms per token,   242.80 tokens per second)\n",
            "llama_print_timings:        eval time =    1634.18 ms /    15 runs   (  108.95 ms per token,     9.18 tokens per second)\n",
            "llama_print_timings:       total time =    2106.87 ms /    81 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@gmaemejota Fear, disgust, sorrow, and everything together. Wonderful consequences of the sexualization and objectification of the female body (regardless of age) since it produces economic return. But yes, then defending reproductive health rights and sexual education is pederasty.\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      12.25 ms /    16 runs   (    0.77 ms per token,  1306.44 tokens per second)\n",
            "llama_print_timings: prompt eval time =     277.45 ms /    98 tokens (    2.83 ms per token,   353.22 tokens per second)\n",
            "llama_print_timings:        eval time =    1846.22 ms /    15 runs   (  123.08 ms per token,     8.12 tokens per second)\n",
            "llama_print_timings:       total time =    2629.02 ms /   113 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@cienlargosdias @Alvaro00813623 @_zerdo @eltivipata Madam, may I remind you that this conversation began due to the objectification of the female body where I defended the elimination of a normative canon and you did not? If you want to translate it into a misogynistic act, okay, but you think your ideology prevents you from seeing this clearly.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.61 ms /    16 runs   (    0.60 ms per token,  1664.41 tokens per second)\n",
            "llama_print_timings: prompt eval time =     288.79 ms /    80 tokens (    3.61 ms per token,   277.02 tokens per second)\n",
            "llama_print_timings:        eval time =    1535.87 ms /    15 runs   (  102.39 ms per token,     9.77 tokens per second)\n",
            "llama_print_timings:       total time =    2061.98 ms /    95 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@amigadatecuen1 @Ashura_chan @Lalauralis @AlicciaDs You are wrong. And I think that is your problem of understanding. One thing is the objectification of the female body (something that occurs in hospital births, by the way) and another is deciding what to do with them, as in abortion.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.58 ms /    16 runs   (    0.54 ms per token,  1865.67 tokens per second)\n",
            "llama_print_timings: prompt eval time =     604.76 ms /    24 tokens (   25.20 ms per token,    39.69 tokens per second)\n",
            "llama_print_timings:        eval time =    1703.69 ms /    15 runs   (  113.58 ms per token,     8.80 tokens per second)\n",
            "llama_print_timings:       total time =    2422.94 ms /    39 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@saintloyal I would happily work as a Panda caregiver 🥰🥰🥰\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.61 ms /    16 runs   (    0.54 ms per token,  1858.09 tokens per second)\n",
            "llama_print_timings: prompt eval time =     673.65 ms /    27 tokens (   24.95 ms per token,    40.08 tokens per second)\n",
            "llama_print_timings:        eval time =    1549.48 ms /    15 runs   (  103.30 ms per token,     9.68 tokens per second)\n",
            "llama_print_timings:       total time =    2342.64 ms /    42 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "I want to be a panda keeper https://t.co/vKcmoz6LT5\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.17 ms /    16 runs   (    0.64 ms per token,  1572.64 tokens per second)\n",
            "llama_print_timings: prompt eval time =     640.47 ms /    20 tokens (   32.02 ms per token,    31.23 tokens per second)\n",
            "llama_print_timings:        eval time =    1763.06 ms /    15 runs   (  117.54 ms per token,     8.51 tokens per second)\n",
            "llama_print_timings:       total time =    2559.63 ms /    35 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "I don't know how I became all my neighbors' cat sitter.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.79 ms /    16 runs   (    0.55 ms per token,  1819.84 tokens per second)\n",
            "llama_print_timings: prompt eval time =     246.53 ms /    40 tokens (    6.16 ms per token,   162.25 tokens per second)\n",
            "llama_print_timings:        eval time =    1534.60 ms /    15 runs   (  102.31 ms per token,     9.77 tokens per second)\n",
            "llama_print_timings:       total time =    1924.65 ms /    55 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "She is Margarita and she is cute, despite her caregiver's poor skills. https://t.co/xANwgmK3aC\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.95 ms /    16 runs   (    0.56 ms per token,  1787.31 tokens per second)\n",
            "llama_print_timings: prompt eval time =     242.46 ms /    42 tokens (    5.77 ms per token,   173.22 tokens per second)\n",
            "llama_print_timings:        eval time =    1467.17 ms /    15 runs   (   97.81 ms per token,    10.22 tokens per second)\n",
            "llama_print_timings:       total time =    1857.61 ms /    57 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "The sound of inclusion: How to be a 24/7 caregiver mom and not die trying? https://t.co/xDv0GHsRpm\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.71 ms /    16 runs   (    0.61 ms per token,  1647.62 tokens per second)\n",
            "llama_print_timings: prompt eval time =     247.56 ms /    50 tokens (    4.95 ms per token,   201.97 tokens per second)\n",
            "llama_print_timings:        eval time =    1497.05 ms /    15 runs   (   99.80 ms per token,    10.02 tokens per second)\n",
            "llama_print_timings:       total time =    1913.75 ms /    65 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Convicted in #Murcia for #attacking his father's caregiver📰@diariolaopinion https://t.co/YD2vKuHNzI\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      12.95 ms /    16 runs   (    0.81 ms per token,  1235.52 tokens per second)\n",
            "llama_print_timings: prompt eval time =     237.25 ms /    38 tokens (    6.24 ms per token,   160.17 tokens per second)\n",
            "llama_print_timings:        eval time =    1814.66 ms /    15 runs   (  120.98 ms per token,     8.27 tokens per second)\n",
            "llama_print_timings:       total time =    2293.31 ms /    53 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@maxiluzbelito_ @RiverLPM The dead don't speak, you died in Madrid, broken ass, pent-up hahaha\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.29 ms /    16 runs   (    0.58 ms per token,  1721.36 tokens per second)\n",
            "llama_print_timings: prompt eval time =     264.84 ms /    53 tokens (    5.00 ms per token,   200.12 tokens per second)\n",
            "llama_print_timings:        eval time =    1593.19 ms /    15 runs   (  106.21 ms per token,     9.42 tokens per second)\n",
            "llama_print_timings:       total time =    2032.25 ms /    68 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@MAndreaNieto And when they said that foreign investment would fall due to fear that Petro would be president, what? That's what Bolivar is referring to, they definitely have the understanding in their asses.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.44 ms /    16 runs   (    0.59 ms per token,  1694.74 tokens per second)\n",
            "llama_print_timings: prompt eval time =     303.62 ms /   105 tokens (    2.89 ms per token,   345.82 tokens per second)\n",
            "llama_print_timings:        eval time =    1500.11 ms /    15 runs   (  100.01 ms per token,    10.00 tokens per second)\n",
            "llama_print_timings:       total time =    2110.54 ms /   120 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@_nao_nao12 @Danny49645523 @MatasCornejo5 @tere_marinovic. Production was stopped by the idiotic illiterate \"comrades\" who took control of expropriated companies..Then they took the \"comrades\" to the UP marches..They didn't know how to wipe their asses , but they managed the companies... Today the same people try to govern...\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       2.86 ms /     5 runs   (    0.57 ms per token,  1747.03 tokens per second)\n",
            "llama_print_timings: prompt eval time =     264.07 ms /    65 tokens (    4.06 ms per token,   246.15 tokens per second)\n",
            "llama_print_timings:        eval time =     428.62 ms /     4 runs   (  107.15 ms per token,     9.33 tokens per second)\n",
            "llama_print_timings:       total time =     851.41 ms /    69 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@moraflorezlucia @ELTIEMPO Oh, shut up, it's obvious that you don't know a damn thing about national history. Rather, she opens an onlyfans, which is the only thing that half a neuron he has is useful for.\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.79 ms /    16 runs   (    0.67 ms per token,  1482.44 tokens per second)\n",
            "llama_print_timings: prompt eval time =     252.31 ms /    75 tokens (    3.36 ms per token,   297.25 tokens per second)\n",
            "llama_print_timings:        eval time =    1639.99 ms /    15 runs   (  109.33 ms per token,     9.15 tokens per second)\n",
            "llama_print_timings:       total time =    2135.72 ms /    90 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "THE COCK BLOWER WHO IS SHOOTING ROCKETS AT 2 IN THE MORNING, WHY DON'T HE THROW IT ON HIS DICK AND END HIS SHIT LIFE??? OR DO YOU HAVE TO FUCK AND SCARED THE BITCH OUT OF ME??\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.89 ms /    16 runs   (    0.56 ms per token,  1799.37 tokens per second)\n",
            "llama_print_timings: prompt eval time =     881.14 ms /    29 tokens (   30.38 ms per token,    32.91 tokens per second)\n",
            "llama_print_timings:        eval time =    1530.05 ms /    15 runs   (  102.00 ms per token,     9.80 tokens per second)\n",
            "llama_print_timings:       total time =    2541.20 ms /    44 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "What a closed ass mijooo hahaha https://t.co/9lcw7zbckZ\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.15 ms /    16 runs   (    0.57 ms per token,  1747.87 tokens per second)\n",
            "llama_print_timings: prompt eval time =     288.25 ms /    77 tokens (    3.74 ms per token,   267.13 tokens per second)\n",
            "llama_print_timings:        eval time =    1539.70 ms /    15 runs   (  102.65 ms per token,     9.74 tokens per second)\n",
            "llama_print_timings:       total time =    2066.32 ms /    92 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@flacovrgncol @estudiantehotSV @TaxiCalienteSV And who are you fighting against that you come out to defend? You were there? Do you know if that is fake or not? Acted or not, this continues to feed rape culture, which is why we have so many idiots who rape instead of fucking\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.30 ms /    16 runs   (    0.58 ms per token,  1719.69 tokens per second)\n",
            "llama_print_timings: prompt eval time =     248.58 ms /    54 tokens (    4.60 ms per token,   217.23 tokens per second)\n",
            "llama_print_timings:        eval time =    1466.26 ms /    15 runs   (   97.75 ms per token,    10.23 tokens per second)\n",
            "llama_print_timings:       total time =    1886.35 ms /    69 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "In the news they keep saying \"the young people\" to refer to victims of chemical submission. Wtf shut up now, stop whitewashing rape culture, out of every 10 cases 9 are women.✨Symbolical violence✨\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.37 ms /    16 runs   (    0.59 ms per token,  1707.40 tokens per second)\n",
            "llama_print_timings: prompt eval time =     620.80 ms /    32 tokens (   19.40 ms per token,    51.55 tokens per second)\n",
            "llama_print_timings:        eval time =    1496.05 ms /    15 runs   (   99.74 ms per token,    10.03 tokens per second)\n",
            "llama_print_timings:       total time =    2299.21 ms /    47 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "When you say no to fucking because you don't have it and they get angry. That culture of rape and violence is stupid.\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.99 ms /    16 runs   (    0.56 ms per token,  1780.35 tokens per second)\n",
            "llama_print_timings: prompt eval time =     236.16 ms /    34 tokens (    6.95 ms per token,   143.97 tokens per second)\n",
            "llama_print_timings:        eval time =    1526.54 ms /    15 runs   (  101.77 ms per token,     9.83 tokens per second)\n",
            "llama_print_timings:       total time =    1898.67 ms /    49 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@zaratus_FF10 @GracielaPaggi We understand that rape culture is bestiality, always, right?\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.64 ms /    16 runs   (    0.60 ms per token,  1659.92 tokens per second)\n",
            "llama_print_timings: prompt eval time =     292.11 ms /    94 tokens (    3.11 ms per token,   321.80 tokens per second)\n",
            "llama_print_timings:        eval time =    1605.51 ms /    15 runs   (  107.03 ms per token,     9.34 tokens per second)\n",
            "llama_print_timings:       total time =    2176.49 ms /   109 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "🟣Campaign to prevent sexual abuse in adolescents and young people with the theme: Rape culture. We talk about what it is, how to recognize it and tips to not encourage it. Help us make this message viral and give it a \"like\". #adavas #adavascontigo #adavassalamanca https://t.co/fXz89gSDK1\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.59 ms /    14 runs   (    0.61 ms per token,  1629.99 tokens per second)\n",
            "llama_print_timings: prompt eval time =     285.67 ms /    70 tokens (    4.08 ms per token,   245.04 tokens per second)\n",
            "llama_print_timings:        eval time =    1293.77 ms /    13 runs   (   99.52 ms per token,    10.05 tokens per second)\n",
            "llama_print_timings:       total time =    1784.71 ms /    83 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Another RAPIST UBER driver. He abused a student on Friday night. She had requested a transfer from her work to the student residence. He was detained. THE CULTURE OF RAPE.And apps without control or security. https://t.co/QlVUVBsiqt\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.43 ms /    16 runs   (    0.59 ms per token,  1697.61 tokens per second)\n",
            "llama_print_timings: prompt eval time =     240.40 ms /    50 tokens (    4.81 ms per token,   207.99 tokens per second)\n",
            "llama_print_timings:        eval time =    1563.31 ms /    15 runs   (  104.22 ms per token,     9.60 tokens per second)\n",
            "llama_print_timings:       total time =    1972.43 ms /    65 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Dexdexdex10 @MPerronegrito @Mister_Wolf_0 Hahaha, you would be happy with your house expropriated in 12 installments to build a road\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.72 ms /    16 runs   (    0.55 ms per token,  1834.44 tokens per second)\n",
            "llama_print_timings: prompt eval time =     246.18 ms /    35 tokens (    7.03 ms per token,   142.17 tokens per second)\n",
            "llama_print_timings:        eval time =    1481.26 ms /    15 runs   (   98.75 ms per token,    10.13 tokens per second)\n",
            "llama_print_timings:       total time =    1866.63 ms /    50 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@latinus_us Today there are no medications, equipment, etc. For those who pay their dues, with this decree it will be worse\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.29 ms /    16 runs   (    0.71 ms per token,  1417.81 tokens per second)\n",
            "llama_print_timings: prompt eval time =     254.55 ms /    46 tokens (    5.53 ms per token,   180.71 tokens per second)\n",
            "llama_print_timings:        eval time =    1910.76 ms /    15 runs   (  127.38 ms per token,     7.85 tokens per second)\n",
            "llama_print_timings:       total time =    2441.29 ms /    61 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Please study the resumes carefully, or justify your appointments. Do we continue with political quotas or is it due to capacity? https://t.co/UI3wxmK71l\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.88 ms /    16 runs   (    0.56 ms per token,  1801.80 tokens per second)\n",
            "llama_print_timings: prompt eval time =     257.04 ms /    48 tokens (    5.35 ms per token,   186.74 tokens per second)\n",
            "llama_print_timings:        eval time =    1471.94 ms /    15 runs   (   98.13 ms per token,    10.19 tokens per second)\n",
            "llama_print_timings:       total time =    1902.50 ms /    63 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@skoda_es 47 installments and stayed 48 months? I don't have to change cars, but if I had to, there's no way it would be that one.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.00 ms /    16 runs   (    0.56 ms per token,  1777.78 tokens per second)\n",
            "llama_print_timings: prompt eval time =     239.43 ms /    38 tokens (    6.30 ms per token,   158.71 tokens per second)\n",
            "llama_print_timings:        eval time =    1575.03 ms /    15 runs   (  105.00 ms per token,     9.52 tokens per second)\n",
            "llama_print_timings:       total time =    1954.90 ms /    53 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Robert_f_1 For OLIMPIA 5 million, for Cerrito and Laundry 500 thousand and in installments\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.81 ms /    16 runs   (    0.55 ms per token,  1815.91 tokens per second)\n",
            "llama_print_timings: prompt eval time =     688.42 ms /    25 tokens (   27.54 ms per token,    36.32 tokens per second)\n",
            "llama_print_timings:        eval time =    1572.09 ms /    15 runs   (  104.81 ms per token,     9.54 tokens per second)\n",
            "llama_print_timings:       total time =    2378.48 ms /    40 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@PatriotaPatito buying on credit and in comfortable installments Everything is Possible in Life Champion\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.81 ms /    16 runs   (    0.61 ms per token,  1630.16 tokens per second)\n",
            "llama_print_timings: prompt eval time =     278.39 ms /    72 tokens (    3.87 ms per token,   258.63 tokens per second)\n",
            "llama_print_timings:        eval time =    1529.64 ms /    15 runs   (  101.98 ms per token,     9.81 tokens per second)\n",
            "llama_print_timings:       total time =    2155.08 ms /    87 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "It did not win in the prison population despite recognizing civic rights for prisoners. It did not win in PETORCA despite changing the entire water regulation regime. It did not win in regions despite being decentralizing and quasi-federal. It did not win among women despite being a democracy parity22/n\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.82 ms /    16 runs   (    0.61 ms per token,  1629.66 tokens per second)\n",
            "llama_print_timings: prompt eval time =     261.10 ms /    64 tokens (    4.08 ms per token,   245.11 tokens per second)\n",
            "llama_print_timings:        eval time =    1493.73 ms /    15 runs   (   99.58 ms per token,    10.04 tokens per second)\n",
            "llama_print_timings:       total time =    1954.57 ms /    79 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Margarita Cedeño said: \"I reiterate in this forum my commitment to promote equal democracy. I will work from my party to motivate the political participation of women, because the more women, the better democracy. And where there are empowered women, societies progress.\"\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.38 ms /    16 runs   (    0.59 ms per token,  1705.21 tokens per second)\n",
            "llama_print_timings: prompt eval time =     277.34 ms /    76 tokens (    3.65 ms per token,   274.03 tokens per second)\n",
            "llama_print_timings:        eval time =    1626.85 ms /    15 runs   (  108.46 ms per token,     9.22 tokens per second)\n",
            "llama_print_timings:       total time =    2142.59 ms /    91 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Parity democracy establishes that parity and equality are central axes of an inclusive State. It is not a women's issue, nor even a relationship between genders, but an opportunity to decide on the State model we want. For an equal Ushuaia! https://t.co/yjZCPMVoEo\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.48 ms /    16 runs   (    0.72 ms per token,  1393.36 tokens per second)\n",
            "llama_print_timings: prompt eval time =     306.58 ms /   109 tokens (    2.81 ms per token,   355.54 tokens per second)\n",
            "llama_print_timings:        eval time =    1794.29 ms /    15 runs   (  119.62 ms per token,     8.36 tokens per second)\n",
            "llama_print_timings:       total time =    2656.79 ms /   124 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Day 4. Camila Moreno – Let's burn the kingdom (Art. 6, 25, 27, 30, 61, 161, 163, 242, 312 and 350. Women's rights and parity democracy). “This land belongs to my son, paganism.” and wild eroticism”https://t.co/X2RNIH3pYd\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.04 ms /    16 runs   (    0.56 ms per token,  1770.30 tokens per second)\n",
            "llama_print_timings: prompt eval time =     272.07 ms /    64 tokens (    4.25 ms per token,   235.23 tokens per second)\n",
            "llama_print_timings:        eval time =    1629.63 ms /    15 runs   (  108.64 ms per token,     9.20 tokens per second)\n",
            "llama_print_timings:       total time =    2098.29 ms /    79 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Joyce_S_Berger 🧵The fact that there are women political leaders contributes to generating new roles and prototypes of women, different from the traditional ones. Redistributing power in a balanced way between men and women as proposed by parity democracy\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.58 ms /    16 runs   (    0.54 ms per token,  1865.24 tokens per second)\n",
            "llama_print_timings: prompt eval time =     242.17 ms /    33 tokens (    7.34 ms per token,   136.27 tokens per second)\n",
            "llama_print_timings:        eval time =    1609.17 ms /    15 runs   (  107.28 ms per token,     9.32 tokens per second)\n",
            "llama_print_timings:       total time =    1989.95 ms /    48 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Do not be afraidRepeat after me: Paritarian Democracy Paritarian Democracy Paritarian Democracy #AprueboCrece\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.65 ms /    16 runs   (    0.60 ms per token,  1657.52 tokens per second)\n",
            "llama_print_timings: prompt eval time =     252.61 ms /    63 tokens (    4.01 ms per token,   249.40 tokens per second)\n",
            "llama_print_timings:        eval time =    1562.10 ms /    15 runs   (  104.14 ms per token,     9.60 tokens per second)\n",
            "llama_print_timings:       total time =    2020.31 ms /    78 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Imagine feeling good because the only thing you do for your children is provide financially thanks to the job you have in your parents' company. Oh, but the girl who gave birth to those two children with postpartum depression, right? How dare you feel anything other than gratitude!!!\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.96 ms /    16 runs   (    0.56 ms per token,  1784.72 tokens per second)\n",
            "llama_print_timings: prompt eval time =     283.17 ms /    92 tokens (    3.08 ms per token,   324.90 tokens per second)\n",
            "llama_print_timings:        eval time =    1622.78 ms /    15 runs   (  108.19 ms per token,     9.24 tokens per second)\n",
            "llama_print_timings:       total time =    2187.27 ms /   107 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "My mother always goes for the jugular with the little thing. She didn't want to have them and doing so caused horrible postpartum depression. She always says that she can't miss what she doesn't know. Once I was born she loved me, but if she hadn't had me she wouldn't have regretted it. https://t.co/aEGPAfTS0g\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.93 ms /    16 runs   (    0.62 ms per token,  1611.12 tokens per second)\n",
            "llama_print_timings: prompt eval time =     261.73 ms /    62 tokens (    4.22 ms per token,   236.89 tokens per second)\n",
            "llama_print_timings:        eval time =    1578.21 ms /    15 runs   (  105.21 ms per token,     9.50 tokens per second)\n",
            "llama_print_timings:       total time =    2032.39 ms /    77 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Friends who have friends in the postpartum period: always keep an eye out, offer a shoulder, an extra pair of arms, listen attentively and affectionately, and address any needs that you can cover, etc. No one is immune to postpartum depression.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.73 ms /    16 runs   (    0.61 ms per token,  1644.06 tokens per second)\n",
            "llama_print_timings: prompt eval time =     619.26 ms /    32 tokens (   19.35 ms per token,    51.67 tokens per second)\n",
            "llama_print_timings:        eval time =    1707.99 ms /    15 runs   (  113.87 ms per token,     8.78 tokens per second)\n",
            "llama_print_timings:       total time =    2471.90 ms /    47 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Postpartum depression affects about 20% of mothers in Chile https://t.co/hGBhieD3iz\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.01 ms /    16 runs   (    0.56 ms per token,  1776.79 tokens per second)\n",
            "llama_print_timings: prompt eval time =     587.41 ms /    32 tokens (   18.36 ms per token,    54.48 tokens per second)\n",
            "llama_print_timings:        eval time =    1465.41 ms /    15 runs   (   97.69 ms per token,    10.24 tokens per second)\n",
            "llama_print_timings:       total time =    2187.40 ms /    47 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "🌵 Men also suffer from postpartum depression... https://t.co/bOm9fFEIJP\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.89 ms /    16 runs   (    0.56 ms per token,  1799.37 tokens per second)\n",
            "llama_print_timings: prompt eval time =     780.05 ms /    30 tokens (   26.00 ms per token,    38.46 tokens per second)\n",
            "llama_print_timings:        eval time =    1533.39 ms /    15 runs   (  102.23 ms per token,     9.78 tokens per second)\n",
            "llama_print_timings:       total time =    2440.51 ms /    45 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Kylie Jenner confesses she had postpartum depression https://t.co/guhcHRVwBe\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.14 ms /    16 runs   (    0.63 ms per token,  1577.44 tokens per second)\n",
            "llama_print_timings: prompt eval time =     289.82 ms /    77 tokens (    3.76 ms per token,   265.68 tokens per second)\n",
            "llama_print_timings:        eval time =    1525.93 ms /    15 runs   (  101.73 ms per token,     9.83 tokens per second)\n",
            "llama_print_timings:       total time =    2046.18 ms /    92 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "🌿Coordinating on-the-ground actions for the training and promotion of Human Rights and intersectoral work for the Sites of Memory, Undersecretary @HOberreuter met with various organizations in the O`Higgins Region 🙌🏽 https://t.co/ mM60gNq4KU\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.53 ms /    16 runs   (    0.60 ms per token,  1678.56 tokens per second)\n",
            "llama_print_timings: prompt eval time =     273.28 ms /    75 tokens (    3.64 ms per token,   274.45 tokens per second)\n",
            "llama_print_timings:        eval time =    1457.47 ms /    15 runs   (   97.16 ms per token,    10.29 tokens per second)\n",
            "llama_print_timings:       total time =    1958.41 ms /    90 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Our friend @adan_augusto at the #PlenariaMorena. I took the opportunity to deliver letters on educational matters from the Education Commission. We are committed to guaranteeing human rights, as well as ensuring a social policy in favor of all. https://t.co/sIv1Y7jpLb\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.39 ms /    16 runs   (    0.59 ms per token,  1704.48 tokens per second)\n",
            "llama_print_timings: prompt eval time =     265.85 ms /    63 tokens (    4.22 ms per token,   236.98 tokens per second)\n",
            "llama_print_timings:        eval time =    1637.59 ms /    15 runs   (  109.17 ms per token,     9.16 tokens per second)\n",
            "llama_print_timings:       total time =    2099.05 ms /    78 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Last night a friend was robbed. They ruined it in the middle of the crisis. Today while we were having mates she went from the wildest punitivism to non-stop guaranteeism. In the end that is what we are, contradictions and human rights.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.83 ms /    16 runs   (    0.74 ms per token,  1352.84 tokens per second)\n",
            "llama_print_timings: prompt eval time =     262.26 ms /    52 tokens (    5.04 ms per token,   198.28 tokens per second)\n",
            "llama_print_timings:        eval time =    1845.79 ms /    15 runs   (  123.05 ms per token,     8.13 tokens per second)\n",
            "llama_print_timings:       total time =    2313.54 ms /    67 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Download and consult the Protocol for Judging from the perspective of sexual orientation, gender identity and expression, and sexual characteristics (SOGIECS) here 🔗 https://t.co/ZZnwhSTOiI\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.61 ms /    16 runs   (    0.54 ms per token,  1859.38 tokens per second)\n",
            "llama_print_timings: prompt eval time =     392.30 ms /   138 tokens (    2.84 ms per token,   351.77 tokens per second)\n",
            "llama_print_timings:        eval time =    1539.04 ms /    15 runs   (  102.60 ms per token,     9.75 tokens per second)\n",
            "llama_print_timings:       total time =    2348.83 ms /   153 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "🔴The #PearlIsland megaproject in #Panama, questioned for human rights violations on the island where it is located, obtains millionaire tax benefits from the State to build a five-star hotel.History in #TierraDeResistenteshttps://t.co/mjugU70mX7 https://t.co/mjugU70mX7 https://t.co/mjugU70mX7 https://t.co/mjugU70mX7 ://t.co/iV9pVHVKdJ\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.67 ms /    16 runs   (    0.60 ms per token,  1654.94 tokens per second)\n",
            "llama_print_timings: prompt eval time =     285.02 ms /    76 tokens (    3.75 ms per token,   266.65 tokens per second)\n",
            "llama_print_timings:        eval time =    1443.71 ms /    15 runs   (   96.25 ms per token,    10.39 tokens per second)\n",
            "llama_print_timings:       total time =    1979.67 ms /    91 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Frente_Amplio The model that failed since the Bolshevik revolution to the present is the one proposed by the FA: Cuba, Venezuela... A model that only brings dictatorships, violation of human rights, poverty and backwardness. Name a single country that, with its model, has brought freedom, progress and prosperity.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.74 ms /    16 runs   (    0.61 ms per token,  1642.37 tokens per second)\n",
            "llama_print_timings: prompt eval time =     275.72 ms /    71 tokens (    3.88 ms per token,   257.51 tokens per second)\n",
            "llama_print_timings:        eval time =    1630.46 ms /    15 runs   (  108.70 ms per token,     9.20 tokens per second)\n",
            "llama_print_timings:       total time =    2134.54 ms /    86 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@sosa_tortuga @Nosti01303346 @elgandalfillo @asturexiliao @Xuxipc In her previous sentences she talks about the sexual and reproductive rights of women. https://t.co/w9RikT5xjm\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.86 ms /    16 runs   (    0.68 ms per token,  1473.57 tokens per second)\n",
            "llama_print_timings: prompt eval time =     290.01 ms /    70 tokens (    4.14 ms per token,   241.37 tokens per second)\n",
            "llama_print_timings:        eval time =    1675.84 ms /    15 runs   (  111.72 ms per token,     8.95 tokens per second)\n",
            "llama_print_timings:       total time =    2325.32 ms /    85 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "The Commission on the Status of Women made an explicit connection between climate justice, care, health, sexual and reproductive rights and the climate crisis in the lives of women and girls. Check: https://t.co/ftTkUN3xy8 https://t.co/HcAPoyP1zd\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.29 ms /    16 runs   (    0.58 ms per token,  1721.54 tokens per second)\n",
            "llama_print_timings: prompt eval time =     277.27 ms /    72 tokens (    3.85 ms per token,   259.67 tokens per second)\n",
            "llama_print_timings:        eval time =    1657.65 ms /    15 runs   (  110.51 ms per token,     9.05 tokens per second)\n",
            "llama_print_timings:       total time =    2155.85 ms /    87 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@fefaagul False, the proposal takes full charge of the Integrated Public Health of all Chileans, in nutritious food, mental health, disabilities of all spectrum, neurodivergents, women and sexual and reproductive rights, senior citizens, etc. #ApproveIn30Days\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.38 ms /    16 runs   (    0.59 ms per token,  1705.39 tokens per second)\n",
            "llama_print_timings: prompt eval time =     276.49 ms /    74 tokens (    3.74 ms per token,   267.64 tokens per second)\n",
            "llama_print_timings:        eval time =    1542.83 ms /    15 runs   (  102.86 ms per token,     9.72 tokens per second)\n",
            "llama_print_timings:       total time =    2050.65 ms /    89 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "#TODAY The last day of the Course - Workshop: \"Capacity Strengthening Conferences on Sexual and Reproductive Rights\" was successfully held. With the support of @JusticiaverdepePúblico: Judicial counselors https://t.co/pwT4vP3x0c\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.11 ms /    16 runs   (    0.63 ms per token,  1581.97 tokens per second)\n",
            "llama_print_timings: prompt eval time =     298.40 ms /    91 tokens (    3.28 ms per token,   304.96 tokens per second)\n",
            "llama_print_timings:        eval time =    1636.99 ms /    15 runs   (  109.13 ms per token,     9.16 tokens per second)\n",
            "llama_print_timings:       total time =    2380.41 ms /   106 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "We are just a few days away from #Zarelia2022 starting ✨. Check out the first day's activities. 🌼 With that approach that we have from @ruda_gt, I will teach a content creation workshop on sexual and reproductive rights 🌿✊🏽. https://t.co/0dGfdDh1rM\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.44 ms /    16 runs   (    0.53 ms per token,  1896.41 tokens per second)\n",
            "llama_print_timings: prompt eval time =     285.21 ms /    89 tokens (    3.20 ms per token,   312.06 tokens per second)\n",
            "llama_print_timings:        eval time =    1532.86 ms /    15 runs   (  102.19 ms per token,     9.79 tokens per second)\n",
            "llama_print_timings:       total time =    2083.46 ms /   104 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "🗣In favor of the Sexual and Reproductive Health and Rights of Women with Disabilities, we dismantle beliefs and demand:✔️Comprehensive sexual education.✔️Access to health with inclusive care protocols. ✔️Updated information ✔️Comprehensive reproductive care. https://t.co/WMvgBvx8Om\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.42 ms /    16 runs   (    0.71 ms per token,  1401.05 tokens per second)\n",
            "llama_print_timings: prompt eval time =     285.24 ms /    79 tokens (    3.61 ms per token,   276.96 tokens per second)\n",
            "llama_print_timings:        eval time =    1837.40 ms /    15 runs   (  122.49 ms per token,     8.16 tokens per second)\n",
            "llama_print_timings:       total time =    2528.24 ms /    94 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Why are you so ridiculous? Don't you get tired of embarrassing others? I really enjoyed reading you. Do you know about indirect discrimination based on gender? I see that no, I'm not going to continue arguing with an asshole who is 0 practical and who only knows the theory. https://t.co/MGsmhVBCvA\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.70 ms /    16 runs   (    0.61 ms per token,  1649.31 tokens per second)\n",
            "llama_print_timings: prompt eval time =     264.14 ms /    55 tokens (    4.80 ms per token,   208.22 tokens per second)\n",
            "llama_print_timings:        eval time =    1589.60 ms /    15 runs   (  105.97 ms per token,     9.44 tokens per second)\n",
            "llama_print_timings:       total time =    2030.80 ms /    70 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Minister, ask, is it correct, in the first instance at work, to rule and invalidate a promotion call because there is indirect discrimination against women? Or could it be invalidated only through protection? @ArturoZaldivarL\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.82 ms /    16 runs   (    0.61 ms per token,  1629.66 tokens per second)\n",
            "llama_print_timings: prompt eval time =     287.16 ms /    78 tokens (    3.68 ms per token,   271.63 tokens per second)\n",
            "llama_print_timings:        eval time =    1542.41 ms /    15 runs   (  102.83 ms per token,     9.73 tokens per second)\n",
            "llama_print_timings:       total time =    2061.23 ms /    93 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "One of the things that is present in Mexican society is discrimination (indirectly and directly) due to skin color. TV shows like the rose of Guadalupe shit on me, since they continue to instill these ideas.\"Clear\" = Rich, Brown and mestizos = Poor https://t.co/3jjEcR9Mem\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.63 ms /    16 runs   (    0.60 ms per token,  1660.61 tokens per second)\n",
            "llama_print_timings: prompt eval time =     277.83 ms /    75 tokens (    3.70 ms per token,   269.95 tokens per second)\n",
            "llama_print_timings:        eval time =    1530.63 ms /    15 runs   (  102.04 ms per token,     9.80 tokens per second)\n",
            "llama_print_timings:       total time =    2033.95 ms /    90 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Second JCR magazine to reject a text on indirect discrimination in the field of HIV. I accept it. It is part of the rules of the game. But I disagree that reviewers make statements lightly without substantiating them. Who controls the quality of the evaluations? https://t.co/3uK3Io6IzU\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.01 ms /    16 runs   (    0.56 ms per token,  1775.61 tokens per second)\n",
            "llama_print_timings: prompt eval time =     241.34 ms /    38 tokens (    6.35 ms per token,   157.45 tokens per second)\n",
            "llama_print_timings:        eval time =    1517.85 ms /    15 runs   (  101.19 ms per token,     9.88 tokens per second)\n",
            "llama_print_timings:       total time =    1902.63 ms /    53 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Indirect discrimination in the incompatibility of permanent disability pensions within the same public Social Security regimehttps://t.co/ErSLBjaZ55\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.79 ms /    16 runs   (    0.61 ms per token,  1634.99 tokens per second)\n",
            "llama_print_timings: prompt eval time =     261.28 ms /    56 tokens (    4.67 ms per token,   214.33 tokens per second)\n",
            "llama_print_timings:        eval time =    1527.64 ms /    15 runs   (  101.84 ms per token,     9.82 tokens per second)\n",
            "llama_print_timings:       total time =    1970.43 ms /    71 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@MundoArbitrato @ReglaXVIII_ We must not confuse equality with indirect discrimination. Making everything within the organization exactly the same for boys and girls would be, practically, the \"extinction\" of the girl referee.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.94 ms /    16 runs   (    0.68 ms per token,  1462.39 tokens per second)\n",
            "llama_print_timings: prompt eval time =     253.44 ms /    42 tokens (    6.03 ms per token,   165.72 tokens per second)\n",
            "llama_print_timings:        eval time =    1843.20 ms /    15 runs   (  122.88 ms per token,     8.14 tokens per second)\n",
            "llama_print_timings:       total time =    2354.80 ms /    57 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "🟢 The Human Rights Commission approves three opinions on affirmative actions, discrimination during health emergencies and multiple discrimination. https://t.co/bzprobrtBv\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.36 ms /    16 runs   (    0.58 ms per token,  1709.58 tokens per second)\n",
            "llama_print_timings: prompt eval time =     265.37 ms /    57 tokens (    4.66 ms per token,   214.79 tokens per second)\n",
            "llama_print_timings:        eval time =    1491.91 ms /    15 runs   (   99.46 ms per token,    10.05 tokens per second)\n",
            "llama_print_timings:       total time =    1931.40 ms /    72 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@saskianino @asulvanam Yes, @saskianino is used as an element similar to intersectionality and multiple discrimination. Plus, they almost always go hand in hand. That you and I do not experience racism is another issue.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.74 ms /    16 runs   (    0.55 ms per token,  1830.04 tokens per second)\n",
            "llama_print_timings: prompt eval time =     245.53 ms /    40 tokens (    6.14 ms per token,   162.91 tokens per second)\n",
            "llama_print_timings:        eval time =    1537.77 ms /    15 runs   (  102.52 ms per token,     9.75 tokens per second)\n",
            "llama_print_timings:       total time =    1928.76 ms /    55 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "When two or more factors are analyzed, it is multiple discrimination; If the intersection is analyzed, the unique and different results produced from these factors simultaneously: intersectional study of discrimination\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.60 ms /    16 runs   (    0.60 ms per token,  1667.01 tokens per second)\n",
            "llama_print_timings: prompt eval time =     254.77 ms /    59 tokens (    4.32 ms per token,   231.59 tokens per second)\n",
            "llama_print_timings:        eval time =    1625.34 ms /    15 runs   (  108.36 ms per token,     9.23 tokens per second)\n",
            "llama_print_timings:       total time =    2060.29 ms /    74 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "The term “multiple/intersectional discrimination” is not recognized in transnational EU law, as it would be in the horizontal Directive proposed in 2008, yet to be adopted, which seeks to equalize levels of protection on several issues.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.21 ms /    16 runs   (    0.58 ms per token,  1737.81 tokens per second)\n",
            "llama_print_timings: prompt eval time =     257.92 ms /    48 tokens (    5.37 ms per token,   186.11 tokens per second)\n",
            "llama_print_timings:        eval time =    1516.01 ms /    15 runs   (  101.07 ms per token,     9.89 tokens per second)\n",
            "llama_print_timings:       total time =    1946.03 ms /    63 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "When do we talk about multiple discrimination in the workplace? When there are factors of age, gender and physical appearance 👇🏾 Czech. https://t.co/T1atizqPEo\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.86 ms /    16 runs   (    0.55 ms per token,  1806.07 tokens per second)\n",
            "llama_print_timings: prompt eval time =     248.56 ms /    33 tokens (    7.53 ms per token,   132.77 tokens per second)\n",
            "llama_print_timings:        eval time =    1536.14 ms /    15 runs   (  102.41 ms per token,     9.76 tokens per second)\n",
            "llama_print_timings:       total time =    1919.05 ms /    48 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "The objective was to identify relevant opportunities that the Central American private sector is offering to young people, mainly belonging to groups that face multiple discrimination.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.77 ms /    16 runs   (    0.55 ms per token,  1825.03 tokens per second)\n",
            "llama_print_timings: prompt eval time =     356.86 ms /   135 tokens (    2.64 ms per token,   378.30 tokens per second)\n",
            "llama_print_timings:        eval time =    1493.51 ms /    15 runs   (   99.57 ms per token,    10.04 tokens per second)\n",
            "llama_print_timings:       total time =    2260.77 ms /   150 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "📌JOB OFFER: FIRST BASIN AND CONSTRUCTION LABOR WITH FUNCTIONAL #DIVERSITY in #Málaga via @ArrabalAID #DIVERSITY and #INTEGRATION PROJECT IN SOCIAL ENTITIES @EgualdadAND 👇👇👇https://t.co/tXgKXqwwLv#inclusion #sociolaboral #Network #bricklayer #laborer https://t.co/ZE02kEt2lC\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.73 ms /    16 runs   (    0.73 ms per token,  1364.26 tokens per second)\n",
            "llama_print_timings: prompt eval time =     283.55 ms /    98 tokens (    2.89 ms per token,   345.62 tokens per second)\n",
            "llama_print_timings:        eval time =    1809.19 ms /    15 runs   (  120.61 ms per token,     8.29 tokens per second)\n",
            "llama_print_timings:       total time =    2424.14 ms /   113 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@mysteryorigin @lola_mamen Don't tell it to us, but to those who have achieved that: Inclusive language is not Braille and if speaking with \"e\" or \"x\" Functional diversity is a scourge, and not a different behavior TELL IT TO THE MINISTRY ABOUT INEQUALITY. TELL IT TO: @IreneMontero @ionebelarra\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.58 ms /    16 runs   (    0.60 ms per token,  1670.84 tokens per second)\n",
            "llama_print_timings: prompt eval time =     287.02 ms /    89 tokens (    3.22 ms per token,   310.08 tokens per second)\n",
            "llama_print_timings:        eval time =    1576.75 ms /    15 runs   (  105.12 ms per token,     9.51 tokens per second)\n",
            "llama_print_timings:       total time =    2144.80 ms /   104 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@AytoFuenlabrada @Fn_noticias We have already started the Friday routine, those who come to the bar believe that this functional diversity square on Gerona Street is so that when they leave drunk the car is closer to them, I would call but I lost faith in that @ Fuenla Police is going to come https://t.co/wPmpXLM11k\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.07 ms /    16 runs   (    0.63 ms per token,  1589.51 tokens per second)\n",
            "llama_print_timings: prompt eval time =     280.91 ms /    70 tokens (    4.01 ms per token,   249.19 tokens per second)\n",
            "llama_print_timings:        eval time =    1478.24 ms /    15 runs   (   98.55 ms per token,    10.15 tokens per second)\n",
            "llama_print_timings:       total time =    1978.13 ms /    85 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@JuntOnDemEspRep You mention that it has intellectual functional diversity. That mother has rights, also from there. But from the point of view of Social Services she is someone who is very manageable in files. That is, if you look at it that way you will see that the point is different. Look.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.70 ms /    16 runs   (    0.61 ms per token,  1648.80 tokens per second)\n",
            "llama_print_timings: prompt eval time =     289.22 ms /    77 tokens (    3.76 ms per token,   266.23 tokens per second)\n",
            "llama_print_timings:        eval time =    1472.45 ms /    15 runs   (   98.16 ms per token,    10.19 tokens per second)\n",
            "llama_print_timings:       total time =    2003.33 ms /    92 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "It is extreme violence, allying yourself with the pack and trying to harm Rocío Carrasco through her functionally diverse son. What ignorance has is that it is cruelty, disguised as innocence.#PrisonforAntonioDavid#OlgaMorenoSinEscrupulos #APOYOROCIO17A\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.26 ms /    16 runs   (    0.70 ms per token,  1421.21 tokens per second)\n",
            "llama_print_timings: prompt eval time =     261.14 ms /    63 tokens (    4.15 ms per token,   241.25 tokens per second)\n",
            "llama_print_timings:        eval time =    1689.08 ms /    15 runs   (  112.61 ms per token,     8.88 tokens per second)\n",
            "llama_print_timings:       total time =    2272.55 ms /    78 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Editorial Móstoles - Móstoles continues working for the socio-labor inclusion of people with functional diversity - https://t.co/4Hg3jiO2jN https://t.co/G0R5DYyWKY\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.38 ms /    16 runs   (    0.59 ms per token,  1706.67 tokens per second)\n",
            "llama_print_timings: prompt eval time =     290.75 ms /    88 tokens (    3.30 ms per token,   302.66 tokens per second)\n",
            "llama_print_timings:        eval time =    1643.91 ms /    15 runs   (  109.59 ms per token,     9.12 tokens per second)\n",
            "llama_print_timings:       total time =    2188.74 ms /   103 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "A 36-year-old woman who goes partying generates more confidence in me than a 60-year-old alcoholic man. Being a woman and being young, double discriminationWhat the Sanna Marin 'scandal' evidences: the sexist scrutiny against young politicians @ElPeriodico_Esp https://t.co/roR9XW3VNb\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.00 ms /    16 runs   (    0.56 ms per token,  1778.57 tokens per second)\n",
            "llama_print_timings: prompt eval time =     250.91 ms /    51 tokens (    4.92 ms per token,   203.26 tokens per second)\n",
            "llama_print_timings:        eval time =    1530.12 ms /    15 runs   (  102.01 ms per token,     9.80 tokens per second)\n",
            "llama_print_timings:       total time =    1949.19 ms /    66 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "More precariousness and zero conciliation: the double discrimination of women in rural environments https://t.co/OaarRwr2cH https://t.co/YBndG3nSMH\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.82 ms /    16 runs   (    0.61 ms per token,  1629.66 tokens per second)\n",
            "llama_print_timings: prompt eval time =     275.14 ms /    81 tokens (    3.40 ms per token,   294.40 tokens per second)\n",
            "llama_print_timings:        eval time =    1503.32 ms /    15 runs   (  100.22 ms per token,     9.98 tokens per second)\n",
            "llama_print_timings:       total time =    2020.24 ms /    96 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "For the Ambassador of Spain in Mexico @EmbEspMex, Juan Duarte Cuadrado @DuarteCuadrado highlighted that the #BartoloméDeLasCasas Award recognizes organizations that fight against double discrimination, for being a woman and for being indigenous https://t.co/BLVjp3ckl1\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.61 ms /    16 runs   (    0.66 ms per token,  1507.44 tokens per second)\n",
            "llama_print_timings: prompt eval time =     285.00 ms /    76 tokens (    3.75 ms per token,   266.66 tokens per second)\n",
            "llama_print_timings:        eval time =    1623.28 ms /    15 runs   (  108.22 ms per token,     9.24 tokens per second)\n",
            "llama_print_timings:       total time =    2274.05 ms /    91 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@cr0quetica \"those people don't suffer any discrimination\" he says while he discriminates against us, calling us sex addicts, vicious and zoophiles 😂😂😂 we have double discrimination, from straight people but also from the collective, but we are \"invisible\" because they don't give us a voice\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.32 ms /    16 runs   (    0.58 ms per token,  1716.00 tokens per second)\n",
            "llama_print_timings: prompt eval time =     278.39 ms /    85 tokens (    3.28 ms per token,   305.33 tokens per second)\n",
            "llama_print_timings:        eval time =    1560.29 ms /    15 runs   (  104.02 ms per token,     9.61 tokens per second)\n",
            "llama_print_timings:       total time =    2087.08 ms /   100 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "#IndigenousWomen'sDay 👩🏽👧🏽 Indigenous women face double discrimination, affecting their development in the home and family, as well as in the political, social, economic and cultural spheres. The vindication of their rights is still valid. All rights for all! https://t.co/uw2KPtCqiI\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.66 ms /    16 runs   (    0.60 ms per token,  1656.83 tokens per second)\n",
            "llama_print_timings: prompt eval time =     267.01 ms /    59 tokens (    4.53 ms per token,   220.96 tokens per second)\n",
            "llama_print_timings:        eval time =    1572.01 ms /    15 runs   (  104.80 ms per token,     9.54 tokens per second)\n",
            "llama_print_timings:       total time =    2021.08 ms /    74 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "“We must make the community understand that we can also be LGBTI” The double discrimination that LGBTIQ indigenous people face via: @quevedo_sara18 https://t.co/TvBSK2P14X\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.74 ms /    16 runs   (    0.67 ms per token,  1489.76 tokens per second)\n",
            "llama_print_timings: prompt eval time =     866.03 ms /    25 tokens (   34.64 ms per token,    28.87 tokens per second)\n",
            "llama_print_timings:        eval time =    1820.86 ms /    15 runs   (  121.39 ms per token,     8.24 tokens per second)\n",
            "llama_print_timings:       total time =    2883.14 ms /    40 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@mateoburgos07 I heard rumors that they are going to start working double shifts\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.80 ms /    16 runs   (    0.61 ms per token,  1631.82 tokens per second)\n",
            "llama_print_timings: prompt eval time =     290.08 ms /    79 tokens (    3.67 ms per token,   272.34 tokens per second)\n",
            "llama_print_timings:        eval time =    1476.84 ms /    15 runs   (   98.46 ms per token,    10.16 tokens per second)\n",
            "llama_print_timings:       total time =    1999.40 ms /    94 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Double day at the Rivaben! Lots of football on Wednesday at the Agustín Rivaben. There will be canteen service by our First Division players. Tickets: $150 pesos. FREE members. Vaaaaamoooo dean 🔴⚫️ https://t.co/N2orDnbf9U\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.14 ms /    16 runs   (    0.57 ms per token,  1750.36 tokens per second)\n",
            "llama_print_timings: prompt eval time =     280.21 ms /    83 tokens (    3.38 ms per token,   296.21 tokens per second)\n",
            "llama_print_timings:        eval time =    1556.43 ms /    15 runs   (  103.76 ms per token,     9.64 tokens per second)\n",
            "llama_print_timings:       total time =    2080.87 ms /    98 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Cautious teacher came to the extra hour that Kicillof establishes in schools. The Unity Front gives the green light, but without effusiveness. Make it optional, the key. Focus on the demand for a full double day. Who is on strike. 20 days after the celebrated increase announcement made https://t.co/hnBDzaMaey\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      13.53 ms /    16 runs   (    0.85 ms per token,  1182.30 tokens per second)\n",
            "llama_print_timings: prompt eval time =     292.85 ms /    83 tokens (    3.53 ms per token,   283.43 tokens per second)\n",
            "llama_print_timings:        eval time =    1867.79 ms /    15 runs   (  124.52 ms per token,     8.03 tokens per second)\n",
            "llama_print_timings:       total time =    2438.53 ms /    98 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "⚜️With any of our plans we add you to our groups in which we can make you grow better https://t.co/IAeEFXhGrw first month: day....⚜️Promo 2: Double day is done..⚜️Consult for more info.You can also follow us @Adultiing_mkt\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.43 ms /    16 runs   (    0.59 ms per token,  1697.25 tokens per second)\n",
            "llama_print_timings: prompt eval time =     293.54 ms /    94 tokens (    3.12 ms per token,   320.23 tokens per second)\n",
            "llama_print_timings:        eval time =    1569.71 ms /    15 runs   (  104.65 ms per token,     9.56 tokens per second)\n",
            "llama_print_timings:       total time =    2131.96 ms /   109 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "🎯 A double day of the Outdoor Modality Tournament was held. On Saturday the 1st date of the Provincial League and on Sunday the Federates in the Fatarco homologated (national) Rankeable Tournament. Our #ArqueríaCapri archers shined! #ComunidadCapri #ClubCapri https://t.co/zuourmMNFm\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.33 ms /    16 runs   (    0.58 ms per token,  1714.90 tokens per second)\n",
            "llama_print_timings: prompt eval time =     258.19 ms /    44 tokens (    5.87 ms per token,   170.42 tokens per second)\n",
            "llama_print_timings:        eval time =    1471.55 ms /    15 runs   (   98.10 ms per token,    10.19 tokens per second)\n",
            "llama_print_timings:       total time =    1886.49 ms /    59 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Give it to your trusted #EspacioAzulFemenil, double shift. 1 pt of 6. https://t.co/q53Jhp7Qia\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.89 ms /    16 runs   (    0.62 ms per token,  1617.47 tokens per second)\n",
            "llama_print_timings: prompt eval time =     250.71 ms /    62 tokens (    4.04 ms per token,   247.29 tokens per second)\n",
            "llama_print_timings:        eval time =    1616.20 ms /    15 runs   (  107.75 ms per token,     9.28 tokens per second)\n",
            "llama_print_timings:       total time =    2058.49 ms /    77 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@liliasolanor A recognition of this process of women in the territory who are like butterflies whose entrepreneurship and leadership has cost them like caterpillars an entire metamorphosis to reveal the beautiful leadership that makes them strong from ecofeminism!!\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.85 ms /    16 runs   (    0.74 ms per token,  1349.98 tokens per second)\n",
            "llama_print_timings: prompt eval time =     275.91 ms /    66 tokens (    4.18 ms per token,   239.20 tokens per second)\n",
            "llama_print_timings:        eval time =    1898.81 ms /    15 runs   (  126.59 ms per token,     7.90 tokens per second)\n",
            "llama_print_timings:       total time =    2513.11 ms /    81 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "It's time to take care of it and conserve it better.#ECOFEMINISM or BARBARIE!!!#BuenosDias 💪🏽💚💜💚💪🏽 https://t.co/fg8KlrroXc\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.77 ms /    16 runs   (    0.61 ms per token,  1637.33 tokens per second)\n",
            "llama_print_timings: prompt eval time =     287.64 ms /    74 tokens (    3.89 ms per token,   257.27 tokens per second)\n",
            "llama_print_timings:        eval time =    1667.59 ms /    15 runs   (  111.17 ms per token,     9.00 tokens per second)\n",
            "llama_print_timings:       total time =    2175.17 ms /    89 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "#Column 🌲Popular Environmentalism🌍📢🟢what are we talking about when we refer to systematic persecution against environmental defenders? @micaelaegarcia tells us and explains the concept of #ecofeminism 🎙️ @tamiastascro 🔥\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.44 ms /    16 runs   (    0.59 ms per token,  1694.92 tokens per second)\n",
            "llama_print_timings: prompt eval time =     297.23 ms /    99 tokens (    3.00 ms per token,   333.08 tokens per second)\n",
            "llama_print_timings:        eval time =    1537.70 ms /    15 runs   (  102.51 ms per token,     9.75 tokens per second)\n",
            "llama_print_timings:       total time =    2128.22 ms /   114 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "New item! Since the beginning of September at Vita we have been talking about the concept of “matrix” and claiming the rights over our bodies-territories. We want to talk about #ecofeminism. Do you know it? https://t.co/JgZwYHAy8G#vitaactivaorg #lineadeayuda #cuerpa https://t.co/LgcOtfi2vr\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.19 ms /    16 runs   (    0.70 ms per token,  1429.98 tokens per second)\n",
            "llama_print_timings: prompt eval time =     298.71 ms /    86 tokens (    3.47 ms per token,   287.91 tokens per second)\n",
            "llama_print_timings:        eval time =    1741.36 ms /    15 runs   (  116.09 ms per token,     8.61 tokens per second)\n",
            "llama_print_timings:       total time =    2466.24 ms /   101 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "I just saw this great report from @InformeSemanal. #ecofeminism has been defending 'slow fashion' and the sustainability of textiles for years. If you missed it, it will be out soon on @rtveplay 🔝🔝🔝 https://t.co/1LwXHnTX45\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.63 ms /    16 runs   (    0.60 ms per token,  1661.47 tokens per second)\n",
            "llama_print_timings: prompt eval time =     291.12 ms /    92 tokens (    3.16 ms per token,   316.02 tokens per second)\n",
            "llama_print_timings:        eval time =    1492.51 ms /    15 runs   (   99.50 ms per token,    10.05 tokens per second)\n",
            "llama_print_timings:       total time =    2049.81 ms /   107 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Is there a link between the subordination of women and the destructive exploitation of nature? Let's reflect together with Ninfa Ambiental (@melissadez_), at the conference \"Mexiquense Ecofeminism\"; this August 19th through our Facebook Live. #SeMujeresEdoméx https://t.co/JXBZ72eeY2\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.66 ms /    16 runs   (    0.60 ms per token,  1656.14 tokens per second)\n",
            "llama_print_timings: prompt eval time =     290.28 ms /    89 tokens (    3.26 ms per token,   306.60 tokens per second)\n",
            "llama_print_timings:        eval time =    1645.66 ms /    15 runs   (  109.71 ms per token,     9.11 tokens per second)\n",
            "llama_print_timings:       total time =    2191.43 ms /   104 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "THEY DISGUISE affective-sexual education based on gender ideology 🏳️‍🌈 in \"respect for diversity\" and the reality is that it is INDOCTRINATION and ATTACKING against the cognitive capacity of children and against the moral and religious principles that we transmit to our children. https://t.co/bToUrqWHm9\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.63 ms /    16 runs   (    0.66 ms per token,  1504.47 tokens per second)\n",
            "llama_print_timings: prompt eval time =     249.15 ms /    49 tokens (    5.08 ms per token,   196.67 tokens per second)\n",
            "llama_print_timings:        eval time =    1710.21 ms /    15 runs   (  114.01 ms per token,     8.77 tokens per second)\n",
            "llama_print_timings:       total time =    2137.15 ms /    64 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "About Montero: Of course, emotional sexual education is needed, adapted to the different stages of development, but starting the earlier the better. The rest is nonsense from far-rightists and meapilas.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.67 ms /    16 runs   (    0.60 ms per token,  1655.29 tokens per second)\n",
            "llama_print_timings: prompt eval time =     287.98 ms /    70 tokens (    4.11 ms per token,   243.07 tokens per second)\n",
            "llama_print_timings:        eval time =    1466.01 ms /    15 runs   (   97.73 ms per token,    10.23 tokens per second)\n",
            "llama_print_timings:       total time =    1963.32 ms /    85 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "We need urgent measures against the insecurity that the chemical submission that is recently practiced in nightclubs is giving us. We have to continue working for quality emotional-sexual education, with global training, and that educates us from a young age https:// t.co/qykk0KgnvQ\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.66 ms /    16 runs   (    0.60 ms per token,  1657.00 tokens per second)\n",
            "llama_print_timings: prompt eval time =     281.59 ms /    88 tokens (    3.20 ms per token,   312.51 tokens per second)\n",
            "llama_print_timings:        eval time =    1599.81 ms /    15 runs   (  106.65 ms per token,     9.38 tokens per second)\n",
            "llama_print_timings:       total time =    2129.71 ms /   103 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@elespanolcom 🤦‍♀️ This is a big hurry, but not a comprehensive affective-sexual education within the school curriculum. To a training that educates so that these types of laws are not necessary, right? That's for what?! It seems unfortunate to me that due to the belief of “because of my ovaries”, this is like this 😖\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.26 ms /    16 runs   (    0.58 ms per token,  1728.80 tokens per second)\n",
            "llama_print_timings: prompt eval time =     256.33 ms /    48 tokens (    5.34 ms per token,   187.26 tokens per second)\n",
            "llama_print_timings:        eval time =    1465.07 ms /    15 runs   (   97.67 ms per token,    10.24 tokens per second)\n",
            "llama_print_timings:       total time =    1882.50 ms /    63 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Consent is submission. A good emotional-sexual education involves knowing and wanting, it is not based on consent #CoeducaciónRealYa https://t.co/mjfuugWFtD\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.67 ms /    16 runs   (    0.73 ms per token,  1371.39 tokens per second)\n",
            "llama_print_timings: prompt eval time =     257.61 ms /    56 tokens (    4.60 ms per token,   217.39 tokens per second)\n",
            "llama_print_timings:        eval time =    1884.74 ms /    15 runs   (  125.65 ms per token,     7.96 tokens per second)\n",
            "llama_print_timings:       total time =    2438.31 ms /    71 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Sexual crimes by minors have increased by 58%. 😱Affective-sexual education is essential and changing the referential models of adult society.https://t.co/CLLO0lcbP5\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.84 ms /    16 runs   (    0.55 ms per token,  1810.98 tokens per second)\n",
            "llama_print_timings: prompt eval time =     281.35 ms /    70 tokens (    4.02 ms per token,   248.80 tokens per second)\n",
            "llama_print_timings:        eval time =    1509.80 ms /    15 runs   (  100.65 ms per token,     9.94 tokens per second)\n",
            "llama_print_timings:       total time =    2000.17 ms /    85 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@nacolets Remember: feminism is a multi-dimensional movement, not a religion. Its principle is equal rights between women and men. Radicalizing the principle does not make you a feminist, it makes you a fanatic. Defending the principle makes you a feminist, no matter who you are.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.72 ms /    16 runs   (    0.54 ms per token,  1835.28 tokens per second)\n",
            "llama_print_timings: prompt eval time =     239.11 ms /    40 tokens (    5.98 ms per token,   167.29 tokens per second)\n",
            "llama_print_timings:        eval time =    1526.70 ms /    15 runs   (  101.78 ms per token,     9.83 tokens per second)\n",
            "llama_print_timings:       total time =    1906.50 ms /    55 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@ArtOfNe so much stupidity and selfishness in a tweet, the truth is it's time to eliminate little shits like you, feminism is cancer.\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.78 ms /    16 runs   (    0.61 ms per token,  1635.49 tokens per second)\n",
            "llama_print_timings: prompt eval time =     253.27 ms /    47 tokens (    5.39 ms per token,   185.57 tokens per second)\n",
            "llama_print_timings:        eval time =    1649.13 ms /    15 runs   (  109.94 ms per token,     9.10 tokens per second)\n",
            "llama_print_timings:       total time =    2075.88 ms /    62 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Juanaafanador1 @petrogustavo Hahaha, how stupid this is. Feminism is even worse than machismo, sectarian groups full of hate against the opposite gender.\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.71 ms /    16 runs   (    0.61 ms per token,  1647.62 tokens per second)\n",
            "llama_print_timings: prompt eval time =     270.05 ms /    64 tokens (    4.22 ms per token,   236.99 tokens per second)\n",
            "llama_print_timings:        eval time =    1511.50 ms /    15 runs   (  100.77 ms per token,     9.92 tokens per second)\n",
            "llama_print_timings:       total time =    1981.34 ms /    79 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@AngelicaLozanoC and what do you say about this co-partisan? When machismo belongs to those in your group, is it okay? Is feminism only when it comes from the left? https://t.co/wS2V7CSw3L\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.24 ms /    16 runs   (    0.58 ms per token,  1731.23 tokens per second)\n",
            "llama_print_timings: prompt eval time =     277.24 ms /    72 tokens (    3.85 ms per token,   259.70 tokens per second)\n",
            "llama_print_timings:        eval time =    1589.34 ms /    15 runs   (  105.96 ms per token,     9.44 tokens per second)\n",
            "llama_print_timings:       total time =    2076.69 ms /    87 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Adonis_MAM @Ant52529536Jose @Doncactus22 Feminism is as diverse as everything human, and as always, what steals the most attention is what will steal the most cameras and publicity. Stereotyping him is a serious mistake!\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.85 ms /    16 runs   (    0.55 ms per token,  1807.09 tokens per second)\n",
            "llama_print_timings: prompt eval time =     803.60 ms /    30 tokens (   26.79 ms per token,    37.33 tokens per second)\n",
            "llama_print_timings:        eval time =    1493.29 ms /    15 runs   (   99.55 ms per token,    10.04 tokens per second)\n",
            "llama_print_timings:       total time =    2425.78 ms /    45 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Alfredolara29 I believe that feminism is an important communicating vessel between FA and Kirchenrism.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.02 ms /    16 runs   (    0.63 ms per token,  1596.81 tokens per second)\n",
            "llama_print_timings: prompt eval time =     764.44 ms /    24 tokens (   31.85 ms per token,    31.40 tokens per second)\n",
            "llama_print_timings:        eval time =    1585.55 ms /    15 runs   (  105.70 ms per token,     9.46 tokens per second)\n",
            "llama_print_timings:       total time =    2516.07 ms /    39 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Since I dreamed of being pregnant, I have had this existential doubt about motherhood.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.90 ms /    16 runs   (    0.56 ms per token,  1797.75 tokens per second)\n",
            "llama_print_timings: prompt eval time =     247.67 ms /    44 tokens (    5.63 ms per token,   177.65 tokens per second)\n",
            "llama_print_timings:        eval time =    1669.76 ms /    15 runs   (  111.32 ms per token,     8.98 tokens per second)\n",
            "llama_print_timings:       total time =    2074.64 ms /    59 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "As the rule in medicine “every woman of childbearing age is pregnant until proven otherwise” In life it should be “every bandit is pregnant until proven otherwise” 🐸\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.67 ms /    16 runs   (    0.54 ms per token,  1846.08 tokens per second)\n",
            "llama_print_timings: prompt eval time =     264.88 ms /    56 tokens (    4.73 ms per token,   211.42 tokens per second)\n",
            "llama_print_timings:        eval time =    1631.39 ms /    15 runs   (  108.76 ms per token,     9.19 tokens per second)\n",
            "llama_print_timings:       total time =    2075.51 ms /    71 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "I'm at 1 am in the morning reading information about the pelvic floor and exercises, I also started watching exercises for pregnant women when I don't have pelvic floor problems nor am I pregnant HAHAHAHAHAHAHA\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.04 ms /    16 runs   (    0.69 ms per token,  1449.93 tokens per second)\n",
            "llama_print_timings: prompt eval time =     261.67 ms /    57 tokens (    4.59 ms per token,   217.83 tokens per second)\n",
            "llama_print_timings:        eval time =    1842.96 ms /    15 runs   (  122.86 ms per token,     8.14 tokens per second)\n",
            "llama_print_timings:       total time =    2326.27 ms /    72 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "We went to the polleria with Martina, she ran into a friend and told him that she was going to have a sister, and then she told him my mom got pregnant out of nowhere! Yes mommy out of nowhere. Hahahahaha\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.33 ms /    16 runs   (    0.58 ms per token,  1715.63 tokens per second)\n",
            "llama_print_timings: prompt eval time =     281.54 ms /    67 tokens (    4.20 ms per token,   237.98 tokens per second)\n",
            "llama_print_timings:        eval time =    1440.23 ms /    15 runs   (   96.02 ms per token,    10.41 tokens per second)\n",
            "llama_print_timings:       total time =    1925.87 ms /    82 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@matildemarti But it is not because that site is reserved for those cases, but rather it is for education!! Just as I know it should be given to an elderly person (or that is what is ethical and correct), also to a pregnant person, it is not that complicated to understand!!!\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.33 ms /    16 runs   (    0.58 ms per token,  1715.82 tokens per second)\n",
            "llama_print_timings: prompt eval time =     240.85 ms /    41 tokens (    5.87 ms per token,   170.23 tokens per second)\n",
            "llama_print_timings:        eval time =    1527.10 ms /    15 runs   (  101.81 ms per token,     9.82 tokens per second)\n",
            "llama_print_timings:       total time =    1919.38 ms /    56 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Now getting together to eat with friends is going out of fun and I can't go because I'm pregnant says the dad dw he blessed her naaaaa this is a lot\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.63 ms /    16 runs   (    0.60 ms per token,  1661.82 tokens per second)\n",
            "llama_print_timings: prompt eval time =     262.54 ms /    51 tokens (    5.15 ms per token,   194.26 tokens per second)\n",
            "llama_print_timings:        eval time =    1558.23 ms /    15 runs   (  103.88 ms per token,     9.63 tokens per second)\n",
            "llama_print_timings:       total time =    1996.04 ms /    66 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@ChaotiColombian @lovek_os12 They always try to female empowerment, when she is with a misogynist who recorded her, cheated on her, and there she continues with the\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.86 ms /    16 runs   (    0.68 ms per token,  1472.89 tokens per second)\n",
            "llama_print_timings: prompt eval time =     243.21 ms /    42 tokens (    5.79 ms per token,   172.69 tokens per second)\n",
            "llama_print_timings:        eval time =    1814.38 ms /    15 runs   (  120.96 ms per token,     8.27 tokens per second)\n",
            "llama_print_timings:       total time =    2233.65 ms /    57 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "(L)Earn ''NEAR Sputnik DAO: community empowerment'' via @LearnNEAR https://t.co/bdEN5LMMBF\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.88 ms /    16 runs   (    0.62 ms per token,  1618.94 tokens per second)\n",
            "llama_print_timings: prompt eval time =     268.23 ms /    60 tokens (    4.47 ms per token,   223.69 tokens per second)\n",
            "llama_print_timings:        eval time =    1482.00 ms /    15 runs   (   98.80 ms per token,    10.12 tokens per second)\n",
            "llama_print_timings:       total time =    1949.47 ms /    75 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Verito_Quimera People don't understand anything. He lacked trans. Lesbo scenes. Female empowerment. There was no LGBT Hannibal. Nah, joke. In reality it was too dark for the tender little hearts of the viewers.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.56 ms /    16 runs   (    0.54 ms per token,  1868.29 tokens per second)\n",
            "llama_print_timings: prompt eval time =     242.51 ms /    54 tokens (    4.49 ms per token,   222.67 tokens per second)\n",
            "llama_print_timings:        eval time =    1491.88 ms /    15 runs   (   99.46 ms per token,    10.05 tokens per second)\n",
            "llama_print_timings:       total time =    1911.66 ms /    69 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "I was listening to salute and I was and what: THAT VOCAL RANGE??????THAT EMPOWERMENT?????THAT TALENT?????THOSE VISUALS????\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.69 ms /    16 runs   (    0.73 ms per token,  1368.34 tokens per second)\n",
            "llama_print_timings: prompt eval time =     260.07 ms /    45 tokens (    5.78 ms per token,   173.03 tokens per second)\n",
            "llama_print_timings:        eval time =    1783.93 ms /    15 runs   (  118.93 ms per token,     8.41 tokens per second)\n",
            "llama_print_timings:       total time =    2312.95 ms /    60 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "(L)Earn ''NEAR Sputnik DAO: community empowerment'' via @LearnNEAR https://t.co/hCgu0cZrBq\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.81 ms /    16 runs   (    0.55 ms per token,  1815.91 tokens per second)\n",
            "llama_print_timings: prompt eval time =     796.09 ms /    30 tokens (   26.54 ms per token,    37.68 tokens per second)\n",
            "llama_print_timings:        eval time =    1533.32 ms /    15 runs   (  102.22 ms per token,     9.78 tokens per second)\n",
            "llama_print_timings:       total time =    2456.92 ms /    45 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@LucianoRevoredo @abeja_peru Caviarín without power. Need \"empowerment\".😎\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.80 ms /    16 runs   (    0.55 ms per token,  1817.77 tokens per second)\n",
            "llama_print_timings: prompt eval time =     614.08 ms /    23 tokens (   26.70 ms per token,    37.45 tokens per second)\n",
            "llama_print_timings:        eval time =    1475.13 ms /    15 runs   (   98.34 ms per token,    10.17 tokens per second)\n",
            "llama_print_timings:       total time =    2201.81 ms /    38 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Today I woke up thinking that I would bring you food on your days on duty.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       3.07 ms /     5 runs   (    0.61 ms per token,  1628.66 tokens per second)\n",
            "llama_print_timings: prompt eval time =     272.59 ms /    92 tokens (    2.96 ms per token,   337.51 tokens per second)\n",
            "llama_print_timings:        eval time =     445.19 ms /     4 runs   (  111.30 ms per token,     8.98 tokens per second)\n",
            "llama_print_timings:       total time =     954.10 ms /    96 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@giiolopezz @willyhands17 @z001110011100 @Santiahi2 @AnarkoAlpiniste @1708Jhonjairo But don't cry, because you cry so much @giiolopezz are you in your days are you menstruating 🩸 or because you cry a lot\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.60 ms /    16 runs   (    0.73 ms per token,  1378.83 tokens per second)\n",
            "llama_print_timings: prompt eval time =     237.44 ms /    61 tokens (    3.89 ms per token,   256.90 tokens per second)\n",
            "llama_print_timings:        eval time =    1833.82 ms /    15 runs   (  122.25 ms per token,     8.18 tokens per second)\n",
            "llama_print_timings:       total time =    2289.07 ms /    76 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@PMunozLedo I'm glad to know that you have a family Give them that pleasure that you are and love Mexico You listened to yourself And know history Don't be the worst or trash when trying to hang out with TRAITORS Think back on your days\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.69 ms /    16 runs   (    0.61 ms per token,  1652.04 tokens per second)\n",
            "llama_print_timings: prompt eval time =     290.25 ms /    75 tokens (    3.87 ms per token,   258.40 tokens per second)\n",
            "llama_print_timings:        eval time =    1540.44 ms /    15 runs   (  102.70 ms per token,     9.74 tokens per second)\n",
            "llama_print_timings:       total time =    2059.19 ms /    90 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Keep me❣️In your eyesAnd remember all my imagesKeep me in your earsAnd hear my voice againAgain and againKeep me in your mouthWith hundreds of \"I love you\"Keep me in your nightsThat have witnessed the most ardent desiresKeep me in your daysThose who are calm ⬇️\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.62 ms /    16 runs   (    0.54 ms per token,  1856.15 tokens per second)\n",
            "llama_print_timings: prompt eval time =     240.63 ms /    37 tokens (    6.50 ms per token,   153.76 tokens per second)\n",
            "llama_print_timings:        eval time =    1524.46 ms /    15 runs   (  101.63 ms per token,     9.84 tokens per second)\n",
            "llama_print_timings:       total time =    1904.88 ms /    52 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Pros of being in your days: you shit all day 👍🏻Con: I have a 3-month pregnant belly 👎🏻\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.48 ms /    16 runs   (    0.59 ms per token,  1687.23 tokens per second)\n",
            "llama_print_timings: prompt eval time =     270.77 ms /    76 tokens (    3.56 ms per token,   280.68 tokens per second)\n",
            "llama_print_timings:        eval time =    1517.57 ms /    15 runs   (  101.17 ms per token,     9.88 tokens per second)\n",
            "llama_print_timings:       total time =    2009.82 ms /    91 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "\"And if just one day you feel bad, you don't want to talk or whatever, tell me and I will understand you even on your bad days🥹. Don't thank me, I do it from the heart because it comes from me\" Healing messages, I am surrounded of beautiful people, I have no doubts.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.28 ms /    16 runs   (    0.58 ms per token,  1724.32 tokens per second)\n",
            "llama_print_timings: prompt eval time =     286.22 ms /    82 tokens (    3.49 ms per token,   286.50 tokens per second)\n",
            "llama_print_timings:        eval time =    1470.69 ms /    15 runs   (   98.05 ms per token,    10.20 tokens per second)\n",
            "llama_print_timings:       total time =    2005.47 ms /    97 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@nataliaFHN Natalia I have two of my mom's. I worked in Oncology and I am a nurse, my life is normal, I am very free of illness if you want to talk, cry or laugh at your disposal, I am from Spain. A hug and I hope for your reference and tell me what country you are from.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       7.70 ms /    16 runs   (    0.48 ms per token,  2079.27 tokens per second)\n",
            "llama_print_timings: prompt eval time =     263.88 ms /    54 tokens (    4.89 ms per token,   204.63 tokens per second)\n",
            "llama_print_timings:        eval time =    1502.48 ms /    15 runs   (  100.17 ms per token,     9.98 tokens per second)\n",
            "llama_print_timings:       total time =    1942.10 ms /    69 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Shit but Ernesto has a different parrot for each nurse AHAHAHAHAHAHAHAHAHA what a guy this is 😹😹😹😹😹\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.66 ms /    16 runs   (    0.67 ms per token,  1501.50 tokens per second)\n",
            "llama_print_timings: prompt eval time =     297.98 ms /    98 tokens (    3.04 ms per token,   328.88 tokens per second)\n",
            "llama_print_timings:        eval time =    1654.68 ms /    15 runs   (  110.31 ms per token,     9.07 tokens per second)\n",
            "llama_print_timings:       total time =    2274.44 ms /   113 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Did someone call a nurse? 💉💕There is a birthday PROMO 🎂💕 40% OFF in my OF ✨. https://t.co/pnnmvjNAbp for this week only ~I will be uploading many photos 🌡️🔥 of this outfit, you can't miss them 💖. https://t.co/VhrhoBZ3KW\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.69 ms /    16 runs   (    0.54 ms per token,  1841.83 tokens per second)\n",
            "llama_print_timings: prompt eval time =     250.64 ms /    34 tokens (    7.37 ms per token,   135.65 tokens per second)\n",
            "llama_print_timings:        eval time =    1612.38 ms /    15 runs   (  107.49 ms per token,     9.30 tokens per second)\n",
            "llama_print_timings:       total time =    2010.80 ms /    49 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Me in the hospital: sick of seeing nursesMy dad: your girlfriend is a nurse😐In my defense my girlfriend is cute😍\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.80 ms /    16 runs   (    0.61 ms per token,  1632.32 tokens per second)\n",
            "llama_print_timings: prompt eval time =     292.00 ms /    94 tokens (    3.11 ms per token,   321.92 tokens per second)\n",
            "llama_print_timings:        eval time =    1491.48 ms /    15 runs   (   99.43 ms per token,    10.06 tokens per second)\n",
            "llama_print_timings:       total time =    2054.78 ms /   109 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "THE KILLER OF THE YOUNG NURSE EDILENIA CAPELLAN IS ALREADY ARRESTED Confirmed from Fantino Cotui that the named Carlos Manuel Peguero is in the hands of the Police there, who this morning murdered his partner with a stab, the now deceased EDILENIA CAPELLAN https:/ /t.co/BArRCZAlYH\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.29 ms /    16 runs   (    0.58 ms per token,  1723.02 tokens per second)\n",
            "llama_print_timings: prompt eval time =     258.18 ms /    46 tokens (    5.61 ms per token,   178.17 tokens per second)\n",
            "llama_print_timings:        eval time =    1530.17 ms /    15 runs   (  102.01 ms per token,     9.80 tokens per second)\n",
            "llama_print_timings:       total time =    1951.01 ms /    61 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "A Cuban doctor, a nurse and a patient's relative died after an armed attack in a hospital in Ecatepec, #EdoMéx #AzucenaxFórmula\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.44 ms /    16 runs   (    0.65 ms per token,  1532.57 tokens per second)\n",
            "llama_print_timings: prompt eval time =     504.34 ms /    18 tokens (   28.02 ms per token,    35.69 tokens per second)\n",
            "llama_print_timings:        eval time =    1705.84 ms /    15 runs   (  113.72 ms per token,     8.79 tokens per second)\n",
            "llama_print_timings:       total time =    2339.39 ms /    33 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Women will never understand men and men think they understand women.\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.98 ms /    16 runs   (    0.56 ms per token,  1781.54 tokens per second)\n",
            "llama_print_timings: prompt eval time =     641.51 ms /    24 tokens (   26.73 ms per token,    37.41 tokens per second)\n",
            "llama_print_timings:        eval time =    1567.63 ms /    15 runs   (  104.51 ms per token,     9.57 tokens per second)\n",
            "llama_print_timings:       total time =    2329.11 ms /    39 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "I will never understand women who get angry because their partners play Play or some other console 😀\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.34 ms /    16 runs   (    0.52 ms per token,  1918.93 tokens per second)\n",
            "llama_print_timings: prompt eval time =     262.68 ms /    60 tokens (    4.38 ms per token,   228.42 tokens per second)\n",
            "llama_print_timings:        eval time =    1649.04 ms /    15 runs   (  109.94 ms per token,     9.10 tokens per second)\n",
            "llama_print_timings:       total time =    2095.04 ms /    75 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "I will never understand women part 100000 If you give her attention, love, you're one more of the bunch Now treat her badly, don't look at her, don't make room for her Bye, you're the love of her life...\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.53 ms /    16 runs   (    0.60 ms per token,  1679.26 tokens per second)\n",
            "llama_print_timings: prompt eval time =     269.64 ms /    72 tokens (    3.74 ms per token,   267.03 tokens per second)\n",
            "llama_print_timings:        eval time =    1558.56 ms /    15 runs   (  103.90 ms per token,     9.62 tokens per second)\n",
            "llama_print_timings:       total time =    2035.22 ms /    87 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Yesterday a friend from work told me about her relationship problems and with a lot of frustration she told me: “Oh Spençer, no matter how hard I try, I can't understand women” And I was like: “Girl, you're a woman” Neta… I got freaked out.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.13 ms /    16 runs   (    0.70 ms per token,  1437.81 tokens per second)\n",
            "llama_print_timings: prompt eval time =     255.64 ms /    52 tokens (    4.92 ms per token,   203.41 tokens per second)\n",
            "llama_print_timings:        eval time =    1937.49 ms /    15 runs   (  129.17 ms per token,     7.74 tokens per second)\n",
            "llama_print_timings:       total time =    2478.49 ms /    67 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@diliarlozano @Mimi07141 From the same writer of the book: HOW TO UNDERSTAND WOMEN, 😄😄😄😄😄😄😄😄🍻\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.91 ms /    16 runs   (    0.56 ms per token,  1795.74 tokens per second)\n",
            "llama_print_timings: prompt eval time =     416.39 ms /    14 tokens (   29.74 ms per token,    33.62 tokens per second)\n",
            "llama_print_timings:        eval time =    1482.63 ms /    15 runs   (   98.84 ms per token,    10.12 tokens per second)\n",
            "llama_print_timings:       total time =    1994.07 ms /    29 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "I give up, I will never understand women\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.03 ms /    16 runs   (    0.56 ms per token,  1772.66 tokens per second)\n",
            "llama_print_timings: prompt eval time =     242.52 ms /    44 tokens (    5.51 ms per token,   181.43 tokens per second)\n",
            "llama_print_timings:        eval time =    1573.60 ms /    15 runs   (  104.91 ms per token,     9.53 tokens per second)\n",
            "llama_print_timings:       total time =    1980.07 ms /    59 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@BTxorri @ConsuorF @ertzaintzaEJGV @EuskalMemoria Those who write those tweets are the biggest scum of this society\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.03 ms /    16 runs   (    0.56 ms per token,  1771.68 tokens per second)\n",
            "llama_print_timings: prompt eval time =     249.69 ms /    47 tokens (    5.31 ms per token,   188.23 tokens per second)\n",
            "llama_print_timings:        eval time =    1543.03 ms /    15 runs   (  102.87 ms per token,     9.72 tokens per second)\n",
            "llama_print_timings:       total time =    1964.53 ms /    62 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@MariettoPonce The vulgar Lilly Téllez who, as long as they fight her, invents self-attacks, the truth is that she does represent scum like Marietto\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.18 ms /    16 runs   (    0.57 ms per token,  1743.11 tokens per second)\n",
            "llama_print_timings: prompt eval time =     260.66 ms /    47 tokens (    5.55 ms per token,   180.31 tokens per second)\n",
            "llama_print_timings:        eval time =    1561.14 ms /    15 runs   (  104.08 ms per token,     9.61 tokens per second)\n",
            "llama_print_timings:       total time =    2055.25 ms /    62 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@franmb1 @Radioesport914 Why the hell do you listen to that scum? For your mental health, stop listening to the ultra that has run down. Fuck the orellut\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.77 ms /    16 runs   (    0.67 ms per token,  1485.19 tokens per second)\n",
            "llama_print_timings: prompt eval time =     278.84 ms /    76 tokens (    3.67 ms per token,   272.56 tokens per second)\n",
            "llama_print_timings:        eval time =    1507.43 ms /    15 runs   (  100.50 ms per token,     9.95 tokens per second)\n",
            "llama_print_timings:       total time =    2013.84 ms /    91 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@javiernegre10 @Macarena_Olona If I were those people I would keep an eye on the wallet in case the right-wing chorizos infiltrate among them. It's clear that your colleague on the camera was waiting for some mistake. Crime is what you scumbags do best.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.98 ms /    16 runs   (    0.62 ms per token,  1603.69 tokens per second)\n",
            "llama_print_timings: prompt eval time =     288.61 ms /    97 tokens (    2.98 ms per token,   336.09 tokens per second)\n",
            "llama_print_timings:        eval time =    1579.19 ms /    15 runs   (  105.28 ms per token,     9.50 tokens per second)\n",
            "llama_print_timings:       total time =    2157.30 ms /   112 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "#FerrerasGate You have lied to us, manipulated us, harassed, defamed and threatened our @PODEMOS Politicians 8 years, 8 years of harassment and demolition, we will not get tired of reminding you that you are scum, if it has to be 8 years we will do it because not I'm sorry https://t.co/eQsAVXv3Bn\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.12 ms /    16 runs   (    0.70 ms per token,  1438.46 tokens per second)\n",
            "llama_print_timings: prompt eval time =     261.57 ms /    46 tokens (    5.69 ms per token,   175.86 tokens per second)\n",
            "llama_print_timings:        eval time =    1862.35 ms /    15 runs   (  124.16 ms per token,     8.05 tokens per second)\n",
            "llama_print_timings:       total time =    2399.02 ms /    61 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@CaIIejonDeIGato @VengansaCoyote @Rita_Maestre Just as you say, no wonder you have such horrible karma. Human waste.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.08 ms /    16 runs   (    0.57 ms per token,  1762.89 tokens per second)\n",
            "llama_print_timings: prompt eval time =     253.30 ms /    40 tokens (    6.33 ms per token,   157.91 tokens per second)\n",
            "llama_print_timings:        eval time =    1530.07 ms /    15 runs   (  102.00 ms per token,     9.80 tokens per second)\n",
            "llama_print_timings:       total time =    1936.31 ms /    55 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@AguilarDassaev @XiomaraCastroZ Now the stereotype is a narco-state, before with them, after them and now with them\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.94 ms /    16 runs   (    0.62 ms per token,  1609.50 tokens per second)\n",
            "llama_print_timings: prompt eval time =     262.52 ms /    63 tokens (    4.17 ms per token,   239.99 tokens per second)\n",
            "llama_print_timings:        eval time =    1611.67 ms /    15 runs   (  107.44 ms per token,     9.31 tokens per second)\n",
            "llama_print_timings:       total time =    2078.19 ms /    78 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Juani_17 @EstebanCervi @Uber_ES @cabify_espana It took me 10 years to fight against the Stereotype, but the newcomers are taking charge of renewing it. We have no solution.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.13 ms /    16 runs   (    0.70 ms per token,  1438.07 tokens per second)\n",
            "llama_print_timings: prompt eval time =     288.14 ms /    98 tokens (    2.94 ms per token,   340.11 tokens per second)\n",
            "llama_print_timings:        eval time =    1729.83 ms /    15 runs   (  115.32 ms per token,     8.67 tokens per second)\n",
            "llama_print_timings:       total time =    2326.52 ms /   113 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "There are no Koreans on my ranch and if there were, they would look for teenagers or people who are very skinny and of the stereotype that their country and culture has. And it's pretty and it's fine. I like them tighter, with beards, cumbersome but with a suit. Elegant as silk and indomitable like the sea. https://t.co/tihtJLUOOQ\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.85 ms /    16 runs   (    0.55 ms per token,  1807.09 tokens per second)\n",
            "llama_print_timings: prompt eval time =     257.06 ms /    42 tokens (    6.12 ms per token,   163.39 tokens per second)\n",
            "llama_print_timings:        eval time =    1594.52 ms /    15 runs   (  106.30 ms per token,     9.41 tokens per second)\n",
            "llama_print_timings:       total time =    1999.11 ms /    57 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Walking down the street a biker called me \"fat lesbian\" and I never felt so flattered, so much effort to fall into the fat stereotype paid off people\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.54 ms /    16 runs   (    0.60 ms per token,  1676.62 tokens per second)\n",
            "llama_print_timings: prompt eval time =     267.51 ms /    64 tokens (    4.18 ms per token,   239.24 tokens per second)\n",
            "llama_print_timings:        eval time =    1537.61 ms /    15 runs   (  102.51 ms per token,     9.76 tokens per second)\n",
            "llama_print_timings:       total time =    1997.89 ms /    79 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@LibretaNegraMx The stereotype of the Archaeologist is a constant in cinema. It would be good if a film script began with some Luz y Fuerza workers finding a \"stone\" that won't let them put in their cables. 😁\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.47 ms /    16 runs   (    0.59 ms per token,  1689.72 tokens per second)\n",
            "llama_print_timings: prompt eval time =     243.11 ms /    47 tokens (    5.17 ms per token,   193.33 tokens per second)\n",
            "llama_print_timings:        eval time =    1575.98 ms /    15 runs   (  105.07 ms per token,     9.52 tokens per second)\n",
            "llama_print_timings:       total time =    1986.64 ms /    62 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Dua's boyfriends were always horrible shit, come on guys, any of you have a chance then!!! They fulfill the stereotype perfectly https://t.co/Cmo2YAYjCC\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      12.47 ms /    16 runs   (    0.78 ms per token,  1282.87 tokens per second)\n",
            "llama_print_timings: prompt eval time =     268.59 ms /    65 tokens (    4.13 ms per token,   242.00 tokens per second)\n",
            "llama_print_timings:        eval time =    1867.47 ms /    15 runs   (  124.50 ms per token,     8.03 tokens per second)\n",
            "llama_print_timings:       total time =    2482.62 ms /    80 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "My mother never read me stories, we created stories. She asked me the questions on the intelligence test from the age of 3 and I knew them all (she never put earrings on me until I wanted to buy Barbies or pink clothes because of gender stereotypes, what a crack?\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.51 ms /    16 runs   (    0.59 ms per token,  1682.09 tokens per second)\n",
            "llama_print_timings: prompt eval time =     262.13 ms /    56 tokens (    4.68 ms per token,   213.63 tokens per second)\n",
            "llama_print_timings:        eval time =    1550.27 ms /    15 runs   (  103.35 ms per token,     9.68 tokens per second)\n",
            "llama_print_timings:       total time =    1994.24 ms /    71 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "The aim is to counteract the historical inequalities suffered by women, girls and people of sexual dissent, as a result of the prior conceptions or gender stereotypes that police officials sometimes possess when hearing about specific cases (2/6).\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.85 ms /    16 runs   (    0.68 ms per token,  1474.93 tokens per second)\n",
            "llama_print_timings: prompt eval time =     266.70 ms /    58 tokens (    4.60 ms per token,   217.47 tokens per second)\n",
            "llama_print_timings:        eval time =    1574.61 ms /    15 runs   (  104.97 ms per token,     9.53 tokens per second)\n",
            "llama_print_timings:       total time =    2033.91 ms /    73 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "At the #BancadaOrange we propose to end this #SexistTax, inequality based on gender stereotypes must disappear. #BancadaOrange 🍊 https://t.co/OUCmWy86AL\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.54 ms /    16 runs   (    0.60 ms per token,  1677.32 tokens per second)\n",
            "llama_print_timings: prompt eval time =     278.72 ms /    68 tokens (    4.10 ms per token,   243.97 tokens per second)\n",
            "llama_print_timings:        eval time =    1504.92 ms /    15 runs   (  100.33 ms per token,     9.97 tokens per second)\n",
            "llama_print_timings:       total time =    1987.01 ms /    83 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "If you want to respect rights, take up the fight against gender stereotypes and do not invent movies like \"gender expression\": a child who plays with dolls is a child. A girl who plays soccer is a girl. She better analyzes those \"rapid-onset gender dysphorias.\"\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.54 ms /    16 runs   (    0.66 ms per token,  1517.88 tokens per second)\n",
            "llama_print_timings: prompt eval time =     300.24 ms /   109 tokens (    2.75 ms per token,   363.05 tokens per second)\n",
            "llama_print_timings:        eval time =    1677.09 ms /    15 runs   (  111.81 ms per token,     8.94 tokens per second)\n",
            "llama_print_timings:       total time =    2500.09 ms /   124 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Meli_Coulter @coolturabasura Inclusive language is FOR EVERYONE, otherwise it is not inclusive😉 And wait for me to finish you off ⬇️Inclusive Language: \"Way of expressing oneself without discriminating against a particular sex, social gender or gender identity and without perpetuating stereotypes of gender\". Greetings, my little ignorant one🤣 https://t.co/aTZ1w6yNtE\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.64 ms /    16 runs   (    0.60 ms per token,  1658.89 tokens per second)\n",
            "llama_print_timings: prompt eval time =     270.74 ms /    65 tokens (    4.17 ms per token,   240.08 tokens per second)\n",
            "llama_print_timings:        eval time =    1477.09 ms /    15 runs   (   98.47 ms per token,    10.16 tokens per second)\n",
            "llama_print_timings:       total time =    1957.44 ms /    80 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "CBT No. 2 Zinacantepec is working on the Gender Equality program, with the theme of gender role and gender stereotypes. @geramonro05 @IsraelJeroL https://t.co/Se1GJJH0sG\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.05 ms /    16 runs   (    0.57 ms per token,  1768.74 tokens per second)\n",
            "llama_print_timings: prompt eval time =     245.46 ms /    33 tokens (    7.44 ms per token,   134.44 tokens per second)\n",
            "llama_print_timings:        eval time =    1512.23 ms /    15 runs   (  100.82 ms per token,     9.92 tokens per second)\n",
            "llama_print_timings:       total time =    1901.32 ms /    48 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@upelienta_sss For me it is a clear example of the close relationship that exists between Spanish and Chilean fascism\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.12 ms /    16 runs   (    0.57 ms per token,  1753.42 tokens per second)\n",
            "llama_print_timings: prompt eval time =     243.75 ms /    35 tokens (    6.96 ms per token,   143.59 tokens per second)\n",
            "llama_print_timings:        eval time =    1682.26 ms /    15 runs   (  112.15 ms per token,     8.92 tokens per second)\n",
            "llama_print_timings:       total time =    2065.62 ms /    50 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "I was putting the propolis in my mouth and I gagged? It must be because I am sensitive and narrow-throated.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.02 ms /    16 runs   (    0.56 ms per token,  1773.84 tokens per second)\n",
            "llama_print_timings: prompt eval time =     756.67 ms /    23 tokens (   32.90 ms per token,    30.40 tokens per second)\n",
            "llama_print_timings:        eval time =    1465.74 ms /    15 runs   (   97.72 ms per token,    10.23 tokens per second)\n",
            "llama_print_timings:       total time =    2380.34 ms /    38 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Don't make yourself small to try to fit into someone else's narrow mind.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.20 ms /    16 runs   (    0.57 ms per token,  1739.32 tokens per second)\n",
            "llama_print_timings: prompt eval time =     271.92 ms /    72 tokens (    3.78 ms per token,   264.78 tokens per second)\n",
            "llama_print_timings:        eval time =    1564.78 ms /    15 runs   (  104.32 ms per token,     9.59 tokens per second)\n",
            "llama_print_timings:       total time =    2060.74 ms /    87 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@febra0621 @selusan @UnaiYus That the guy ahead with a car in front tells you that he probably didn't have time to brake. It's not the cyclist's fault. It is the fault of allowing such different speeds on such a narrow road.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.48 ms /    16 runs   (    0.59 ms per token,  1687.76 tokens per second)\n",
            "llama_print_timings: prompt eval time =     269.84 ms /    69 tokens (    3.91 ms per token,   255.71 tokens per second)\n",
            "llama_print_timings:        eval time =    1476.61 ms /    15 runs   (   98.44 ms per token,    10.16 tokens per second)\n",
            "llama_print_timings:       total time =    1947.86 ms /    84 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Rest in peace. “Hereditary monarchies have a great advantage: the particular interest of a family is constantly closely linked to the interest of the State. Never a single moment passes in which it is left to itself.\" Tocqueville https://t.co/kmjGXfiBTC\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.87 ms /    16 runs   (    0.74 ms per token,  1348.05 tokens per second)\n",
            "llama_print_timings: prompt eval time =     260.47 ms /    58 tokens (    4.49 ms per token,   222.68 tokens per second)\n",
            "llama_print_timings:        eval time =    1833.69 ms /    15 runs   (  122.25 ms per token,     8.18 tokens per second)\n",
            "llama_print_timings:       total time =    2405.60 ms /    73 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Capri is the opposite of Libra, everyone loves this sign for its sociability and supposed beauty, so no, I don't have a close relationship with my cousins ​​because they obviously don't understand my seriousness and asociality.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.72 ms /    16 runs   (    0.54 ms per token,  1835.28 tokens per second)\n",
            "llama_print_timings: prompt eval time =     253.76 ms /    37 tokens (    6.86 ms per token,   145.81 tokens per second)\n",
            "llama_print_timings:        eval time =    1515.23 ms /    15 runs   (  101.02 ms per token,     9.90 tokens per second)\n",
            "llama_print_timings:       total time =    1909.82 ms /    52 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@IsabelArugula I don't know yet haha ​​but I'm looking at options for gender studies, international studies or public policy\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.57 ms /    16 runs   (    0.60 ms per token,  1671.72 tokens per second)\n",
            "llama_print_timings: prompt eval time =     280.01 ms /   105 tokens (    2.67 ms per token,   374.99 tokens per second)\n",
            "llama_print_timings:        eval time =    1495.74 ms /    15 runs   (   99.72 ms per token,    10.03 tokens per second)\n",
            "llama_print_timings:       total time =    2086.34 ms /   120 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Postgraduate Refresher CourseDesign, Feminist Theory and Gender Studies.Start: 01/11, 18hsRegistration and fee consultation: centrocap@fadu.uba.ar#UBA #UBAPosgrados #FADU #architecture #design #urbanism #gender #feminist #theory #studies #course #postgraduate https://t.co/h7XLicRXaL\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.43 ms /    16 runs   (    0.59 ms per token,  1697.61 tokens per second)\n",
            "llama_print_timings: prompt eval time =     257.12 ms /    42 tokens (    6.12 ms per token,   163.35 tokens per second)\n",
            "llama_print_timings:        eval time =    1611.26 ms /    15 runs   (  107.42 ms per token,     9.31 tokens per second)\n",
            "llama_print_timings:       total time =    2019.14 ms /    57 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "La salle inviting a MAN specialized in (attention): gender studies! to explain the historical context of feminism. What a laugh, what a tremendous laugh 💀.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.38 ms /    16 runs   (    0.65 ms per token,  1540.98 tokens per second)\n",
            "llama_print_timings: prompt eval time =     305.12 ms /   102 tokens (    2.99 ms per token,   334.29 tokens per second)\n",
            "llama_print_timings:        eval time =    1633.57 ms /    15 runs   (  108.90 ms per token,     9.18 tokens per second)\n",
            "llama_print_timings:       total time =    2412.16 ms /   117 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@ServiciosSevip @adrianalg83 @urielesqueda4 Hahahahahaha biological reality hahahahahaLook brut0, first of all it would be good for you to read about gender studies, not to agree, but so that you UNDERSTAND what they refer to, one thing is sex and another is gender and your example of Asian man is wrong, that is transage. 🤦🏻‍♂️\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.03 ms /    16 runs   (    0.56 ms per token,  1771.09 tokens per second)\n",
            "llama_print_timings: prompt eval time =     705.50 ms /    27 tokens (   26.13 ms per token,    38.27 tokens per second)\n",
            "llama_print_timings:        eval time =    1482.89 ms /    15 runs   (   98.86 ms per token,    10.12 tokens per second)\n",
            "llama_print_timings:       total time =    2307.76 ms /    42 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "If the minister is so ugly, why doesn't she work at the Gender Studies Officer? 🤔\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.92 ms /    16 runs   (    0.62 ms per token,  1613.39 tokens per second)\n",
            "llama_print_timings: prompt eval time =     273.91 ms /    72 tokens (    3.80 ms per token,   262.86 tokens per second)\n",
            "llama_print_timings:        eval time =    1605.22 ms /    15 runs   (  107.01 ms per token,     9.34 tokens per second)\n",
            "llama_print_timings:       total time =    2092.87 ms /    87 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "In apocalyptic terms taken from the ortho, it is more important to know about gender studies to build a surviving society that is not so horrendous and more equitable, obviously. The bread would be made in community for the consumption of the community itself https://t.co/CJja0ITosT\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.83 ms /    16 runs   (    0.68 ms per token,  1477.51 tokens per second)\n",
            "llama_print_timings: prompt eval time =     294.86 ms /    89 tokens (    3.31 ms per token,   301.84 tokens per second)\n",
            "llama_print_timings:        eval time =    1637.69 ms /    15 runs   (  109.18 ms per token,     9.16 tokens per second)\n",
            "llama_print_timings:       total time =    2350.70 ms /   104 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "#MelodyBarreraPresente! Police officer Darío Jesús Chaves Rubio received life for the crime of homicide aggravated by hatred of gender expression or gender identity. Triumph of the movement of women and diversities and their family. #enoughcrimesofhate #FueTravesticidio https://t.co/FXUyreJtD5\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.35 ms /    16 runs   (    0.58 ms per token,  1710.68 tokens per second)\n",
            "llama_print_timings: prompt eval time =     239.14 ms /    41 tokens (    5.83 ms per token,   171.44 tokens per second)\n",
            "llama_print_timings:        eval time =    1544.76 ms /    15 runs   (  102.98 ms per token,     9.71 tokens per second)\n",
            "llama_print_timings:       total time =    1930.04 ms /    56 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "anyone with feminine gender expression, or clear feminine/masculine energy soft person, in general https://t.co/j89o6fwWLR\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.14 ms /    16 runs   (    0.57 ms per token,  1749.59 tokens per second)\n",
            "llama_print_timings: prompt eval time =     277.31 ms /    78 tokens (    3.56 ms per token,   281.28 tokens per second)\n",
            "llama_print_timings:        eval time =    1569.73 ms /    15 runs   (  104.65 ms per token,     9.56 tokens per second)\n",
            "llama_print_timings:       total time =    2071.38 ms /    93 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@ddeschouw Art. 25: \"All forms of discrimination are prohibited, especially when based on one or more grounds such as nationality or statelessness, age, sex, sexual characteristics, sexual or emotional orientation, gender identity and expression, etc. . \" and then: https://t.co/XR7x8slfyi\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.09 ms /    16 runs   (    0.69 ms per token,  1442.48 tokens per second)\n",
            "llama_print_timings: prompt eval time =     297.63 ms /    92 tokens (    3.24 ms per token,   309.10 tokens per second)\n",
            "llama_print_timings:        eval time =    1922.97 ms /    15 runs   (  128.20 ms per token,     7.80 tokens per second)\n",
            "llama_print_timings:       total time =    2693.16 ms /   107 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@PedroVictor9210 @JuankarlitoGago @ElBohioMio Pedro Víctor, mijo, you have exposed yourself and made a fool of yourself. Stop feeling bad and learn not to give opinions about what you are not even basically informed about. If you are interested, there is a lot of literature on the topic. Sex, gender, gender identity and expression.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.87 ms /    16 runs   (    0.55 ms per token,  1804.65 tokens per second)\n",
            "llama_print_timings: prompt eval time =     705.68 ms /    25 tokens (   28.23 ms per token,    35.43 tokens per second)\n",
            "llama_print_timings:        eval time =    1435.40 ms /    15 runs   (   95.69 ms per token,    10.45 tokens per second)\n",
            "llama_print_timings:       total time =    2259.38 ms /    40 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@anderelcane @carpediemcr People whose gender identity and expression coincides with sex...\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.10 ms /    16 runs   (    0.57 ms per token,  1758.24 tokens per second)\n",
            "llama_print_timings: prompt eval time =     243.76 ms /    45 tokens (    5.42 ms per token,   184.61 tokens per second)\n",
            "llama_print_timings:        eval time =    1593.94 ms /    15 runs   (  106.26 ms per token,     9.41 tokens per second)\n",
            "llama_print_timings:       total time =    2002.58 ms /    60 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@MarianaBelda @DWiehls That's not what I said. When I mentioned gender expression it was because I wanted to understand what @DWiehls was referring to\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.36 ms /    16 runs   (    0.52 ms per token,  1913.65 tokens per second)\n",
            "llama_print_timings: prompt eval time =     680.17 ms /    27 tokens (   25.19 ms per token,    39.70 tokens per second)\n",
            "llama_print_timings:        eval time =    1490.45 ms /    15 runs   (   99.36 ms per token,    10.06 tokens per second)\n",
            "llama_print_timings:       total time =    2301.16 ms /    42 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@citrikav She always had her forehead very high, her tongue very long... And her skirt was very short\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.87 ms /    16 runs   (    0.68 ms per token,  1471.81 tokens per second)\n",
            "llama_print_timings: prompt eval time =     243.69 ms /    35 tokens (    6.96 ms per token,   143.63 tokens per second)\n",
            "llama_print_timings:        eval time =    1898.83 ms /    15 runs   (  126.59 ms per token,     7.90 tokens per second)\n",
            "llama_print_timings:       total time =    2375.46 ms /    50 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Danielus678 @IleanaSchinder Ileana says it's Argentinians' fault for wearing very short skirts\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.14 ms /    16 runs   (    0.57 ms per token,  1750.36 tokens per second)\n",
            "llama_print_timings: prompt eval time =     793.48 ms /    30 tokens (   26.45 ms per token,    37.81 tokens per second)\n",
            "llama_print_timings:        eval time =    1587.65 ms /    15 runs   (  105.84 ms per token,     9.45 tokens per second)\n",
            "llama_print_timings:       total time =    2508.05 ms /    45 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@laci_beles @liusivaya @javiersolana I'm sure Japan wore her skirt very short\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.29 ms /    16 runs   (    0.58 ms per token,  1721.54 tokens per second)\n",
            "llama_print_timings: prompt eval time =     551.32 ms /    32 tokens (   17.23 ms per token,    58.04 tokens per second)\n",
            "llama_print_timings:        eval time =    1642.92 ms /    15 runs   (  109.53 ms per token,     9.13 tokens per second)\n",
            "llama_print_timings:       total time =    2328.75 ms /    47 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@PJoliCo @davidgambarte They wore their skirts very short and that's why they were squatted...\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.65 ms /    16 runs   (    0.54 ms per token,  1850.57 tokens per second)\n",
            "llama_print_timings: prompt eval time =     242.16 ms /    35 tokens (    6.92 ms per token,   144.53 tokens per second)\n",
            "llama_print_timings:        eval time =    1494.71 ms /    15 runs   (   99.65 ms per token,    10.04 tokens per second)\n",
            "llama_print_timings:       total time =    1872.66 ms /    50 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@eldiarioes She wore her skirt very short, like Ciudadanos in the Basque Country or like VOX in Vallecas.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.70 ms /    16 runs   (    0.67 ms per token,  1495.33 tokens per second)\n",
            "llama_print_timings: prompt eval time =     932.73 ms /    29 tokens (   32.16 ms per token,    31.09 tokens per second)\n",
            "llama_print_timings:        eval time =    1789.94 ms /    15 runs   (  119.33 ms per token,     8.38 tokens per second)\n",
            "llama_print_timings:       total time =    2930.95 ms /    44 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@CanalUGR The speaker had a very short skirt and incited the violent, right? You're nasty.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.97 ms /    16 runs   (    0.56 ms per token,  1783.13 tokens per second)\n",
            "llama_print_timings: prompt eval time =     810.83 ms /    31 tokens (   26.16 ms per token,    38.23 tokens per second)\n",
            "llama_print_timings:        eval time =    1533.00 ms /    15 runs   (  102.20 ms per token,     9.78 tokens per second)\n",
            "llama_print_timings:       total time =    2474.72 ms /    46 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@SmokingGolem People so big and in skirts, how come you are a bunny girl on your back?\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.28 ms /    16 runs   (    0.58 ms per token,  1723.40 tokens per second)\n",
            "llama_print_timings: prompt eval time =     260.84 ms /    68 tokens (    3.84 ms per token,   260.69 tokens per second)\n",
            "llama_print_timings:        eval time =    1483.54 ms /    15 runs   (   98.90 ms per token,    10.11 tokens per second)\n",
            "llama_print_timings:       total time =    1947.13 ms /    83 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Those who go to school and sit their children in a separate seat that takes up space instead of sitting them on their lap? Sister, don't you see that I've been standing for half an hour? It's hard for you, God, I can't keep dealing with these people.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       2.94 ms /     5 runs   (    0.59 ms per token,  1700.10 tokens per second)\n",
            "llama_print_timings: prompt eval time =     271.61 ms /    76 tokens (    3.57 ms per token,   279.81 tokens per second)\n",
            "llama_print_timings:        eval time =     417.83 ms /     4 runs   (  104.46 ms per token,     9.57 tokens per second)\n",
            "llama_print_timings:       total time =     866.02 ms /    80 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@alexiarivass What a shame you are, women who talk like that and go against another. I don't know if I should call it envy or that you don't have a life. Namaste I wish you learned from Cristina Porta that you are missing boards and they are not exactly the ones on your skirt.\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.54 ms /    16 runs   (    0.72 ms per token,  1387.08 tokens per second)\n",
            "llama_print_timings: prompt eval time =     232.12 ms /    51 tokens (    4.55 ms per token,   219.71 tokens per second)\n",
            "llama_print_timings:        eval time =    1811.36 ms /    15 runs   (  120.76 ms per token,     8.28 tokens per second)\n",
            "llama_print_timings:       total time =    2237.26 ms /    66 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@EsposasPuebla Exquista to hike up her skirt and kiss her ass mmm 😋😋😛😛😛😈😈😈\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.66 ms /    16 runs   (    0.60 ms per token,  1656.66 tokens per second)\n",
            "llama_print_timings: prompt eval time =     278.42 ms /    75 tokens (    3.71 ms per token,   269.38 tokens per second)\n",
            "llama_print_timings:        eval time =    1642.68 ms /    15 runs   (  109.51 ms per token,     9.13 tokens per second)\n",
            "llama_print_timings:       total time =    2142.34 ms /    90 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "That 👏🏿 first to address relevant issues!! Now that you can choose whether to wear a skirt or not, you will be able to comfortably go out and do your activities without fear of being shot or disappeared by hitmen in Caborca ​​https://t.co/uEhTYzlIQi\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.61 ms /    16 runs   (    0.60 ms per token,  1664.59 tokens per second)\n",
            "llama_print_timings: prompt eval time =     291.28 ms /   101 tokens (    2.88 ms per token,   346.75 tokens per second)\n",
            "llama_print_timings:        eval time =    1627.98 ms /    15 runs   (  108.53 ms per token,     9.21 tokens per second)\n",
            "llama_print_timings:       total time =    2203.45 ms /   116 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "I recommend Smoked Brisket, Smoked Rib-eye, Smoked T-bone, even Smoked Turkey or any other 🥩 but smoked. We have a smoker, it is very Anglo-Saxon culture. You'll like it, I guarantee it👌🏽. Apart from the 🇺🇸 USA, it has the best breeds of cows, and Japan🇯🇵.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.58 ms /    16 runs   (    0.60 ms per token,  1669.45 tokens per second)\n",
            "llama_print_timings: prompt eval time =     279.88 ms /    66 tokens (    4.24 ms per token,   235.81 tokens per second)\n",
            "llama_print_timings:        eval time =    1635.81 ms /    15 runs   (  109.05 ms per token,     9.17 tokens per second)\n",
            "llama_print_timings:       total time =    2148.58 ms /    81 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@HuancaYorkTimes Poor Castillo, so much coupism, racism, classism, discrimination, machismo, phallocentrism, fatphobia, cacaphobia, etc, etc, etc, no more poor people in a rich country. GAAAAA!\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.67 ms /    16 runs   (    0.60 ms per token,  1654.94 tokens per second)\n",
            "llama_print_timings: prompt eval time =     265.35 ms /    64 tokens (    4.15 ms per token,   241.19 tokens per second)\n",
            "llama_print_timings:        eval time =    1655.70 ms /    15 runs   (  110.38 ms per token,     9.06 tokens per second)\n",
            "llama_print_timings:       total time =    2211.14 ms /    79 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Bart045603771 @jagarrogomez Due to transcription problems, a phallus for companies...the lighthouses are more coastal, in Madrid and the Complutense they are more phallocentrism since Podemos arrived.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.06 ms /    16 runs   (    0.63 ms per token,  1590.14 tokens per second)\n",
            "llama_print_timings: prompt eval time =     274.97 ms /    74 tokens (    3.72 ms per token,   269.13 tokens per second)\n",
            "llama_print_timings:        eval time =    1612.70 ms /    15 runs   (  107.51 ms per token,     9.30 tokens per second)\n",
            "llama_print_timings:       total time =    2108.19 ms /    89 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "“And I always speak with evidence,” says Villavicencio, the fugitive who slipped into the jungle. Together with his friend Vivanco, he does not delay in setting up a new smokescreen to divert attention from his corrupt activities. They will flirt about phallocentrism: who has it bigger.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       7.96 ms /    16 runs   (    0.50 ms per token,  2009.55 tokens per second)\n",
            "llama_print_timings: prompt eval time =     246.28 ms /    37 tokens (    6.66 ms per token,   150.24 tokens per second)\n",
            "llama_print_timings:        eval time =    1588.36 ms /    15 runs   (  105.89 ms per token,     9.44 tokens per second)\n",
            "llama_print_timings:       total time =    1980.12 ms /    52 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "so much phallocentrism and there is no phallocentrism in the places that matter ‼️‼️‼️\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.72 ms /    16 runs   (    0.73 ms per token,  1365.19 tokens per second)\n",
            "llama_print_timings: prompt eval time =     256.74 ms /    54 tokens (    4.75 ms per token,   210.33 tokens per second)\n",
            "llama_print_timings:        eval time =    1870.13 ms /    15 runs   (  124.68 ms per token,     8.02 tokens per second)\n",
            "llama_print_timings:       total time =    2450.75 ms /    69 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "I feel that there are many heterosexuals due to the issue of modesty and society because women are beautiful, more intelligent, with more emotional responsibility, sex lasts longer and orgasm is guaranteed. Phallocentrism bothers me.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.21 ms /    16 runs   (    0.58 ms per token,  1736.49 tokens per second)\n",
            "llama_print_timings: prompt eval time =     262.03 ms /    51 tokens (    5.14 ms per token,   194.63 tokens per second)\n",
            "llama_print_timings:        eval time =    1523.64 ms /    15 runs   (  101.58 ms per token,     9.84 tokens per second)\n",
            "llama_print_timings:       total time =    1955.28 ms /    66 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "and my penis and my penis and my penis and my penis, that's all they know how to say, even the ovary of their phallocentrism https://t.co/bqobpeteO1\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.96 ms /    16 runs   (    0.56 ms per token,  1786.51 tokens per second)\n",
            "llama_print_timings: prompt eval time =     698.28 ms /    27 tokens (   25.86 ms per token,    38.67 tokens per second)\n",
            "llama_print_timings:        eval time =    1473.18 ms /    15 runs   (   98.21 ms per token,    10.18 tokens per second)\n",
            "llama_print_timings:       total time =    2294.25 ms /    42 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@AntonioMautor You reek of a false ally seeking approval. We have you very interested.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.17 ms /    16 runs   (    0.57 ms per token,  1744.63 tokens per second)\n",
            "llama_print_timings: prompt eval time =     254.38 ms /    50 tokens (    5.09 ms per token,   196.56 tokens per second)\n",
            "llama_print_timings:        eval time =    1575.78 ms /    15 runs   (  105.05 ms per token,     9.52 tokens per second)\n",
            "llama_print_timings:       total time =    2000.63 ms /    65 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@antigua_roma \"...Christianity is a false ally of Rome. Roman structures are for the church only a context, a base on which to rely, an instrument to assert itself\" Jacques Le Goff\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.82 ms /    16 runs   (    0.61 ms per token,  1629.00 tokens per second)\n",
            "llama_print_timings: prompt eval time =     295.62 ms /    85 tokens (    3.48 ms per token,   287.53 tokens per second)\n",
            "llama_print_timings:        eval time =    1675.63 ms /    15 runs   (  111.71 ms per token,     8.95 tokens per second)\n",
            "llama_print_timings:       total time =    2218.02 ms /   100 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@MatildeyMilagro @petrogustavo @cielo_rusinque @petrogustavo since he arrived late to the feminist debate and did not know the difference between gender identity and sexual identity I knew he was a false ally. Listen. Educate yourself. It is not our job to do it for you. That's not the change we wanted.\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.28 ms /    16 runs   (    0.58 ms per token,  1724.14 tokens per second)\n",
            "llama_print_timings: prompt eval time =     257.51 ms /    52 tokens (    4.95 ms per token,   201.94 tokens per second)\n",
            "llama_print_timings:        eval time =    1478.10 ms /    15 runs   (   98.54 ms per token,    10.15 tokens per second)\n",
            "llama_print_timings:       total time =    1902.53 ms /    67 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Jaim2326Y @DiegoQuispeSanc @menoscanas Excellent unmasking @menoscanas, increasingly equidistance ends up being a danger more than a false “ally”\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.21 ms /    16 runs   (    0.70 ms per token,  1427.04 tokens per second)\n",
            "llama_print_timings: prompt eval time =     264.76 ms /    50 tokens (    5.30 ms per token,   188.85 tokens per second)\n",
            "llama_print_timings:        eval time =    1811.59 ms /    15 runs   (  120.77 ms per token,     8.28 tokens per second)\n",
            "llama_print_timings:       total time =    2346.52 ms /    65 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Misogynistic Comumacho and false ally. That's what should apply to you. Go away, Mr. Eggs. https://t.co/ysydDRJMg8\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.02 ms /    16 runs   (    0.56 ms per token,  1773.84 tokens per second)\n",
            "llama_print_timings: prompt eval time =     831.99 ms /    30 tokens (   27.73 ms per token,    36.06 tokens per second)\n",
            "llama_print_timings:        eval time =    1518.31 ms /    15 runs   (  101.22 ms per token,     9.88 tokens per second)\n",
            "llama_print_timings:       total time =    2478.81 ms /    45 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@jananeme Q it was better to have an enemy or adversary than just a treacherous false ally!!!\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.68 ms /    16 runs   (    0.54 ms per token,  1844.17 tokens per second)\n",
            "llama_print_timings: prompt eval time =     778.89 ms /    29 tokens (   26.86 ms per token,    37.23 tokens per second)\n",
            "llama_print_timings:        eval time =    1521.43 ms /    15 runs   (  101.43 ms per token,     9.86 tokens per second)\n",
            "llama_print_timings:       total time =    2423.97 ms /    44 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "My boyfriend came to Santa Fe to meet my family and they adore him. Very in love 🤍\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.93 ms /    16 runs   (    0.56 ms per token,  1791.31 tokens per second)\n",
            "llama_print_timings: prompt eval time =     237.84 ms /    39 tokens (    6.10 ms per token,   163.98 tokens per second)\n",
            "llama_print_timings:        eval time =    1535.74 ms /    15 runs   (  102.38 ms per token,     9.77 tokens per second)\n",
            "llama_print_timings:       total time =    1918.13 ms /    54 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "OH NOOOO I made a tiktok AND MY FAMILY SAW IT I forced myself to come out of the closet🤡🤡🤡🤡🤡\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.73 ms /    16 runs   (    0.67 ms per token,  1491.01 tokens per second)\n",
            "llama_print_timings: prompt eval time =     272.27 ms /    64 tokens (    4.25 ms per token,   235.06 tokens per second)\n",
            "llama_print_timings:        eval time =    1723.19 ms /    15 runs   (  114.88 ms per token,     8.70 tokens per second)\n",
            "llama_print_timings:       total time =    2299.05 ms /    79 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "My father-in-law had to go to my brother-in-law's school because he got into a fight at school and he came and told him \"don't fight inside the school when you leave school, you have to beat them up\" a normal family wanted me🤣\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.84 ms /    16 runs   (    0.55 ms per token,  1810.98 tokens per second)\n",
            "llama_print_timings: prompt eval time =     252.79 ms /    45 tokens (    5.62 ms per token,   178.02 tokens per second)\n",
            "llama_print_timings:        eval time =    1597.84 ms /    15 runs   (  106.52 ms per token,     9.39 tokens per second)\n",
            "llama_print_timings:       total time =    2007.61 ms /    60 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "FOR ADOPTION ♥️He is LEON, a beautiful puppy who is looking for that family that is for him. https://t.co/jeKdChYVvH\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.23 ms /    16 runs   (    0.58 ms per token,  1733.10 tokens per second)\n",
            "llama_print_timings: prompt eval time =     593.38 ms /    22 tokens (   26.97 ms per token,    37.08 tokens per second)\n",
            "llama_print_timings:        eval time =    1585.91 ms /    15 runs   (  105.73 ms per token,     9.46 tokens per second)\n",
            "llama_print_timings:       total time =    2298.04 ms /    37 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Objective: have money Difficulty: my family treats me like an ATM\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.05 ms /    16 runs   (    0.63 ms per token,  1591.56 tokens per second)\n",
            "llama_print_timings: prompt eval time =     249.19 ms /    36 tokens (    6.92 ms per token,   144.47 tokens per second)\n",
            "llama_print_timings:        eval time =    1773.47 ms /    15 runs   (  118.23 ms per token,     8.46 tokens per second)\n",
            "llama_print_timings:       total time =    2186.01 ms /    51 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Jenniffer That wasn't the stupid fucking National Guard, it was neighbors who risked everything to rescue a family in a state of emergency.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.60 ms /    16 runs   (    0.54 ms per token,  1861.55 tokens per second)\n",
            "llama_print_timings: prompt eval time =     777.59 ms /    29 tokens (   26.81 ms per token,    37.29 tokens per second)\n",
            "llama_print_timings:        eval time =    1594.38 ms /    15 runs   (  106.29 ms per token,     9.41 tokens per second)\n",
            "llama_print_timings:       total time =    2496.17 ms /    44 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@soymsbaby Wow but I'm not a bitch, what an ugly carnal attitude 🤣🤣🤣\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.46 ms /    16 runs   (    0.53 ms per token,  1892.15 tokens per second)\n",
            "llama_print_timings: prompt eval time =     765.73 ms /    31 tokens (   24.70 ms per token,    40.48 tokens per second)\n",
            "llama_print_timings:        eval time =    1584.36 ms /    15 runs   (  105.62 ms per token,     9.47 tokens per second)\n",
            "llama_print_timings:       total time =    2483.49 ms /    46 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "I don't know if the route to come to Bolson is uglier or the streets of Bolson, how unfortunate\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.58 ms /    16 runs   (    0.54 ms per token,  1865.02 tokens per second)\n",
            "llama_print_timings: prompt eval time =     251.76 ms /    33 tokens (    7.63 ms per token,   131.08 tokens per second)\n",
            "llama_print_timings:        eval time =    1538.32 ms /    15 runs   (  102.55 ms per token,     9.75 tokens per second)\n",
            "llama_print_timings:       total time =    1920.43 ms /    48 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@OtraAcida And they leave you with a super ugly doubt. Those types of people are not worth it. Cheer up!\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.84 ms /    16 runs   (    0.55 ms per token,  1810.57 tokens per second)\n",
            "llama_print_timings: prompt eval time =     897.02 ms /    29 tokens (   30.93 ms per token,    32.33 tokens per second)\n",
            "llama_print_timings:        eval time =    1549.64 ms /    15 runs   (  103.31 ms per token,     9.68 tokens per second)\n",
            "llama_print_timings:       total time =    2619.77 ms /    44 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "An ugly, hairy, slimy spider. https://t.co/TxC4jfdDEn\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.10 ms /    16 runs   (    0.63 ms per token,  1584.94 tokens per second)\n",
            "llama_print_timings: prompt eval time =     280.83 ms /    72 tokens (    3.90 ms per token,   256.38 tokens per second)\n",
            "llama_print_timings:        eval time =    1645.82 ms /    15 runs   (  109.72 ms per token,     9.11 tokens per second)\n",
            "llama_print_timings:       total time =    2135.90 ms /    87 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "I'm going to meet a friend who I haven't seen in a long time but she has me waiting for more than 30 minutes. MK DON'T be like that, what an ugly thing to be unpunctual!!! https://t.co/FQT7lt8b2D\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.95 ms /    16 runs   (    0.56 ms per token,  1788.31 tokens per second)\n",
            "llama_print_timings: prompt eval time =     563.09 ms /    21 tokens (   26.81 ms per token,    37.29 tokens per second)\n",
            "llama_print_timings:        eval time =    1516.49 ms /    15 runs   (  101.10 ms per token,     9.89 tokens per second)\n",
            "llama_print_timings:       total time =    2186.24 ms /    36 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@OfeFernandez_ Only plane parasites, ugly fat woman\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.97 ms /    16 runs   (    0.62 ms per token,  1604.17 tokens per second)\n",
            "llama_print_timings: prompt eval time =     285.84 ms /    82 tokens (    3.49 ms per token,   286.87 tokens per second)\n",
            "llama_print_timings:        eval time =    1626.19 ms /    15 runs   (  108.41 ms per token,     9.22 tokens per second)\n",
            "llama_print_timings:       total time =    2313.96 ms /    97 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Liatanis Rojipardo is a category that is used to disqualify any political rival with whom one does not agree and does not buy the ideological pack of progressivism. Reminds me of TERF/feminazi. I'm not saying there aren't any, but it's used very happily with anyone you disagree with.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.95 ms /    16 runs   (    0.56 ms per token,  1788.31 tokens per second)\n",
            "llama_print_timings: prompt eval time =     247.24 ms /    41 tokens (    6.03 ms per token,   165.83 tokens per second)\n",
            "llama_print_timings:        eval time =    1601.39 ms /    15 runs   (  106.76 ms per token,     9.37 tokens per second)\n",
            "llama_print_timings:       total time =    1996.92 ms /    56 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@EvaArenales @conha_no @oscar_puente_ I'll make you a drawing, Eva??? From machirulo to feminazi.\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.55 ms /    16 runs   (    0.60 ms per token,  1674.69 tokens per second)\n",
            "llama_print_timings: prompt eval time =     280.07 ms /    87 tokens (    3.22 ms per token,   310.64 tokens per second)\n",
            "llama_print_timings:        eval time =    1477.77 ms /    15 runs   (   98.52 ms per token,    10.15 tokens per second)\n",
            "llama_print_timings:       total time =    2008.00 ms /   102 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "I was going to make a bad joke about this but we don't know what she has... I was going to say that it was the metamorphosis to feminazi... but no, the poor thing has problems, I hope she finds a solution with the people who love her. And no matter what happens, you will recover. https://t.co/ZCgLSXvipp\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      12.21 ms /    16 runs   (    0.76 ms per token,  1310.19 tokens per second)\n",
            "llama_print_timings: prompt eval time =     248.70 ms /    52 tokens (    4.78 ms per token,   209.09 tokens per second)\n",
            "llama_print_timings:        eval time =    1877.09 ms /    15 runs   (  125.14 ms per token,     7.99 tokens per second)\n",
            "llama_print_timings:       total time =    2329.48 ms /    67 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@tangoenkimono @VictorF40868938 @mvacarezza A feminazi says that husbands should “educate” their wives 😉… ‘tay clear dog.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.95 ms /    16 runs   (    0.56 ms per token,  1788.31 tokens per second)\n",
            "llama_print_timings: prompt eval time =     248.44 ms /    45 tokens (    5.52 ms per token,   181.13 tokens per second)\n",
            "llama_print_timings:        eval time =    1586.06 ms /    15 runs   (  105.74 ms per token,     9.46 tokens per second)\n",
            "llama_print_timings:       total time =    1986.92 ms /    60 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "What happens is that a red man cannot buy a house and a feminazi cannot enjoy herself without a man in the middle. https://t.co/4XKdaXJ56Z\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.85 ms /    16 runs   (    0.62 ms per token,  1624.20 tokens per second)\n",
            "llama_print_timings: prompt eval time =     281.55 ms /    83 tokens (    3.39 ms per token,   294.80 tokens per second)\n",
            "llama_print_timings:        eval time =    1518.20 ms /    15 runs   (  101.21 ms per token,     9.88 tokens per second)\n",
            "llama_print_timings:       total time =    2036.06 ms /    98 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@nachocastillo87 @cisneitzel28 Exactly. What if, after reading many books, your son/daughter, instead of being an atheist, queer, lesbian, socialist or feminazi, decides to be a full-fledged Christian and devoted to his God? Are you going to repudiate him?\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.11 ms /    16 runs   (    0.63 ms per token,  1582.43 tokens per second)\n",
            "llama_print_timings: prompt eval time =     266.32 ms /    61 tokens (    4.37 ms per token,   229.05 tokens per second)\n",
            "llama_print_timings:        eval time =    1548.12 ms /    15 runs   (  103.21 ms per token,     9.69 tokens per second)\n",
            "llama_print_timings:       total time =    2009.46 ms /    76 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "They locate a lifeless woman inside a hotel on Col. Verde Valle de Gdl. She had a blow to the head and the Femicide protocol was activated @nmasguadalajara https://t.co/8txvauwa9B\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.70 ms /    16 runs   (    0.61 ms per token,  1649.48 tokens per second)\n",
            "llama_print_timings: prompt eval time =     260.84 ms /    41 tokens (    6.36 ms per token,   157.18 tokens per second)\n",
            "llama_print_timings:        eval time =    1590.18 ms /    15 runs   (  106.01 ms per token,     9.43 tokens per second)\n",
            "llama_print_timings:       total time =    2081.53 ms /    56 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@kenialopezr @Claudiashein First learn that it is a feminicide and then you make garbage for your 420 PAN spectators.\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.67 ms /    16 runs   (    0.60 ms per token,  1653.92 tokens per second)\n",
            "llama_print_timings: prompt eval time =     282.64 ms /    75 tokens (    3.77 ms per token,   265.35 tokens per second)\n",
            "llama_print_timings:        eval time =    1499.48 ms /    15 runs   (   99.97 ms per token,    10.00 tokens per second)\n",
            "llama_print_timings:       total time =    1998.53 ms /    90 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "This moment Stand in front of the @FiscaliaEcuador of relatives of missing persons @covidefem1 and @AsfadecEc for the Femicide of #MariaBelenBernalWAS A STATE CRIME https://t.co/OqYf9Ftfg9\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.37 ms /    16 runs   (    0.59 ms per token,  1707.03 tokens per second)\n",
            "llama_print_timings: prompt eval time =     248.00 ms /    45 tokens (    5.51 ms per token,   181.45 tokens per second)\n",
            "llama_print_timings:        eval time =    1479.58 ms /    15 runs   (   98.64 ms per token,    10.14 tokens per second)\n",
            "llama_print_timings:       total time =    1886.78 ms /    60 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "The case of the femicide of Luz Raquel Padilla in Zapopan registers more doubts than certainty https://t.co/9N1939vDZM\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.24 ms /    16 runs   (    0.58 ms per token,  1731.41 tokens per second)\n",
            "llama_print_timings: prompt eval time =     243.77 ms /    38 tokens (    6.41 ms per token,   155.89 tokens per second)\n",
            "llama_print_timings:        eval time =    1640.07 ms /    15 runs   (  109.34 ms per token,     9.15 tokens per second)\n",
            "llama_print_timings:       total time =    2029.90 ms /    53 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Suspects arrested over the weekend for robberies, rape and attempted femicide https://t.co/9ZqmWgXtFi\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.59 ms /    16 runs   (    0.66 ms per token,  1510.57 tokens per second)\n",
            "llama_print_timings: prompt eval time =     267.86 ms /    52 tokens (    5.15 ms per token,   194.13 tokens per second)\n",
            "llama_print_timings:        eval time =    1607.03 ms /    15 runs   (  107.14 ms per token,     9.33 tokens per second)\n",
            "llama_print_timings:       total time =    2150.39 ms /    67 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Nooo 💔 TikTok user finds a dialogue in The Flintstones that is generating a lot of discontent. Did you notice it?https://t.co/SZ7CDNPLho\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.75 ms /    16 runs   (    0.61 ms per token,  1641.87 tokens per second)\n",
            "llama_print_timings: prompt eval time =     282.39 ms /    82 tokens (    3.44 ms per token,   290.38 tokens per second)\n",
            "llama_print_timings:        eval time =    1458.02 ms /    15 runs   (   97.20 ms per token,    10.29 tokens per second)\n",
            "llama_print_timings:       total time =    1981.38 ms /    97 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Dra_Blink @theblinksuprema Because... How is it that blnk is using the \"feminist\" discourse again (honestly it is stupid because feminism goes much further than what the discourse of bourgeois feminism says) and at the same time he is defending a pimp like the CEO of y/g?\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.36 ms /    16 runs   (    0.58 ms per token,  1709.95 tokens per second)\n",
            "llama_print_timings: prompt eval time =     255.22 ms /    64 tokens (    3.99 ms per token,   250.77 tokens per second)\n",
            "llama_print_timings:        eval time =    1579.97 ms /    15 runs   (  105.33 ms per token,     9.49 tokens per second)\n",
            "llama_print_timings:       total time =    2028.05 ms /    79 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Aemon3428 They are the same ones who screwed Hollman Morris and made Claudia López mayor. If a woman reaches a position through her own merit and without personal interests in having a contract, they attack her, what an empowered and inclusive feminism.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.52 ms /    16 runs   (    0.59 ms per token,  1681.03 tokens per second)\n",
            "llama_print_timings: prompt eval time =     259.34 ms /    48 tokens (    5.40 ms per token,   185.08 tokens per second)\n",
            "llama_print_timings:        eval time =    1615.81 ms /    15 runs   (  107.72 ms per token,     9.28 tokens per second)\n",
            "llama_print_timings:       total time =    2046.31 ms /    63 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@BSepulvedaHales I mean if they are left-handed they have feminist support, otherwise they have the hatred of women hahahaha that is not feminism, it is just cheap politics\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.28 ms /    16 runs   (    0.58 ms per token,  1724.32 tokens per second)\n",
            "llama_print_timings: prompt eval time =     266.88 ms /    52 tokens (    5.13 ms per token,   194.84 tokens per second)\n",
            "llama_print_timings:        eval time =    1575.83 ms /    15 runs   (  105.06 ms per token,     9.52 tokens per second)\n",
            "llama_print_timings:       total time =    2074.97 ms /    67 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "CHRISTIANIST OR CRETINIST FEMINISM IS THE DENIAL OF EVITA'S THOUGHT. https://t.co/O4mDlNKoxJ\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.85 ms /    16 runs   (    0.55 ms per token,  1808.93 tokens per second)\n",
            "llama_print_timings: prompt eval time =     240.64 ms /    35 tokens (    6.88 ms per token,   145.44 tokens per second)\n",
            "llama_print_timings:        eval time =    1479.59 ms /    15 runs   (   98.64 ms per token,    10.14 tokens per second)\n",
            "llama_print_timings:       total time =    1859.30 ms /    50 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "It doesn't fail that all the aunts who are ultra radicalized with feminism have daddy issues.ToDasToDiTas\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.03 ms /    16 runs   (    0.69 ms per token,  1450.46 tokens per second)\n",
            "llama_print_timings: prompt eval time =     278.42 ms /    77 tokens (    3.62 ms per token,   276.56 tokens per second)\n",
            "llama_print_timings:        eval time =    1709.80 ms /    15 runs   (  113.99 ms per token,     8.77 tokens per second)\n",
            "llama_print_timings:       total time =    2230.02 ms /    92 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@TheBloodyStone @ivan_unalcoyano Aaaah. Anti-feminism profile and false complaints everywhere. More claustrophobic attire than reading the Metamorphosis or taking the Madrid circular. I met him at a fachaparty in Madrid. What a lazy guy. Me with Gilbert\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.75 ms /    16 runs   (    0.55 ms per token,  1828.57 tokens per second)\n",
            "llama_print_timings: prompt eval time =     586.74 ms /    21 tokens (   27.94 ms per token,    35.79 tokens per second)\n",
            "llama_print_timings:        eval time =    1462.59 ms /    15 runs   (   97.51 ms per token,    10.26 tokens per second)\n",
            "llama_print_timings:       total time =    2155.34 ms /    36 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@RahulkMex Wow for a moment I thought it was a photo\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.92 ms /    16 runs   (    0.62 ms per token,  1612.74 tokens per second)\n",
            "llama_print_timings: prompt eval time =     254.31 ms /    61 tokens (    4.17 ms per token,   239.87 tokens per second)\n",
            "llama_print_timings:        eval time =    1502.68 ms /    15 runs   (  100.18 ms per token,     9.98 tokens per second)\n",
            "llama_print_timings:       total time =    1949.68 ms /    76 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@FJalifas @ThisIsMarsella Better say that they are from somewhere in Nuevo León, there if Carta Blanca is taken (and those in the photo look like they are from Los Cardenales de NL)... 😆 🙄\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.60 ms /    16 runs   (    0.60 ms per token,  1665.97 tokens per second)\n",
            "llama_print_timings: prompt eval time =     244.82 ms /    58 tokens (    4.22 ms per token,   236.91 tokens per second)\n",
            "llama_print_timings:        eval time =    1539.71 ms /    15 runs   (  102.65 ms per token,     9.74 tokens per second)\n",
            "llama_print_timings:       total time =    1966.40 ms /    73 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@ismaelr37811372 @Corruptos_NoMas @SARGENTOCHALA @ESMIC_EJC In your photo the only officer I see is the corrupt one from Zapateiro\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.25 ms /    16 runs   (    0.64 ms per token,  1560.67 tokens per second)\n",
            "llama_print_timings: prompt eval time =     781.22 ms /    29 tokens (   26.94 ms per token,    37.12 tokens per second)\n",
            "llama_print_timings:        eval time =    1772.76 ms /    15 runs   (  118.18 ms per token,     8.46 tokens per second)\n",
            "llama_print_timings:       total time =    2700.66 ms /    44 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "My personality is literally reflected in a photo with Mickey who says not to touch and poses like a gym bro.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.65 ms /    16 runs   (    0.54 ms per token,  1849.07 tokens per second)\n",
            "llama_print_timings: prompt eval time =     698.86 ms /    27 tokens (   25.88 ms per token,    38.63 tokens per second)\n",
            "llama_print_timings:        eval time =    1593.44 ms /    15 runs   (  106.23 ms per token,     9.41 tokens per second)\n",
            "llama_print_timings:       total time =    2413.11 ms /    42 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@QuKaNegrita Of course I ask because I suppose he wore it like that for the photo\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.32 ms /    16 runs   (    0.58 ms per token,  1716.55 tokens per second)\n",
            "llama_print_timings: prompt eval time =     262.79 ms /    61 tokens (    4.31 ms per token,   232.13 tokens per second)\n",
            "llama_print_timings:        eval time =    1611.77 ms /    15 runs   (  107.45 ms per token,     9.31 tokens per second)\n",
            "llama_print_timings:       total time =    2067.73 ms /    76 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Pride_JA Hey sir, this is too much, I was watching nopor to my liking, and now I get this, instead of messing around with a video of an old woman, I finished it and came back with your photo 😳😳😳\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.94 ms /    16 runs   (    0.56 ms per token,  1788.91 tokens per second)\n",
            "llama_print_timings: prompt eval time =     252.86 ms /    35 tokens (    7.22 ms per token,   138.42 tokens per second)\n",
            "llama_print_timings:        eval time =    1561.48 ms /    15 runs   (  104.10 ms per token,     9.61 tokens per second)\n",
            "llama_print_timings:       total time =    1948.91 ms /    50 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@90minutosdpCSE @teleamazonasec Noo, she is frigid. Ben soldier commtando😂😂😂\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.93 ms /    16 runs   (    0.75 ms per token,  1341.04 tokens per second)\n",
            "llama_print_timings: prompt eval time =     269.56 ms /    67 tokens (    4.02 ms per token,   248.56 tokens per second)\n",
            "llama_print_timings:        eval time =    1777.74 ms /    15 runs   (  118.52 ms per token,     8.44 tokens per second)\n",
            "llama_print_timings:       total time =    2386.14 ms /    82 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "They never really touched even one of my tits because a girl is very frigid; They were power relationships and I had blocked many of them. As a result of that chapter I began to relive images and I finally understood why I was the whore despite being surrounded by people who hurt themselves.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.26 ms /    16 runs   (    0.58 ms per token,  1727.68 tokens per second)\n",
            "llama_print_timings: prompt eval time =     275.97 ms /    66 tokens (    4.18 ms per token,   239.15 tokens per second)\n",
            "llama_print_timings:        eval time =    1598.00 ms /    15 runs   (  106.53 ms per token,     9.39 tokens per second)\n",
            "llama_print_timings:       total time =    2074.22 ms /    81 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@ladyprecarizada Frigid progress of the other, if I don't contribute, I don't have to have the right to a retirement. It is unfair to everyone who contributed their entire lives, and it is UNSUSTAINABLE financially for the government. Fool\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.08 ms /    16 runs   (    0.57 ms per token,  1762.50 tokens per second)\n",
            "llama_print_timings: prompt eval time =     253.73 ms /    40 tokens (    6.34 ms per token,   157.65 tokens per second)\n",
            "llama_print_timings:        eval time =    1549.92 ms /    15 runs   (  103.33 ms per token,     9.68 tokens per second)\n",
            "llama_print_timings:       total time =    1949.84 ms /    55 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "poor latorre who of all the cats he could have ended up with married this frigid https://t.co/I4UWURNDk0\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.97 ms /    16 runs   (    0.56 ms per token,  1783.33 tokens per second)\n",
            "llama_print_timings: prompt eval time =     255.33 ms /    46 tokens (    5.55 ms per token,   180.16 tokens per second)\n",
            "llama_print_timings:        eval time =    1480.20 ms /    15 runs   (   98.68 ms per token,    10.13 tokens per second)\n",
            "llama_print_timings:       total time =    1895.27 ms /    61 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@hamaxx1 SINCE THE FATHER EATEN MORIA, SHE IS MORE FRIGID EVER.. LIKE THE BOSS OF THE BAND 😂\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       3.45 ms /     5 runs   (    0.69 ms per token,  1447.60 tokens per second)\n",
            "llama_print_timings: prompt eval time =     276.09 ms /    60 tokens (    4.60 ms per token,   217.32 tokens per second)\n",
            "llama_print_timings:        eval time =     489.79 ms /     4 runs   (  122.45 ms per token,     8.17 tokens per second)\n",
            "llama_print_timings:       total time =    1027.12 ms /    64 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@charovargas_ That is why she will eat and the years will eat her, because she is frustrated, frigid and stupid.😌🥳❤️❤️ https://t.co/8xkHaO8dAg\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.57 ms /    16 runs   (    0.54 ms per token,  1866.54 tokens per second)\n",
            "llama_print_timings: prompt eval time =     627.77 ms /    26 tokens (   24.14 ms per token,    41.42 tokens per second)\n",
            "llama_print_timings:        eval time =    1521.64 ms /    15 runs   (  101.44 ms per token,     9.86 tokens per second)\n",
            "llama_print_timings:       total time =    2267.03 ms /    41 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "This means doing it at gulf time https://t.co/Vk7fyqtfnS\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.79 ms /    16 runs   (    0.55 ms per token,  1820.25 tokens per second)\n",
            "llama_print_timings: prompt eval time =     261.64 ms /    55 tokens (    4.76 ms per token,   210.21 tokens per second)\n",
            "llama_print_timings:        eval time =    1509.52 ms /    15 runs   (  100.63 ms per token,     9.94 tokens per second)\n",
            "llama_print_timings:       total time =    1947.85 ms /    70 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Carlitos Alcaraz returns with a desire for revenge. And here we are to see it. Night live, golf nights in CincinnatiVamooosss https://t.co/NiqWGkvQ2m\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.99 ms /    16 runs   (    0.56 ms per token,  1779.95 tokens per second)\n",
            "llama_print_timings: prompt eval time =     241.10 ms /    37 tokens (    6.52 ms per token,   153.46 tokens per second)\n",
            "llama_print_timings:        eval time =    1552.97 ms /    15 runs   (  103.53 ms per token,     9.66 tokens per second)\n",
            "llama_print_timings:       total time =    1937.65 ms /    52 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@ionebelarra Apparently for Belarra these deserved it, she will be a bitchhttps://t.co/ETOmASgol5\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.76 ms /    16 runs   (    0.73 ms per token,  1360.66 tokens per second)\n",
            "llama_print_timings: prompt eval time =     720.41 ms /    27 tokens (   26.68 ms per token,    37.48 tokens per second)\n",
            "llama_print_timings:        eval time =    1846.93 ms /    15 runs   (  123.13 ms per token,     8.12 tokens per second)\n",
            "llama_print_timings:       total time =    2721.83 ms /    42 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Jojare2 Sarna Hernández Golfa has Colombian nationality, unfortunately it is not there.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.31 ms /    16 runs   (    0.58 ms per token,  1718.95 tokens per second)\n",
            "llama_print_timings: prompt eval time =     280.98 ms /    69 tokens (    4.07 ms per token,   245.57 tokens per second)\n",
            "llama_print_timings:        eval time =    1490.57 ms /    15 runs   (   99.37 ms per token,    10.06 tokens per second)\n",
            "llama_print_timings:       total time =    1991.31 ms /    84 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "How sorry I am for those people who believe that you share their value system and assume that you are like them, yes, one of those people who exchange their bodies so that they are loved. It's so nice to be a bitch and fuck the guy you like, just like that 💅🏼\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.58 ms /    16 runs   (    0.54 ms per token,  1865.02 tokens per second)\n",
            "llama_print_timings: prompt eval time =     670.74 ms /    26 tokens (   25.80 ms per token,    38.76 tokens per second)\n",
            "llama_print_timings:        eval time =    1643.90 ms /    15 runs   (  109.59 ms per token,     9.12 tokens per second)\n",
            "llama_print_timings:       total time =    2436.96 ms /    41 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@TonoSVJ A third-rate slut and her pimp. Could anyone think otherwise?\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.84 ms /    16 runs   (    0.55 ms per token,  1809.34 tokens per second)\n",
            "llama_print_timings: prompt eval time =     755.96 ms /    29 tokens (   26.07 ms per token,    38.36 tokens per second)\n",
            "llama_print_timings:        eval time =    1523.10 ms /    15 runs   (  101.54 ms per token,     9.85 tokens per second)\n",
            "llama_print_timings:       total time =    2406.43 ms /    44 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Pounding the mud and slamming it on the table is fucking therapeutic, it's just that\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.59 ms /    16 runs   (    0.60 ms per token,  1668.40 tokens per second)\n",
            "llama_print_timings: prompt eval time =     254.26 ms /    33 tokens (    7.70 ms per token,   129.79 tokens per second)\n",
            "llama_print_timings:        eval time =    1654.39 ms /    15 runs   (  110.29 ms per token,     9.07 tokens per second)\n",
            "llama_print_timings:       total time =    2114.61 ms /    48 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@rmgarciav On a street of minimal dimensions. As a gift, they knocked down the street lamp when it hit the pole.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.11 ms /    16 runs   (    0.57 ms per token,  1756.50 tokens per second)\n",
            "llama_print_timings: prompt eval time =     249.91 ms /    45 tokens (    5.55 ms per token,   180.06 tokens per second)\n",
            "llama_print_timings:        eval time =    1587.91 ms /    15 runs   (  105.86 ms per token,     9.45 tokens per second)\n",
            "llama_print_timings:       total time =    1993.56 ms /    60 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@_____ErenJaeger Empathic psychopath yes, like when the mother says before hitting the child \"this is going to hurt me more than it will hurt you\" 🙃\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.23 ms /    16 runs   (    0.58 ms per token,  1733.48 tokens per second)\n",
            "llama_print_timings: prompt eval time =     286.83 ms /    71 tokens (    4.04 ms per token,   247.54 tokens per second)\n",
            "llama_print_timings:        eval time =    1584.29 ms /    15 runs   (  105.62 ms per token,     9.47 tokens per second)\n",
            "llama_print_timings:       total time =    2081.63 ms /    86 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Rabona is an art of Argentine origin, a different way of hitting the ball with one foot that passes behind the leg that supports the entire weight of the body, that is, crossing both legs. There are many reasons why a player opts... https://t.co/THTkNB9s9w\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.64 ms /    16 runs   (    0.60 ms per token,  1658.89 tokens per second)\n",
            "llama_print_timings: prompt eval time =     275.16 ms /    81 tokens (    3.40 ms per token,   294.38 tokens per second)\n",
            "llama_print_timings:        eval time =    1535.10 ms /    15 runs   (  102.34 ms per token,     9.77 tokens per second)\n",
            "llama_print_timings:       total time =    2042.47 ms /    96 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@rojasdiazduran What militarization. You are a cretin, where are you seeing that the army is used to repress, beat or intimidate citizens, the president wants and the majority of us support him so that he protects our institution @GN_MEXICO_ from bad rulers #ProtejamosLaGuardiaNacional\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.09 ms /    16 runs   (    0.57 ms per token,  1759.40 tokens per second)\n",
            "llama_print_timings: prompt eval time =     861.76 ms /    26 tokens (   33.14 ms per token,    30.17 tokens per second)\n",
            "llama_print_timings:        eval time =    1510.72 ms /    15 runs   (  100.71 ms per token,     9.93 tokens per second)\n",
            "llama_print_timings:       total time =    2535.92 ms /    41 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "A bike just hit me at university and my back hurts like hell HAHAHAHAHAHAHA\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.32 ms /    16 runs   (    0.58 ms per token,  1717.11 tokens per second)\n",
            "llama_print_timings: prompt eval time =     274.26 ms /    67 tokens (    4.09 ms per token,   244.29 tokens per second)\n",
            "llama_print_timings:        eval time =    1540.05 ms /    15 runs   (  102.67 ms per token,     9.74 tokens per second)\n",
            "llama_print_timings:       total time =    2010.08 ms /    82 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "#MariaBelenBernal-A woman is brutally beaten in Guayaquil.- A police officer on active duty beat his partner on the Vinces boardwalk.- A lieutenant killed his wife in a training school. Disgust of society!! They are killing us. How many more?\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.80 ms /    16 runs   (    0.55 ms per token,  1818.60 tokens per second)\n",
            "llama_print_timings: prompt eval time =     238.33 ms /    43 tokens (    5.54 ms per token,   180.43 tokens per second)\n",
            "llama_print_timings:        eval time =    1521.15 ms /    15 runs   (  101.41 ms per token,     9.86 tokens per second)\n",
            "llama_print_timings:       total time =    1908.86 ms /    58 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "In the best moment of the Uruguayan team, the dragão struck first with Pereira who sent a cross for Luiz Fernando to connect with a header at the near post.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.37 ms /    16 runs   (    0.59 ms per token,  1707.21 tokens per second)\n",
            "llama_print_timings: prompt eval time =     284.11 ms /    97 tokens (    2.93 ms per token,   341.41 tokens per second)\n",
            "llama_print_timings:        eval time =    1534.80 ms /    15 runs   (  102.32 ms per token,     9.77 tokens per second)\n",
            "llama_print_timings:       total time =    2100.15 ms /   112 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@EvyMedinz @aycomochingas @nadadetuiter But that is not respectful parenting, I correct my son and actions that are wrong have consequences, I do not hit him and I educate him with love, those misbehaved children are generally not raised by their parents that is why they are like that , they are raised by TV, games, babysitters and they do not receive love.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.17 ms /    16 runs   (    0.70 ms per token,  1432.02 tokens per second)\n",
            "llama_print_timings: prompt eval time =     258.82 ms /    51 tokens (    5.07 ms per token,   197.05 tokens per second)\n",
            "llama_print_timings:        eval time =    1565.54 ms /    15 runs   (  104.37 ms per token,     9.58 tokens per second)\n",
            "llama_print_timings:       total time =    2101.07 ms /    66 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Minister @Vi11atoro reports the capture of a motorcyclist who hit a person in the Antiguo Cuscatlán area. https://t.co/Pu6cjsCpzu\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.15 ms /    16 runs   (    0.57 ms per token,  1749.40 tokens per second)\n",
            "llama_print_timings: prompt eval time =     260.14 ms /    58 tokens (    4.49 ms per token,   222.95 tokens per second)\n",
            "llama_print_timings:        eval time =    1602.25 ms /    15 runs   (  106.82 ms per token,     9.36 tokens per second)\n",
            "llama_print_timings:       total time =    2044.60 ms /    73 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@iBanishedHero ⠀⠀⠀⠀   ⠀ ───He just rolled his eyes and started serving the customers who took a long time and while walking behind the counter, he accidentally hit the guy a couple of times.───\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.94 ms /    16 runs   (    0.56 ms per token,  1790.11 tokens per second)\n",
            "llama_print_timings: prompt eval time =     596.94 ms /    23 tokens (   25.95 ms per token,    38.53 tokens per second)\n",
            "llama_print_timings:        eval time =    1557.00 ms /    15 runs   (  103.80 ms per token,     9.63 tokens per second)\n",
            "llama_print_timings:       total time =    2273.48 ms /    38 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "I hit the ATM keys, sweaters with holes, always a new mambo\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.07 ms /    16 runs   (    0.63 ms per token,  1588.88 tokens per second)\n",
            "llama_print_timings: prompt eval time =     618.27 ms /    23 tokens (   26.88 ms per token,    37.20 tokens per second)\n",
            "llama_print_timings:        eval time =    1709.29 ms /    15 runs   (  113.95 ms per token,     8.78 tokens per second)\n",
            "llama_print_timings:       total time =    2457.47 ms /    38 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "my fat fan weekend officially ended. Belén, 16, would be very proud\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.18 ms /    16 runs   (    0.57 ms per token,  1743.30 tokens per second)\n",
            "llama_print_timings: prompt eval time =     262.70 ms /    56 tokens (    4.69 ms per token,   213.17 tokens per second)\n",
            "llama_print_timings:        eval time =    1624.64 ms /    15 runs   (  108.31 ms per token,     9.23 tokens per second)\n",
            "llama_print_timings:       total time =    2064.92 ms /    71 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@WilsonMendez86 She's a fat girl who sucks dick instead of first saying, \"It's perfect for theirs, no, always defending, but then it's their turn and the fat girl goes crazy.\"\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.81 ms /    16 runs   (    0.55 ms per token,  1815.71 tokens per second)\n",
            "llama_print_timings: prompt eval time =     240.22 ms /    37 tokens (    6.49 ms per token,   154.03 tokens per second)\n",
            "llama_print_timings:        eval time =    1672.98 ms /    15 runs   (  111.53 ms per token,     8.97 tokens per second)\n",
            "llama_print_timings:       total time =    2055.26 ms /    52 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@ultramacrista23 @marce01971 @infobae She is a fat woman who hates women who prefer men\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.48 ms /    16 runs   (    0.59 ms per token,  1688.30 tokens per second)\n",
            "llama_print_timings: prompt eval time =     267.93 ms /    59 tokens (    4.54 ms per token,   220.21 tokens per second)\n",
            "llama_print_timings:        eval time =    1560.15 ms /    15 runs   (  104.01 ms per token,     9.61 tokens per second)\n",
            "llama_print_timings:       total time =    2007.86 ms /    74 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@ugharufck JSJDKAKDJSJS we have the same illness, only I justify it with end-of-year fatigue!!! It doesn't matter if the fat woman here becomes very delirious or we all immolate ourselves directly.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      12.31 ms /    16 runs   (    0.77 ms per token,  1300.18 tokens per second)\n",
            "llama_print_timings: prompt eval time =     767.42 ms /    31 tokens (   24.76 ms per token,    40.39 tokens per second)\n",
            "llama_print_timings:        eval time =    1778.72 ms /    15 runs   (  118.58 ms per token,     8.43 tokens per second)\n",
            "llama_print_timings:       total time =    2708.86 ms /    46 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@hugomndzz @follacamiones24 @solmorote and a fat cock who knows Asturias\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.77 ms /    16 runs   (    0.55 ms per token,  1824.40 tokens per second)\n",
            "llama_print_timings: prompt eval time =     798.88 ms /    30 tokens (   26.63 ms per token,    37.55 tokens per second)\n",
            "llama_print_timings:        eval time =    1620.49 ms /    15 runs   (  108.03 ms per token,     9.26 tokens per second)\n",
            "llama_print_timings:       total time =    2550.72 ms /    45 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "How I hate going out in short sleeves and having to come back with a fat jacket, the fucking motherfucker.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.46 ms /    16 runs   (    0.59 ms per token,  1691.51 tokens per second)\n",
            "llama_print_timings: prompt eval time =     260.01 ms /    52 tokens (    5.00 ms per token,   199.99 tokens per second)\n",
            "llama_print_timings:        eval time =    1564.48 ms /    15 runs   (  104.30 ms per token,     9.59 tokens per second)\n",
            "llama_print_timings:       total time =    1996.36 ms /    67 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@1312caba @daanifdzz_ @secoweedcodein @dgarcian08 I think I'm eating slut, pass me the ketchup hahahahaha\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.34 ms /    16 runs   (    0.58 ms per token,  1712.51 tokens per second)\n",
            "llama_print_timings: prompt eval time =     300.96 ms /   121 tokens (    2.49 ms per token,   402.05 tokens per second)\n",
            "llama_print_timings:        eval time =    1525.30 ms /    15 runs   (  101.69 ms per token,     9.83 tokens per second)\n",
            "llama_print_timings:       total time =    2181.09 ms /   136 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Old slut plays Twitch in rankeds Come see me https://t.co/xd1VavJcGN.#smallstreamer #twitch #twitchaffiliate #TwitchStreaming #twitchenlinea #twitchtv #LeagueOfLegends #twitchcommunity@twitchpr0mo@Promo_Twitch_RT@StreamersApoyo@ComunidadTwitch@streamsspain@lol_es https:/ /t.co/AmraYcloCm\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.95 ms /    16 runs   (    0.68 ms per token,  1461.45 tokens per second)\n",
            "llama_print_timings: prompt eval time =     826.90 ms /    26 tokens (   31.80 ms per token,    31.44 tokens per second)\n",
            "llama_print_timings:        eval time =    1793.09 ms /    15 runs   (  119.54 ms per token,     8.37 tokens per second)\n",
            "llama_print_timings:       total time =    2817.38 ms /    41 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "The dirty joke of removing Griezmann in the 64th minute is worth it eh\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.97 ms /    16 runs   (    0.56 ms per token,  1783.92 tokens per second)\n",
            "llama_print_timings: prompt eval time =     242.54 ms /    34 tokens (    7.13 ms per token,   140.18 tokens per second)\n",
            "llama_print_timings:        eval time =    1536.12 ms /    15 runs   (  102.41 ms per token,     9.76 tokens per second)\n",
            "llama_print_timings:       total time =    1923.12 ms /    49 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@GamberrosATM @chasalSDH The one who really looks like a slut that you freak out about is your mother\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.24 ms /    16 runs   (    0.58 ms per token,  1731.98 tokens per second)\n",
            "llama_print_timings: prompt eval time =     788.12 ms /    30 tokens (   26.27 ms per token,    38.07 tokens per second)\n",
            "llama_print_timings:        eval time =    1472.44 ms /    15 runs   (   98.16 ms per token,    10.19 tokens per second)\n",
            "llama_print_timings:       total time =    2390.90 ms /    45 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@mblopezz3 BUT YOU SAY YOU PIECE OF A SLUT, LOUIE😎🤘\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.54 ms /    16 runs   (    0.53 ms per token,  1872.88 tokens per second)\n",
            "llama_print_timings: prompt eval time =     762.32 ms /    30 tokens (   25.41 ms per token,    39.35 tokens per second)\n",
            "llama_print_timings:        eval time =    1516.95 ms /    15 runs   (  101.13 ms per token,     9.89 tokens per second)\n",
            "llama_print_timings:       total time =    2403.33 ms /    45 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Beatriz_co_14 But slut... in the literal sense of the word slut? My mother?\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.81 ms /    16 runs   (    0.68 ms per token,  1480.11 tokens per second)\n",
            "llama_print_timings: prompt eval time =     260.83 ms /    51 tokens (    5.11 ms per token,   195.53 tokens per second)\n",
            "llama_print_timings:        eval time =    1670.05 ms /    15 runs   (  111.34 ms per token,     8.98 tokens per second)\n",
            "llama_print_timings:       total time =    2194.73 ms /    66 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@ElisaLoncon Thank you so much Elisa....you are one of the people who generated hives in Chileans and contributed to the rejection today...thank you!!! #LONCON #REJECTION\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       2.65 ms /     5 runs   (    0.53 ms per token,  1886.08 tokens per second)\n",
            "llama_print_timings: prompt eval time =     257.90 ms /    64 tokens (    4.03 ms per token,   248.16 tokens per second)\n",
            "llama_print_timings:        eval time =     389.78 ms /     4 runs   (   97.44 ms per token,    10.26 tokens per second)\n",
            "llama_print_timings:       total time =     811.76 ms /    68 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@bartije These ladies are a shame for the genre! 🤮🤬🤬🤬🤬 And the worst thing is that they are not even useful to society 🤮🤮🤮\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.79 ms /    16 runs   (    0.61 ms per token,  1635.16 tokens per second)\n",
            "llama_print_timings: prompt eval time =     258.10 ms /    82 tokens (    3.15 ms per token,   317.71 tokens per second)\n",
            "llama_print_timings:        eval time =    1490.18 ms /    15 runs   (   99.35 ms per token,    10.07 tokens per second)\n",
            "llama_print_timings:       total time =    1998.49 ms /    97 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Luis22373580 @bereaguilarv @lopezobrador_ It is not a simulation, the lack of water was generated when in 2019 they fired many technicians from Conagua de Nuevo León, due to austerity, they avoided the theft of water and took care of the dams.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.90 ms /    16 runs   (    0.56 ms per token,  1798.36 tokens per second)\n",
            "llama_print_timings: prompt eval time =     251.53 ms /    36 tokens (    6.99 ms per token,   143.12 tokens per second)\n",
            "llama_print_timings:        eval time =    1649.30 ms /    15 runs   (  109.95 ms per token,     9.09 tokens per second)\n",
            "llama_print_timings:       total time =    2045.90 ms /    51 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "My next birthday has me thinking about all the unnecessary emotional and physical wear and tear that living doing masking without knowing for 36 years caused me.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.01 ms /    16 runs   (    0.63 ms per token,  1598.24 tokens per second)\n",
            "llama_print_timings: prompt eval time =     262.75 ms /    57 tokens (    4.61 ms per token,   216.94 tokens per second)\n",
            "llama_print_timings:        eval time =    1565.18 ms /    15 runs   (  104.35 ms per token,     9.58 tokens per second)\n",
            "llama_print_timings:       total time =    2009.39 ms /    72 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@inigobastida @veronicafumanal What nonsense. First you ask that they be treated with discipline and then about the rooms. I used Capello as mister. You always orient everything to gender. Capello towards military concentrations\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.19 ms /    16 runs   (    0.57 ms per token,  1741.40 tokens per second)\n",
            "llama_print_timings: prompt eval time =     256.43 ms /    59 tokens (    4.35 ms per token,   230.08 tokens per second)\n",
            "llama_print_timings:        eval time =    1544.07 ms /    15 runs   (  102.94 ms per token,     9.71 tokens per second)\n",
            "llama_print_timings:       total time =    1980.94 ms /    74 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Victimization continues, apparently Carrera is going to change sex, to be able to victimize herself with the issue of gender violence, it is the only thing she has left. https://t.co/Qa1SQj2wJj\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.61 ms /    16 runs   (    0.60 ms per token,  1664.76 tokens per second)\n",
            "llama_print_timings: prompt eval time =     260.21 ms /    48 tokens (    5.42 ms per token,   184.47 tokens per second)\n",
            "llama_print_timings:        eval time =    1524.56 ms /    15 runs   (  101.64 ms per token,     9.84 tokens per second)\n",
            "llama_print_timings:       total time =    1952.82 ms /    63 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@AntonioMautor Hembrism is not totally transversal. He understands ideologies. It is true that it abounds in some more than in others, but unfortunately it knocks on all doors.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.47 ms /    16 runs   (    0.59 ms per token,  1689.72 tokens per second)\n",
            "llama_print_timings: prompt eval time =     295.31 ms /    87 tokens (    3.39 ms per token,   294.61 tokens per second)\n",
            "llama_print_timings:        eval time =    1531.68 ms /    15 runs   (  102.11 ms per token,     9.79 tokens per second)\n",
            "llama_print_timings:       total time =    2068.47 ms /   102 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@AfricaCuevasR Hembrism without further ado.... a man, just because he is a man, does not have the right to deductions even if he has children, let's be clear about what he says, you have to be homosexual or a woman. I love them both but where is the real feminism? Another attack on man for the fact of being one 🤷\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.81 ms /    16 runs   (    0.61 ms per token,  1630.66 tokens per second)\n",
            "llama_print_timings: prompt eval time =     257.51 ms /    56 tokens (    4.60 ms per token,   217.47 tokens per second)\n",
            "llama_print_timings:        eval time =    1557.74 ms /    15 runs   (  103.85 ms per token,     9.63 tokens per second)\n",
            "llama_print_timings:       total time =    1997.04 ms /    71 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@IsaMellen That is fembrism... feminism is equity, let's stop talking about the rights of women/men and let it be just RIGHTS OF PEOPLE. Something so simple and that even today we have to fight\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.50 ms /    16 runs   (    0.59 ms per token,  1683.68 tokens per second)\n",
            "llama_print_timings: prompt eval time =     264.31 ms /    55 tokens (    4.81 ms per token,   208.09 tokens per second)\n",
            "llama_print_timings:        eval time =    1573.97 ms /    15 runs   (  104.93 ms per token,     9.53 tokens per second)\n",
            "llama_print_timings:       total time =    2015.86 ms /    70 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Roinaldinho4 @LocksleyRober @interiorgob @guardiacivil You are wrong. Hembrism only seeks privileges for women. Feminism seeks equality in criteria of real and well-understood justice.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.65 ms /    16 runs   (    0.54 ms per token,  1850.35 tokens per second)\n",
            "llama_print_timings: prompt eval time =     930.77 ms /    30 tokens (   31.03 ms per token,    32.23 tokens per second)\n",
            "llama_print_timings:        eval time =    1571.03 ms /    15 runs   (  104.74 ms per token,     9.55 tokens per second)\n",
            "llama_print_timings:       total time =    2682.62 ms /    45 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Profecampusano It is not feminism... It is hembrism, another empty progressive movement without arguments...\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.40 ms /    16 runs   (    0.59 ms per token,  1702.67 tokens per second)\n",
            "llama_print_timings: prompt eval time =     284.54 ms /    82 tokens (    3.47 ms per token,   288.18 tokens per second)\n",
            "llama_print_timings:        eval time =    1500.30 ms /    15 runs   (  100.02 ms per token,    10.00 tokens per second)\n",
            "llama_print_timings:       total time =    2014.65 ms /    97 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@YoBramanta @charovargas_ False. They achieved equality and now they are about to achieve hembrism, the imposition of women over men. They ended equality before the law, they eliminated the presumption of innocence, they continue to ask for Alliemoney and even alimony for children who do not belong to their husbands. They passed\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.79 ms /    16 runs   (    0.61 ms per token,  1633.82 tokens per second)\n",
            "llama_print_timings: prompt eval time =     281.32 ms /    68 tokens (    4.14 ms per token,   241.71 tokens per second)\n",
            "llama_print_timings:        eval time =    1674.32 ms /    15 runs   (  111.62 ms per token,     8.96 tokens per second)\n",
            "llama_print_timings:       total time =    2175.66 ms /    83 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@rosaruizarmi @AFBohorquez I think that is partly what Antonio says. The school is organized so that we all have access to a type of education, not just some. If that freedom of education and respect for an ideology are not ensured, the concert has no meaning.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.15 ms /    16 runs   (    0.57 ms per token,  1748.44 tokens per second)\n",
            "llama_print_timings: prompt eval time =     265.59 ms /    48 tokens (    5.53 ms per token,   180.73 tokens per second)\n",
            "llama_print_timings:        eval time =    1511.83 ms /    15 runs   (  100.79 ms per token,     9.92 tokens per second)\n",
            "llama_print_timings:       total time =    1982.52 ms /    63 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@PedroCastilloTe Very late now you want to put out your corruption with handouts, broad base when from the beginning you didn't care about Peru, only your ideology and destroying the economy.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.98 ms /    16 runs   (    0.56 ms per token,  1780.94 tokens per second)\n",
            "llama_print_timings: prompt eval time =     586.24 ms /    23 tokens (   25.49 ms per token,    39.23 tokens per second)\n",
            "llama_print_timings:        eval time =    1608.48 ms /    15 runs   (  107.23 ms per token,     9.33 tokens per second)\n",
            "llama_print_timings:       total time =    2313.33 ms /    38 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@EdySmol I think your fashion idea is in line with your political ideology...\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.60 ms /    16 runs   (    0.72 ms per token,  1379.55 tokens per second)\n",
            "llama_print_timings: prompt eval time =     279.59 ms /    78 tokens (    3.58 ms per token,   278.98 tokens per second)\n",
            "llama_print_timings:        eval time =    1705.76 ms /    15 runs   (  113.72 ms per token,     8.79 tokens per second)\n",
            "llama_print_timings:       total time =    2227.05 ms /    93 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Talk about the ideology of the conservative and liberal parties; It's talking about more than 100 years ago. That is obsolete in the world of civility, science, information, communications. The mocha heads were far away #camiloelbreve. https://t.co/fsZhKbb7b6\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.48 ms /    16 runs   (    0.59 ms per token,  1686.87 tokens per second)\n",
            "llama_print_timings: prompt eval time =     282.98 ms /    67 tokens (    4.22 ms per token,   236.76 tokens per second)\n",
            "llama_print_timings:        eval time =    1507.03 ms /    15 runs   (  100.47 ms per token,     9.95 tokens per second)\n",
            "llama_print_timings:       total time =    1986.48 ms /    82 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@parlaencatala @arqueoleg Territory that has welcomed him. What a flower-eating shit that is. The territory, neither the land nor anything welcomed them, they came to work and were exploited by the businessmen as always happens. Fuck your host land ideology.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.16 ms /    16 runs   (    0.57 ms per token,  1746.92 tokens per second)\n",
            "llama_print_timings: prompt eval time =     252.31 ms /    52 tokens (    4.85 ms per token,   206.10 tokens per second)\n",
            "llama_print_timings:        eval time =    1593.23 ms /    15 runs   (  106.22 ms per token,     9.41 tokens per second)\n",
            "llama_print_timings:       total time =    2016.73 ms /    67 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Lu19_92 @Kabroneitor That doesn't exist here and I don't think it exists because every time you want to build that popular ideology, someone powerful comes to set it on fire...\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.28 ms /    16 runs   (    0.58 ms per token,  1723.40 tokens per second)\n",
            "llama_print_timings: prompt eval time =     578.04 ms /    21 tokens (   27.53 ms per token,    36.33 tokens per second)\n",
            "llama_print_timings:        eval time =    1652.58 ms /    15 runs   (  110.17 ms per token,     9.08 tokens per second)\n",
            "llama_print_timings:       total time =    2344.14 ms /    36 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@interiorgob @guardiacivil Well, you have destroyed equal opportunities.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.83 ms /    16 runs   (    0.55 ms per token,  1812.62 tokens per second)\n",
            "llama_print_timings: prompt eval time =     279.39 ms /    76 tokens (    3.68 ms per token,   272.02 tokens per second)\n",
            "llama_print_timings:        eval time =    1515.98 ms /    15 runs   (  101.07 ms per token,     9.89 tokens per second)\n",
            "llama_print_timings:       total time =    2006.31 ms /    91 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@NataliGuissen @murra22 @isidoraalcalde It is not because of a more patriarchal society. It is because men and women have different interests. Women are more inclined towards people and men towards things. The greater the equality of opportunities, the greater the gender difference in the different occupations in society!\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.83 ms /    16 runs   (    0.61 ms per token,  1627.50 tokens per second)\n",
            "llama_print_timings: prompt eval time =     276.94 ms /    78 tokens (    3.55 ms per token,   281.65 tokens per second)\n",
            "llama_print_timings:        eval time =    1550.70 ms /    15 runs   (  103.38 ms per token,     9.67 tokens per second)\n",
            "llama_print_timings:       total time =    2055.43 ms /    93 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@mlevyholden @zeinu1 @oasisdehorror + these difficulties translate into inequality of opportunities and it is not about just saying “study and try hard” because not everyone can and it is evident in the fact that the average salary is $7,500. It is about increasing equal opportunities to stop being a developing country\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.76 ms /    16 runs   (    0.61 ms per token,  1639.68 tokens per second)\n",
            "llama_print_timings: prompt eval time =     274.04 ms /    77 tokens (    3.56 ms per token,   280.98 tokens per second)\n",
            "llama_print_timings:        eval time =    1500.26 ms /    15 runs   (  100.02 ms per token,    10.00 tokens per second)\n",
            "llama_print_timings:       total time =    2000.94 ms /    92 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@user17700871792 @mparracgmailcom @maylwino @mmlagoscc The socialist term \"Substantive equality\" implies equalizing results (taking from some to give to others) not equality of opportunities, that is reason enough to reject that ideologized and poorly written text\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.57 ms /    16 runs   (    0.66 ms per token,  1513.43 tokens per second)\n",
            "llama_print_timings: prompt eval time =     269.91 ms /    49 tokens (    5.51 ms per token,   181.54 tokens per second)\n",
            "llama_print_timings:        eval time =    1737.33 ms /    15 runs   (  115.82 ms per token,     8.63 tokens per second)\n",
            "llama_print_timings:       total time =    2265.28 ms /    64 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@MariaMar_2020 @natumader I agree with that, hopefully one day there will be equal opportunities, then over the years it will be seen that it is more popular and profitable as a show\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.63 ms /    16 runs   (    0.60 ms per token,  1661.47 tokens per second)\n",
            "llama_print_timings: prompt eval time =     267.55 ms /    66 tokens (    4.05 ms per token,   246.68 tokens per second)\n",
            "llama_print_timings:        eval time =    1624.17 ms /    15 runs   (  108.28 ms per token,     9.24 tokens per second)\n",
            "llama_print_timings:       total time =    2109.82 ms /    81 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@romoyluna @Claudiashein Because I have always been on the left, I have always supported the fight for equal opportunities, the main characteristic of the left, while the right sees inequality as something Normal, something that is given and therefore always the strongest eats the \"weakest\"\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.37 ms /    16 runs   (    0.65 ms per token,  1542.76 tokens per second)\n",
            "llama_print_timings: prompt eval time =     267.21 ms /    61 tokens (    4.38 ms per token,   228.28 tokens per second)\n",
            "llama_print_timings:        eval time =    1573.01 ms /    15 runs   (  104.87 ms per token,     9.54 tokens per second)\n",
            "llama_print_timings:       total time =    2040.26 ms /    76 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@gonzalofullu Did anyone get hurt? Compare on equal terms and with a little judgment, can Parra end his career because of the killers that your team has as barrists and do you say that it is comparable to entering and facing the players themselves?\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.53 ms /    16 runs   (    0.60 ms per token,  1679.26 tokens per second)\n",
            "llama_print_timings: prompt eval time =     257.20 ms /    64 tokens (    4.02 ms per token,   248.83 tokens per second)\n",
            "llama_print_timings:        eval time =    1596.58 ms /    15 runs   (  106.44 ms per token,     9.40 tokens per second)\n",
            "llama_print_timings:       total time =    2048.25 ms /    79 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "for a future of politics that meets each person without violence of any kind, in equality and equity. I thank @CarolinaMoises and each of the people who were part of this beautiful, federal and horizontal day for a better Argentina ✌️🇦🇷\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.85 ms /    16 runs   (    0.62 ms per token,  1624.53 tokens per second)\n",
            "llama_print_timings: prompt eval time =     283.48 ms /    67 tokens (    4.23 ms per token,   236.34 tokens per second)\n",
            "llama_print_timings:        eval time =    1538.94 ms /    15 runs   (  102.60 ms per token,     9.75 tokens per second)\n",
            "llama_print_timings:       total time =    2022.76 ms /    82 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@mermelber @VFuture But I'm ashamed of having more than one man when we've been crowing about equality all our lives. Now we dont want her? Is the armchair of the extra rights of being able to fleece and destroy them more cool? Not me!\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.86 ms /    16 runs   (    0.62 ms per token,  1622.88 tokens per second)\n",
            "llama_print_timings: prompt eval time =     266.93 ms /    60 tokens (    4.45 ms per token,   224.78 tokens per second)\n",
            "llama_print_timings:        eval time =    1618.58 ms /    15 runs   (  107.91 ms per token,     9.27 tokens per second)\n",
            "llama_print_timings:       total time =    2076.90 ms /    75 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@marticasaspino The only ones it violates are those “mothers” who hold their children hostage against their parents! Equal rights, both emotional and economic! That's called justice, I understand you don't know what I'm talking about!\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.92 ms /    16 runs   (    0.68 ms per token,  1465.47 tokens per second)\n",
            "llama_print_timings: prompt eval time =     292.51 ms /    85 tokens (    3.44 ms per token,   290.59 tokens per second)\n",
            "llama_print_timings:        eval time =    1775.11 ms /    15 runs   (  118.34 ms per token,     8.45 tokens per second)\n",
            "llama_print_timings:       total time =    2338.64 ms /   100 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Party for all the boys and girls organized by the Noble Equality MPA Cooperative, thank God for so much blessing, we were overwhelmed with joy to see so many families sharing with us a special afternoon full of surprises for the little ones 😊♥️🇦🇷 https:/ /t.co/L4IzRQwtvv\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.69 ms /    16 runs   (    0.61 ms per token,  1651.87 tokens per second)\n",
            "llama_print_timings: prompt eval time =     299.95 ms /   105 tokens (    2.86 ms per token,   350.06 tokens per second)\n",
            "llama_print_timings:        eval time =    1630.31 ms /    15 runs   (  108.69 ms per token,     9.20 tokens per second)\n",
            "llama_print_timings:       total time =    2234.04 ms /   120 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Child Development: Rights of the present, future possibilities.This #UltimoBondi is a joint production of Colectivo +igualdad and @el_lado_fWe are accompanied by Anabella Santoro and Mira Colacce.Here is the link👇🔗 https://t.co/gO9JykEDw2 🧵 https:// t.co/uwRXhc4oSX\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.66 ms /    16 runs   (    0.60 ms per token,  1656.14 tokens per second)\n",
            "llama_print_timings: prompt eval time =     256.90 ms /    55 tokens (    4.67 ms per token,   214.09 tokens per second)\n",
            "llama_print_timings:        eval time =    1579.22 ms /    15 runs   (  105.28 ms per token,     9.50 tokens per second)\n",
            "llama_print_timings:       total time =    2014.93 ms /    70 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@AntonioMautor If you believe in the free market, in equal opportunities, that it does not produce results and queer feminism or intersectionality seems like nonsense to you, you are an unrepentant fascist who eats children\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.08 ms /    16 runs   (    0.63 ms per token,  1587.14 tokens per second)\n",
            "llama_print_timings: prompt eval time =     272.26 ms /    73 tokens (    3.73 ms per token,   268.13 tokens per second)\n",
            "llama_print_timings:        eval time =    1487.79 ms /    15 runs   (   99.19 ms per token,    10.08 tokens per second)\n",
            "llama_print_timings:       total time =    1982.90 ms /    88 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "The theory of intersectionality refers to complex processes that in each situation derive from the interaction of factors of various kinds. In fact, every phenomenon is the product of multiple causes (multicausality) according to the materialist dialectic on which science is based. https://t.co/W6ySZvXrm0\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.29 ms /    16 runs   (    0.58 ms per token,  1721.73 tokens per second)\n",
            "llama_print_timings: prompt eval time =     280.25 ms /    80 tokens (    3.50 ms per token,   285.46 tokens per second)\n",
            "llama_print_timings:        eval time =    1571.44 ms /    15 runs   (  104.76 ms per token,     9.55 tokens per second)\n",
            "llama_print_timings:       total time =    2081.82 ms /    95 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Exactly. It doesn't matter the color of your skin, the problem is the cult of the categories of gender, ethnicity or sexual orientation that promotes the theory of intersectionality and other garbage that comes out of universities in the USA. This is the opposite of what Luther King Jr. preached. https://t.co/OOcLmeFPND\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.43 ms /    16 runs   (    0.59 ms per token,  1697.07 tokens per second)\n",
            "llama_print_timings: prompt eval time =     255.12 ms /    45 tokens (    5.67 ms per token,   176.39 tokens per second)\n",
            "llama_print_timings:        eval time =    1628.55 ms /    15 runs   (  108.57 ms per token,     9.21 tokens per second)\n",
            "llama_print_timings:       total time =    2042.66 ms /    60 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Start of the Diploma in Gender Intersectionality and Citizenship #MovimientoCiudadano https://t.co/Wa85rUqOfF\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.67 ms /    16 runs   (    0.60 ms per token,  1654.77 tokens per second)\n",
            "llama_print_timings: prompt eval time =     292.44 ms /    77 tokens (    3.80 ms per token,   263.31 tokens per second)\n",
            "llama_print_timings:        eval time =    1629.72 ms /    15 runs   (  108.65 ms per token,     9.20 tokens per second)\n",
            "llama_print_timings:       total time =    2166.54 ms /    92 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Today Gloria Jean Watkins, known as bell hooks, would turn 70 years old. She is an American writer, feminist and social activist. The intersectionality between race, class and gender, in education, art, history, sexuality, media and feminism. https://t.co/snQjfrre4r\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.33 ms /    16 runs   (    0.58 ms per token,  1714.16 tokens per second)\n",
            "llama_print_timings: prompt eval time =     267.57 ms /    53 tokens (    5.05 ms per token,   198.08 tokens per second)\n",
            "llama_print_timings:        eval time =    1498.58 ms /    15 runs   (   99.91 ms per token,    10.01 tokens per second)\n",
            "llama_print_timings:       total time =    2029.50 ms /    68 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@nicalibe I am surprised by the number of people who are giving their opinion without even having any knowledge of intersectionality or black history, struggles and resistance. One of the most incredible things is that people think that reverse racism exists.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.34 ms /    16 runs   (    0.58 ms per token,  1712.33 tokens per second)\n",
            "llama_print_timings: prompt eval time =     289.65 ms /    84 tokens (    3.45 ms per token,   290.00 tokens per second)\n",
            "llama_print_timings:        eval time =    1487.00 ms /    15 runs   (   99.13 ms per token,    10.09 tokens per second)\n",
            "llama_print_timings:       total time =    2017.67 ms /    99 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Margaritarosadf I want equality between men and women but for it to be in everything, and for this not to become like in Spain where a man is bad just because he is a man, tough on the abuser, the harasser, the abuser, but highlighting those who are not. Long live human equality, which dignifies humanity and not sex.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.62 ms /    16 runs   (    0.60 ms per token,  1663.37 tokens per second)\n",
            "llama_print_timings: prompt eval time =     262.82 ms /    59 tokens (    4.45 ms per token,   224.49 tokens per second)\n",
            "llama_print_timings:        eval time =    1510.02 ms /    15 runs   (  100.67 ms per token,     9.93 tokens per second)\n",
            "llama_print_timings:       total time =    1961.09 ms /    74 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "society of that time, given that Roscio was determined to defend equality between all human beings, pointing out merit as the only valid difference between people, an unacceptable situation at that time with such established caste prejudices. This case is one of the\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.02 ms /    16 runs   (    0.56 ms per token,  1773.84 tokens per second)\n",
            "llama_print_timings: prompt eval time =     261.26 ms /    54 tokens (    4.84 ms per token,   206.69 tokens per second)\n",
            "llama_print_timings:        eval time =    1456.67 ms /    15 runs   (   97.11 ms per token,    10.30 tokens per second)\n",
            "llama_print_timings:       total time =    1899.83 ms /    69 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Rumbalion @PapiTorru Imagine. Equality between the sexes destroyed the family. That men and women have the same rights destroyed the family. The traditional family depended on the woman being subjugated. Okay.\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.07 ms /    16 runs   (    0.57 ms per token,  1764.06 tokens per second)\n",
            "llama_print_timings: prompt eval time =     276.25 ms /    70 tokens (    3.95 ms per token,   253.40 tokens per second)\n",
            "llama_print_timings:        eval time =    1599.17 ms /    15 runs   (  106.61 ms per token,     9.38 tokens per second)\n",
            "llama_print_timings:       total time =    2078.62 ms /    85 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "You're sure it's not about that? Isn't it the ministry of equality? So everything you say is equality between all of us, so that's what the poster is about, but isn't that the case? Why not? https://t.co/MCaGE6l3bl\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.74 ms /    16 runs   (    0.61 ms per token,  1643.05 tokens per second)\n",
            "llama_print_timings: prompt eval time =     300.16 ms /    88 tokens (    3.41 ms per token,   293.18 tokens per second)\n",
            "llama_print_timings:        eval time =    1577.44 ms /    15 runs   (  105.16 ms per token,     9.51 tokens per second)\n",
            "llama_print_timings:       total time =    2272.92 ms /   103 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Speech by Calmen Calvo at the Rota Feminist Congress. Review of the feminist struggle, for equality between the male and female sex, because women are half of the population, not a minority. They are not going to make us invisible To do +++ retwitter ✊💜🌹https://t.co/wZ01xrdH5y\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.75 ms /    16 runs   (    0.61 ms per token,  1640.35 tokens per second)\n",
            "llama_print_timings: prompt eval time =     281.39 ms /    76 tokens (    3.70 ms per token,   270.08 tokens per second)\n",
            "llama_print_timings:        eval time =    1541.26 ms /    15 runs   (  102.75 ms per token,     9.73 tokens per second)\n",
            "llama_print_timings:       total time =    2040.92 ms /    91 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "No one is going to read it because my account is locked and I'm not going to change it but: being a feminist is not going against the oppressive sex or I don't know how the hell they say it, feminism seeks equality between all. Let's see if we study, because then there are always problems+\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       2.92 ms /     5 runs   (    0.58 ms per token,  1712.33 tokens per second)\n",
            "llama_print_timings: prompt eval time =     253.69 ms /    58 tokens (    4.37 ms per token,   228.62 tokens per second)\n",
            "llama_print_timings:        eval time =     381.14 ms /     4 runs   (   95.29 ms per token,    10.49 tokens per second)\n",
            "llama_print_timings:       total time =     769.51 ms /    62 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@MariahM64685386 @Avefeni38769590 Most of the women who participate in these protests end up being prostitutes or criminals!!! Those women are an additional burden on society!!!\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.54 ms /    16 runs   (    0.53 ms per token,  1872.88 tokens per second)\n",
            "llama_print_timings: prompt eval time =     227.14 ms /    33 tokens (    6.88 ms per token,   145.29 tokens per second)\n",
            "llama_print_timings:        eval time =    1509.36 ms /    15 runs   (  100.62 ms per token,     9.94 tokens per second)\n",
            "llama_print_timings:       total time =    1872.68 ms /    48 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@victoriacaracev Most women are not going to be happy, not with love, not with money, not with sex.\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.53 ms /    16 runs   (    0.66 ms per token,  1520.19 tokens per second)\n",
            "llama_print_timings: prompt eval time =     251.45 ms /    40 tokens (    6.29 ms per token,   159.08 tokens per second)\n",
            "llama_print_timings:        eval time =    1874.45 ms /    15 runs   (  124.96 ms per token,     8.00 tokens per second)\n",
            "llama_print_timings:       total time =    2368.79 ms /    55 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "People who clearly don't know strength or contact sports, in which most women look like that. https://t.co/xAw9qXQMtU\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.71 ms /    16 runs   (    0.61 ms per token,  1648.46 tokens per second)\n",
            "llama_print_timings: prompt eval time =     282.01 ms /    65 tokens (    4.34 ms per token,   230.49 tokens per second)\n",
            "llama_print_timings:        eval time =    1585.22 ms /    15 runs   (  105.68 ms per token,     9.46 tokens per second)\n",
            "llama_print_timings:       total time =    2069.92 ms /    80 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@chan_ougi @Nosue18 @David_D4C @TheDarkraimola Considerable perhaps xD.But the difference is only 10 years and I already told you that at 43 years old most women don't usually look like that.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.97 ms /    16 runs   (    0.56 ms per token,  1784.32 tokens per second)\n",
            "llama_print_timings: prompt eval time =     260.82 ms /    48 tokens (    5.43 ms per token,   184.03 tokens per second)\n",
            "llama_print_timings:        eval time =    1595.43 ms /    15 runs   (  106.36 ms per token,     9.40 tokens per second)\n",
            "llama_print_timings:       total time =    2016.76 ms /    63 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@deunhidoret Exactly! And how do these people think the majority of white women in Europe live? How do you think Eastern women live? Single mothers? Victims of abuse? What clowns.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.94 ms /    16 runs   (    0.56 ms per token,  1789.51 tokens per second)\n",
            "llama_print_timings: prompt eval time =     260.61 ms /    50 tokens (    5.21 ms per token,   191.86 tokens per second)\n",
            "llama_print_timings:        eval time =    1556.17 ms /    15 runs   (  103.74 ms per token,     9.64 tokens per second)\n",
            "llama_print_timings:       total time =    1994.04 ms /    65 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Humanity is mediocre. Most women are neither superior nor inferior to most men. We are equal. We all deserve the same contempt. https://t.co/nRRuqawbvq\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.89 ms /    16 runs   (    0.56 ms per token,  1800.59 tokens per second)\n",
            "llama_print_timings: prompt eval time =     269.10 ms /    66 tokens (    4.08 ms per token,   245.26 tokens per second)\n",
            "llama_print_timings:        eval time =    1531.41 ms /    15 runs   (  102.09 ms per token,     9.79 tokens per second)\n",
            "llama_print_timings:       total time =    2001.77 ms /    81 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@mariaFFreijo It sounds harsh to hear it and it is tremendous, but on a day-to-day basis it is like this, without such a specific speech but with other actions, society acts like this. Not only can women not be desired, but they also have no desires.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.66 ms /    16 runs   (    0.73 ms per token,  1372.21 tokens per second)\n",
            "llama_print_timings: prompt eval time =     256.60 ms /    36 tokens (    7.13 ms per token,   140.30 tokens per second)\n",
            "llama_print_timings:        eval time =    1683.36 ms /    15 runs   (  112.22 ms per token,     8.91 tokens per second)\n",
            "llama_print_timings:       total time =    2092.64 ms /    51 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@TatianaAstengoB For many Women, women Can't have sex Just for pleasure... This is how we are Worse, worse\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.39 ms /    16 runs   (    0.59 ms per token,  1703.58 tokens per second)\n",
            "llama_print_timings: prompt eval time =     284.15 ms /    78 tokens (    3.64 ms per token,   274.50 tokens per second)\n",
            "llama_print_timings:        eval time =    1606.87 ms /    15 runs   (  107.12 ms per token,     9.33 tokens per second)\n",
            "llama_print_timings:       total time =    2113.38 ms /    93 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "To the woke friends of the “very good” in international relations and who celebrate the stupidity of not receiving the credentials of the Ambassador of Israel, I tell you that at the same event those of the Ambassador of Saudi Arabia were received, a country where women cannot drive. . https://t.co/qXA5Hb1jjp\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.03 ms /    16 runs   (    0.56 ms per token,  1772.85 tokens per second)\n",
            "llama_print_timings: prompt eval time =     243.38 ms /    39 tokens (    6.24 ms per token,   160.24 tokens per second)\n",
            "llama_print_timings:        eval time =    1636.38 ms /    15 runs   (  109.09 ms per token,     9.17 tokens per second)\n",
            "llama_print_timings:       total time =    2026.74 ms /    54 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Women can't make anything hot, men automatically want to give you a 4?? how delicious write to me put photos of the chistri calm down please\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.73 ms /    16 runs   (    0.61 ms per token,  1644.23 tokens per second)\n",
            "llama_print_timings: prompt eval time =     263.13 ms /    60 tokens (    4.39 ms per token,   228.03 tokens per second)\n",
            "llama_print_timings:        eval time =    1523.21 ms /    15 runs   (  101.55 ms per token,     9.85 tokens per second)\n",
            "llama_print_timings:       total time =    1977.44 ms /    75 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Women can't do black kissing, Madonna in 1992 pretending to black kiss a model, women can do it all and even more trans ones 🏳‍⚧ https://t.co/hYeYFtnE0f\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.87 ms /    16 runs   (    0.68 ms per token,  1471.67 tokens per second)\n",
            "llama_print_timings: prompt eval time =     249.36 ms /    38 tokens (    6.56 ms per token,   152.39 tokens per second)\n",
            "llama_print_timings:        eval time =    1857.76 ms /    15 runs   (  123.85 ms per token,     8.07 tokens per second)\n",
            "llama_print_timings:       total time =    2284.44 ms /    53 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@keilin_mota Abel Martínez said that women cannot govern this country, what a mistake made by his friend Abel Martínez.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.92 ms /    16 runs   (    0.56 ms per token,  1794.53 tokens per second)\n",
            "llama_print_timings: prompt eval time =     243.59 ms /    34 tokens (    7.16 ms per token,   139.58 tokens per second)\n",
            "llama_print_timings:        eval time =    1661.06 ms /    15 runs   (  110.74 ms per token,     9.03 tokens per second)\n",
            "llama_print_timings:       total time =    2042.47 ms /    49 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "That like means that you still love me and that you are going to leave your little lizard and come back to me, right? 😭\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.55 ms /    16 runs   (    0.53 ms per token,  1872.00 tokens per second)\n",
            "llama_print_timings: prompt eval time =     804.03 ms /    30 tokens (   26.80 ms per token,    37.31 tokens per second)\n",
            "llama_print_timings:        eval time =    1632.32 ms /    15 runs   (  108.82 ms per token,     9.19 tokens per second)\n",
            "llama_print_timings:       total time =    2562.86 ms /    45 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@CynthiaRivarol5 Shut up corrupt lizard. You should be a little ashamed.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.32 ms /    16 runs   (    0.58 ms per token,  1716.92 tokens per second)\n",
            "llama_print_timings: prompt eval time =     253.92 ms /    43 tokens (    5.91 ms per token,   169.35 tokens per second)\n",
            "llama_print_timings:        eval time =    1584.13 ms /    15 runs   (  105.61 ms per token,     9.47 tokens per second)\n",
            "llama_print_timings:       total time =    1989.45 ms /    58 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@VicenteFoxHow shameless it was that your stepsons and your lagartona wife have benefited from Pemex and other corruption, beggar shits devils\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.81 ms /    16 runs   (    0.74 ms per token,  1354.78 tokens per second)\n",
            "llama_print_timings: prompt eval time =     278.14 ms /    76 tokens (    3.66 ms per token,   273.24 tokens per second)\n",
            "llama_print_timings:        eval time =    1773.25 ms /    15 runs   (  118.22 ms per token,     8.46 tokens per second)\n",
            "llama_print_timings:       total time =    2451.99 ms /    91 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "The Other, The Lover, The Hidden One, The Small House, The Husband Stealer, The Home Breaker, The Buscona, The Small Detail, The Lagartona sometimes they can fulfill their Fairy Tale ccp @weblade https://t.co/HsjnARIe1o\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.22 ms /    16 runs   (    0.58 ms per token,  1734.79 tokens per second)\n",
            "llama_print_timings: prompt eval time =     252.24 ms /    36 tokens (    7.01 ms per token,   142.72 tokens per second)\n",
            "llama_print_timings:        eval time =    1511.89 ms /    15 runs   (  100.79 ms per token,     9.92 tokens per second)\n",
            "llama_print_timings:       total time =    1906.37 ms /    51 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@PosaTres Blonde doesn't suit Gigi. It looks better on a lizard redhead brunette hahahaha.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.08 ms /    16 runs   (    0.57 ms per token,  1761.92 tokens per second)\n",
            "llama_print_timings: prompt eval time =     285.64 ms /    86 tokens (    3.32 ms per token,   301.08 tokens per second)\n",
            "llama_print_timings:        eval time =    1509.64 ms /    15 runs   (  100.64 ms per token,     9.94 tokens per second)\n",
            "llama_print_timings:       total time =    2040.77 ms /   101 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Are they going to study or are they going to gossip? If a teacher commits any improper act, it should be investigated and the complainants should be investigated. There are many lizards pretending to be dead. #Cuernavaca #Morelos #Jiutepec #Temixco https://t.co/iRgYeIrXAw\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.37 ms /    16 runs   (    0.59 ms per token,  1707.76 tokens per second)\n",
            "llama_print_timings: prompt eval time =     278.03 ms /    73 tokens (    3.81 ms per token,   262.56 tokens per second)\n",
            "llama_print_timings:        eval time =    1528.22 ms /    15 runs   (  101.88 ms per token,     9.82 tokens per second)\n",
            "llama_print_timings:       total time =    2026.58 ms /    88 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "I just finished the drawing that I will post tomorrow. Girls can't do this and don't do anything about it, first and last warning @LadyReahOfi @Christerva @terduki @Dangelisa @meieff this has only just begun 😈😈\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.27 ms /    16 runs   (    0.64 ms per token,  1558.69 tokens per second)\n",
            "llama_print_timings: prompt eval time =     272.75 ms /    59 tokens (    4.62 ms per token,   216.31 tokens per second)\n",
            "llama_print_timings:        eval time =    1683.26 ms /    15 runs   (  112.22 ms per token,     8.91 tokens per second)\n",
            "llama_print_timings:       total time =    2247.96 ms /    74 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "The worst thing is that after the tour they have a Japanese comeback, or BBC does something or we orbits have to get our act together and demand a good rest for the girls, because seriously, the girls can't continue overexerting themselves.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.73 ms /    16 runs   (    0.55 ms per token,  1833.39 tokens per second)\n",
            "llama_print_timings: prompt eval time =     258.15 ms /    58 tokens (    4.45 ms per token,   224.67 tokens per second)\n",
            "llama_print_timings:        eval time =    1482.30 ms /    15 runs   (   98.82 ms per token,    10.12 tokens per second)\n",
            "llama_print_timings:       total time =    1923.62 ms /    73 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@AnibalMortera Well, I feel offended because you said guys, what is it that girls can't respond to your Tweet? 🚩🚩🚩🚩🚩\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.12 ms /    16 runs   (    0.57 ms per token,  1754.58 tokens per second)\n",
            "llama_print_timings: prompt eval time =     240.22 ms /    40 tokens (    6.01 ms per token,   166.51 tokens per second)\n",
            "llama_print_timings:        eval time =    1614.51 ms /    15 runs   (  107.63 ms per token,     9.29 tokens per second)\n",
            "llama_print_timings:       total time =    2000.04 ms /    55 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "They are a very professional and high quality group, the girls couldn't be in better hands! https://t.co/R6eYvpiR07\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.85 ms /    16 runs   (    0.62 ms per token,  1624.70 tokens per second)\n",
            "llama_print_timings: prompt eval time =     278.80 ms /    73 tokens (    3.82 ms per token,   261.84 tokens per second)\n",
            "llama_print_timings:        eval time =    1541.89 ms /    15 runs   (  102.79 ms per token,     9.73 tokens per second)\n",
            "llama_print_timings:       total time =    2050.56 ms /    88 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Girls cannot play football in many schools in the United Kingdom because they can only do 'girls' sports. I found out when I had to substitute in Physical Education. I was amazed. 💪🏼 Very good initiative from the English players. https://t.co/NQQm7U62Fb\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.09 ms /    16 runs   (    0.57 ms per token,  1760.37 tokens per second)\n",
            "llama_print_timings: prompt eval time =     704.57 ms /    26 tokens (   27.10 ms per token,    36.90 tokens per second)\n",
            "llama_print_timings:        eval time =    1495.18 ms /    15 runs   (   99.68 ms per token,    10.03 tokens per second)\n",
            "llama_print_timings:       total time =    2317.40 ms /    41 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@adrianabravist6 Girls can't differentiate between discriminatory and descriptive\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.74 ms /    16 runs   (    0.55 ms per token,  1831.08 tokens per second)\n",
            "llama_print_timings: prompt eval time =     239.86 ms /    39 tokens (    6.15 ms per token,   162.59 tokens per second)\n",
            "llama_print_timings:        eval time =    1564.66 ms /    15 runs   (  104.31 ms per token,     9.59 tokens per second)\n",
            "llama_print_timings:       total time =    1960.82 ms /    54 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@DanannOficial you have to make a Sketch of what feminists think men's meetings are like and what it really is like... Hahahahaha\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.75 ms /    16 runs   (    0.67 ms per token,  1488.65 tokens per second)\n",
            "llama_print_timings: prompt eval time =     623.32 ms /    24 tokens (   25.97 ms per token,    38.50 tokens per second)\n",
            "llama_print_timings:        eval time =    1837.16 ms /    15 runs   (  122.48 ms per token,     8.16 tokens per second)\n",
            "llama_print_timings:       total time =    2606.59 ms /    39 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@laubenavidesg I love it when feminists attack a woman over a man.\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.90 ms /    16 runs   (    0.62 ms per token,  1615.35 tokens per second)\n",
            "llama_print_timings: prompt eval time =     295.96 ms /   113 tokens (    2.62 ms per token,   381.80 tokens per second)\n",
            "llama_print_timings:        eval time =    1606.46 ms /    15 runs   (  107.10 ms per token,     9.34 tokens per second)\n",
            "llama_print_timings:       total time =    2223.57 ms /   128 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@segoviag969 @EstherPedroche @Nievessebastia1 @madredecabrones @ElenaValenciano @carmencalvo_ @PSOE They have not been silent. You criticize them precisely because they have spoken, but you want them to tear up their cards. The PSOE feminists are not the enemy and it is certainly outrageous to say that they reinforce patriarchy. This is also reinforced by fundamentalism of any kind.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       2.98 ms /     5 runs   (    0.60 ms per token,  1678.42 tokens per second)\n",
            "llama_print_timings: prompt eval time =     264.54 ms /    74 tokens (    3.57 ms per token,   279.74 tokens per second)\n",
            "llama_print_timings:        eval time =     402.49 ms /     4 runs   (  100.62 ms per token,     9.94 tokens per second)\n",
            "llama_print_timings:       total time =     838.99 ms /    78 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Feminists take advantage of any shit to get into trouble, they don't understand that we are not getting involved with a woman, but with a position. For the same reasons, they must be fine with the despicable Boris Johnson's parties https://t.co/2f2xCl0i3V\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.26 ms /    16 runs   (    0.58 ms per token,  1728.61 tokens per second)\n",
            "llama_print_timings: prompt eval time =     254.76 ms /    82 tokens (    3.11 ms per token,   321.88 tokens per second)\n",
            "llama_print_timings:        eval time =    1536.49 ms /    15 runs   (  102.43 ms per token,     9.76 tokens per second)\n",
            "llama_print_timings:       total time =    2023.35 ms /    97 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "I don't see the Argentine feminists protesting for Mahsa Amini. I don't see the Argentine progressivity supporting the epic rebellion in which the Iranian people are bravely embarking against a theocratic, medieval, bloodthirsty and misogynistic dictatorship. The left and its double standard are disgusting.\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.08 ms /    16 runs   (    0.69 ms per token,  1444.56 tokens per second)\n",
            "llama_print_timings: prompt eval time =     289.17 ms /    84 tokens (    3.44 ms per token,   290.49 tokens per second)\n",
            "llama_print_timings:        eval time =    1701.78 ms /    15 runs   (  113.45 ms per token,     8.81 tokens per second)\n",
            "llama_print_timings:       total time =    2422.25 ms /    99 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "\"Wherever there is gender inequality, there is inequality in the laws. Wherever you see sexism, in your own daily life, in your private life. Don't let it go. In my own life, once I saw it, I never let it go pass\": Vivian Gornick 💜https://t.co/3x9Vssw9bP\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.38 ms /    16 runs   (    0.59 ms per token,  1705.03 tokens per second)\n",
            "llama_print_timings: prompt eval time =     274.60 ms /    69 tokens (    3.98 ms per token,   251.27 tokens per second)\n",
            "llama_print_timings:        eval time =    1554.69 ms /    15 runs   (  103.65 ms per token,     9.65 tokens per second)\n",
            "llama_print_timings:       total time =    2031.98 ms /    84 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@ericaasgg_ @Cobratate I like several things he says (not all of them) there are things I disagree with but he does say many times realistic things that no one says because women today want to see most of them like Kim kardashian and that shit about being lazy and worse\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.04 ms /    16 runs   (    0.63 ms per token,  1593.78 tokens per second)\n",
            "llama_print_timings: prompt eval time =     282.32 ms /    65 tokens (    4.34 ms per token,   230.24 tokens per second)\n",
            "llama_print_timings:        eval time =    1499.05 ms /    15 runs   (   99.94 ms per token,    10.01 tokens per second)\n",
            "llama_print_timings:       total time =    1986.55 ms /    80 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "woman: she does not have children because she cannot balance work/family life or due to economic instabilitypeople: women today are selfish, they prefer to travel and party than have children mothernophobia blablabla https://t.co/iyMWG3OArH\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.06 ms /    16 runs   (    0.69 ms per token,  1446.52 tokens per second)\n",
            "llama_print_timings: prompt eval time =     286.47 ms /    71 tokens (    4.03 ms per token,   247.85 tokens per second)\n",
            "llama_print_timings:        eval time =    1750.63 ms /    15 runs   (  116.71 ms per token,     8.57 tokens per second)\n",
            "llama_print_timings:       total time =    2263.68 ms /    86 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Above all, unsubmissive... well, she is a totally valid and independent woman... what women are today, despite the sinister Montero. This dictator does not allow anyone to make him see that he is wrong and contradict him. https://t.co/cURGFnO6wc\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.63 ms /    16 runs   (    0.60 ms per token,  1661.99 tokens per second)\n",
            "llama_print_timings: prompt eval time =     259.59 ms /    49 tokens (    5.30 ms per token,   188.76 tokens per second)\n",
            "llama_print_timings:        eval time =    1588.95 ms /    15 runs   (  105.93 ms per token,     9.44 tokens per second)\n",
            "llama_print_timings:       total time =    2012.59 ms /    64 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@interiorgob @guardiacivil Olazas that uterus carriers or modern-day women like these will opt for? https://t.co/rXQ2ZwZBTg\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.73 ms /    16 runs   (    0.55 ms per token,  1833.18 tokens per second)\n",
            "llama_print_timings: prompt eval time =     672.15 ms /    26 tokens (   25.85 ms per token,    38.68 tokens per second)\n",
            "llama_print_timings:        eval time =    1486.09 ms /    15 runs   (   99.07 ms per token,    10.09 tokens per second)\n",
            "llama_print_timings:       total time =    2277.79 ms /    41 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "AJSHAHAHAHAHA but whateeee happens to women today? 😂😂😂\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.81 ms /    16 runs   (    0.61 ms per token,  1630.49 tokens per second)\n",
            "llama_print_timings: prompt eval time =     265.77 ms /    61 tokens (    4.36 ms per token,   229.52 tokens per second)\n",
            "llama_print_timings:        eval time =    1523.19 ms /    15 runs   (  101.55 ms per token,     9.85 tokens per second)\n",
            "llama_print_timings:       total time =    1984.82 ms /    76 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@natiibedoya @smilelalis Have women today not burned down churches \"fighting\" for equality? The bullying was started by that cachalte...that suck. https://t.co/S9788rDFoA\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.34 ms /    16 runs   (    0.65 ms per token,  1548.14 tokens per second)\n",
            "llama_print_timings: prompt eval time =     297.97 ms /   106 tokens (    2.81 ms per token,   355.74 tokens per second)\n",
            "llama_print_timings:        eval time =    1539.77 ms /    15 runs   (  102.65 ms per token,     9.74 tokens per second)\n",
            "llama_print_timings:       total time =    2143.83 ms /   121 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@javitagracia @thezampah @terfforever @bcscienceiscool Are you medicated? Don't you understand that given the VULNERABILITY of the FEMALE SEX, Women SHOULD NOT BE MIXED WITH PEOPLE OF THE MALE SEX precisely to PREVENT ABUSE AND RAPE??? What's on your mind? Are you a defender of feelings instead of REALITIES???\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.09 ms /    16 runs   (    0.57 ms per token,  1761.14 tokens per second)\n",
            "llama_print_timings: prompt eval time =     281.75 ms /    73 tokens (    3.86 ms per token,   259.09 tokens per second)\n",
            "llama_print_timings:        eval time =    1609.97 ms /    15 runs   (  107.33 ms per token,     9.32 tokens per second)\n",
            "llama_print_timings:       total time =    2104.72 ms /    88 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Freedom of expression has limits, if you don't want to understand it, it's not our problem. It is not freedom of expression to say, for example, that I hate black people, that women should not work, among other things, do not try to make a victim of the person who is the complete opposite.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.22 ms /    16 runs   (    0.58 ms per token,  1736.11 tokens per second)\n",
            "llama_print_timings: prompt eval time =     255.51 ms /    56 tokens (    4.56 ms per token,   219.17 tokens per second)\n",
            "llama_print_timings:        eval time =    1640.63 ms /    15 runs   (  109.38 ms per token,     9.14 tokens per second)\n",
            "llama_print_timings:       total time =    2074.80 ms /    71 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "For a couple of months I have been living an experience that has allowed me to reaffirm my decision not to be a mother and has made me respect those who play that role even more. In short, women should not be forced to become mothers.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.92 ms /    16 runs   (    0.56 ms per token,  1793.12 tokens per second)\n",
            "llama_print_timings: prompt eval time =     606.12 ms /    32 tokens (   18.94 ms per token,    52.79 tokens per second)\n",
            "llama_print_timings:        eval time =    1598.70 ms /    15 runs   (  106.58 ms per token,     9.38 tokens per second)\n",
            "llama_print_timings:       total time =    2379.64 ms /    47 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Women should not waste time forgiving men because when the roles are reversed, men actually protect their peace and put themselves first.\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.33 ms /    16 runs   (    0.58 ms per token,  1714.90 tokens per second)\n",
            "llama_print_timings: prompt eval time =     288.54 ms /    85 tokens (    3.39 ms per token,   294.59 tokens per second)\n",
            "llama_print_timings:        eval time =    1513.41 ms /    15 runs   (  100.89 ms per token,     9.91 tokens per second)\n",
            "llama_print_timings:       total time =    2044.41 ms /   100 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@JB_Lenoir @frannn34 @diagoabiel @CLMerlo You must be the typical one who thinks that because there are rapists in the streets, women should not go out in skirts on the street. A sexist idiot who doesn't know he's sexist. Or he knows it and wants to hide it. One of two.\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.94 ms /    16 runs   (    0.56 ms per token,  1789.11 tokens per second)\n",
            "llama_print_timings: prompt eval time =     582.91 ms /    32 tokens (   18.22 ms per token,    54.90 tokens per second)\n",
            "llama_print_timings:        eval time =    1519.94 ms /    15 runs   (  101.33 ms per token,     9.87 tokens per second)\n",
            "llama_print_timings:       total time =    2246.96 ms /    47 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "“Women should NOT look muscular like a man” https://t.co/aJ527yDAWo\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.79 ms /    16 runs   (    0.61 ms per token,  1633.65 tokens per second)\n",
            "llama_print_timings: prompt eval time =     281.93 ms /    88 tokens (    3.20 ms per token,   312.13 tokens per second)\n",
            "llama_print_timings:        eval time =    1628.91 ms /    15 runs   (  108.59 ms per token,     9.21 tokens per second)\n",
            "llama_print_timings:       total time =    2165.05 ms /   103 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@SheldonEXastor These miserable rats are causing... We are outraged and we beat them up on RRSS... They manage to get on the agenda and get us to talk about them. I wouldn't be surprised if they end up declaring that women shouldn't vote, and we'll take the bait again. The background: attention 🤬🤡\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.06 ms /    16 runs   (    0.57 ms per token,  1765.81 tokens per second)\n",
            "llama_print_timings: prompt eval time =     255.78 ms /    40 tokens (    6.39 ms per token,   156.38 tokens per second)\n",
            "llama_print_timings:        eval time =    1598.46 ms /    15 runs   (  106.56 ms per token,     9.38 tokens per second)\n",
            "llama_print_timings:       total time =    1997.72 ms /    55 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@LauraMex This guy is violent with women. They shouldn't leave it in Image. #GustavoAdolfoInfante @ImagenTVMex\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.41 ms /    16 runs   (    0.65 ms per token,  1536.69 tokens per second)\n",
            "llama_print_timings: prompt eval time =     271.52 ms /    68 tokens (    3.99 ms per token,   250.44 tokens per second)\n",
            "llama_print_timings:        eval time =    1634.68 ms /    15 runs   (  108.98 ms per token,     9.18 tokens per second)\n",
            "llama_print_timings:       total time =    2125.93 ms /    83 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Alberto_Fallen yes but that depends on your perception too. Remember that in the end they are matters of opinion, obviously if I say that women should not be protagonists of films, it is clear the type of person I am. but there are comments that remain in the gray and are condemned\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.26 ms /    16 runs   (    0.58 ms per token,  1728.61 tokens per second)\n",
            "llama_print_timings: prompt eval time =     639.24 ms /    22 tokens (   29.06 ms per token,    34.42 tokens per second)\n",
            "llama_print_timings:        eval time =    1496.61 ms /    15 runs   (   99.77 ms per token,    10.02 tokens per second)\n",
            "llama_print_timings:       total time =    2253.51 ms /    37 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@europapress Women should not even have the right to have their own phones.\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.38 ms /    16 runs   (    0.59 ms per token,  1706.48 tokens per second)\n",
            "llama_print_timings: prompt eval time =     244.56 ms /    55 tokens (    4.45 ms per token,   224.89 tokens per second)\n",
            "llama_print_timings:        eval time =    1555.63 ms /    15 runs   (  103.71 ms per token,     9.64 tokens per second)\n",
            "llama_print_timings:       total time =    1983.50 ms /    70 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "What a stress the \"high value\" girls on tiktok wn because they keep appearing to me JAJDKDJ like they force me to say that all women should not pay a single peso in a relationship that is cool\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.83 ms /    16 runs   (    0.61 ms per token,  1627.34 tokens per second)\n",
            "llama_print_timings: prompt eval time =     282.15 ms /    75 tokens (    3.76 ms per token,   265.82 tokens per second)\n",
            "llama_print_timings:        eval time =    1517.08 ms /    15 runs   (  101.14 ms per token,     9.89 tokens per second)\n",
            "llama_print_timings:       total time =    2013.20 ms /    90 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "They have no right to tell women how to dress, much less \"teach\" them by beating... it makes me very helpless to see these types of cases, women should not die for the simple fact of not following moral rules imposed by men, they They deserve to be free https://t.co/ecKl4HO4VX\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.17 ms /    16 runs   (    0.64 ms per token,  1573.56 tokens per second)\n",
            "llama_print_timings: prompt eval time =     237.04 ms /    34 tokens (    6.97 ms per token,   143.44 tokens per second)\n",
            "llama_print_timings:        eval time =    1827.07 ms /    15 runs   (  121.80 ms per token,     8.21 tokens per second)\n",
            "llama_print_timings:       total time =    2228.47 ms /    49 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@NotRuka Women don't know how to write scripts, finally https://t.co/1mKygduTzy\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.05 ms /    16 runs   (    0.57 ms per token,  1767.76 tokens per second)\n",
            "llama_print_timings: prompt eval time =     247.84 ms /    43 tokens (    5.76 ms per token,   173.50 tokens per second)\n",
            "llama_print_timings:        eval time =    1643.77 ms /    15 runs   (  109.58 ms per token,     9.13 tokens per second)\n",
            "llama_print_timings:       total time =    2041.11 ms /    58 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Women don't know what us guys suffer after the handjob HAHAHA the world is coming to you https://t.co/aC03q30Sdz\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.29 ms /    16 runs   (    0.58 ms per token,  1721.73 tokens per second)\n",
            "llama_print_timings: prompt eval time =     255.23 ms /    46 tokens (    5.55 ms per token,   180.23 tokens per second)\n",
            "llama_print_timings:        eval time =    1599.53 ms /    15 runs   (  106.64 ms per token,     9.38 tokens per second)\n",
            "llama_print_timings:       total time =    2016.66 ms /    61 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "BECAUSE OF MAJORS LIKE YOU THEY MAKE YOU BELIEVE THAT WOMEN DON'T KNOW ABOUT FOOTBALL, ASSHOLE\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.00 ms /    16 runs   (    0.56 ms per token,  1777.19 tokens per second)\n",
            "llama_print_timings: prompt eval time =     258.10 ms /    52 tokens (    4.96 ms per token,   201.48 tokens per second)\n",
            "llama_print_timings:        eval time =    1634.52 ms /    15 runs   (  108.97 ms per token,     9.18 tokens per second)\n",
            "llama_print_timings:       total time =    2072.12 ms /    67 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@bufanogero all kids answer you, that's because women don't know how to truly appreciate beauty and true men like you can only appreciate it as peers like us who know well what a gentleman should be like.\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.33 ms /    16 runs   (    0.65 ms per token,  1548.44 tokens per second)\n",
            "llama_print_timings: prompt eval time =     255.14 ms /    40 tokens (    6.38 ms per token,   156.78 tokens per second)\n",
            "llama_print_timings:        eval time =    1838.64 ms /    15 runs   (  122.58 ms per token,     8.16 tokens per second)\n",
            "llama_print_timings:       total time =    2278.30 ms /    55 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "1 women don't know how to chamuyar 2 pretty ones don't need it https://t.co/4WymRE4D0u\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.97 ms /    16 runs   (    0.56 ms per token,  1784.12 tokens per second)\n",
            "llama_print_timings: prompt eval time =     618.70 ms /    22 tokens (   28.12 ms per token,    35.56 tokens per second)\n",
            "llama_print_timings:        eval time =    1550.37 ms /    15 runs   (  103.36 ms per token,     9.68 tokens per second)\n",
            "llama_print_timings:       total time =    2281.65 ms /    37 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Santy_Calfu Women do not know how to value good men\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       2.92 ms /     5 runs   (    0.58 ms per token,  1711.16 tokens per second)\n",
            "llama_print_timings: prompt eval time =     283.31 ms /   102 tokens (    2.78 ms per token,   360.03 tokens per second)\n",
            "llama_print_timings:        eval time =     467.36 ms /     4 runs   (  116.84 ms per token,     8.56 tokens per second)\n",
            "llama_print_timings:       total time =    1000.67 ms /   106 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Hey @searsmexico... What's wrong with your language... men are UNIVERSITY GUYS while women are YOUNG GIRLS... #machismo #machistapublicity #micromachismos #girlpower I share this art with you, if it looks cool the other way around, ask your market manly if that makes sense to you. https://t.co/k9z5gsPPNU\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.29 ms /    16 runs   (    0.52 ms per token,  1931.20 tokens per second)\n",
            "llama_print_timings: prompt eval time =     227.38 ms /    37 tokens (    6.15 ms per token,   162.72 tokens per second)\n",
            "llama_print_timings:        eval time =    1433.34 ms /    15 runs   (   95.56 ms per token,    10.47 tokens per second)\n",
            "llama_print_timings:       total time =    1801.08 ms /    52 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "All women are perverts in the right hands, but not all men are the right ones, not all hands have magic. Vogard Pastelin F.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.37 ms /    16 runs   (    0.65 ms per token,  1543.66 tokens per second)\n",
            "llama_print_timings: prompt eval time =     257.99 ms /    72 tokens (    3.58 ms per token,   279.08 tokens per second)\n",
            "llama_print_timings:        eval time =    1667.38 ms /    15 runs   (  111.16 ms per token,     9.00 tokens per second)\n",
            "llama_print_timings:       total time =    2144.06 ms /    87 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@AntoniramonMol1 @DanyDani3l @COTESFERRO @luisagoenaga1 Women are simple beings if you only want them for sex, pay them and that's it, but yes, it does good because otherwise they block you or start treating you as a \"friend\"\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.82 ms /    16 runs   (    0.55 ms per token,  1813.24 tokens per second)\n",
            "llama_print_timings: prompt eval time =     847.69 ms /    26 tokens (   32.60 ms per token,    30.67 tokens per second)\n",
            "llama_print_timings:        eval time =    1461.59 ms /    15 runs   (   97.44 ms per token,    10.26 tokens per second)\n",
            "llama_print_timings:       total time =    2471.74 ms /    41 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Mood: excitedBut that doesn't mean I'm going to say that women are the worst\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.83 ms /    16 runs   (    0.55 ms per token,  1811.39 tokens per second)\n",
            "llama_print_timings: prompt eval time =     259.27 ms /    43 tokens (    6.03 ms per token,   165.85 tokens per second)\n",
            "llama_print_timings:        eval time =    1544.95 ms /    15 runs   (  103.00 ms per token,     9.71 tokens per second)\n",
            "llama_print_timings:       total time =    1960.10 ms /    58 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "All wrong! 🥲 | Women are the main victims of modern slavery in the mining areas of Venezuela | https://t.co/WV2lVrehbi\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.29 ms /    16 runs   (    0.58 ms per token,  1721.36 tokens per second)\n",
            "llama_print_timings: prompt eval time =     250.75 ms /    49 tokens (    5.12 ms per token,   195.41 tokens per second)\n",
            "llama_print_timings:        eval time =    1543.52 ms /    15 runs   (  102.90 ms per token,     9.72 tokens per second)\n",
            "llama_print_timings:       total time =    1957.54 ms /    64 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@samuel_arqui @PedroHe64552161 @MexicoLGBTTTI I think so, as women are also the ones who support women the least…\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.94 ms /    16 runs   (    0.62 ms per token,  1609.98 tokens per second)\n",
            "llama_print_timings: prompt eval time =     258.39 ms /    51 tokens (    5.07 ms per token,   197.37 tokens per second)\n",
            "llama_print_timings:        eval time =    1513.28 ms /    15 runs   (  100.89 ms per token,     9.91 tokens per second)\n",
            "llama_print_timings:       total time =    1937.40 ms /    66 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Yes, you would be surprised. I always wanted to practice some but my grandmother wouldn't let me. She said that the ladies didn't kick. https://t.co/8hH7qvBPok\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.70 ms /    16 runs   (    0.54 ms per token,  1838.45 tokens per second)\n",
            "llama_print_timings: prompt eval time =     588.12 ms /    32 tokens (   18.38 ms per token,    54.41 tokens per second)\n",
            "llama_print_timings:        eval time =    1450.88 ms /    15 runs   (   96.73 ms per token,    10.34 tokens per second)\n",
            "llama_print_timings:       total time =    2174.87 ms /    47 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "- Mom at school they say you're bullshitting me. - Who? - The ladies - No, who asked you?\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.24 ms /    16 runs   (    0.58 ms per token,  1732.16 tokens per second)\n",
            "llama_print_timings: prompt eval time =     255.03 ms /    49 tokens (    5.20 ms per token,   192.14 tokens per second)\n",
            "llama_print_timings:        eval time =    1596.69 ms /    15 runs   (  106.45 ms per token,     9.39 tokens per second)\n",
            "llama_print_timings:       total time =    2018.83 ms /    64 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Thegirlins Aimed!!! Likewise, the ladies don't eat arugula and only Bamboo likes lamb's lettuce, but we will try it 😂💙\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.09 ms /    16 runs   (    0.69 ms per token,  1443.26 tokens per second)\n",
            "llama_print_timings: prompt eval time =     259.46 ms /    37 tokens (    7.01 ms per token,   142.61 tokens per second)\n",
            "llama_print_timings:        eval time =    1722.49 ms /    15 runs   (  114.83 ms per token,     8.71 tokens per second)\n",
            "llama_print_timings:       total time =    2214.97 ms /    52 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "The ladies can't deal with Iran, kids; It takes time to take care of succulents, buy faso and look for clone recipes.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.40 ms /    16 runs   (    0.59 ms per token,  1702.67 tokens per second)\n",
            "llama_print_timings: prompt eval time =     271.99 ms /    70 tokens (    3.89 ms per token,   257.36 tokens per second)\n",
            "llama_print_timings:        eval time =    1632.43 ms /    15 runs   (  108.83 ms per token,     9.19 tokens per second)\n",
            "llama_print_timings:       total time =    2114.68 ms /    85 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Since you managed to divert the focus from #VildaOUT, could you tell me if the ladies, I'm not puppets, are going to referee the second date https://t.co/XxEJgADo59 https://t.co/mQml9zwEWq\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       2.75 ms /     5 runs   (    0.55 ms per token,  1816.20 tokens per second)\n",
            "llama_print_timings: prompt eval time =     289.81 ms /    81 tokens (    3.58 ms per token,   279.49 tokens per second)\n",
            "llama_print_timings:        eval time =     474.40 ms /     4 runs   (  118.60 ms per token,     8.43 tokens per second)\n",
            "llama_print_timings:       total time =     953.42 ms /    85 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "She slaps him—The ladies don't shout or say bad words. Don't you see that I'm doing this for your own good? You won't find any man in your life who loves you if you're that big-mouthed. You have to be helpful to the man. Be there for him at all timesClick your tongue+\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.57 ms /    16 runs   (    0.66 ms per token,  1513.86 tokens per second)\n",
            "llama_print_timings: prompt eval time =     249.28 ms /    68 tokens (    3.67 ms per token,   272.78 tokens per second)\n",
            "llama_print_timings:        eval time =    1665.25 ms /    15 runs   (  111.02 ms per token,     9.01 tokens per second)\n",
            "llama_print_timings:       total time =    2137.49 ms /    83 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "It makes me laugh that in Mexico they take out the RAE for everything, not even the Spanish respect it that much, I have met people who believe that in Latin America they had some independent academy 🙄. Use inclusive language if you want, the RAE doesn't even know who they are.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.25 ms /    16 runs   (    0.58 ms per token,  1729.17 tokens per second)\n",
            "llama_print_timings: prompt eval time =     705.28 ms /    27 tokens (   26.12 ms per token,    38.28 tokens per second)\n",
            "llama_print_timings:        eval time =    1468.13 ms /    15 runs   (   97.88 ms per token,    10.22 tokens per second)\n",
            "llama_print_timings:       total time =    2296.58 ms /    42 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "There are more people using inclusive language as a joke than with the intention of integrating it into the language.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.98 ms /    16 runs   (    0.56 ms per token,  1781.94 tokens per second)\n",
            "llama_print_timings: prompt eval time =     237.08 ms /    34 tokens (    6.97 ms per token,   143.41 tokens per second)\n",
            "llama_print_timings:        eval time =    1537.65 ms /    15 runs   (  102.51 ms per token,     9.76 tokens per second)\n",
            "llama_print_timings:       total time =    1912.88 ms /    49 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@davidrianov Someone who says 'all' deserves to be a contractor for much longer, what a visual cancer inclusive language is.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.55 ms /    16 runs   (    0.53 ms per token,  1870.25 tokens per second)\n",
            "llama_print_timings: prompt eval time =     517.79 ms /    19 tokens (   27.25 ms per token,    36.69 tokens per second)\n",
            "llama_print_timings:        eval time =    1636.43 ms /    15 runs   (  109.10 ms per token,     9.17 tokens per second)\n",
            "llama_print_timings:       total time =    2256.28 ms /    34 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@LaInsolenta I love seeing heteres collapse because of inclusive language\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.29 ms /    16 runs   (    0.71 ms per token,  1417.81 tokens per second)\n",
            "llama_print_timings: prompt eval time =     264.90 ms /    58 tokens (    4.57 ms per token,   218.95 tokens per second)\n",
            "llama_print_timings:        eval time =    1710.96 ms /    15 runs   (  114.06 ms per token,     8.77 tokens per second)\n",
            "llama_print_timings:       total time =    2196.43 ms /    73 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@luchofigo1742 @Vengador2100 Just because custom normalizes its use does not mean that it is okay, same case of inclusive language (everyone for example), printed is another example, words that damage the language\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.30 ms /    16 runs   (    0.58 ms per token,  1720.62 tokens per second)\n",
            "llama_print_timings: prompt eval time =     253.84 ms /    35 tokens (    7.25 ms per token,   137.88 tokens per second)\n",
            "llama_print_timings:        eval time =    1613.31 ms /    15 runs   (  107.55 ms per token,     9.30 tokens per second)\n",
            "llama_print_timings:       total time =    2006.65 ms /    50 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@_VicenteViloni VICENTE VILONI USING INCLUSIVE LANGUAGE TOTAL CRACK\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.14 ms /    16 runs   (    0.57 ms per token,  1751.31 tokens per second)\n",
            "llama_print_timings: prompt eval time =     555.32 ms /    32 tokens (   17.35 ms per token,    57.62 tokens per second)\n",
            "llama_print_timings:        eval time =    1566.06 ms /    15 runs   (  104.40 ms per token,     9.58 tokens per second)\n",
            "llama_print_timings:       total time =    2262.12 ms /    47 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@LaLaithYagami https://t.co/3h4smCeTIo I send a hug from a distance\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.88 ms /    16 runs   (    0.56 ms per token,  1801.19 tokens per second)\n",
            "llama_print_timings: prompt eval time =     753.53 ms /    29 tokens (   25.98 ms per token,    38.49 tokens per second)\n",
            "llama_print_timings:        eval time =    1480.24 ms /    15 runs   (   98.68 ms per token,    10.13 tokens per second)\n",
            "llama_print_timings:       total time =    2360.05 ms /    44 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Don't gaslight someone who overthinks things a lot, because you're not going to achieve anything.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.08 ms /    16 runs   (    0.69 ms per token,  1444.56 tokens per second)\n",
            "llama_print_timings: prompt eval time =     286.50 ms /    71 tokens (    4.04 ms per token,   247.82 tokens per second)\n",
            "llama_print_timings:        eval time =    1764.10 ms /    15 runs   (  117.61 ms per token,     8.50 tokens per second)\n",
            "llama_print_timings:       total time =    2428.74 ms /    86 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@adrian_cordoba7 @SoyUnMitoGenia1 @Shine_McShine Much would have to be erased from historical memories and signed by the Pope and others. It would be like saying now that the Berlin Wall did not exist. A very large gas light would have to be installed.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.89 ms /    16 runs   (    0.62 ms per token,  1618.45 tokens per second)\n",
            "llama_print_timings: prompt eval time =     267.83 ms /    67 tokens (    4.00 ms per token,   250.16 tokens per second)\n",
            "llama_print_timings:        eval time =    1666.10 ms /    15 runs   (  111.07 ms per token,     9.00 tokens per second)\n",
            "llama_print_timings:       total time =    2138.67 ms /    82 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@BrujaPiruja1234 @Vanessa_Naveira I have asked you where he laughed, as you say, I have already explained to you that he has not denied the obvious link but the 'magical' link and am I the one who gaslights? Oh\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.91 ms /    16 runs   (    0.56 ms per token,  1796.14 tokens per second)\n",
            "llama_print_timings: prompt eval time =     261.52 ms /    45 tokens (    5.81 ms per token,   172.07 tokens per second)\n",
            "llama_print_timings:        eval time =    1546.23 ms /    15 runs   (  103.08 ms per token,     9.70 tokens per second)\n",
            "llama_print_timings:       total time =    1962.61 ms /    60 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Not everything is misinformation, obstetric violence by professionals exists and denying it and wanting to make those who have experienced it question their experience is gaslighting like a piano. End of matter.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.27 ms /    16 runs   (    0.58 ms per token,  1726.93 tokens per second)\n",
            "llama_print_timings: prompt eval time =     270.89 ms /    90 tokens (    3.01 ms per token,   332.23 tokens per second)\n",
            "llama_print_timings:        eval time =    1473.28 ms /    15 runs   (   98.22 ms per token,    10.18 tokens per second)\n",
            "llama_print_timings:       total time =    2002.28 ms /   105 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@salvameoficial @BelenEstebanM Lidia looks like the old lady of the Simson cats. She falls asleep from the night's hangover and when she wakes up she comes out screaming yes, Princess Leonor, yes, the gas light... When what is being talked about? It's from Paquirrin kicking the girl in the audience hahahahahaha\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.81 ms /    16 runs   (    0.68 ms per token,  1479.56 tokens per second)\n",
            "llama_print_timings: prompt eval time =     261.05 ms /    60 tokens (    4.35 ms per token,   229.84 tokens per second)\n",
            "llama_print_timings:        eval time =    1780.61 ms /    15 runs   (  118.71 ms per token,     8.42 tokens per second)\n",
            "llama_print_timings:       total time =    2357.80 ms /    75 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@CatalinaSuarezB It's not machismo, it's that the minister doesn't help herself. When she doesn't screw up, her ambiguous and unfocused statements leave the impression that that purse is too big for her.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.09 ms /    16 runs   (    0.57 ms per token,  1760.18 tokens per second)\n",
            "llama_print_timings: prompt eval time =     289.42 ms /    80 tokens (    3.62 ms per token,   276.42 tokens per second)\n",
            "llama_print_timings:        eval time =    1514.62 ms /    15 runs   (  100.97 ms per token,     9.90 tokens per second)\n",
            "llama_print_timings:       total time =    2045.76 ms /    95 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@MafeCarrascal Unlearning this you with your problems, the reality is that you see machismo where it does not exist, classism where there is none, racism and structural problems that you use in the campaign... Today you do not use them and you want to correct them 🤣🤣🤣typical hypocritical dynamic of the politician🤣🤣🤣\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.50 ms /    16 runs   (    0.53 ms per token,  1881.47 tokens per second)\n",
            "llama_print_timings: prompt eval time =     777.25 ms /    31 tokens (   25.07 ms per token,    39.88 tokens per second)\n",
            "llama_print_timings:        eval time =    1446.23 ms /    15 runs   (   96.42 ms per token,    10.37 tokens per second)\n",
            "llama_print_timings:       total time =    2361.08 ms /    46 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@veintimillapier What if my dog ​​says yes? And with enthusiasm. That's dog machismo\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.54 ms /    16 runs   (    0.72 ms per token,  1386.12 tokens per second)\n",
            "llama_print_timings: prompt eval time =     288.65 ms /    87 tokens (    3.32 ms per token,   301.40 tokens per second)\n",
            "llama_print_timings:        eval time =    1814.12 ms /    15 runs   (  120.94 ms per token,     8.27 tokens per second)\n",
            "llama_print_timings:       total time =    2530.58 ms /   102 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@RCalasich @hermanntertsch Basically they are telling you that men harass you with their compliments, with their family protection or their machismo just because of what they have between their legs, but feminism can walk its clam, toto, chumino wherever it wants damn \"with your\" 20,000,000,000.\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.24 ms /    16 runs   (    0.58 ms per token,  1731.23 tokens per second)\n",
            "llama_print_timings: prompt eval time =     251.16 ms /    44 tokens (    5.71 ms per token,   175.19 tokens per second)\n",
            "llama_print_timings:        eval time =    1506.68 ms /    15 runs   (  100.45 ms per token,     9.96 tokens per second)\n",
            "llama_print_timings:       total time =    1913.48 ms /    59 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Pay attention to your children, so that they do not grow up believing that wearing a skirt “removes” machismo. https://t.co/04I6uEQEsw\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.43 ms /    16 runs   (    0.59 ms per token,  1696.89 tokens per second)\n",
            "llama_print_timings: prompt eval time =     261.67 ms /    60 tokens (    4.36 ms per token,   229.30 tokens per second)\n",
            "llama_print_timings:        eval time =    1589.19 ms /    15 runs   (  105.95 ms per token,     9.44 tokens per second)\n",
            "llama_print_timings:       total time =    2035.14 ms /    75 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@patovt Thanks Pato, in fact we tried to bring Barmaids Map to Spain at the beginning of this year but we found little receptivity to these and other topics, the scene was super fragmented and a lot of machismo even among women.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.11 ms /    16 runs   (    0.57 ms per token,  1757.28 tokens per second)\n",
            "llama_print_timings: prompt eval time =     288.41 ms /    92 tokens (    3.13 ms per token,   318.99 tokens per second)\n",
            "llama_print_timings:        eval time =    1546.07 ms /    15 runs   (  103.07 ms per token,     9.70 tokens per second)\n",
            "llama_print_timings:       total time =    2089.31 ms /   107 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@chanuwu22 @salmiaux @heartlessmedusa @Gise1393 @lightupmmylife that's why whenever a (feminist) woman says something stupid, she's going to say that it's \"mansplaining\" and that anyone who contradicts them is a fool and that's it, they stay so cool without needing to support their stupidity.\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      13.39 ms /    16 runs   (    0.84 ms per token,  1194.56 tokens per second)\n",
            "llama_print_timings: prompt eval time =     258.00 ms /    41 tokens (    6.29 ms per token,   158.92 tokens per second)\n",
            "llama_print_timings:        eval time =    1822.26 ms /    15 runs   (  121.48 ms per token,     8.23 tokens per second)\n",
            "llama_print_timings:       total time =    2343.16 ms /    56 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Uber is mansplaining me about life because I told him I studied Law and he told me that he knew more than me because he studied \"Criminal Justice\"\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.88 ms /    16 runs   (    0.55 ms per token,  1802.41 tokens per second)\n",
            "llama_print_timings: prompt eval time =     602.48 ms /    24 tokens (   25.10 ms per token,    39.84 tokens per second)\n",
            "llama_print_timings:        eval time =    1466.80 ms /    15 runs   (   97.79 ms per token,    10.23 tokens per second)\n",
            "llama_print_timings:       total time =    2186.57 ms /    39 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Today I discovered that straight men mansplaining among themselves HAHA how I hate them\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.39 ms /    16 runs   (    0.52 ms per token,  1906.80 tokens per second)\n",
            "llama_print_timings: prompt eval time =     246.78 ms /    37 tokens (    6.67 ms per token,   149.93 tokens per second)\n",
            "llama_print_timings:        eval time =    1588.14 ms /    15 runs   (  105.88 ms per token,     9.44 tokens per second)\n",
            "llama_print_timings:       total time =    1977.13 ms /    52 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "I'm sorry for all the mansplaining from an inge at my work, I'm already very warm for the metrorrey session today\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.57 ms /    16 runs   (    0.54 ms per token,  1867.85 tokens per second)\n",
            "llama_print_timings: prompt eval time =     708.91 ms /    26 tokens (   27.27 ms per token,    36.68 tokens per second)\n",
            "llama_print_timings:        eval time =    1480.89 ms /    15 runs   (   98.73 ms per token,    10.13 tokens per second)\n",
            "llama_print_timings:       total time =    2305.25 ms /    41 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Do men never get tired of mansplaining about absolutely everything? Well, how lazy some people are\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.90 ms /    16 runs   (    0.62 ms per token,  1616.81 tokens per second)\n",
            "llama_print_timings: prompt eval time =     306.35 ms /   106 tokens (    2.89 ms per token,   346.01 tokens per second)\n",
            "llama_print_timings:        eval time =    1493.13 ms /    15 runs   (   99.54 ms per token,    10.05 tokens per second)\n",
            "llama_print_timings:       total time =    2097.25 ms /   121 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@tefahernandez16 @ChefDSanmartin @charovargas_ How many times has our proofreader changed the words and because we were in a hurry we have not realized it or we have simply made a mistake!? In your case, it not only corrects you but also demonstrates how to do it: \"Mansplaining\"! He didn't give his opinion on the abortion, he questioned your spelling...🤦🏻‍♀️\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.26 ms /    16 runs   (    0.58 ms per token,  1727.30 tokens per second)\n",
            "llama_print_timings: prompt eval time =     751.72 ms /    29 tokens (   25.92 ms per token,    38.58 tokens per second)\n",
            "llama_print_timings:        eval time =    1463.12 ms /    15 runs   (   97.54 ms per token,    10.25 tokens per second)\n",
            "llama_print_timings:       total time =    2339.87 ms /    44 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Sit next to a manspreading man so that he does not occupy two places with his legs, check\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.87 ms /    16 runs   (    0.55 ms per token,  1803.22 tokens per second)\n",
            "llama_print_timings: prompt eval time =     239.17 ms /    35 tokens (    6.83 ms per token,   146.34 tokens per second)\n",
            "llama_print_timings:        eval time =    1475.92 ms /    15 runs   (   98.39 ms per token,    10.16 tokens per second)\n",
            "llama_print_timings:       total time =    1851.08 ms /    50 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Since I saw the tiktok of the girl spreading her legs also when someone next to her was manspreading I have taken on that personality\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.18 ms /    16 runs   (    0.70 ms per token,  1431.51 tokens per second)\n",
            "llama_print_timings: prompt eval time =     247.91 ms /    54 tokens (    4.59 ms per token,   217.83 tokens per second)\n",
            "llama_print_timings:        eval time =    1760.15 ms /    15 runs   (  117.34 ms per token,     8.52 tokens per second)\n",
            "llama_print_timings:       total time =    2207.66 ms /    69 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "THIS IS FEMINISM. I encourage feminists who are complaining about 'manspreading' in Spain to go to Iran to support those who are really fighting. https://t.co/oJ8UTCVtOS\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.08 ms /    16 runs   (    0.57 ms per token,  1762.11 tokens per second)\n",
            "llama_print_timings: prompt eval time =     250.71 ms /    33 tokens (    7.60 ms per token,   131.63 tokens per second)\n",
            "llama_print_timings:        eval time =    1480.01 ms /    15 runs   (   98.67 ms per token,    10.14 tokens per second)\n",
            "llama_print_timings:       total time =    1862.50 ms /    48 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Sorry but you are not manspreading. It has been deconstructed https://t.co/byPL72PNMB\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.60 ms /    16 runs   (    0.54 ms per token,  1860.25 tokens per second)\n",
            "llama_print_timings: prompt eval time =     601.99 ms /    23 tokens (   26.17 ms per token,    38.21 tokens per second)\n",
            "llama_print_timings:        eval time =    1557.80 ms /    15 runs   (  103.85 ms per token,     9.63 tokens per second)\n",
            "llama_print_timings:       total time =    2277.82 ms /    38 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "I was thinking about the pants torn by the bike, silently fighting the manspreading\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.52 ms /    16 runs   (    0.53 ms per token,  1878.82 tokens per second)\n",
            "llama_print_timings: prompt eval time =     766.37 ms /    29 tokens (   26.43 ms per token,    37.84 tokens per second)\n",
            "llama_print_timings:        eval time =    1550.07 ms /    15 runs   (  103.34 ms per token,     9.68 tokens per second)\n",
            "llama_print_timings:       total time =    2441.35 ms /    44 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "I'm actually in favor of men doing manspreading https://t.co/PNHuc7DOgn\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.76 ms /    16 runs   (    0.67 ms per token,  1487.68 tokens per second)\n",
            "llama_print_timings: prompt eval time =     271.79 ms /    61 tokens (    4.46 ms per token,   224.44 tokens per second)\n",
            "llama_print_timings:        eval time =    1523.85 ms /    15 runs   (  101.59 ms per token,     9.84 tokens per second)\n",
            "llama_print_timings:       total time =    2096.01 ms /    76 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Legend has it that Porfirio Díaz boasted that he governed Mexico as one would govern a madhouse. From the author of “Marimacho Mexico”! ($250) https://t.co/08scBDHRMU\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.04 ms /    16 runs   (    0.57 ms per token,  1769.32 tokens per second)\n",
            "llama_print_timings: prompt eval time =     573.21 ms /    22 tokens (   26.05 ms per token,    38.38 tokens per second)\n",
            "llama_print_timings:        eval time =    1609.33 ms /    15 runs   (  107.29 ms per token,     9.32 tokens per second)\n",
            "llama_print_timings:       total time =    2298.73 ms /    37 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "I can't be a sexy woman with this cold over and tomboy always...\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.55 ms /    16 runs   (    0.60 ms per token,  1674.69 tokens per second)\n",
            "llama_print_timings: prompt eval time =     244.09 ms /    49 tokens (    4.98 ms per token,   200.74 tokens per second)\n",
            "llama_print_timings:        eval time =    1578.94 ms /    15 runs   (  105.26 ms per token,     9.50 tokens per second)\n",
            "llama_print_timings:       total time =    1986.20 ms /    64 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "My dad calls me a tomboy, my colachon (with the tone of a dazed dad) and I look at him like that😍 https://t.co/KUx3g8AdSI\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.00 ms /    16 runs   (    0.63 ms per token,  1599.52 tokens per second)\n",
            "llama_print_timings: prompt eval time =     258.31 ms /    64 tokens (    4.04 ms per token,   247.77 tokens per second)\n",
            "llama_print_timings:        eval time =    1505.99 ms /    15 runs   (  100.40 ms per token,     9.96 tokens per second)\n",
            "llama_print_timings:       total time =    1963.29 ms /    79 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@EnClavePolitik @LassoGuillermo @CarinaVanceEC @OrlandoPerezEC @teleSURtv Isn't this tomboy the one who bought overpriced ambulances that had ashtrays for medical instruments? 🤔\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.23 ms /    16 runs   (    0.58 ms per token,  1734.23 tokens per second)\n",
            "llama_print_timings: prompt eval time =     271.39 ms /    46 tokens (    5.90 ms per token,   169.50 tokens per second)\n",
            "llama_print_timings:        eval time =    1473.42 ms /    15 runs   (   98.23 ms per token,    10.18 tokens per second)\n",
            "llama_print_timings:       total time =    1976.92 ms /    61 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "What a stupid daughter of a thousand whores, she only broke up with Thiago when it was convenient for her, I hope you get cancer, you fucking tomboy, I like you like hell.\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.49 ms /    16 runs   (    0.59 ms per token,  1686.70 tokens per second)\n",
            "llama_print_timings: prompt eval time =     289.98 ms /    79 tokens (    3.67 ms per token,   272.44 tokens per second)\n",
            "llama_print_timings:        eval time =    1481.56 ms /    15 runs   (   98.77 ms per token,    10.12 tokens per second)\n",
            "llama_print_timings:       total time =    1994.69 ms /    94 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Jo from Little Women. The original tomboy. Always with burns on her dresses because she stands near the fireplace. Justified fratricidal tendencies. She cuts her hair so she doesn't ask for money from her horrible aunt. Disaster in general. This speech:https://t.co/ZFWEgYJymc\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.73 ms /    16 runs   (    0.61 ms per token,  1644.40 tokens per second)\n",
            "llama_print_timings: prompt eval time =     248.90 ms /    35 tokens (    7.11 ms per token,   140.62 tokens per second)\n",
            "llama_print_timings:        eval time =    1776.52 ms /    15 runs   (  118.43 ms per token,     8.44 tokens per second)\n",
            "llama_print_timings:       total time =    2180.24 ms /    50 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Masculinism is urgently needed to fight against feminism. https://t.co/5s4jHOM1iT\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.01 ms /    16 runs   (    0.56 ms per token,  1776.59 tokens per second)\n",
            "llama_print_timings: prompt eval time =     254.06 ms /    45 tokens (    5.65 ms per token,   177.12 tokens per second)\n",
            "llama_print_timings:        eval time =    1554.15 ms /    15 runs   (  103.61 ms per token,     9.65 tokens per second)\n",
            "llama_print_timings:       total time =    1964.30 ms /    60 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@plopezperalvo @MasculinismoLi1 @jhon_lawrence1 @Alpaca_espon An account called liberal masculinismo siendl serie?\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.14 ms /    16 runs   (    0.57 ms per token,  1750.16 tokens per second)\n",
            "llama_print_timings: prompt eval time =     679.18 ms /    28 tokens (   24.26 ms per token,    41.23 tokens per second)\n",
            "llama_print_timings:        eval time =    1532.28 ms /    15 runs   (  102.15 ms per token,     9.79 tokens per second)\n",
            "llama_print_timings:       total time =    2333.26 ms /    43 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "I just saw the thing about liberal masculinism or whatever it's called, oh my god the red flags\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.97 ms /    16 runs   (    0.56 ms per token,  1784.32 tokens per second)\n",
            "llama_print_timings: prompt eval time =     294.50 ms /    85 tokens (    3.46 ms per token,   288.62 tokens per second)\n",
            "llama_print_timings:        eval time =    1504.68 ms /    15 runs   (  100.31 ms per token,     9.97 tokens per second)\n",
            "llama_print_timings:       total time =    2042.74 ms /   100 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Bot_del_Rechazo @BrunoBellenger @luzliv25 @MaresCuarentona Machismo is not the counterpart of feminism, for machismo it is \"feminism\" and for feminism it is masculinism, the first two terms are patriarchal, that is, they resort to violence to solve problems.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       3.02 ms /     5 runs   (    0.60 ms per token,  1656.18 tokens per second)\n",
            "llama_print_timings: prompt eval time =     288.27 ms /    88 tokens (    3.28 ms per token,   305.27 tokens per second)\n",
            "llama_print_timings:        eval time =     431.00 ms /     4 runs   (  107.75 ms per token,     9.28 tokens per second)\n",
            "llama_print_timings:       total time =    1061.71 ms /    92 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@klaster_fx @Patri79gg @Rita_Maestre In other words, if a man gets a girl pregnant and doesn't want to take charge, he has every right in the world to leave her behind. Let her worry about what she does. He doesn't have to pay anything...Today's radical feminism is giving way to the new masculinism.\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.30 ms /    16 runs   (    0.58 ms per token,  1720.25 tokens per second)\n",
            "llama_print_timings: prompt eval time =     231.59 ms /    48 tokens (    4.82 ms per token,   207.27 tokens per second)\n",
            "llama_print_timings:        eval time =    1654.42 ms /    15 runs   (  110.29 ms per token,     9.07 tokens per second)\n",
            "llama_print_timings:       total time =    2050.58 ms /    63 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@neurorebelde @IsaMellen I think you are referring to hembrism/machismo. And it would be very wrong too. Feminism/masculinism seeks equality.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.90 ms /    16 runs   (    0.56 ms per token,  1798.16 tokens per second)\n",
            "llama_print_timings: prompt eval time =     253.16 ms /    60 tokens (    4.22 ms per token,   237.01 tokens per second)\n",
            "llama_print_timings:        eval time =    1523.74 ms /    15 runs   (  101.58 ms per token,     9.84 tokens per second)\n",
            "llama_print_timings:       total time =    1959.98 ms /    75 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "I became obsessed with ONEPIECE and The Forced Marriage #Japanbooks #draw #Japancomicshttps://t.co/fcfIbvCdOq https://t.co/kbY5bIgBrn\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.43 ms /    16 runs   (    0.59 ms per token,  1697.61 tokens per second)\n",
            "llama_print_timings: prompt eval time =     245.75 ms /    61 tokens (    4.03 ms per token,   248.22 tokens per second)\n",
            "llama_print_timings:        eval time =    1683.45 ms /    15 runs   (  112.23 ms per token,     8.91 tokens per second)\n",
            "llama_print_timings:       total time =    2115.39 ms /    76 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "AntMan and The Forced Marriage are the best comics I've ever read #slayers #ink #Japanbookshttps://t.co/QUmjakJTwe https://t.co/qyPMEl93V6\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.42 ms /    16 runs   (    0.53 ms per token,  1900.24 tokens per second)\n",
            "llama_print_timings: prompt eval time =     258.19 ms /    39 tokens (    6.62 ms per token,   151.05 tokens per second)\n",
            "llama_print_timings:        eval time =    1548.46 ms /    15 runs   (  103.23 ms per token,     9.69 tokens per second)\n",
            "llama_print_timings:       total time =    2021.70 ms /    54 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "These people pull you into the alliance without breaking you. It seems more like a forced marriage. https://t.co/kkO0gPZ1g5\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.30 ms /    16 runs   (    0.58 ms per token,  1719.51 tokens per second)\n",
            "llama_print_timings: prompt eval time =     274.52 ms /    70 tokens (    3.92 ms per token,   254.99 tokens per second)\n",
            "llama_print_timings:        eval time =    1525.68 ms /    15 runs   (  101.71 ms per token,     9.83 tokens per second)\n",
            "llama_print_timings:       total time =    2007.55 ms /    85 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "I love the drawing style in \"The Forced Marriage\"! Is beautiful! And the character design is incredible. I highly recommend it! #artist #Summer #animationdevhttps://t.co/gid3CBmWeI https://t.co/XGE064d9ET\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.41 ms /    16 runs   (    0.59 ms per token,  1700.50 tokens per second)\n",
            "llama_print_timings: prompt eval time =     259.92 ms /    60 tokens (    4.33 ms per token,   230.84 tokens per second)\n",
            "llama_print_timings:        eval time =    1686.88 ms /    15 runs   (  112.46 ms per token,     8.89 tokens per second)\n",
            "llama_print_timings:       total time =    2132.89 ms /    75 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "I became obsessed with ONEPIECE and The Forced Marriage #plzsupport #conceptart #animememehttps://t.co/ZcAetm2Uvg https://t.co/3Ptun7tQzX\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.24 ms /    16 runs   (    0.64 ms per token,  1562.81 tokens per second)\n",
            "llama_print_timings: prompt eval time =     286.41 ms /    70 tokens (    4.09 ms per token,   244.40 tokens per second)\n",
            "llama_print_timings:        eval time =    1612.25 ms /    15 runs   (  107.48 ms per token,     9.30 tokens per second)\n",
            "llama_print_timings:       total time =    2228.92 ms /    85 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Discover more at Bilibili Comics - Search for \"The Forced Marriage\" and add it to your favorites! #originalcharacter #imagecomics #Japanbookshttps://t.co/zsFOEtdfiW https://t.co/bR6g3XrGvX\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.85 ms /    16 runs   (    0.55 ms per token,  1807.50 tokens per second)\n",
            "llama_print_timings: prompt eval time =     252.66 ms /    41 tokens (    6.16 ms per token,   162.28 tokens per second)\n",
            "llama_print_timings:        eval time =    1587.88 ms /    15 runs   (  105.86 ms per token,     9.45 tokens per second)\n",
            "llama_print_timings:       total time =    1988.25 ms /    56 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "What deceptive weather, I came out in balls because it was hot and on the way back, it was a bit of a surprise for me. I caught pneumonia\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.63 ms /    16 runs   (    0.54 ms per token,  1853.14 tokens per second)\n",
            "llama_print_timings: prompt eval time =     643.47 ms /    22 tokens (   29.25 ms per token,    34.19 tokens per second)\n",
            "llama_print_timings:        eval time =    1527.89 ms /    15 runs   (  101.86 ms per token,     9.82 tokens per second)\n",
            "llama_print_timings:       total time =    2280.85 ms /    37 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "What a beautiful rain God!! It's a shame he caught me walking through the center\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.95 ms /    16 runs   (    0.62 ms per token,  1607.88 tokens per second)\n",
            "llama_print_timings: prompt eval time =     243.11 ms /    48 tokens (    5.06 ms per token,   197.44 tokens per second)\n",
            "llama_print_timings:        eval time =    1597.77 ms /    15 runs   (  106.52 ms per token,     9.39 tokens per second)\n",
            "llama_print_timings:       total time =    2013.10 ms /    63 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "She grabbed my cell phone and blocked me more than 150 girls, even my cousins ​​blocked me and then she says she's not sick 🤦🏿‍♂️\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.25 ms /    16 runs   (    0.58 ms per token,  1729.54 tokens per second)\n",
            "llama_print_timings: prompt eval time =     251.62 ms /    33 tokens (    7.62 ms per token,   131.15 tokens per second)\n",
            "llama_print_timings:        eval time =    1578.37 ms /    15 runs   (  105.22 ms per token,     9.50 tokens per second)\n",
            "llama_print_timings:       total time =    2020.83 ms /    48 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Like I suddenly got a craving for the cookies that @imberrrt forgot to bring me for my birthday 🥲\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.91 ms /    16 runs   (    0.56 ms per token,  1796.54 tokens per second)\n",
            "llama_print_timings: prompt eval time =     246.56 ms /    33 tokens (    7.47 ms per token,   133.84 tokens per second)\n",
            "llama_print_timings:        eval time =    1623.87 ms /    15 runs   (  108.26 ms per token,     9.24 tokens per second)\n",
            "llama_print_timings:       total time =    2012.94 ms /    48 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@FueguitoMansoo caught me leaving the house https://t.co/9UeMobQ0Hd\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.60 ms /    16 runs   (    0.54 ms per token,  1860.68 tokens per second)\n",
            "llama_print_timings: prompt eval time =     247.80 ms /    39 tokens (    6.35 ms per token,   157.38 tokens per second)\n",
            "llama_print_timings:        eval time =    1641.60 ms /    15 runs   (  109.44 ms per token,     9.14 tokens per second)\n",
            "llama_print_timings:       total time =    2033.83 ms /    54 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Ñeeee the dream that caught me culiaaa I want to go out, what if I take a mini nap when I leave work? Dangerous right?\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.89 ms /    16 runs   (    0.68 ms per token,  1468.56 tokens per second)\n",
            "llama_print_timings: prompt eval time =     260.17 ms /    48 tokens (    5.42 ms per token,   184.49 tokens per second)\n",
            "llama_print_timings:        eval time =    1807.83 ms /    15 runs   (  120.52 ms per token,     8.30 tokens per second)\n",
            "llama_print_timings:       total time =    2257.86 ms /    63 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "My dad came from e.r and took me to the facu, I got out and yelled at me, pay attention and BEHAVE WELL 🤌🏻 I went back to primary school\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.63 ms /    16 runs   (    0.54 ms per token,  1854.00 tokens per second)\n",
            "llama_print_timings: prompt eval time =     253.81 ms /    38 tokens (    6.68 ms per token,   149.72 tokens per second)\n",
            "llama_print_timings:        eval time =    1544.51 ms /    15 runs   (  102.97 ms per token,     9.71 tokens per second)\n",
            "llama_print_timings:       total time =    1940.88 ms /    53 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "What a look you look like a model the bus driver yelled at me with his exploited bondi jsjdjsjjsj lpmm I almost died of shame\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.13 ms /    16 runs   (    0.57 ms per token,  1752.85 tokens per second)\n",
            "llama_print_timings: prompt eval time =     288.65 ms /    77 tokens (    3.75 ms per token,   266.76 tokens per second)\n",
            "llama_print_timings:        eval time =    1523.24 ms /    15 runs   (  101.55 ms per token,     9.85 tokens per second)\n",
            "llama_print_timings:       total time =    2033.85 ms /    92 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "I just entered the subway🇨🇱 and on the platform I see a 3rd year old lady alone and crying, I approached her to ask if she needed help and give her some candy, she screamed at me to leave her alone🥺 It broke my heart! I just ask God to heal hers 💔\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.94 ms /    16 runs   (    0.62 ms per token,  1609.66 tokens per second)\n",
            "llama_print_timings: prompt eval time =     260.10 ms /    64 tokens (    4.06 ms per token,   246.06 tokens per second)\n",
            "llama_print_timings:        eval time =    1526.82 ms /    15 runs   (  101.79 ms per token,     9.82 tokens per second)\n",
            "llama_print_timings:       total time =    1992.07 ms /    79 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "when my mother yelled at me that playing role-playing games led to jumping off bridges, taking drugs, robbing warehouses and stealing cars. What an idiot's face I got jsjsjsj https://t.co/FHBfcWPZTa\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.22 ms /    16 runs   (    0.58 ms per token,  1736.11 tokens per second)\n",
            "llama_print_timings: prompt eval time =     292.83 ms /    87 tokens (    3.37 ms per token,   297.10 tokens per second)\n",
            "llama_print_timings:        eval time =    1483.42 ms /    15 runs   (   98.89 ms per token,    10.11 tokens per second)\n",
            "llama_print_timings:       total time =    2018.91 ms /   102 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Last night on the train, Gollum came up to me and stomped on my foot for no other reason than to hurt me. When I was in front of him he shouted at me \"the ring is mine, my treasure!!!\". And he did it simply because he saw that I am a Hobbit of the Shire. https://t.co/fU6ogHpryg\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.14 ms /    16 runs   (    0.51 ms per token,  1966.33 tokens per second)\n",
            "llama_print_timings: prompt eval time =     243.49 ms /    45 tokens (    5.41 ms per token,   184.82 tokens per second)\n",
            "llama_print_timings:        eval time =    1547.71 ms /    15 runs   (  103.18 ms per token,     9.69 tokens per second)\n",
            "llama_print_timings:       total time =    1946.12 ms /    60 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "my uber saw me bitching at a guy in the city and yelled at me CAGUESELE CAGUESELE hahahahahahahahaha noooooooo\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.77 ms /    16 runs   (    0.55 ms per token,  1823.57 tokens per second)\n",
            "llama_print_timings: prompt eval time =     253.61 ms /    42 tokens (    6.04 ms per token,   165.61 tokens per second)\n",
            "llama_print_timings:        eval time =    1548.50 ms /    15 runs   (  103.23 ms per token,     9.69 tokens per second)\n",
            "llama_print_timings:       total time =    1967.70 ms /    57 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Ur4vity___ I would like to fuck you so hard that I end up giving you the next day but I don't think it's going to be possible\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.62 ms /    16 runs   (    0.73 ms per token,  1376.34 tokens per second)\n",
            "llama_print_timings: prompt eval time =     586.93 ms /    32 tokens (   18.34 ms per token,    54.52 tokens per second)\n",
            "llama_print_timings:        eval time =    1830.89 ms /    15 runs   (  122.06 ms per token,     8.19 tokens per second)\n",
            "llama_print_timings:       total time =    2580.78 ms /    47 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@M150696978 @spider_906 I would like to fuck you both are very handsome\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.58 ms /    16 runs   (    0.54 ms per token,  1865.45 tokens per second)\n",
            "llama_print_timings: prompt eval time =     246.54 ms /    33 tokens (    7.47 ms per token,   133.85 tokens per second)\n",
            "llama_print_timings:        eval time =    1574.94 ms /    15 runs   (  105.00 ms per token,     9.52 tokens per second)\n",
            "llama_print_timings:       total time =    1959.03 ms /    48 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@CAMILALA2CO @CAMILACOLOMBIA5 Of course I would also like to fuck with you love 💕\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.72 ms /    16 runs   (    0.61 ms per token,  1645.41 tokens per second)\n",
            "llama_print_timings: prompt eval time =     289.22 ms /    76 tokens (    3.81 ms per token,   262.77 tokens per second)\n",
            "llama_print_timings:        eval time =    1512.79 ms /    15 runs   (  100.85 ms per token,     9.92 tokens per second)\n",
            "llama_print_timings:       total time =    2023.79 ms /    91 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@libreromarica How annoying you are with your frikadas. I wouldn't like to fuck an 'aunt' with a cock and that doesn't mean I hate that person. You use demagoguery very quickly and call transphobe at the first opportunity and thus you are taking away the meaning of that word.\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.89 ms /    16 runs   (    0.56 ms per token,  1798.97 tokens per second)\n",
            "llama_print_timings: prompt eval time =     790.32 ms /    31 tokens (   25.49 ms per token,    39.22 tokens per second)\n",
            "llama_print_timings:        eval time =    1577.45 ms /    15 runs   (  105.16 ms per token,     9.51 tokens per second)\n",
            "llama_print_timings:       total time =    2505.37 ms /    46 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Nicolle53447890 How delicious you are, my heart, I would like to fuck with you\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.12 ms /    16 runs   (    0.63 ms per token,  1581.34 tokens per second)\n",
            "llama_print_timings: prompt eval time =     906.09 ms /    31 tokens (   29.23 ms per token,    34.21 tokens per second)\n",
            "llama_print_timings:        eval time =    1596.66 ms /    15 runs   (  106.44 ms per token,     9.39 tokens per second)\n",
            "llama_print_timings:       total time =    2700.43 ms /    46 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@InkaProduction @morenahot21 @MazzimoMontana I would like to fuck with that beautiful nerita\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.49 ms /    16 runs   (    0.59 ms per token,  1685.81 tokens per second)\n",
            "llama_print_timings: prompt eval time =     307.65 ms /   107 tokens (    2.88 ms per token,   347.80 tokens per second)\n",
            "llama_print_timings:        eval time =    1556.76 ms /    15 runs   (  103.78 ms per token,     9.64 tokens per second)\n",
            "llama_print_timings:       total time =    2166.09 ms /   122 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Everyone knows that the one who really deserves to win is our Aluxe 👊👊 #ZERBONIGANADOR #LCDLF2 #Zerboni #NoAlFraude @TLMDRealities @SANDARTI @Jimenagallegotv @carlosadyan @RodnerFigueroa @JorgeBernal https://t.co/qoxthIivpj\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.70 ms /    16 runs   (    0.54 ms per token,  1838.24 tokens per second)\n",
            "llama_print_timings: prompt eval time =     780.53 ms /    30 tokens (   26.02 ms per token,    38.44 tokens per second)\n",
            "llama_print_timings:        eval time =    1533.25 ms /    15 runs   (  102.22 ms per token,     9.78 tokens per second)\n",
            "llama_print_timings:       total time =    2441.23 ms /    45 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "We deserve to lose it because we are a disaster. Only Centurión deserves to win it and I hope he wins it\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.21 ms /    16 runs   (    0.64 ms per token,  1566.78 tokens per second)\n",
            "llama_print_timings: prompt eval time =     777.33 ms /    30 tokens (   25.91 ms per token,    38.59 tokens per second)\n",
            "llama_print_timings:        eval time =    1861.37 ms /    15 runs   (  124.09 ms per token,     8.06 tokens per second)\n",
            "llama_print_timings:       total time =    2791.04 ms /    45 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "She does deserve to be president... not like the doctor https://t.co/0F6vvfDa0a\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.07 ms /    16 runs   (    0.57 ms per token,  1764.25 tokens per second)\n",
            "llama_print_timings: prompt eval time =     697.55 ms /    28 tokens (   24.91 ms per token,    40.14 tokens per second)\n",
            "llama_print_timings:        eval time =    1528.08 ms /    15 runs   (  101.87 ms per token,     9.82 tokens per second)\n",
            "llama_print_timings:       total time =    2359.57 ms /    43 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@AntonioVuarnet I can't stand it either. What is your opinion of the film?\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.05 ms /    16 runs   (    0.57 ms per token,  1767.17 tokens per second)\n",
            "llama_print_timings: prompt eval time =     292.30 ms /   102 tokens (    2.87 ms per token,   348.95 tokens per second)\n",
            "llama_print_timings:        eval time =    1522.46 ms /    15 runs   (  101.50 ms per token,     9.85 tokens per second)\n",
            "llama_print_timings:       total time =    2099.02 ms /   117 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@AndresMagri @MillosFCoficial As a Santafereña 🇲🇨🦁 if that weighs on you My team would also be like that I don't hate Millos and 💙 the millionaire brother doesn't deserve That and where are Serpita Chuki and Camachito because they don't do anything. And strangely enough, the dimayor does whatever they want\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.91 ms /    16 runs   (    0.56 ms per token,  1795.94 tokens per second)\n",
            "llama_print_timings: prompt eval time =     763.58 ms /    30 tokens (   25.45 ms per token,    39.29 tokens per second)\n",
            "llama_print_timings:        eval time =    1466.23 ms /    15 runs   (   97.75 ms per token,    10.23 tokens per second)\n",
            "llama_print_timings:       total time =    2356.73 ms /    45 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "It sounds very crazy to say that I would like to see Perin for a while to see if he deserves the title?\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.68 ms /    16 runs   (    0.67 ms per token,  1497.99 tokens per second)\n",
            "llama_print_timings: prompt eval time =     272.14 ms /    55 tokens (    4.95 ms per token,   202.10 tokens per second)\n",
            "llama_print_timings:        eval time =    1675.92 ms /    15 runs   (  111.73 ms per token,     8.95 tokens per second)\n",
            "llama_print_timings:       total time =    2224.11 ms /    70 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Some of those men are the kind of people to whom you give a minimum of attention and they are hallucinated after three sucks of mango... beginning to understand misandry https://t.co/CnxmxXjgYy\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.74 ms /    16 runs   (    0.55 ms per token,  1831.50 tokens per second)\n",
            "llama_print_timings: prompt eval time =     249.62 ms /    41 tokens (    6.09 ms per token,   164.25 tokens per second)\n",
            "llama_print_timings:        eval time =    1543.68 ms /    15 runs   (  102.91 ms per token,     9.72 tokens per second)\n",
            "llama_print_timings:       total time =    1940.91 ms /    56 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@naminohire Andros = man in Greek, more translated as male, misandry is hatred of menGenos = woman, misogyny hatred of women\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.10 ms /    16 runs   (    0.57 ms per token,  1758.43 tokens per second)\n",
            "llama_print_timings: prompt eval time =     287.07 ms /    67 tokens (    4.28 ms per token,   233.39 tokens per second)\n",
            "llama_print_timings:        eval time =    1514.68 ms /    15 runs   (  100.98 ms per token,     9.90 tokens per second)\n",
            "llama_print_timings:       total time =    2001.04 ms /    82 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "It's TOTALLY LIKE THIS, it's not that \"there are no female directors\" it's that there are no female directors who are given opportunities!!!! banquen girls cinema moment total misandry sisters!!!! https://t.co/WEMJfMcEYP\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.95 ms /    16 runs   (    0.68 ms per token,  1461.19 tokens per second)\n",
            "llama_print_timings: prompt eval time =     243.79 ms /    37 tokens (    6.59 ms per token,   151.77 tokens per second)\n",
            "llama_print_timings:        eval time =    1823.27 ms /    15 runs   (  121.55 ms per token,     8.23 tokens per second)\n",
            "llama_print_timings:       total time =    2246.66 ms /    52 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "say it queen #girlpower #misandria #tiatxulisima https://t.co/Z6BqpLaHgF\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.42 ms /    16 runs   (    0.53 ms per token,  1900.91 tokens per second)\n",
            "llama_print_timings: prompt eval time =     797.54 ms /    30 tokens (   26.58 ms per token,    37.62 tokens per second)\n",
            "llama_print_timings:        eval time =    1534.13 ms /    15 runs   (  102.28 ms per token,     9.78 tokens per second)\n",
            "llama_print_timings:       total time =    2465.66 ms /    45 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Before I liked men's perfume and now it disgusts me, misandry takes over more and more of me\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.62 ms /    16 runs   (    0.60 ms per token,  1663.20 tokens per second)\n",
            "llama_print_timings: prompt eval time =     265.05 ms /    57 tokens (    4.65 ms per token,   215.06 tokens per second)\n",
            "llama_print_timings:        eval time =    1529.05 ms /    15 runs   (  101.94 ms per token,     9.81 tokens per second)\n",
            "llama_print_timings:       total time =    1987.08 ms /    72 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "A man or a woman should not be judged for being good or bad based on their gender. Misandry is as unfair, deplorable and dangerous as misogyny. https://t.co/gwAFhEMmQr\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.50 ms /    16 runs   (    0.59 ms per token,  1684.39 tokens per second)\n",
            "llama_print_timings: prompt eval time =     261.98 ms /    68 tokens (    3.85 ms per token,   259.56 tokens per second)\n",
            "llama_print_timings:        eval time =    1564.27 ms /    15 runs   (  104.28 ms per token,     9.59 tokens per second)\n",
            "llama_print_timings:       total time =    2039.64 ms /    83 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@CLjck7 And they never tire of giving the same excuse as to why their favs deserve this and that!! They always bring out the \"misogyny card\" when they cannot give a valid argument when the talent of their favs and the awards for which they are nominated are questioned...\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.69 ms /    16 runs   (    0.67 ms per token,  1496.59 tokens per second)\n",
            "llama_print_timings: prompt eval time =     286.62 ms /    74 tokens (    3.87 ms per token,   258.18 tokens per second)\n",
            "llama_print_timings:        eval time =    1627.10 ms /    15 runs   (  108.47 ms per token,     9.22 tokens per second)\n",
            "llama_print_timings:       total time =    2256.27 ms /    89 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Thank you very much Wendy, your support and that of the women who have joined strengthen me, it calms my anxiety a little as I have been fighting alone against the misogyny, indifference and grievances of the municipal government, a hug. https://t.co/JqfV3dx5E3\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.31 ms /    16 runs   (    0.58 ms per token,  1717.84 tokens per second)\n",
            "llama_print_timings: prompt eval time =     257.20 ms /    50 tokens (    5.14 ms per token,   194.40 tokens per second)\n",
            "llama_print_timings:        eval time =    1510.38 ms /    15 runs   (  100.69 ms per token,     9.93 tokens per second)\n",
            "llama_print_timings:       total time =    1932.59 ms /    65 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@robsoriano_sv He is not imprisoned for criticizing, but for misogyny. He loves to insult female deputies and government officials. In addition to insulting officials, including the President.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.08 ms /    16 runs   (    0.57 ms per token,  1761.53 tokens per second)\n",
            "llama_print_timings: prompt eval time =     257.30 ms /    46 tokens (    5.59 ms per token,   178.78 tokens per second)\n",
            "llama_print_timings:        eval time =    1529.82 ms /    15 runs   (  101.99 ms per token,     9.81 tokens per second)\n",
            "llama_print_timings:       total time =    1943.08 ms /    61 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@figaromoren0 @RobertoMadrazo_ @LillyTellez Because we are women, do we have to start washing the dishes? How misogyny and ignorant!\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.96 ms /    16 runs   (    0.75 ms per token,  1337.57 tokens per second)\n",
            "llama_print_timings: prompt eval time =     273.76 ms /    75 tokens (    3.65 ms per token,   273.96 tokens per second)\n",
            "llama_print_timings:        eval time =    1815.49 ms /    15 runs   (  121.03 ms per token,     8.26 tokens per second)\n",
            "llama_print_timings:       total time =    2355.75 ms /    90 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "So you are a misogynist and violent miser who hits other deputies with his fists while sober... When do you have a psychiatric study? We want to know what the results are to see if you are qualified for the position @carreragonzalo https://t.co/lsXwxr69X8\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.99 ms /    16 runs   (    0.62 ms per token,  1600.96 tokens per second)\n",
            "llama_print_timings: prompt eval time =     274.32 ms /    66 tokens (    4.16 ms per token,   240.59 tokens per second)\n",
            "llama_print_timings:        eval time =    1584.14 ms /    15 runs   (  105.61 ms per token,     9.47 tokens per second)\n",
            "llama_print_timings:       total time =    2056.62 ms /    81 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@labixxota @rosalia the t-shirt has the phrase \"porn stars who are no longer with us\" because all those girls were murdered in quite strong contexts and Rosalía wears it remembering that the pornographic industry is full of misogyny and it kills you\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.04 ms /    16 runs   (    0.57 ms per token,  1769.52 tokens per second)\n",
            "llama_print_timings: prompt eval time =     256.98 ms /    46 tokens (    5.59 ms per token,   179.00 tokens per second)\n",
            "llama_print_timings:        eval time =    1585.86 ms /    15 runs   (  105.72 ms per token,     9.46 tokens per second)\n",
            "llama_print_timings:       total time =    2009.60 ms /    61 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@orlandogotay @DoliaEstevez It would be explained by the prudish (and, above all, hypocritical) attitude of the gringos on the matter.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.24 ms /    16 runs   (    0.51 ms per token,  1942.45 tokens per second)\n",
            "llama_print_timings: prompt eval time =     302.10 ms /    99 tokens (    3.05 ms per token,   327.71 tokens per second)\n",
            "llama_print_timings:        eval time =    1597.15 ms /    15 runs   (  106.48 ms per token,     9.39 tokens per second)\n",
            "llama_print_timings:       total time =    2179.77 ms /   114 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "#laleydebaltazar, apart from being hot and prudish, the Anita who loves them all... is very cool... at home, may Feña take care of the little boy, while she walks with her teenage love interest with Gabriel's cake, etc. She loads my CSM 🤬🤬🤬🤬🤬🤬🤬\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.07 ms /    16 runs   (    0.69 ms per token,  1445.61 tokens per second)\n",
            "llama_print_timings: prompt eval time =     248.50 ms /    43 tokens (    5.78 ms per token,   173.04 tokens per second)\n",
            "llama_print_timings:        eval time =    1868.87 ms /    15 runs   (  124.59 ms per token,     8.03 tokens per second)\n",
            "llama_print_timings:       total time =    2376.75 ms /    58 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@angelicapinzon8 @Mistermopilas Another sanctimonious cachaca! They think and say one thing, but give them space and they go crazy\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.66 ms /    16 runs   (    0.54 ms per token,  1847.58 tokens per second)\n",
            "llama_print_timings: prompt eval time =     254.69 ms /    35 tokens (    7.28 ms per token,   137.42 tokens per second)\n",
            "llama_print_timings:        eval time =    1529.96 ms /    15 runs   (  102.00 ms per token,     9.80 tokens per second)\n",
            "llama_print_timings:       total time =    1918.46 ms /    50 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@ClaudiaOrtizSV Ayyyy the exalted one with that prudish face and pose is not going to happen to you\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.66 ms /    16 runs   (    0.60 ms per token,  1656.31 tokens per second)\n",
            "llama_print_timings: prompt eval time =     265.58 ms /    56 tokens (    4.74 ms per token,   210.86 tokens per second)\n",
            "llama_print_timings:        eval time =    1511.26 ms /    15 runs   (  100.75 ms per token,     9.93 tokens per second)\n",
            "llama_print_timings:       total time =    1961.56 ms /    71 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "She doesn't mince words, she's not a prude and she is raflá @cindyBO23 the mere filly ♥️ https://t.co/hh2W0zDw6m\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.74 ms /    16 runs   (    0.55 ms per token,  1830.87 tokens per second)\n",
            "llama_print_timings: prompt eval time =     751.23 ms /    29 tokens (   25.90 ms per token,    38.60 tokens per second)\n",
            "llama_print_timings:        eval time =    1496.14 ms /    15 runs   (   99.74 ms per token,    10.03 tokens per second)\n",
            "llama_print_timings:       total time =    2369.02 ms /    44 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@negrovandalic @ElMorenoALV Are you nervous? What a prude hahahaha\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.84 ms /    16 runs   (    0.74 ms per token,  1351.92 tokens per second)\n",
            "llama_print_timings: prompt eval time =     284.98 ms /    83 tokens (    3.43 ms per token,   291.25 tokens per second)\n",
            "llama_print_timings:        eval time =    1820.42 ms /    15 runs   (  121.36 ms per token,     8.24 tokens per second)\n",
            "llama_print_timings:       total time =    2516.16 ms /    98 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@ignaciadepano @SireneTana A lot of feminism but what it says is that the super macho Pablo and Pedro are the ones who, together (on one side of the table) with the electric girls (on the other), will illuminate the world. This woman is pathetic, I can't handle her, she makes me gag.\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.99 ms /    16 runs   (    0.62 ms per token,  1601.92 tokens per second)\n",
            "llama_print_timings: prompt eval time =     278.40 ms /    70 tokens (    3.98 ms per token,   251.43 tokens per second)\n",
            "llama_print_timings:        eval time =    1610.00 ms /    15 runs   (  107.33 ms per token,     9.32 tokens per second)\n",
            "llama_print_timings:       total time =    2092.57 ms /    85 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "My neighbor fixed it for me because I told my stepfather that I had jumped and knowing me he called the neighbor directly to fix it, in conclusion a lot of feminism but at the mercy of men and Pedro I come back I miss you https://t. co/9Y6A3NW6G0\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.84 ms /    16 runs   (    0.55 ms per token,  1809.34 tokens per second)\n",
            "llama_print_timings: prompt eval time =     253.61 ms /    37 tokens (    6.85 ms per token,   145.90 tokens per second)\n",
            "llama_print_timings:        eval time =    1531.37 ms /    15 runs   (  102.09 ms per token,     9.80 tokens per second)\n",
            "llama_print_timings:       total time =    1923.01 ms /    52 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@DCognitivos That's right. A lot of feminism but deep down they are sexists. Or polyamorous as they say now.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.93 ms /    16 runs   (    0.62 ms per token,  1610.95 tokens per second)\n",
            "llama_print_timings: prompt eval time =     242.24 ms /    34 tokens (    7.12 ms per token,   140.36 tokens per second)\n",
            "llama_print_timings:        eval time =    1718.38 ms /    15 runs   (  114.56 ms per token,     8.73 tokens per second)\n",
            "llama_print_timings:       total time =    2106.22 ms /    49 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Yes, there is a lot of feminism but they continue to stand next to a little idiot who yells at mines and they justify them?\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.61 ms /    16 runs   (    0.60 ms per token,  1665.80 tokens per second)\n",
            "llama_print_timings: prompt eval time =     265.90 ms /    43 tokens (    6.18 ms per token,   161.72 tokens per second)\n",
            "llama_print_timings:        eval time =    1514.17 ms /    15 runs   (  100.94 ms per token,     9.91 tokens per second)\n",
            "llama_print_timings:       total time =    2028.86 ms /    58 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@JTemplaria @_benjaminsg Let's see if they put the gender quota in there, a lot of feminism but only for office positions 😎\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.24 ms /    16 runs   (    0.58 ms per token,  1730.85 tokens per second)\n",
            "llama_print_timings: prompt eval time =     248.61 ms /    33 tokens (    7.53 ms per token,   132.74 tokens per second)\n",
            "llama_print_timings:        eval time =    1600.62 ms /    15 runs   (  106.71 ms per token,     9.37 tokens per second)\n",
            "llama_print_timings:       total time =    1985.69 ms /    48 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Manuelswow Given the choice of dictators as they should disappear because there is a lot of feminism but it is selective\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.59 ms /    16 runs   (    0.54 ms per token,  1863.72 tokens per second)\n",
            "llama_print_timings: prompt eval time =     251.97 ms /    33 tokens (    7.64 ms per token,   130.97 tokens per second)\n",
            "llama_print_timings:        eval time =    1536.23 ms /    15 runs   (  102.42 ms per token,     9.76 tokens per second)\n",
            "llama_print_timings:       total time =    1920.87 ms /    48 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "What was that like as a woman behind the wheel...?🤔😆😆 https://t.co/i4AsEONIQu\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.27 ms /    16 runs   (    0.58 ms per token,  1726.00 tokens per second)\n",
            "llama_print_timings: prompt eval time =     245.60 ms /    38 tokens (    6.46 ms per token,   154.73 tokens per second)\n",
            "llama_print_timings:        eval time =    1698.01 ms /    15 runs   (  113.20 ms per token,     8.83 tokens per second)\n",
            "llama_print_timings:       total time =    2101.26 ms /    53 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "HAHAHAHAHAHA WOMAN DRIVING, INSTANT DANGER. https://t.co/U7rhFumuds\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.74 ms /    16 runs   (    0.55 ms per token,  1831.29 tokens per second)\n",
            "llama_print_timings: prompt eval time =     797.48 ms /    30 tokens (   26.58 ms per token,    37.62 tokens per second)\n",
            "llama_print_timings:        eval time =    1548.97 ms /    15 runs   (  103.26 ms per token,     9.68 tokens per second)\n",
            "llama_print_timings:       total time =    2474.19 ms /    45 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@info7mty woman behind the wheel...constant danger...thank goodness she didn't take someone to meet her\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.37 ms /    16 runs   (    0.59 ms per token,  1707.40 tokens per second)\n",
            "llama_print_timings: prompt eval time =     466.59 ms /    17 tokens (   27.45 ms per token,    36.43 tokens per second)\n",
            "llama_print_timings:        eval time =    1571.69 ms /    15 runs   (  104.78 ms per token,     9.54 tokens per second)\n",
            "llama_print_timings:       total time =    2143.05 ms /    32 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Today they showed me that a woman driving is certain death\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.11 ms /    16 runs   (    0.57 ms per token,  1755.93 tokens per second)\n",
            "llama_print_timings: prompt eval time =     488.87 ms /    19 tokens (   25.73 ms per token,    38.87 tokens per second)\n",
            "llama_print_timings:        eval time =    1521.70 ms /    15 runs   (  101.45 ms per token,     9.86 tokens per second)\n",
            "llama_print_timings:       total time =    2115.64 ms /    34 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@lluciaasampol Tell her queen woman driving constant danger\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.81 ms /    16 runs   (    0.74 ms per token,  1354.33 tokens per second)\n",
            "llama_print_timings: prompt eval time =     245.13 ms /    45 tokens (    5.45 ms per token,   183.57 tokens per second)\n",
            "llama_print_timings:        eval time =    1853.53 ms /    15 runs   (  123.57 ms per token,     8.09 tokens per second)\n",
            "llama_print_timings:       total time =    2281.63 ms /    60 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Imagine the look on my face when the Uber Man told me “woman behind the wheel, constant danger.” I'm in danger of slapping him if he keeps telling me stupid things.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       3.23 ms /     5 runs   (    0.65 ms per token,  1545.60 tokens per second)\n",
            "llama_print_timings: prompt eval time =     281.88 ms /    65 tokens (    4.34 ms per token,   230.59 tokens per second)\n",
            "llama_print_timings:        eval time =     431.15 ms /     4 runs   (  107.79 ms per token,     9.28 tokens per second)\n",
            "llama_print_timings:       total time =     867.00 ms /    69 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@EstadioRetro @MALPICAJA Worry more because it is not going to be perpetuated, but if through Sheinbaum who, like a good docile and submissive woman, will blindly obey it, that is what should really worry you\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.65 ms /    16 runs   (    0.60 ms per token,  1658.37 tokens per second)\n",
            "llama_print_timings: prompt eval time =     227.95 ms /    40 tokens (    5.70 ms per token,   175.48 tokens per second)\n",
            "llama_print_timings:        eval time =    1433.16 ms /    15 runs   (   95.54 ms per token,    10.47 tokens per second)\n",
            "llama_print_timings:       total time =    1814.34 ms /    55 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Good night my submissive, how did you wake up, beautiful docile and obedient woman https://t.co/ZCSap1OxmW\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.56 ms /    16 runs   (    0.60 ms per token,  1673.64 tokens per second)\n",
            "llama_print_timings: prompt eval time =     285.15 ms /    95 tokens (    3.00 ms per token,   333.15 tokens per second)\n",
            "llama_print_timings:        eval time =    1454.34 ms /    15 runs   (   96.96 ms per token,    10.31 tokens per second)\n",
            "llama_print_timings:       total time =    2004.13 ms /   110 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "\"The fascist regime that spread an ideal of a docile and submissive woman ignored the work of the writer like someone who throws a black blanket over an object that they want to hide, without making noise, so that no one ever sees it.\" Aurora Bertrana Salazar \"was in the way because she was a free woman.\"💞 https://t.co/rNcK0QIlK0\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.71 ms /    16 runs   (    0.61 ms per token,  1647.11 tokens per second)\n",
            "llama_print_timings: prompt eval time =     282.88 ms /    91 tokens (    3.11 ms per token,   321.70 tokens per second)\n",
            "llama_print_timings:        eval time =    1491.93 ms /    15 runs   (   99.46 ms per token,    10.05 tokens per second)\n",
            "llama_print_timings:       total time =    2028.22 ms /   106 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Dear friends, We already presented to society our current factor object of Psychoanalytic Ethics on Thursday at the UCSG with the number of speakers!!! I invite you to read the text that I wrote for that special occasion, docile to Styleethics...https ://t.co/w36yt9AGuT https://t.co/b2vCs5OGHN\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.88 ms /    16 runs   (    0.55 ms per token,  1802.00 tokens per second)\n",
            "llama_print_timings: prompt eval time =     254.83 ms /    42 tokens (    6.07 ms per token,   164.82 tokens per second)\n",
            "llama_print_timings:        eval time =    1567.01 ms /    15 runs   (  104.47 ms per token,     9.57 tokens per second)\n",
            "llama_print_timings:       total time =    1969.72 ms /    57 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@ymouled The parents and families of these students will have some blame. Maybe they would prefer to have a docile woman than a teenager who is trained and thinks for herself.\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.31 ms /    16 runs   (    0.58 ms per token,  1719.14 tokens per second)\n",
            "llama_print_timings: prompt eval time =     286.90 ms /    93 tokens (    3.08 ms per token,   324.16 tokens per second)\n",
            "llama_print_timings:        eval time =    1633.99 ms /    15 runs   (  108.93 ms per token,     9.18 tokens per second)\n",
            "llama_print_timings:       total time =    2177.01 ms /   108 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "🙏Let's not confuse submission with learned helplessness. Submission is characterized by being a docile, obedient, subordinate, surrendered or subjugated woman before her abuser and learned helplessness is what @anaisbernal explains in this video💜 # Learned Helplessness # MareaFuchsia https://t.co/1HoTXrGy1w\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.59 ms /    16 runs   (    0.60 ms per token,  1667.88 tokens per second)\n",
            "llama_print_timings: prompt eval time =     269.38 ms /    68 tokens (    3.96 ms per token,   252.43 tokens per second)\n",
            "llama_print_timings:        eval time =    1535.23 ms /    15 runs   (  102.35 ms per token,     9.77 tokens per second)\n",
            "llama_print_timings:       total time =    2017.13 ms /    83 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Empowered, respectful, empathetic and simple woman, worthy of representing us before this international institution.@suselparedes@ConfluenciaPeru#ConfluenciaPeru@MujerEmpoderadahttps://t.co/aPxo4h643a\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.10 ms /    16 runs   (    0.63 ms per token,  1583.69 tokens per second)\n",
            "llama_print_timings: prompt eval time =     263.74 ms /    45 tokens (    5.86 ms per token,   170.62 tokens per second)\n",
            "llama_print_timings:        eval time =    1683.76 ms /    15 runs   (  112.25 ms per token,     8.91 tokens per second)\n",
            "llama_print_timings:       total time =    2189.43 ms /    60 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "They talk about #QueenIsabelII as an \"empowered woman\", don't screw it! If she was governed by retrograde rules. What's empowering about that?\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.16 ms /    16 runs   (    0.57 ms per token,  1746.72 tokens per second)\n",
            "llama_print_timings: prompt eval time =     274.98 ms /    65 tokens (    4.23 ms per token,   236.38 tokens per second)\n",
            "llama_print_timings:        eval time =    1559.64 ms /    15 runs   (  103.98 ms per token,     9.62 tokens per second)\n",
            "llama_print_timings:       total time =    2038.80 ms /    80 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "I also gave up my career to be a mom 24/7 and? Are the feminists going to massacre me because I left aside my role as an empowered, independent and brutal woman? I want to see them then managing a house!! Hpta thing I tell you!\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.80 ms /    16 runs   (    0.55 ms per token,  1818.80 tokens per second)\n",
            "llama_print_timings: prompt eval time =     255.10 ms /    40 tokens (    6.38 ms per token,   156.80 tokens per second)\n",
            "llama_print_timings:        eval time =    1528.94 ms /    15 runs   (  101.93 ms per token,     9.81 tokens per second)\n",
            "llama_print_timings:       total time =    1930.61 ms /    55 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Allyson Felix is ​​an example of an empowered woman who moves forward through her own means and talents. Let's share her story to inspire more women.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.05 ms /    16 runs   (    0.57 ms per token,  1767.57 tokens per second)\n",
            "llama_print_timings: prompt eval time =     257.09 ms /    41 tokens (    6.27 ms per token,   159.48 tokens per second)\n",
            "llama_print_timings:        eval time =    1535.08 ms /    15 runs   (  102.34 ms per token,     9.77 tokens per second)\n",
            "llama_print_timings:       total time =    1941.18 ms /    56 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "TAMARA FALCÓ EMPOWERED WOMAN - Ramsey Ferrero. https://t.co/TsbmF6GaHn\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.07 ms /    16 runs   (    0.57 ms per token,  1764.25 tokens per second)\n",
            "llama_print_timings: prompt eval time =     239.41 ms /    39 tokens (    6.14 ms per token,   162.90 tokens per second)\n",
            "llama_print_timings:        eval time =    1524.32 ms /    15 runs   (  101.62 ms per token,     9.84 tokens per second)\n",
            "llama_print_timings:       total time =    1905.28 ms /    54 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Leonaypeleona Aha, can't you see that I am an empowered woman? At least tell me queen papichulo hahaha\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.85 ms /    16 runs   (    0.62 ms per token,  1624.86 tokens per second)\n",
            "llama_print_timings: prompt eval time =     584.46 ms /    21 tokens (   27.83 ms per token,    35.93 tokens per second)\n",
            "llama_print_timings:        eval time =    1596.31 ms /    15 runs   (  106.42 ms per token,     9.40 tokens per second)\n",
            "llama_print_timings:       total time =    2301.81 ms /    36 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "how well I cook on god I love being the vase woman of my friends\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.71 ms /    16 runs   (    0.54 ms per token,  1838.02 tokens per second)\n",
            "llama_print_timings: prompt eval time =     782.75 ms /    29 tokens (   26.99 ms per token,    37.05 tokens per second)\n",
            "llama_print_timings:        eval time =    1467.48 ms /    15 runs   (   97.83 ms per token,    10.22 tokens per second)\n",
            "llama_print_timings:       total time =    2371.09 ms /    44 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "I am looking for a rich boyfriend or rich girlfriend to be a vase woman because I am tired of adult life.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.75 ms /    16 runs   (    0.61 ms per token,  1641.36 tokens per second)\n",
            "llama_print_timings: prompt eval time =     259.91 ms /    64 tokens (    4.06 ms per token,   246.24 tokens per second)\n",
            "llama_print_timings:        eval time =    1417.07 ms /    15 runs   (   94.47 ms per token,    10.59 tokens per second)\n",
            "llama_print_timings:       total time =    1870.84 ms /    79 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@motasluna @sergiobarbosach @AlexFlorezH So you don't go around flirting with people because you lose the image of a vase woman that you have to maintain because your self-esteem is tied to what people will say.\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.18 ms /    16 runs   (    0.57 ms per token,  1742.54 tokens per second)\n",
            "llama_print_timings: prompt eval time =     241.95 ms /    33 tokens (    7.33 ms per token,   136.39 tokens per second)\n",
            "llama_print_timings:        eval time =    1474.59 ms /    15 runs   (   98.31 ms per token,    10.17 tokens per second)\n",
            "llama_print_timings:       total time =    1862.61 ms /    48 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@SaraSalamo @abc_es You dedicate yourself to something worse, pretty: being the vase wife of a millionaire.\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.67 ms /    16 runs   (    0.54 ms per token,  1846.08 tokens per second)\n",
            "llama_print_timings: prompt eval time =     288.80 ms /    88 tokens (    3.28 ms per token,   304.71 tokens per second)\n",
            "llama_print_timings:        eval time =    1608.22 ms /    15 runs   (  107.21 ms per token,     9.33 tokens per second)\n",
            "llama_print_timings:       total time =    2142.74 ms /   103 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@PabloEchenique The mouth with teeth is by Irene Montero Mujer Vase. She moved it herself and she said the words. No matter how many dies you take, no matter how fast you speak and how much you move your hand, you won't be right. And no matter how much you repeat it, it doesn't change, we've all heard it.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.33 ms /    16 runs   (    0.58 ms per token,  1715.63 tokens per second)\n",
            "llama_print_timings: prompt eval time =     281.24 ms /    75 tokens (    3.75 ms per token,   266.67 tokens per second)\n",
            "llama_print_timings:        eval time =    1507.36 ms /    15 runs   (  100.49 ms per token,     9.95 tokens per second)\n",
            "llama_print_timings:       total time =    2001.91 ms /    90 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@SaraSalamo The feminism of the vase woman, the environmentalism of the rich woman who goes on a yacht, the lessons of the one who does nothing... and you still want people not to give their opinion about your hypocrisy. Don't try to call it machismo that doesn't work, queen!\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.66 ms /    16 runs   (    0.54 ms per token,  1848.43 tokens per second)\n",
            "llama_print_timings: prompt eval time =     551.14 ms /    19 tokens (   29.01 ms per token,    34.47 tokens per second)\n",
            "llama_print_timings:        eval time =    1530.75 ms /    15 runs   (  102.05 ms per token,     9.80 tokens per second)\n",
            "llama_print_timings:       total time =    2188.02 ms /    34 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@abersta hey please let me have studies I am a free woman\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.36 ms /    16 runs   (    0.71 ms per token,  1408.08 tokens per second)\n",
            "llama_print_timings: prompt eval time =     252.50 ms /    44 tokens (    5.74 ms per token,   174.26 tokens per second)\n",
            "llama_print_timings:        eval time =    1916.06 ms /    15 runs   (  127.74 ms per token,     7.83 tokens per second)\n",
            "llama_print_timings:       total time =    2365.50 ms /    59 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@__huesitos I have never used these services, but if a free woman freely decides to have sex in exchange for money with X or Y. Who are you to decide for that woman?\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.98 ms /    16 runs   (    0.56 ms per token,  1781.34 tokens per second)\n",
            "llama_print_timings: prompt eval time =     247.97 ms /    41 tokens (    6.05 ms per token,   165.34 tokens per second)\n",
            "llama_print_timings:        eval time =    1524.84 ms /    15 runs   (  101.66 ms per token,     9.84 tokens per second)\n",
            "llama_print_timings:       total time =    1917.57 ms /    56 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "I like the dietThe tonedGymSexoI love feeling lovedBeing a free woman https://t.co/nRmTkL1LP9\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.07 ms /    16 runs   (    0.57 ms per token,  1764.25 tokens per second)\n",
            "llama_print_timings: prompt eval time =     734.04 ms /    28 tokens (   26.22 ms per token,    38.15 tokens per second)\n",
            "llama_print_timings:        eval time =    1494.86 ms /    15 runs   (   99.66 ms per token,    10.03 tokens per second)\n",
            "llama_print_timings:       total time =    2355.98 ms /    43 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "A man sees a free woman = \"She's a joke.\" When the hell are they going to change?\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.16 ms /    16 runs   (    0.64 ms per token,  1574.65 tokens per second)\n",
            "llama_print_timings: prompt eval time =     243.20 ms /    53 tokens (    4.59 ms per token,   217.93 tokens per second)\n",
            "llama_print_timings:        eval time =    1564.71 ms /    15 runs   (  104.31 ms per token,     9.59 tokens per second)\n",
            "llama_print_timings:       total time =    1989.28 ms /    68 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "the untraditional phrases of a free woman and a single man. AND THAT WAS THE MOST BEAUTIFUL NIGHT IN THE WORLD EVEN THOUGH IT LASTED ONLY ONE SECOND\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.11 ms /    16 runs   (    0.69 ms per token,  1440.40 tokens per second)\n",
            "llama_print_timings: prompt eval time =     895.56 ms /    29 tokens (   30.88 ms per token,    32.38 tokens per second)\n",
            "llama_print_timings:        eval time =    1875.58 ms /    15 runs   (  125.04 ms per token,     8.00 tokens per second)\n",
            "llama_print_timings:       total time =    2972.79 ms /    44 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@KHdezmd And you? Do you like them all or just 1? Free Woman vs Free Man\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.02 ms /    16 runs   (    0.56 ms per token,  1773.64 tokens per second)\n",
            "llama_print_timings: prompt eval time =     267.65 ms /    62 tokens (    4.32 ms per token,   231.65 tokens per second)\n",
            "llama_print_timings:        eval time =    1562.37 ms /    15 runs   (  104.16 ms per token,     9.60 tokens per second)\n",
            "llama_print_timings:       total time =    2020.13 ms /    77 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "inalienable of myself. Telling bizarre things too, but I would do that even if I were a cashier. Yes, people like that also exist: those who don't value you for being a good, obedient woman, but for your human quality.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.10 ms /    16 runs   (    0.63 ms per token,  1583.53 tokens per second)\n",
            "llama_print_timings: prompt eval time =     281.49 ms /    77 tokens (    3.66 ms per token,   273.54 tokens per second)\n",
            "llama_print_timings:        eval time =    1534.57 ms /    15 runs   (  102.30 ms per token,     9.77 tokens per second)\n",
            "llama_print_timings:       total time =    2045.30 ms /    92 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@CasioLongino @EgualdadGob The plan is clear. The feminist charocracy wants to turn men into the worst stereotype of obedient and submissive women from before the civil war, to take revenge for their historical traumas and their hatred and resentment. Or we stop them ......\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       3.17 ms /     5 runs   (    0.63 ms per token,  1579.28 tokens per second)\n",
            "llama_print_timings: prompt eval time =     284.47 ms /    70 tokens (    4.06 ms per token,   246.07 tokens per second)\n",
            "llama_print_timings:        eval time =     413.26 ms /     4 runs   (  103.31 ms per token,     9.68 tokens per second)\n",
            "llama_print_timings:       total time =     857.23 ms /    74 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@MonederoJC @abc_es The obedient, quiet and submissive woman whose only right is to give birth. And I wonder... why is it that the male sex is obsessed with having a pet and not a partner who thinks, who works, and if she wants, she has children?\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.32 ms /    16 runs   (    0.71 ms per token,  1413.93 tokens per second)\n",
            "llama_print_timings: prompt eval time =     300.92 ms /    90 tokens (    3.34 ms per token,   299.08 tokens per second)\n",
            "llama_print_timings:        eval time =    1897.41 ms /    15 runs   (  126.49 ms per token,     7.91 tokens per second)\n",
            "llama_print_timings:       total time =    2635.89 ms /   105 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@josecarmelopaz @Mariorun85 @CarlRamirezA And I say “it reminds you” because neither you nor I know for sure what it was like…. Only her physical appearance is presupposed by the beauty that she represents in writing as a great woman, obedient, firm and mother of our Lord... .. just like Jesus... We do not eat his face\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.80 ms /    16 runs   (    0.61 ms per token,  1631.99 tokens per second)\n",
            "llama_print_timings: prompt eval time =     280.75 ms /    77 tokens (    3.65 ms per token,   274.26 tokens per second)\n",
            "llama_print_timings:        eval time =    1510.88 ms /    15 runs   (  100.73 ms per token,     9.93 tokens per second)\n",
            "llama_print_timings:       total time =    2024.62 ms /    92 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Girls, teenagers, and \"well-behaved\" women give me a very strange feeling because I was one and in many ways I still am. I don't want to see even one \"obedient\" \"well-behaved\" woman because that's how they brainwash us to take away our freedom.\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.06 ms /    16 runs   (    0.57 ms per token,  1766.20 tokens per second)\n",
            "llama_print_timings: prompt eval time =     759.91 ms /    30 tokens (   25.33 ms per token,    39.48 tokens per second)\n",
            "llama_print_timings:        eval time =    1475.90 ms /    15 runs   (   98.39 ms per token,    10.16 tokens per second)\n",
            "llama_print_timings:       total time =    2365.06 ms /    45 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@TainimLaFuria In summary: an obedient woman, without experience, who does not go out\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.34 ms /    16 runs   (    0.58 ms per token,  1713.80 tokens per second)\n",
            "llama_print_timings: prompt eval time =     659.65 ms /    26 tokens (   25.37 ms per token,    39.41 tokens per second)\n",
            "llama_print_timings:        eval time =    1499.37 ms /    15 runs   (   99.96 ms per token,    10.00 tokens per second)\n",
            "llama_print_timings:       total time =    2284.36 ms /    41 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@YuniskiD She is the rebellious woman of #Bitcoin, no matter what she does\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.48 ms /    16 runs   (    0.59 ms per token,  1687.41 tokens per second)\n",
            "llama_print_timings: prompt eval time =     284.66 ms /    69 tokens (    4.13 ms per token,   242.39 tokens per second)\n",
            "llama_print_timings:        eval time =    1617.76 ms /    15 runs   (  107.85 ms per token,     9.27 tokens per second)\n",
            "llama_print_timings:       total time =    2105.63 ms /    84 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Happy to accompany our beloved @gmcarrasco in her possession as advisor to the Ministry of Education. A rebellious woman, passionate and committed to social justice and education. The country gains a lot with a public servant like her. https://t.co/ef2boYyL27\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.35 ms /    16 runs   (    0.58 ms per token,  1711.23 tokens per second)\n",
            "llama_print_timings: prompt eval time =     280.26 ms /    71 tokens (    3.95 ms per token,   253.34 tokens per second)\n",
            "llama_print_timings:        eval time =    1609.52 ms /    15 runs   (  107.30 ms per token,     9.32 tokens per second)\n",
            "llama_print_timings:       total time =    2096.64 ms /    86 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Donatella presented a goth collection for Spring 2023. Platforms, black leather, lace... \"I have always liked a rebellious, confident, intelligent and a little diva woman\" - #Versace told the press. https://t.co/8w8pAYeOPR\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.55 ms /    16 runs   (    0.60 ms per token,  1674.69 tokens per second)\n",
            "llama_print_timings: prompt eval time =     277.54 ms /    87 tokens (    3.19 ms per token,   313.46 tokens per second)\n",
            "llama_print_timings:        eval time =    1517.64 ms /    15 runs   (  101.18 ms per token,     9.88 tokens per second)\n",
            "llama_print_timings:       total time =    2031.17 ms /   102 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@radionica @SimonaSanchez @marianavelezga @lavozgerald Good day everyoneThe rebellious woman who inspires me is the First Female Drummer of Colombia.Angela Isaza Drummer of (La Gran Sociedad Del Estado) Pure Colombian Rock from the early 70's.ROCK AND HEALTH for all!!\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      12.54 ms /    16 runs   (    0.78 ms per token,  1275.92 tokens per second)\n",
            "llama_print_timings: prompt eval time =     248.16 ms /    44 tokens (    5.64 ms per token,   177.30 tokens per second)\n",
            "llama_print_timings:        eval time =    1857.80 ms /    15 runs   (  123.85 ms per token,     8.07 tokens per second)\n",
            "llama_print_timings:       total time =    2376.81 ms /    59 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "The Rebel Woman: The Story of Margaret SangerA book by Peter Bagge at @LaCupulaComichttps://t.co/ouy2qxjgnZ\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.49 ms /    16 runs   (    0.59 ms per token,  1685.99 tokens per second)\n",
            "llama_print_timings: prompt eval time =     682.44 ms /    25 tokens (   27.30 ms per token,    36.63 tokens per second)\n",
            "llama_print_timings:        eval time =    1486.69 ms /    15 runs   (   99.11 ms per token,    10.09 tokens per second)\n",
            "llama_print_timings:       total time =    2291.46 ms /    40 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@gabimgaona_ There is no rebellious woman, only lazy gaucho love.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.09 ms /    16 runs   (    0.57 ms per token,  1759.79 tokens per second)\n",
            "llama_print_timings: prompt eval time =     235.29 ms /    33 tokens (    7.13 ms per token,   140.25 tokens per second)\n",
            "llama_print_timings:        eval time =    1551.56 ms /    15 runs   (  103.44 ms per token,     9.67 tokens per second)\n",
            "llama_print_timings:       total time =    1922.75 ms /    48 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@AndreaButelmann @AdrianaValdes8 @VpAmaro She is most likely a submissive woman.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.33 ms /    16 runs   (    0.58 ms per token,  1715.63 tokens per second)\n",
            "llama_print_timings: prompt eval time =     286.88 ms /    89 tokens (    3.22 ms per token,   310.24 tokens per second)\n",
            "llama_print_timings:        eval time =    1487.46 ms /    15 runs   (   99.16 ms per token,    10.08 tokens per second)\n",
            "llama_print_timings:       total time =    2023.45 ms /   104 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "+In said chapter 138, Naoya has this conversation with the Twins' mother, where she implies that \"they have the same face and is equal to her\" but highlights that Mai is better material as a submissive woman. Furthermore, it seems that being a woman within the Zenin clan was a hostile place https://t.co/c4xWlZYl6S\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      12.85 ms /    16 runs   (    0.80 ms per token,  1245.62 tokens per second)\n",
            "llama_print_timings: prompt eval time =     256.71 ms /    50 tokens (    5.13 ms per token,   194.78 tokens per second)\n",
            "llama_print_timings:        eval time =    1942.73 ms /    15 runs   (  129.52 ms per token,     7.72 tokens per second)\n",
            "llama_print_timings:       total time =    2473.59 ms /    65 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Lala_lena @MemeYamelCA It is incredible that Mexican culture has not changed anything in the last century. The useless man in the house and the submissive and egg-keeping woman.\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.04 ms /    16 runs   (    0.63 ms per token,  1592.83 tokens per second)\n",
            "llama_print_timings: prompt eval time =     291.87 ms /    89 tokens (    3.28 ms per token,   304.93 tokens per second)\n",
            "llama_print_timings:        eval time =    1540.34 ms /    15 runs   (  102.69 ms per token,     9.74 tokens per second)\n",
            "llama_print_timings:       total time =    2080.38 ms /   104 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Beautiful is the woman who imposes her character, even at the risk of being left alone, rather than the submissive woman who endures everything for fear of being alone. 💁🏾‍♀️😎#04Ago #04Agosto #FolloMe #SiguemeYTeSigo https://t.co/4Ckb3zBIUi\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.62 ms /    16 runs   (    0.54 ms per token,  1855.07 tokens per second)\n",
            "llama_print_timings: prompt eval time =     299.54 ms /    94 tokens (    3.19 ms per token,   313.82 tokens per second)\n",
            "llama_print_timings:        eval time =    1542.67 ms /    15 runs   (  102.84 ms per token,     9.72 tokens per second)\n",
            "llama_print_timings:       total time =    2113.66 ms /   109 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Santiago6400 @cmgorriaran @IreneMontero Seriously, Carlos, you believe what you say. The church for 40 years made women submissive. Of those 2000000 years, women have been able to emancipate themselves in the last 80 years. You think we are jilipoyas like the Catholics.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.08 ms /    16 runs   (    0.63 ms per token,  1587.46 tokens per second)\n",
            "llama_print_timings: prompt eval time =     244.37 ms /    44 tokens (    5.55 ms per token,   180.05 tokens per second)\n",
            "llama_print_timings:        eval time =    1820.20 ms /    15 runs   (  121.35 ms per token,     8.24 tokens per second)\n",
            "llama_print_timings:       total time =    2249.40 ms /    59 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Beautiful is the woman who imposes her character, even at the risk of being left alone, rather than the submissive woman, who endures everything for fear of being alone.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.67 ms /    16 runs   (    0.60 ms per token,  1655.46 tokens per second)\n",
            "llama_print_timings: prompt eval time =     255.71 ms /    55 tokens (    4.65 ms per token,   215.08 tokens per second)\n",
            "llama_print_timings:        eval time =    1611.38 ms /    15 runs   (  107.43 ms per token,     9.31 tokens per second)\n",
            "llama_print_timings:       total time =    2057.84 ms /    70 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@maxijimenez Hahahaha I saw it for a while, beyond the comical aspect, the guy came out to defend his wife, one may or may not agree, but in the discussion Lavin Jr did well in my opinion\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.33 ms /    16 runs   (    0.52 ms per token,  1919.85 tokens per second)\n",
            "llama_print_timings: prompt eval time =     254.49 ms /    38 tokens (    6.70 ms per token,   149.32 tokens per second)\n",
            "llama_print_timings:        eval time =    1511.28 ms /    15 runs   (  100.75 ms per token,     9.93 tokens per second)\n",
            "llama_print_timings:       total time =    1925.12 ms /    53 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@liscuestacuba God, what a ridiculous woman she is with the old woman she is 💩💩💩\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.90 ms /    16 runs   (    0.56 ms per token,  1796.74 tokens per second)\n",
            "llama_print_timings: prompt eval time =     251.69 ms /    39 tokens (    6.45 ms per token,   154.95 tokens per second)\n",
            "llama_print_timings:        eval time =    1546.46 ms /    15 runs   (  103.10 ms per token,     9.70 tokens per second)\n",
            "llama_print_timings:       total time =    1948.08 ms /    54 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@santiagobucaram @johacalderon11 @betcrisecuador Ronaldinho fell in love with so much beauty of a woman\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.12 ms /    16 runs   (    0.70 ms per token,  1438.20 tokens per second)\n",
            "llama_print_timings: prompt eval time =     255.92 ms /    61 tokens (    4.20 ms per token,   238.36 tokens per second)\n",
            "llama_print_timings:        eval time =    1810.69 ms /    15 runs   (  120.71 ms per token,     8.28 tokens per second)\n",
            "llama_print_timings:       total time =    2281.28 ms /    76 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "I will never forget when Sofí goes for a lazy guy, maybe he has a girlfriend and I look at him and tell him he has a wife and two children hahahahaha poor thing my baby https://t.co/PhLWiP0OWT\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.67 ms /    16 runs   (    0.60 ms per token,  1655.29 tokens per second)\n",
            "llama_print_timings: prompt eval time =     284.81 ms /    91 tokens (    3.13 ms per token,   319.52 tokens per second)\n",
            "llama_print_timings:        eval time =    1534.86 ms /    15 runs   (  102.32 ms per token,     9.77 tokens per second)\n",
            "llama_print_timings:       total time =    2070.80 ms /   106 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Depends. Although we are men, we are not all equal. My wife and I are going to be together for 4 years, and we met here. I have made friends here. It all depends on the type of person one is. Are you personal, or impersonal? When you write do you forget who you are? And so... https://t.co/rvfCCG4HbV\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.50 ms /    16 runs   (    0.72 ms per token,  1391.30 tokens per second)\n",
            "llama_print_timings: prompt eval time =     291.88 ms /    81 tokens (    3.60 ms per token,   277.52 tokens per second)\n",
            "llama_print_timings:        eval time =    1878.59 ms /    15 runs   (  125.24 ms per token,     7.98 tokens per second)\n",
            "llama_print_timings:       total time =    2433.28 ms /    96 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@lorenmontalvo @annyestherburg @HazimNoelia you already know: the pregnant human \"neutralizes\" the effect of the medicines that the woman requires to treat her condition and, therefore, it must be killed. They look for any case to promote the agenda! https://t.co/cu0S3mj6RV\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.09 ms /    16 runs   (    0.57 ms per token,  1760.18 tokens per second)\n",
            "llama_print_timings: prompt eval time =     248.55 ms /    38 tokens (    6.54 ms per token,   152.88 tokens per second)\n",
            "llama_print_timings:        eval time =    1630.08 ms /    15 runs   (  108.67 ms per token,     9.20 tokens per second)\n",
            "llama_print_timings:       total time =    2027.01 ms /    53 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@latinus_us Take it so that women learn not to be \"worshipping\" the 4T and Morena! Don't they have dignity?\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.39 ms /    16 runs   (    0.52 ms per token,  1907.26 tokens per second)\n",
            "llama_print_timings: prompt eval time =     769.68 ms /    29 tokens (   26.54 ms per token,    37.68 tokens per second)\n",
            "llama_print_timings:        eval time =    1584.05 ms /    15 runs   (  105.60 ms per token,     9.47 tokens per second)\n",
            "llama_print_timings:       total time =    2478.73 ms /    44 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Women in the Garden, Claude Monet. https://t.co/9ia9FWUxZC\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.26 ms /    16 runs   (    0.58 ms per token,  1727.49 tokens per second)\n",
            "llama_print_timings: prompt eval time =     245.63 ms /    42 tokens (    5.85 ms per token,   170.99 tokens per second)\n",
            "llama_print_timings:        eval time =    1601.32 ms /    15 runs   (  106.75 ms per token,     9.37 tokens per second)\n",
            "llama_print_timings:       total time =    2010.27 ms /    57 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Using the feminism card to defend a mediocre performance is disrespectful to women who fight daily to win spaces where we are invisible. You really give me extreme allergies.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.92 ms /    16 runs   (    0.74 ms per token,  1342.51 tokens per second)\n",
            "llama_print_timings: prompt eval time =     253.38 ms /    48 tokens (    5.28 ms per token,   189.44 tokens per second)\n",
            "llama_print_timings:        eval time =    1821.88 ms /    15 runs   (  121.46 ms per token,     8.23 tokens per second)\n",
            "llama_print_timings:       total time =    2342.88 ms /    63 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "It is important to highlight that all the trees that have been planted are adaptable to the area. The main purpose of this project is to diversify the diet and food production of peasant women and their families.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.23 ms /    16 runs   (    0.51 ms per token,  1943.87 tokens per second)\n",
            "llama_print_timings: prompt eval time =     712.48 ms /    26 tokens (   27.40 ms per token,    36.49 tokens per second)\n",
            "llama_print_timings:        eval time =    1537.60 ms /    15 runs   (  102.51 ms per token,     9.76 tokens per second)\n",
            "llama_print_timings:       total time =    2368.15 ms /    41 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "I grew up fighting with my brotherSo you women don't scare me.😌\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.50 ms /    16 runs   (    0.59 ms per token,  1684.21 tokens per second)\n",
            "llama_print_timings: prompt eval time =     280.51 ms /    78 tokens (    3.60 ms per token,   278.07 tokens per second)\n",
            "llama_print_timings:        eval time =    1589.52 ms /    15 runs   (  105.97 ms per token,     9.44 tokens per second)\n",
            "llama_print_timings:       total time =    2086.81 ms /    93 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "I'm sure you've heard terms like NoMo, pank, neomamma or shahm. They are terms that have emerged recently and that refer to different social conditions of women. and today I explain it to you in #MejorconGabyVargasNoMohttps://t.co/WScIm2Jc3S\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.01 ms /    16 runs   (    0.63 ms per token,  1597.76 tokens per second)\n",
            "llama_print_timings: prompt eval time =     286.68 ms /    89 tokens (    3.22 ms per token,   310.45 tokens per second)\n",
            "llama_print_timings:        eval time =    1576.43 ms /    15 runs   (  105.10 ms per token,     9.52 tokens per second)\n",
            "llama_print_timings:       total time =    2115.40 ms /   104 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@IvanMontalvo52 @rafaeldelgado20 You have stolen not a single real from us but you are full of hate, you repeat gossip without evidence, you accuse, you denigrate without support, and from within you the human filth that you carry inside has come out and the country really does not need a man who lives under gossip, hate evil lie.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.31 ms /    16 runs   (    0.64 ms per token,  1551.74 tokens per second)\n",
            "llama_print_timings: prompt eval time =     267.78 ms /    50 tokens (    5.36 ms per token,   186.72 tokens per second)\n",
            "llama_print_timings:        eval time =    1681.69 ms /    15 runs   (  112.11 ms per token,     8.92 tokens per second)\n",
            "llama_print_timings:       total time =    2214.69 ms /    65 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@ryo_hermoso YES, MEXICO NEEDS A MAN LIKE HIM...IN AN URGENT QUALITY https://t.co/xEiah52pHl\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.07 ms /    16 runs   (    0.57 ms per token,  1763.47 tokens per second)\n",
            "llama_print_timings: prompt eval time =     681.02 ms /    25 tokens (   27.24 ms per token,    36.71 tokens per second)\n",
            "llama_print_timings:        eval time =    1600.90 ms /    15 runs   (  106.73 ms per token,     9.37 tokens per second)\n",
            "llama_print_timings:       total time =    2402.45 ms /    40 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@guz_bravo That bitch needs a man, not a girl like the one who married her\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.43 ms /    16 runs   (    0.59 ms per token,  1696.17 tokens per second)\n",
            "llama_print_timings: prompt eval time =     252.31 ms /    48 tokens (    5.26 ms per token,   190.24 tokens per second)\n",
            "llama_print_timings:        eval time =    1541.14 ms /    15 runs   (  102.74 ms per token,     9.73 tokens per second)\n",
            "llama_print_timings:       total time =    1959.20 ms /    63 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@VaqueraUSA Needs a Man to take away those Aberrations! Please get Margarita Bernardo to do a show for her at least, so she can calm down! One NA' more!\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.19 ms /    16 runs   (    0.64 ms per token,  1570.63 tokens per second)\n",
            "llama_print_timings: prompt eval time =     264.06 ms /    52 tokens (    5.08 ms per token,   196.93 tokens per second)\n",
            "llama_print_timings:        eval time =    1851.34 ms /    15 runs   (  123.42 ms per token,     8.10 tokens per second)\n",
            "llama_print_timings:       total time =    2395.28 ms /    67 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "The feminist, the empowered, the one without fear of success, the one who doesn't need a man... 🤣🤣🤣🤣🤣🤣 what one finds out on social media. 🤣🤣🤣🤣🤣🤣\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.42 ms /    16 runs   (    0.53 ms per token,  1899.79 tokens per second)\n",
            "llama_print_timings: prompt eval time =     768.72 ms /    30 tokens (   25.62 ms per token,    39.03 tokens per second)\n",
            "llama_print_timings:        eval time =    1547.65 ms /    15 runs   (  103.18 ms per token,     9.69 tokens per second)\n",
            "llama_print_timings:       total time =    2444.14 ms /    45 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "A tall woman needs a tall man A short woman also needs a tall man Short men can fall in love with each other!\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.79 ms /    16 runs   (    0.55 ms per token,  1820.25 tokens per second)\n",
            "llama_print_timings: prompt eval time =     263.53 ms /    72 tokens (    3.66 ms per token,   273.22 tokens per second)\n",
            "llama_print_timings:        eval time =    1497.77 ms /    15 runs   (   99.85 ms per token,    10.01 tokens per second)\n",
            "llama_print_timings:       total time =    1973.38 ms /    87 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Rbn_cnls @TDL06757591 @Gimledas @PEPEGOTERAYOTI9 @mariaa__75 I'm back, you'll be happy, right, babe??😘🤮🖕🤡\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.48 ms /    16 runs   (    0.59 ms per token,  1688.30 tokens per second)\n",
            "llama_print_timings: prompt eval time =     310.12 ms /   112 tokens (    2.77 ms per token,   361.15 tokens per second)\n",
            "llama_print_timings:        eval time =    1540.69 ms /    15 runs   (  102.71 ms per token,     9.74 tokens per second)\n",
            "llama_print_timings:       total time =    2162.30 ms /   127 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@noseaspetronto @julesnroll @MunozMenco @soy_gilbert Zero capacity and coherence to answer that you resort to tacky insults, nonsense even to insult...x it's true that you are one of those that even if others cut the topic, you act oblivious to cut it yourself, childish at that. I can't hahaha, goodbye, I'm going to cure the pupae of your offenses😭😭\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      12.41 ms /    16 runs   (    0.78 ms per token,  1289.80 tokens per second)\n",
            "llama_print_timings: prompt eval time =     275.93 ms /    70 tokens (    3.94 ms per token,   253.69 tokens per second)\n",
            "llama_print_timings:        eval time =    1710.16 ms /    15 runs   (  114.01 ms per token,     8.77 tokens per second)\n",
            "llama_print_timings:       total time =    2323.30 ms /    85 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@santicalvicidad @dianafasc With that approach I only see two options: That she catches a girl from those new masculinities of PSOE/C's Or a second one, that she becomes a lesbian. With a normal guy she has no option of achieving anything serious.\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.79 ms /    16 runs   (    0.61 ms per token,  1634.82 tokens per second)\n",
            "llama_print_timings: prompt eval time =     307.63 ms /   110 tokens (    2.80 ms per token,   357.57 tokens per second)\n",
            "llama_print_timings:        eval time =    1537.43 ms /    15 runs   (  102.50 ms per token,     9.76 tokens per second)\n",
            "llama_print_timings:       total time =    2149.17 ms /   125 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@MonederoJC @joaquinaraujo @sunsplash_es @amturiel @JuanBordera Of course the world is an idiot for you ha ha ha but you are the son of a big bitch, a bastard, a sucker and a faggot, what a piece of FOOL, the only thing you are good for is being in twitter and put others in the dark. Get to work LAMB. Now you block me and maybe Twitter does too\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.14 ms /    16 runs   (    0.57 ms per token,  1751.12 tokens per second)\n",
            "llama_print_timings: prompt eval time =     244.68 ms /    49 tokens (    4.99 ms per token,   200.26 tokens per second)\n",
            "llama_print_timings:        eval time =    1551.84 ms /    15 runs   (  103.46 ms per token,     9.67 tokens per second)\n",
            "llama_print_timings:       total time =    1960.03 ms /    64 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "He could perfectly well be the holy debot of the left but since he's a sissy he's not going to do it. https://t.co/gEcWnv4ov9\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       3.33 ms /     5 runs   (    0.67 ms per token,  1502.40 tokens per second)\n",
            "llama_print_timings: prompt eval time =     261.03 ms /    53 tokens (    4.93 ms per token,   203.04 tokens per second)\n",
            "llama_print_timings:        eval time =     468.45 ms /     4 runs   (  117.11 ms per token,     8.54 tokens per second)\n",
            "llama_print_timings:       total time =     868.11 ms /    57 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@elmundoes Those who put their pussy as their flag and ride the male Alfalfa for a https://t.co/f5iwgb7pww biggest hen that exists is him.NENAZA.\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.96 ms /    16 runs   (    0.69 ms per token,  1459.32 tokens per second)\n",
            "llama_print_timings: prompt eval time =     245.88 ms /    51 tokens (    4.82 ms per token,   207.42 tokens per second)\n",
            "llama_print_timings:        eval time =    1730.37 ms /    15 runs   (  115.36 ms per token,     8.67 tokens per second)\n",
            "llama_print_timings:       total time =    2258.61 ms /    66 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@IdiazAyuso You are a stupid, unsupportive scoundrel who thinks you are the navel of the world and you are nothing more than a poorly educated girl that many Madrid residents laugh at and you have no\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.17 ms /    16 runs   (    0.57 ms per token,  1745.39 tokens per second)\n",
            "llama_print_timings: prompt eval time =     622.75 ms /    23 tokens (   27.08 ms per token,    36.93 tokens per second)\n",
            "llama_print_timings:        eval time =    1623.87 ms /    15 runs   (  108.26 ms per token,     9.24 tokens per second)\n",
            "llama_print_timings:       total time =    2364.98 ms /    38 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@trifasico__ If envy kills you, die girl 😘\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.82 ms /    16 runs   (    0.55 ms per token,  1814.88 tokens per second)\n",
            "llama_print_timings: prompt eval time =     244.79 ms /    35 tokens (    6.99 ms per token,   142.98 tokens per second)\n",
            "llama_print_timings:        eval time =    1568.07 ms /    15 runs   (  104.54 ms per token,     9.57 tokens per second)\n",
            "llama_print_timings:       total time =    1948.36 ms /    50 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@IreneMontero @ionebelarra No brat. That is the objective of the Spanish OUT, the Super awaits you\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.70 ms /    16 runs   (    0.54 ms per token,  1838.66 tokens per second)\n",
            "llama_print_timings: prompt eval time =     252.15 ms /    46 tokens (    5.48 ms per token,   182.43 tokens per second)\n",
            "llama_print_timings:        eval time =    1555.65 ms /    15 runs   (  103.71 ms per token,     9.64 tokens per second)\n",
            "llama_print_timings:       total time =    1965.93 ms /    61 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Me and my good luck with EVERYTHING that I get from a bitter lady who calls me a rude brat for getting up from my chair to enjoy the concert HAHAHAHAHAHAHA\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.72 ms /    16 runs   (    0.61 ms per token,  1645.41 tokens per second)\n",
            "llama_print_timings: prompt eval time =     265.24 ms /    35 tokens (    7.58 ms per token,   131.96 tokens per second)\n",
            "llama_print_timings:        eval time =    1778.48 ms /    15 runs   (  118.57 ms per token,     8.43 tokens per second)\n",
            "llama_print_timings:       total time =    2252.33 ms /    50 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@ionebelarra @PabloEchenique Don't carburize, good little girl, uselesslll perrofluuta\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.55 ms /    16 runs   (    0.53 ms per token,  1870.69 tokens per second)\n",
            "llama_print_timings: prompt eval time =     258.07 ms /    42 tokens (    6.14 ms per token,   162.75 tokens per second)\n",
            "llama_print_timings:        eval time =    1540.61 ms /    15 runs   (  102.71 ms per token,     9.74 tokens per second)\n",
            "llama_print_timings:       total time =    1947.62 ms /    57 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "God can't get me off Galadriel's ship, little girl, full on with her movie https://t.co/IPqw9B739q\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.37 ms /    16 runs   (    0.59 ms per token,  1708.49 tokens per second)\n",
            "llama_print_timings: prompt eval time =     582.11 ms /    22 tokens (   26.46 ms per token,    37.79 tokens per second)\n",
            "llama_print_timings:        eval time =    1617.65 ms /    15 runs   (  107.84 ms per token,     9.27 tokens per second)\n",
            "llama_print_timings:       total time =    2312.31 ms /    37 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Not all men are equal, one is always worse than the previous one hahaha\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.24 ms /    16 runs   (    0.58 ms per token,  1732.35 tokens per second)\n",
            "llama_print_timings: prompt eval time =     251.75 ms /    54 tokens (    4.66 ms per token,   214.50 tokens per second)\n",
            "llama_print_timings:        eval time =    1707.60 ms /    15 runs   (  113.84 ms per token,     8.78 tokens per second)\n",
            "llama_print_timings:       total time =    2146.62 ms /    69 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@MeenaKamal12 But, it is true that women are the most beautiful thing in the world, it is not a saying, it is a reality. What is true is that not all men see it the same way.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.62 ms /    16 runs   (    0.54 ms per token,  1855.72 tokens per second)\n",
            "llama_print_timings: prompt eval time =     773.69 ms /    22 tokens (   35.17 ms per token,    28.44 tokens per second)\n",
            "llama_print_timings:        eval time =    1515.34 ms /    15 runs   (  101.02 ms per token,     9.90 tokens per second)\n",
            "llama_print_timings:       total time =    2434.81 ms /    37 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "All a woman wants is a man who shows that not all men are the same.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.78 ms /    16 runs   (    0.55 ms per token,  1822.74 tokens per second)\n",
            "llama_print_timings: prompt eval time =     249.39 ms /    41 tokens (    6.08 ms per token,   164.40 tokens per second)\n",
            "llama_print_timings:        eval time =    1597.81 ms /    15 runs   (  106.52 ms per token,     9.39 tokens per second)\n",
            "llama_print_timings:       total time =    1993.43 ms /    56 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "And then they dare to say that not all men are the same. They even have the phrases preloaded https://t.co/xkXzo43jYc\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.76 ms /    16 runs   (    0.55 ms per token,  1826.69 tokens per second)\n",
            "llama_print_timings: prompt eval time =     613.01 ms /    24 tokens (   25.54 ms per token,    39.15 tokens per second)\n",
            "llama_print_timings:        eval time =    1571.23 ms /    15 runs   (  104.75 ms per token,     9.55 tokens per second)\n",
            "llama_print_timings:       total time =    2297.97 ms /    39 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Not all men are equal, there are Xiao Zhan and Wang Yibo duh\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.03 ms /    16 runs   (    0.69 ms per token,  1450.19 tokens per second)\n",
            "llama_print_timings: prompt eval time =     252.63 ms /    61 tokens (    4.14 ms per token,   241.46 tokens per second)\n",
            "llama_print_timings:        eval time =    1824.19 ms /    15 runs   (  121.61 ms per token,     8.22 tokens per second)\n",
            "llama_print_timings:       total time =    2284.97 ms /    76 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "The first thing is respect and the second is that we are treated as equals in any area you can imagine. Not all men are looking for the same thing, just like we women are not, but a relationship that does not begin with education and respect is doomed to failure.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.99 ms /    16 runs   (    0.56 ms per token,  1779.56 tokens per second)\n",
            "llama_print_timings: prompt eval time =     259.62 ms /    54 tokens (    4.81 ms per token,   208.00 tokens per second)\n",
            "llama_print_timings:        eval time =    1534.95 ms /    15 runs   (  102.33 ms per token,     9.77 tokens per second)\n",
            "llama_print_timings:       total time =    1987.70 ms /    69 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "You don't give a shit about the kids in the video, otherwise you wouldn't say that where are the women? You would say that what are they doing doing that shit? They only take the opportunity to hate women for free.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.46 ms /    16 runs   (    0.53 ms per token,  1891.48 tokens per second)\n",
            "llama_print_timings: prompt eval time =     254.39 ms /    43 tokens (    5.92 ms per token,   169.03 tokens per second)\n",
            "llama_print_timings:        eval time =    1493.39 ms /    15 runs   (   99.56 ms per token,    10.04 tokens per second)\n",
            "llama_print_timings:       total time =    1899.22 ms /    58 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "She tells me “I'm not like everyone else.” Queen, you caught me at the moment where I hate women the most and where I don't believe anything jsjsjsjs\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.64 ms /    16 runs   (    0.54 ms per token,  1851.85 tokens per second)\n",
            "llama_print_timings: prompt eval time =     759.47 ms /    31 tokens (   24.50 ms per token,    40.82 tokens per second)\n",
            "llama_print_timings:        eval time =    1601.86 ms /    15 runs   (  106.79 ms per token,     9.36 tokens per second)\n",
            "llama_print_timings:       total time =    2488.99 ms /    46 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "The mines always hate men and such, I end up hating women and I end up hanging on the woman's bridge.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.90 ms /    16 runs   (    0.68 ms per token,  1467.49 tokens per second)\n",
            "llama_print_timings: prompt eval time =     290.03 ms /    73 tokens (    3.97 ms per token,   251.70 tokens per second)\n",
            "llama_print_timings:        eval time =    1759.65 ms /    15 runs   (  117.31 ms per token,     8.52 tokens per second)\n",
            "llama_print_timings:       total time =    2409.40 ms /    88 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "If a man kills a woman it is out of hatred for women and it is femicide, and if a woman kills a man the victim is the woman. Isn't anyone going to tell them enough is enough? How long are we going to tolerate this lack of respect for intelligence? Are we all hostages to feminism?\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.65 ms /    16 runs   (    0.60 ms per token,  1658.72 tokens per second)\n",
            "llama_print_timings: prompt eval time =     281.20 ms /    69 tokens (    4.08 ms per token,   245.38 tokens per second)\n",
            "llama_print_timings:        eval time =    1576.82 ms /    15 runs   (  105.12 ms per token,     9.51 tokens per second)\n",
            "llama_print_timings:       total time =    2061.83 ms /    84 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "It's one thing to do with black humor jokes and another thing to say through \"memes\": I hate women because I'm a Nazi, disgusting black people, haha ​​look I played the anthem Die Fahne Hoch! etc.... do not confuse being stupid with being stupid\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.55 ms /    16 runs   (    0.53 ms per token,  1871.78 tokens per second)\n",
            "llama_print_timings: prompt eval time =     525.21 ms /    19 tokens (   27.64 ms per token,    36.18 tokens per second)\n",
            "llama_print_timings:        eval time =    1585.80 ms /    15 runs   (  105.72 ms per token,     9.46 tokens per second)\n",
            "llama_print_timings:       total time =    2218.11 ms /    34 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "I hate women and I will never like one (I hate women)\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.55 ms /    16 runs   (    0.53 ms per token,  1871.78 tokens per second)\n",
            "llama_print_timings: prompt eval time =     253.68 ms /    37 tokens (    6.86 ms per token,   145.85 tokens per second)\n",
            "llama_print_timings:        eval time =    1505.03 ms /    15 runs   (  100.34 ms per token,     9.97 tokens per second)\n",
            "llama_print_timings:       total time =    1895.62 ms /    52 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Sandy gave romanticism to a very ugly and bad time to be a girl in this country! #Sandy #OliviaNewtonJohn 🥺\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.94 ms /    16 runs   (    0.56 ms per token,  1790.71 tokens per second)\n",
            "llama_print_timings: prompt eval time =     285.75 ms /    79 tokens (    3.62 ms per token,   276.47 tokens per second)\n",
            "llama_print_timings:        eval time =    1628.80 ms /    15 runs   (  108.59 ms per token,     9.21 tokens per second)\n",
            "llama_print_timings:       total time =    2152.47 ms /    94 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "What a shame that today there are still comments like the one they just made to me: “Well, for a girl, you play like a bitch mother.” How to be a girl???!!!! If this alpha male had told me “hey, you play very well,” he would have looked like a gentleman. The “to be a girl” was unnecessary.\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.32 ms /    16 runs   (    0.58 ms per token,  1716.37 tokens per second)\n",
            "llama_print_timings: prompt eval time =     289.90 ms /    85 tokens (    3.41 ms per token,   293.20 tokens per second)\n",
            "llama_print_timings:        eval time =    1611.83 ms /    15 runs   (  107.46 ms per token,     9.31 tokens per second)\n",
            "llama_print_timings:       total time =    2139.70 ms /   100 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "He got my number from the group, I didn't give it to him. It makes me feel stalked, in our little interaction she has said things like \"you can't beat me\" \"the students are tremendous, then they tell you that you are gay, and not how\" \"for a girl you are very fast\" \"how tremendous\" In your bitch life, old man\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.70 ms /    16 runs   (    0.61 ms per token,  1649.31 tokens per second)\n",
            "llama_print_timings: prompt eval time =     255.17 ms /    62 tokens (    4.12 ms per token,   242.98 tokens per second)\n",
            "llama_print_timings:        eval time =    1626.44 ms /    15 runs   (  108.43 ms per token,     9.22 tokens per second)\n",
            "llama_print_timings:       total time =    2069.98 ms /    77 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "| Sometimes yes, ehh, sometimes I have a somewhat deep voice for a girl, only sometimes and well... Those few times that I have put on the microphone they have tried to insult me ​​for that https://t.co/GsttitBj6Q\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.64 ms /    16 runs   (    0.60 ms per token,  1660.27 tokens per second)\n",
            "llama_print_timings: prompt eval time =     264.03 ms /    61 tokens (    4.33 ms per token,   231.03 tokens per second)\n",
            "llama_print_timings:        eval time =    1678.56 ms /    15 runs   (  111.90 ms per token,     8.94 tokens per second)\n",
            "llama_print_timings:       total time =    2232.04 ms /    76 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "3. He respects a thousand times when I tell him that one day I'm ready to be a girl, he doesn't see me as strange when I tell him that I want to be a girl and he makes me feel like the most beautiful and respected girl.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.17 ms /    16 runs   (    0.57 ms per token,  1745.77 tokens per second)\n",
            "llama_print_timings: prompt eval time =     256.81 ms /    46 tokens (    5.58 ms per token,   179.12 tokens per second)\n",
            "llama_print_timings:        eval time =    1561.61 ms /    15 runs   (  104.11 ms per token,     9.61 tokens per second)\n",
            "llama_print_timings:       total time =    1991.68 ms /    61 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Poor girl who even advertised to be a blue independence girl and at the mere hour they said that she could only get on if she was of legal age jjsjsjsjsjajjss\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.55 ms /    16 runs   (    0.53 ms per token,  1871.78 tokens per second)\n",
            "llama_print_timings: prompt eval time =     685.62 ms /    25 tokens (   27.42 ms per token,    36.46 tokens per second)\n",
            "llama_print_timings:        eval time =    1613.47 ms /    15 runs   (  107.56 ms per token,     9.30 tokens per second)\n",
            "llama_print_timings:       total time =    2413.71 ms /    40 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@DrTr00per Nothing like being a mutilated man to be a woman (?\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       3.81 ms /     5 runs   (    0.76 ms per token,  1313.72 tokens per second)\n",
            "llama_print_timings: prompt eval time =     283.68 ms /    74 tokens (    3.83 ms per token,   260.85 tokens per second)\n",
            "llama_print_timings:        eval time =     431.87 ms /     4 runs   (  107.97 ms per token,     9.26 tokens per second)\n",
            "llama_print_timings:       total time =     889.66 ms /    78 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@fannar_a @Davidcito_D87 @DonIzquierdo_ Alejandra, I have always said that women are much more intelligent than men, and I will always say it,... you, 🤔?, you made me look bad,...what a pain!!! So little brain to be a woman.\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.43 ms /    16 runs   (    0.59 ms per token,  1696.53 tokens per second)\n",
            "llama_print_timings: prompt eval time =     280.71 ms /    76 tokens (    3.69 ms per token,   270.74 tokens per second)\n",
            "llama_print_timings:        eval time =    1557.64 ms /    15 runs   (  103.84 ms per token,     9.63 tokens per second)\n",
            "llama_print_timings:       total time =    2060.82 ms /    91 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Wasn't Charles going to abdicate in favor of William? Why don't they say that in the United Kingdom many people are not in favor of the monarchy and do not love Charles? I may disagree with the monarchical system, but you have to have ovaries to be a woman and reign for 70 years\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.48 ms /    16 runs   (    0.53 ms per token,  1887.46 tokens per second)\n",
            "llama_print_timings: prompt eval time =     248.23 ms /    41 tokens (    6.05 ms per token,   165.17 tokens per second)\n",
            "llama_print_timings:        eval time =    1596.62 ms /    15 runs   (  106.44 ms per token,     9.39 tokens per second)\n",
            "llama_print_timings:       total time =    1989.77 ms /    56 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "A man told me that I am tall for a woman and I am 1.65😭 https://t.co/39AOe6JRpI\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.33 ms /    16 runs   (    0.58 ms per token,  1715.27 tokens per second)\n",
            "llama_print_timings: prompt eval time =     274.42 ms /    75 tokens (    3.66 ms per token,   273.31 tokens per second)\n",
            "llama_print_timings:        eval time =    1471.18 ms /    15 runs   (   98.08 ms per token,    10.20 tokens per second)\n",
            "llama_print_timings:       total time =    1958.26 ms /    90 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Sol_Downey @lv_maka @Fermoro_Pampino @T13 Madam! I don't know where it comes out that you are a woman, to be a woman, fine!🤦🏽‍♀️🤣🤣🤣 Because what about klio uffffff of the rae!\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.95 ms /    16 runs   (    0.75 ms per token,  1339.47 tokens per second)\n",
            "llama_print_timings: prompt eval time =     273.81 ms /    61 tokens (    4.49 ms per token,   222.78 tokens per second)\n",
            "llama_print_timings:        eval time =    1885.12 ms /    15 runs   (  125.67 ms per token,     7.96 tokens per second)\n",
            "llama_print_timings:       total time =    2491.52 ms /    76 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Javi19704 @FrankVOXMadrid Don't think you're a woman, my partner cleans more than I do. I'm more into fixing taps, climbing roofs, we have the poles changed.🤣🤣🤣\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.62 ms /    16 runs   (    0.60 ms per token,  1663.20 tokens per second)\n",
            "llama_print_timings: prompt eval time =     259.79 ms /    55 tokens (    4.72 ms per token,   211.71 tokens per second)\n",
            "llama_print_timings:        eval time =    1523.47 ms /    15 runs   (  101.56 ms per token,     9.85 tokens per second)\n",
            "llama_print_timings:       total time =    1962.06 ms /    70 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@enzosodo enzo to be an indie girl you have to spend money on big headphones so people ask you if you listen to the smiths and then have a romance that will end badly, that's the life of a woman\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.44 ms /    16 runs   (    0.53 ms per token,  1894.84 tokens per second)\n",
            "llama_print_timings: prompt eval time =     249.57 ms /    36 tokens (    6.93 ms per token,   144.25 tokens per second)\n",
            "llama_print_timings:        eval time =    1552.36 ms /    15 runs   (  103.49 ms per token,     9.66 tokens per second)\n",
            "llama_print_timings:       total time =    1939.86 ms /    51 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "I'm not looking forward to living in a city with a beach, I was born to be a Mediterranean girl🍊🩴\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.06 ms /    16 runs   (    0.57 ms per token,  1765.23 tokens per second)\n",
            "llama_print_timings: prompt eval time =     244.16 ms /    33 tokens (    7.40 ms per token,   135.16 tokens per second)\n",
            "llama_print_timings:        eval time =    1523.48 ms /    15 runs   (  101.57 ms per token,     9.85 tokens per second)\n",
            "llama_print_timings:       total time =    1899.83 ms /    48 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "very ready to be a Girl now that I bought some fun scrunchies and picked up an essay by Susan Sontag in the library\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      12.47 ms /    16 runs   (    0.78 ms per token,  1283.29 tokens per second)\n",
            "llama_print_timings: prompt eval time =     307.77 ms /   102 tokens (    3.02 ms per token,   331.41 tokens per second)\n",
            "llama_print_timings:        eval time =    1826.11 ms /    15 runs   (  121.74 ms per token,     8.21 tokens per second)\n",
            "llama_print_timings:       total time =    2649.40 ms /   117 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "God, I have a tremendous allergy and I don't have pills but I don't want to buy them either because they are prescription-only and very expensive aaaaaa I'm tired of winter coming back just the damn thing I wanted to make an effort to be a girl 🌸spring but I'm already DESTROYED I prefer to be at -10 degrees https://t.co/wFXnfPuPPM\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.85 ms /    16 runs   (    0.55 ms per token,  1807.91 tokens per second)\n",
            "llama_print_timings: prompt eval time =     268.59 ms /    61 tokens (    4.40 ms per token,   227.11 tokens per second)\n",
            "llama_print_timings:        eval time =    1487.71 ms /    15 runs   (   99.18 ms per token,    10.08 tokens per second)\n",
            "llama_print_timings:       total time =    1940.27 ms /    76 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "He won't be able to get out of bed for a week. \"Oh?\" Damn, what a deep voice for a girl. She'll probably have a little cold. \"I'm Kini! I arrived a couple of weeks ago, and you?\"\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.03 ms /    16 runs   (    0.56 ms per token,  1771.09 tokens per second)\n",
            "llama_print_timings: prompt eval time =     662.34 ms /    26 tokens (   25.47 ms per token,    39.25 tokens per second)\n",
            "llama_print_timings:        eval time =    1536.48 ms /    15 runs   (  102.43 ms per token,     9.76 tokens per second)\n",
            "llama_print_timings:       total time =    2330.52 ms /    41 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Why didn't anyone warn me that you have to cook a lot to be a fit girl 🥺\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.18 ms /    16 runs   (    0.70 ms per token,  1431.51 tokens per second)\n",
            "llama_print_timings: prompt eval time =     239.18 ms /    33 tokens (    7.25 ms per token,   137.97 tokens per second)\n",
            "llama_print_timings:        eval time =    1873.90 ms /    15 runs   (  124.93 ms per token,     8.00 tokens per second)\n",
            "llama_print_timings:       total time =    2299.08 ms /    48 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@JefersonEstaci2 You already look like a whore, receiving payments to defame, lash out and annoy the opposition\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.21 ms /    16 runs   (    0.58 ms per token,  1737.62 tokens per second)\n",
            "llama_print_timings: prompt eval time =     276.83 ms /    78 tokens (    3.55 ms per token,   281.76 tokens per second)\n",
            "llama_print_timings:        eval time =    1525.54 ms /    15 runs   (  101.70 ms per token,     9.83 tokens per second)\n",
            "llama_print_timings:       total time =    2038.54 ms /    93 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@nathan_ghost16 @amablitz If I wanted to attract attention I would be your friend, literally you seek a lot of attention, it bothers you that there are people commenting on other people, bro but not even the person they comment on is bothered like you who seem like a crazy bitch responding to them wow, love yourself.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.43 ms /    15 runs   (    0.56 ms per token,  1779.36 tokens per second)\n",
            "llama_print_timings: prompt eval time =     247.91 ms /    34 tokens (    7.29 ms per token,   137.15 tokens per second)\n",
            "llama_print_timings:        eval time =    1296.69 ms /    14 runs   (   92.62 ms per token,    10.80 tokens per second)\n",
            "llama_print_timings:       total time =    1678.42 ms /    48 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@CuentaMister It's just that you look like a fucking account of the heavies of Madrid putting up bullshit all the fucking time\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.42 ms /    16 runs   (    0.53 ms per token,  1901.14 tokens per second)\n",
            "llama_print_timings: prompt eval time =     235.21 ms /    36 tokens (    6.53 ms per token,   153.05 tokens per second)\n",
            "llama_print_timings:        eval time =    1515.82 ms /    15 runs   (  101.05 ms per token,     9.90 tokens per second)\n",
            "llama_print_timings:       total time =    1885.34 ms /    51 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Son of a bitch you don't even look like a real fucking leaf https://t.co/Ci5vmWpq6C\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.04 ms /    16 runs   (    0.56 ms per token,  1770.11 tokens per second)\n",
            "llama_print_timings: prompt eval time =     292.24 ms /    82 tokens (    3.56 ms per token,   280.59 tokens per second)\n",
            "llama_print_timings:        eval time =    1472.24 ms /    15 runs   (   98.15 ms per token,    10.19 tokens per second)\n",
            "llama_print_timings:       total time =    1997.30 ms /    97 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Eyebrow arched again, inspecting more closely. “Redd?” What a fucking mania with the little changes, huh. You look like a fucking woman with so much grooming. — She snorted, who actually didn't even know if she had changed, but in her eyes there was a difference. — How fucking disgusting, no. —\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.84 ms /    16 runs   (    0.55 ms per token,  1809.95 tokens per second)\n",
            "llama_print_timings: prompt eval time =     771.68 ms /    29 tokens (   26.61 ms per token,    37.58 tokens per second)\n",
            "llama_print_timings:        eval time =    1492.38 ms /    15 runs   (   99.49 ms per token,    10.05 tokens per second)\n",
            "llama_print_timings:       total time =    2391.65 ms /    44 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@CristinaSegui_ Get those teeth fixed, Cristi aunt, you look like a junkie whore\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.19 ms /    16 runs   (    0.57 ms per token,  1741.59 tokens per second)\n",
            "llama_print_timings: prompt eval time =     264.44 ms /    55 tokens (    4.81 ms per token,   207.99 tokens per second)\n",
            "llama_print_timings:        eval time =    1501.36 ms /    15 runs   (  100.09 ms per token,     9.99 tokens per second)\n",
            "llama_print_timings:       total time =    1941.79 ms /    70 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Water, the environment, parity, indigenous peoples, THE SOCIAL AND DEMOCRATIC STATE OF LAW, etc. Were we so wrong? #PlebiscitoChile #Elecciones2022\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      12.15 ms /    16 runs   (    0.76 ms per token,  1316.87 tokens per second)\n",
            "llama_print_timings: prompt eval time =     291.42 ms /    80 tokens (    3.64 ms per token,   274.52 tokens per second)\n",
            "llama_print_timings:        eval time =    1658.44 ms /    15 runs   (  110.56 ms per token,     9.04 tokens per second)\n",
            "llama_print_timings:       total time =    2323.10 ms /    95 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Today we celebrate #InternationalDemocracyDay. It cannot survive without freedom of expression, without us combating misinformation, without transparency and gender parity in electoral processes. These must be a commitment for everyone.@cnegobec @TCE_Ecuador https://t.co/RQ78JWa4n8\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.66 ms /    16 runs   (    0.60 ms per token,  1656.83 tokens per second)\n",
            "llama_print_timings: prompt eval time =     276.62 ms /    77 tokens (    3.59 ms per token,   278.36 tokens per second)\n",
            "llama_print_timings:        eval time =    1559.51 ms /    15 runs   (  103.97 ms per token,     9.62 tokens per second)\n",
            "llama_print_timings:       total time =    2060.32 ms /    92 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Years of struggle by thousands of women to achieve parity and the counter-reform approved yesterday by the Congress of #Oaxaca is a betrayal of women's rights sadly exercised by other WOMEN. #Oaxaca should not go back on this right. #NiUnPasoAtrás 🙌🏼💜\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.14 ms /    16 runs   (    0.57 ms per token,  1749.78 tokens per second)\n",
            "llama_print_timings: prompt eval time =     254.11 ms /    39 tokens (    6.52 ms per token,   153.48 tokens per second)\n",
            "llama_print_timings:        eval time =    1598.81 ms /    15 runs   (  106.59 ms per token,     9.38 tokens per second)\n",
            "llama_print_timings:       total time =    2023.85 ms /    54 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@HuobiGlobal explained why its #HUSD stablecoin temporarily lost peg to the USD.🤔 https://t.co/HtzFCSGWUB\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.44 ms /    16 runs   (    0.65 ms per token,  1532.57 tokens per second)\n",
            "llama_print_timings: prompt eval time =     254.77 ms /    48 tokens (    5.31 ms per token,   188.41 tokens per second)\n",
            "llama_print_timings:        eval time =    1670.89 ms /    15 runs   (  111.39 ms per token,     8.98 tokens per second)\n",
            "llama_print_timings:       total time =    2113.80 ms /    63 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Adrián Portillo crucial in Colegiales' victory against Rubio Ñu, scoring the goal of parity 👏🏼 https://t.co/HBieC5owQh\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.95 ms /    16 runs   (    0.56 ms per token,  1788.11 tokens per second)\n",
            "llama_print_timings: prompt eval time =     284.94 ms /    70 tokens (    4.07 ms per token,   245.66 tokens per second)\n",
            "llama_print_timings:        eval time =    1552.16 ms /    15 runs   (  103.48 ms per token,     9.66 tokens per second)\n",
            "llama_print_timings:       total time =    2043.77 ms /    85 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@BrujaPatipelada You should be clear about this before voting. He is going to reform a self-destructive system in the same way, but with parity and all that. Big capital was not touched, the system is not touched and the system is what has us like this or not?\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.07 ms /    16 runs   (    0.57 ms per token,  1763.67 tokens per second)\n",
            "llama_print_timings: prompt eval time =     255.63 ms /    57 tokens (    4.48 ms per token,   222.98 tokens per second)\n",
            "llama_print_timings:        eval time =    1659.41 ms /    15 runs   (  110.63 ms per token,     9.04 tokens per second)\n",
            "llama_print_timings:       total time =    2092.76 ms /    72 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "If we want to forge another reality, we must attack capitalism, colonialism and patriarchy equally. This means studying Marx together with the worldviews of indigenous peoples and feminist theses, and not continuing to search for answers in foreign realities.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.57 ms /    16 runs   (    0.54 ms per token,  1866.98 tokens per second)\n",
            "llama_print_timings: prompt eval time =     238.64 ms /    34 tokens (    7.02 ms per token,   142.47 tokens per second)\n",
            "llama_print_timings:        eval time =    1485.28 ms /    15 runs   (   99.02 ms per token,    10.10 tokens per second)\n",
            "llama_print_timings:       total time =    1860.74 ms /    49 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Me saying I want to live under the patriarchy 🫣 https://t.co/RV3sSmh2tM\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.64 ms /    16 runs   (    0.67 ms per token,  1503.48 tokens per second)\n",
            "llama_print_timings: prompt eval time =     632.11 ms /    20 tokens (   31.61 ms per token,    31.64 tokens per second)\n",
            "llama_print_timings:        eval time =    1850.08 ms /    15 runs   (  123.34 ms per token,     8.11 tokens per second)\n",
            "llama_print_timings:       total time =    2658.07 ms /    35 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "How I love men, they are superior beings, long live patriarchy.\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.85 ms /    16 runs   (    0.55 ms per token,  1808.73 tokens per second)\n",
            "llama_print_timings: prompt eval time =     263.95 ms /    54 tokens (    4.89 ms per token,   204.58 tokens per second)\n",
            "llama_print_timings:        eval time =    1494.35 ms /    15 runs   (   99.62 ms per token,    10.04 tokens per second)\n",
            "llama_print_timings:       total time =    1931.54 ms /    69 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "What a shame to have been born when I like football so much. At five, they already sent my brother to a club, when I was 10, I wanted to and they didn't let me, damn the patriarchy.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.68 ms /    16 runs   (    0.60 ms per token,  1653.58 tokens per second)\n",
            "llama_print_timings: prompt eval time =     281.79 ms /    84 tokens (    3.35 ms per token,   298.09 tokens per second)\n",
            "llama_print_timings:        eval time =    1472.27 ms /    15 runs   (   98.15 ms per token,    10.19 tokens per second)\n",
            "llama_print_timings:       total time =    1997.19 ms /    99 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@GabyGoby @NohemiHervada @745lmau @PittTweet @PittEats While women fight among ourselves, patriarchy continues to advance in its different presentations. The Sea Witches were not even going to have a forum on gender, but rather on daily femicides, but apparently your priorities are different. Reaction to.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.80 ms /    16 runs   (    0.61 ms per token,  1632.15 tokens per second)\n",
            "llama_print_timings: prompt eval time =     263.53 ms /    75 tokens (    3.51 ms per token,   284.59 tokens per second)\n",
            "llama_print_timings:        eval time =    1525.61 ms /    15 runs   (  101.71 ms per token,     9.83 tokens per second)\n",
            "llama_print_timings:       total time =    2013.39 ms /    90 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "😌👌🏽✨, but RIPLEY lacked being at the empowered level of this idiot. 100% free of PATRIARCHY and GLUTEN-free. #SheHulk ..What garbage...🙄🤣 https://t.co/G07es3M8s6\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      12.13 ms /    16 runs   (    0.76 ms per token,  1319.04 tokens per second)\n",
            "llama_print_timings: prompt eval time =     268.87 ms /    36 tokens (    7.47 ms per token,   133.89 tokens per second)\n",
            "llama_print_timings:        eval time =    1825.77 ms /    15 runs   (  121.72 ms per token,     8.22 tokens per second)\n",
            "llama_print_timings:       total time =    2346.26 ms /    51 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Salome181 @OrlandoPerezEC Didn't he hit you? I mean, because he was convicted for hitting women.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.09 ms /    16 runs   (    0.57 ms per token,  1759.60 tokens per second)\n",
            "llama_print_timings: prompt eval time =     251.59 ms /    34 tokens (    7.40 ms per token,   135.14 tokens per second)\n",
            "llama_print_timings:        eval time =    1527.57 ms /    15 runs   (  101.84 ms per token,     9.82 tokens per second)\n",
            "llama_print_timings:       total time =    1910.61 ms /    49 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "You can tell he's used to hitting women. Expulsion for life. https://t.co/FSnpeyJYJS\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.41 ms /    16 runs   (    0.59 ms per token,  1700.14 tokens per second)\n",
            "llama_print_timings: prompt eval time =     255.23 ms /    57 tokens (    4.48 ms per token,   223.33 tokens per second)\n",
            "llama_print_timings:        eval time =    1672.87 ms /    15 runs   (  111.52 ms per token,     8.97 tokens per second)\n",
            "llama_print_timings:       total time =    2108.32 ms /    72 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Let's see, if you were a guy, I would beat you up and leave you hanging, but I don't like hitting women. I prefer... to retire with dignity. https://t.co/7saAdW5XvB\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.16 ms /    16 runs   (    0.70 ms per token,  1433.18 tokens per second)\n",
            "llama_print_timings: prompt eval time =     301.17 ms /    83 tokens (    3.63 ms per token,   275.59 tokens per second)\n",
            "llama_print_timings:        eval time =    1688.10 ms /    15 runs   (  112.54 ms per token,     8.89 tokens per second)\n",
            "llama_print_timings:       total time =    2399.01 ms /    98 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@fabiancodel The good ones: for a girl, a bribe, to extort, to hit women, to not take care of their families, to flee the country for not paying alimony, to hit the people and not the thief, to cover up, to say that's not my area THAT'S WHAT THEY ARE GOOD FOR\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.98 ms /    16 runs   (    0.56 ms per token,  1780.94 tokens per second)\n",
            "llama_print_timings: prompt eval time =     598.04 ms /    23 tokens (   26.00 ms per token,    38.46 tokens per second)\n",
            "llama_print_timings:        eval time =    1480.22 ms /    15 runs   (   98.68 ms per token,    10.13 tokens per second)\n",
            "llama_print_timings:       total time =    2190.84 ms /    38 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@IzquierdaPe I hate those ronderos that are good for hitting women.\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.98 ms /    16 runs   (    0.56 ms per token,  1781.74 tokens per second)\n",
            "llama_print_timings: prompt eval time =     274.58 ms /    88 tokens (    3.12 ms per token,   320.49 tokens per second)\n",
            "llama_print_timings:        eval time =    1558.60 ms /    15 runs   (  103.91 ms per token,     9.62 tokens per second)\n",
            "llama_print_timings:       total time =    2073.11 ms /   103 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@boulman9 @HctorG903 @mayormentevk @aviSiset_ https://t.co/YtWQlxY1fDhttps://t.co/7jfS3pdCcBhttps://t.co/Y1oSPyTzF2Why in Islam they don't even bother to hide what they are\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.96 ms /    16 runs   (    0.56 ms per token,  1784.72 tokens per second)\n",
            "llama_print_timings: prompt eval time =     251.34 ms /    49 tokens (    5.13 ms per token,   194.95 tokens per second)\n",
            "llama_print_timings:        eval time =    1523.31 ms /    15 runs   (  101.55 ms per token,     9.85 tokens per second)\n",
            "llama_print_timings:       total time =    1938.28 ms /    64 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Spicy_Mochi_UwU YEAH LETS GOOOOOOOOOOOOO*crazy bitch screams* https://t.co/tqoZAN5Bei\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.07 ms /    16 runs   (    0.63 ms per token,  1589.35 tokens per second)\n",
            "llama_print_timings: prompt eval time =     283.17 ms /    74 tokens (    3.83 ms per token,   261.33 tokens per second)\n",
            "llama_print_timings:        eval time =    1679.94 ms /    15 runs   (  112.00 ms per token,     8.93 tokens per second)\n",
            "llama_print_timings:       total time =    2314.33 ms /    89 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Memories, ufff, how that bitch moaned, let me see more. On her knees, she stuck out her tongue, asking him to cum on her, in four strokes, phew, she is a real whore” And after that she laughed to simply hide her essence again to protect her mind. of the guest\"\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.61 ms /    16 runs   (    0.54 ms per token,  1857.44 tokens per second)\n",
            "llama_print_timings: prompt eval time =     253.96 ms /    44 tokens (    5.77 ms per token,   173.26 tokens per second)\n",
            "llama_print_timings:        eval time =    1527.58 ms /    15 runs   (  101.84 ms per token,     9.82 tokens per second)\n",
            "llama_print_timings:       total time =    1938.80 ms /    59 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "I'm sure that I will never find a friend like her in my life :( who made me feel complete and caused many things in me ☹️ I miss that damn bitch\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.43 ms /    16 runs   (    0.53 ms per token,  1898.43 tokens per second)\n",
            "llama_print_timings: prompt eval time =     714.23 ms /    26 tokens (   27.47 ms per token,    36.40 tokens per second)\n",
            "llama_print_timings:        eval time =    1527.74 ms /    15 runs   (  101.85 ms per token,     9.82 tokens per second)\n",
            "llama_print_timings:       total time =    2360.21 ms /    41 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "What an ending The Godfather has, without saying anything it says everything. Bitch movie masterpiece.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.81 ms /    16 runs   (    0.55 ms per token,  1815.71 tokens per second)\n",
            "llama_print_timings: prompt eval time =     238.69 ms /    38 tokens (    6.28 ms per token,   159.20 tokens per second)\n",
            "llama_print_timings:        eval time =    1564.15 ms /    15 runs   (  104.28 ms per token,     9.59 tokens per second)\n",
            "llama_print_timings:       total time =    1949.12 ms /    53 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@YOSHUACB2022 You're in empowered bitch mode https://t.co/ukQ82JsAQZ\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.99 ms /    16 runs   (    0.56 ms per token,  1779.16 tokens per second)\n",
            "llama_print_timings: prompt eval time =     927.01 ms /    30 tokens (   30.90 ms per token,    32.36 tokens per second)\n",
            "llama_print_timings:        eval time =    1612.98 ms /    15 runs   (  107.53 ms per token,     9.30 tokens per second)\n",
            "llama_print_timings:       total time =    2720.22 ms /    45 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@imhannahmichin @elcazadorbuho Fucking bitch I envy I bring you 😔\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.82 ms /    16 runs   (    0.55 ms per token,  1814.26 tokens per second)\n",
            "llama_print_timings: prompt eval time =     253.88 ms /    49 tokens (    5.18 ms per token,   193.01 tokens per second)\n",
            "llama_print_timings:        eval time =    1553.46 ms /    15 runs   (  103.56 ms per token,     9.66 tokens per second)\n",
            "llama_print_timings:       total time =    1977.54 ms /    64 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "My neighbor has a nice thick cock 🤤🇲🇽🇺🇸🇨🇴 https://t.co/OQ8CDEzYJO\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.02 ms /    16 runs   (    0.56 ms per token,  1773.05 tokens per second)\n",
            "llama_print_timings: prompt eval time =     644.17 ms /    24 tokens (   26.84 ms per token,    37.26 tokens per second)\n",
            "llama_print_timings:        eval time =    1568.55 ms /    15 runs   (  104.57 ms per token,     9.56 tokens per second)\n",
            "llama_print_timings:       total time =    2328.27 ms /    39 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Look at the next guy who tries to measure his cock with me, I'll break it\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.08 ms /    16 runs   (    0.63 ms per token,  1586.67 tokens per second)\n",
            "llama_print_timings: prompt eval time =     592.89 ms /    22 tokens (   26.95 ms per token,    37.11 tokens per second)\n",
            "llama_print_timings:        eval time =    1779.45 ms /    15 runs   (  118.63 ms per token,     8.43 tokens per second)\n",
            "llama_print_timings:       total time =    2512.72 ms /    37 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "good time to remind zombies that they can suck all of South America's cock\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.33 ms /    16 runs   (    0.58 ms per token,  1714.16 tokens per second)\n",
            "llama_print_timings: prompt eval time =     632.16 ms /    21 tokens (   30.10 ms per token,    33.22 tokens per second)\n",
            "llama_print_timings:        eval time =    1538.47 ms /    15 runs   (  102.56 ms per token,     9.75 tokens per second)\n",
            "llama_print_timings:       total time =    2285.73 ms /    36 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "ptaaaa half a round that dav1d did and he missed the cock round\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.58 ms /    16 runs   (    0.54 ms per token,  1865.89 tokens per second)\n",
            "llama_print_timings: prompt eval time =     774.34 ms /    30 tokens (   25.81 ms per token,    38.74 tokens per second)\n",
            "llama_print_timings:        eval time =    1550.83 ms /    15 runs   (  103.39 ms per token,     9.67 tokens per second)\n",
            "llama_print_timings:       total time =    2456.47 ms /    45 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "if you want to change the oil you eat my dick https://t.co/OdSRmoP0l8\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.64 ms /    16 runs   (    0.54 ms per token,  1851.64 tokens per second)\n",
            "llama_print_timings: prompt eval time =     712.68 ms /    28 tokens (   25.45 ms per token,    39.29 tokens per second)\n",
            "llama_print_timings:        eval time =    1597.20 ms /    15 runs   (  106.48 ms per token,     9.39 tokens per second)\n",
            "llama_print_timings:       total time =    2432.11 ms /    43 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Thread about how I have watched the worlds matches: I update when it comes out of my mind and when I remember\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.09 ms /    16 runs   (    0.63 ms per token,  1585.26 tokens per second)\n",
            "llama_print_timings: prompt eval time =     242.33 ms /    36 tokens (    6.73 ms per token,   148.56 tokens per second)\n",
            "llama_print_timings:        eval time =    1828.53 ms /    15 runs   (  121.90 ms per token,     8.20 tokens per second)\n",
            "llama_print_timings:       total time =    2302.67 ms /    51 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Lately I see pure Pride and Prejudice posts, it will be a sign to see it 🤔🙊🙊\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.01 ms /    16 runs   (    0.56 ms per token,  1775.61 tokens per second)\n",
            "llama_print_timings: prompt eval time =     797.74 ms /    31 tokens (   25.73 ms per token,    38.86 tokens per second)\n",
            "llama_print_timings:        eval time =    1546.80 ms /    15 runs   (  103.12 ms per token,     9.70 tokens per second)\n",
            "llama_print_timings:       total time =    2477.68 ms /    46 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "I will never get tired of saying it, Pride and Prejudice is my favorite romantic novel and movie ever ❤️\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.71 ms /    16 runs   (    0.54 ms per token,  1836.97 tokens per second)\n",
            "llama_print_timings: prompt eval time =     668.33 ms /    26 tokens (   25.70 ms per token,    38.90 tokens per second)\n",
            "llama_print_timings:        eval time =    1566.68 ms /    15 runs   (  104.45 ms per token,     9.57 tokens per second)\n",
            "llama_print_timings:       total time =    2351.97 ms /    41 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "So far this year, reading Pride and Prejudice translated into Spanish was one of my biggest mistakes\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.50 ms /    16 runs   (    0.53 ms per token,  1882.13 tokens per second)\n",
            "llama_print_timings: prompt eval time =     309.27 ms /   113 tokens (    2.74 ms per token,   365.38 tokens per second)\n",
            "llama_print_timings:        eval time =    1545.86 ms /    15 runs   (  103.06 ms per token,     9.70 tokens per second)\n",
            "llama_print_timings:       total time =    2170.72 ms /   128 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "DARE TO RESPOND1. 372. Last Friday3. None4. On Friday5. Pride and prejudice6. Yes 7. No8. Yes and he is my boyfriend9. Yes 10. Yes 11. Yes 12. Sometimes13. No14. 415. On Friday and not 😢16. My abdomen / My hair17. Last night18. NoEmoji and I send you the questions\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.37 ms /    16 runs   (    0.59 ms per token,  1707.40 tokens per second)\n",
            "llama_print_timings: prompt eval time =     242.27 ms /    49 tokens (    4.94 ms per token,   202.25 tokens per second)\n",
            "llama_print_timings:        eval time =    1505.48 ms /    15 runs   (  100.37 ms per token,     9.96 tokens per second)\n",
            "llama_print_timings:       total time =    1920.50 ms /    64 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@ColWithOut0 @PoderAccionSoci @MONYRODRIGUEZOF Reality is relative according to your prejudice in this case and homophobia, which is another serious story\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.61 ms /    16 runs   (    0.73 ms per token,  1378.60 tokens per second)\n",
            "llama_print_timings: prompt eval time =     290.25 ms /    72 tokens (    4.03 ms per token,   248.06 tokens per second)\n",
            "llama_print_timings:        eval time =    1818.14 ms /    15 runs   (  121.21 ms per token,     8.25 tokens per second)\n",
            "llama_print_timings:       total time =    2478.34 ms /    87 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@denegrj @rickymyers What it does do is expose a very harmful prejudice: the idea that one should only support those who fit their lifestyle. That is, no one who is well-off can vote for policies that benefit the poor without being \"hypocritical.\" Amoeba cognitive level, seriously\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.54 ms /    16 runs   (    0.60 ms per token,  1677.85 tokens per second)\n",
            "llama_print_timings: prompt eval time =     254.35 ms /    58 tokens (    4.39 ms per token,   228.03 tokens per second)\n",
            "llama_print_timings:        eval time =    1578.99 ms /    15 runs   (  105.27 ms per token,     9.50 tokens per second)\n",
            "llama_print_timings:       total time =    2013.24 ms /    73 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "What it doesn't say there is if they are from Catholic schools. In the United States there have been cases of even forced prostitution of minors by the administrators of a Catholic school. https://t.co/XIBVkINlsy\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.96 ms /    16 runs   (    0.56 ms per token,  1784.92 tokens per second)\n",
            "llama_print_timings: prompt eval time =     256.76 ms /    61 tokens (    4.21 ms per token,   237.58 tokens per second)\n",
            "llama_print_timings:        eval time =    1582.18 ms /    15 runs   (  105.48 ms per token,     9.48 tokens per second)\n",
            "llama_print_timings:       total time =    2026.40 ms /    76 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@IvanCepedaCast That they do not attack the Police or the Army anymore, that they do not do more hiring, that they do not go out to rob, steal and kill.!! That they do not continue kidnapping or deceiving women into forced prostitution\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.38 ms /    16 runs   (    0.59 ms per token,  1706.48 tokens per second)\n",
            "llama_print_timings: prompt eval time =     282.42 ms /    67 tokens (    4.22 ms per token,   237.24 tokens per second)\n",
            "llama_print_timings:        eval time =    1586.02 ms /    15 runs   (  105.73 ms per token,     9.46 tokens per second)\n",
            "llama_print_timings:       total time =    2064.33 ms /    82 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "That day, in 1913, Law No. 9,143 was passed in Argentina, the purpose of which was to punish white trafficking, forced prostitution and pimping 🧵https://t.co/M3oDrweL3O\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.09 ms /    16 runs   (    0.63 ms per token,  1585.57 tokens per second)\n",
            "llama_print_timings: prompt eval time =     272.47 ms /    63 tokens (    4.32 ms per token,   231.22 tokens per second)\n",
            "llama_print_timings:        eval time =    1615.16 ms /    15 runs   (  107.68 ms per token,     9.29 tokens per second)\n",
            "llama_print_timings:       total time =    2194.05 ms /    78 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Venezuelan women inside and outside the country find themselves in vulnerable situations, with different effects. Additionally, some of them are found in contexts of forced prostitution, sexual slavery, trafficking and trafficking #EstaEnLaLey #IdentificaLasViolencias\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.29 ms /    16 runs   (    0.58 ms per token,  1722.84 tokens per second)\n",
            "llama_print_timings: prompt eval time =     284.70 ms /    71 tokens (    4.01 ms per token,   249.38 tokens per second)\n",
            "llama_print_timings:        eval time =    1619.78 ms /    15 runs   (  107.99 ms per token,     9.26 tokens per second)\n",
            "llama_print_timings:       total time =    2111.63 ms /    86 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@telefenoticias the accusations against Juan Percowicz and his gang would be: 1) human trafficking 2) disappearance of bodies 3) forced prostitution 4) fraud 5) aggravated robbery and appropriation of property 6) serious illegal practice of medicine with deaths\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.83 ms /    16 runs   (    0.55 ms per token,  1812.62 tokens per second)\n",
            "llama_print_timings: prompt eval time =     258.62 ms /    44 tokens (    5.88 ms per token,   170.13 tokens per second)\n",
            "llama_print_timings:        eval time =    1558.14 ms /    15 runs   (  103.88 ms per token,     9.63 tokens per second)\n",
            "llama_print_timings:       total time =    1969.29 ms /    59 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Do you know that forced prostitution is a form of violence? We tell you. 🗣️ https://t.co/gW2k7VeKH0\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.75 ms /    16 runs   (    0.67 ms per token,  1488.93 tokens per second)\n",
            "llama_print_timings: prompt eval time =     783.77 ms /    27 tokens (   29.03 ms per token,    34.45 tokens per second)\n",
            "llama_print_timings:        eval time =    1811.72 ms /    15 runs   (  120.78 ms per token,     8.28 tokens per second)\n",
            "llama_print_timings:       total time =    2793.23 ms /    42 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@gometsazules123 I recommend \"Your mother is a whore\" is a curious group\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.93 ms /    16 runs   (    0.56 ms per token,  1791.51 tokens per second)\n",
            "llama_print_timings: prompt eval time =     601.90 ms /    24 tokens (   25.08 ms per token,    39.87 tokens per second)\n",
            "llama_print_timings:        eval time =    1464.00 ms /    15 runs   (   97.60 ms per token,    10.25 tokens per second)\n",
            "llama_print_timings:       total time =    2190.10 ms /    39 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "And today none of these sons of bitches are injured, they all want to meet Messi\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.31 ms /    16 runs   (    0.52 ms per token,  1926.09 tokens per second)\n",
            "llama_print_timings: prompt eval time =     574.23 ms /    20 tokens (   28.71 ms per token,    34.83 tokens per second)\n",
            "llama_print_timings:        eval time =    1459.34 ms /    15 runs   (   97.29 ms per token,    10.28 tokens per second)\n",
            "llama_print_timings:       total time =    2136.02 ms /    35 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "What a bitch, this cold takes away all your desire, what a crap\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.98 ms /    16 runs   (    0.56 ms per token,  1781.74 tokens per second)\n",
            "llama_print_timings: prompt eval time =     770.30 ms /    29 tokens (   26.56 ms per token,    37.65 tokens per second)\n",
            "llama_print_timings:        eval time =    1505.42 ms /    15 runs   (  100.36 ms per token,     9.96 tokens per second)\n",
            "llama_print_timings:       total time =    2403.15 ms /    44 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@av1spakul0na ostia the park isabel the catholic what a great place thank you\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.22 ms /    16 runs   (    0.70 ms per token,  1426.02 tokens per second)\n",
            "llama_print_timings: prompt eval time =     247.61 ms /    45 tokens (    5.50 ms per token,   181.74 tokens per second)\n",
            "llama_print_timings:        eval time =    1816.06 ms /    15 runs   (  121.07 ms per token,     8.26 tokens per second)\n",
            "llama_print_timings:       total time =    2325.17 ms /    60 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "What a way to chorear zeballos brother, all the same songs, same rhythm, same flow, same variations, change something for me brother, the bitch that gave birth to you\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.60 ms /    16 runs   (    0.54 ms per token,  1860.25 tokens per second)\n",
            "llama_print_timings: prompt eval time =     527.87 ms /    19 tokens (   27.78 ms per token,    35.99 tokens per second)\n",
            "llama_print_timings:        eval time =    1658.16 ms /    15 runs   (  110.54 ms per token,     9.05 tokens per second)\n",
            "llama_print_timings:       total time =    2291.33 ms /    34 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Saint Iker Casillas is the Brazilian son of a bitch this\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.81 ms /    16 runs   (    0.55 ms per token,  1815.91 tokens per second)\n",
            "llama_print_timings: prompt eval time =     670.04 ms /    26 tokens (   25.77 ms per token,    38.80 tokens per second)\n",
            "llama_print_timings:        eval time =    1454.74 ms /    15 runs   (   96.98 ms per token,    10.31 tokens per second)\n",
            "llama_print_timings:       total time =    2254.06 ms /    41 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "I don't understand why whores continue to wear face masks if they only cover their chins...\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.70 ms /    16 runs   (    0.54 ms per token,  1838.24 tokens per second)\n",
            "llama_print_timings: prompt eval time =     241.97 ms /    36 tokens (    6.72 ms per token,   148.78 tokens per second)\n",
            "llama_print_timings:        eval time =    1514.14 ms /    15 runs   (  100.94 ms per token,     9.91 tokens per second)\n",
            "llama_print_timings:       total time =    1894.62 ms /    51 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@esloquehay1984 Where there are leading men, there are whore women, because for sex you need one of each!\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.00 ms /    16 runs   (    0.69 ms per token,  1455.21 tokens per second)\n",
            "llama_print_timings: prompt eval time =     259.11 ms /    38 tokens (    6.82 ms per token,   146.66 tokens per second)\n",
            "llama_print_timings:        eval time =    1701.66 ms /    15 runs   (  113.44 ms per token,     8.81 tokens per second)\n",
            "llama_print_timings:       total time =    2187.88 ms /    53 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Can someone tell me that Rochet is not a son of a thousand bitches and hollow? https://t.co/KibTa4iWPy\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.12 ms /    16 runs   (    0.57 ms per token,  1754.19 tokens per second)\n",
            "llama_print_timings: prompt eval time =     261.24 ms /    49 tokens (    5.33 ms per token,   187.57 tokens per second)\n",
            "llama_print_timings:        eval time =    1522.04 ms /    15 runs   (  101.47 ms per token,     9.86 tokens per second)\n",
            "llama_print_timings:       total time =    1945.93 ms /    64 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@SanPaloma_ They have such an extensive infrastructure that that is why they live here and thank God because they also help the economy of this city that is not built on whores and micro-trafficking.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.31 ms /    16 runs   (    0.52 ms per token,  1925.62 tokens per second)\n",
            "llama_print_timings: prompt eval time =     792.71 ms /    30 tokens (   26.42 ms per token,    37.84 tokens per second)\n",
            "llama_print_timings:        eval time =    1516.28 ms /    15 runs   (  101.09 ms per token,     9.89 tokens per second)\n",
            "llama_print_timings:       total time =    2433.95 ms /    45 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "I've been so busy all this time that I don't know what the hell I'm going to study😭\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.42 ms /    16 runs   (    0.71 ms per token,  1400.56 tokens per second)\n",
            "llama_print_timings: prompt eval time =     246.05 ms /    51 tokens (    4.82 ms per token,   207.28 tokens per second)\n",
            "llama_print_timings:        eval time =    1838.07 ms /    15 runs   (  122.54 ms per token,     8.16 tokens per second)\n",
            "llama_print_timings:       total time =    2286.90 ms /    66 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@scipio91 @ituerahipster @evelio_prieto @BlasIgnacio @PovedaJB They haven't even worked in China, they are like fucking goats.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.73 ms /    16 runs   (    0.55 ms per token,  1832.13 tokens per second)\n",
            "llama_print_timings: prompt eval time =     793.69 ms /    30 tokens (   26.46 ms per token,    37.80 tokens per second)\n",
            "llama_print_timings:        eval time =    1492.90 ms /    15 runs   (   99.53 ms per token,    10.05 tokens per second)\n",
            "llama_print_timings:       total time =    2415.96 ms /    45 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@ervyvegano ntp king, things that criticize whorephobia do not bother, quite the opposite\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.57 ms /    16 runs   (    0.54 ms per token,  1866.11 tokens per second)\n",
            "llama_print_timings: prompt eval time =     249.90 ms /    56 tokens (    4.46 ms per token,   224.09 tokens per second)\n",
            "llama_print_timings:        eval time =    1556.98 ms /    15 runs   (  103.80 ms per token,     9.63 tokens per second)\n",
            "llama_print_timings:       total time =    1985.17 ms /    71 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "I hate when it says \"the greatest enemy of a Mexican is another Mexican\" because no, the greatest enemy of a Mexican is classism, racism, misogynism, LGBT+phobia, ableism, whorephobia...\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.35 ms /    16 runs   (    0.52 ms per token,  1916.40 tokens per second)\n",
            "llama_print_timings: prompt eval time =     262.63 ms /    51 tokens (    5.15 ms per token,   194.19 tokens per second)\n",
            "llama_print_timings:        eval time =    1560.30 ms /    15 runs   (  104.02 ms per token,     9.61 tokens per second)\n",
            "llama_print_timings:       total time =    1989.62 ms /    66 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "My aunt shielded her racism and whorephobia with “we are Mexican and we are always going to criticize.” Gross. 🤮🤮🤮🤮\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.47 ms /    16 runs   (    0.65 ms per token,  1527.88 tokens per second)\n",
            "llama_print_timings: prompt eval time =     252.37 ms /    38 tokens (    6.64 ms per token,   150.57 tokens per second)\n",
            "llama_print_timings:        eval time =    1686.88 ms /    15 runs   (  112.46 ms per token,     8.89 tokens per second)\n",
            "llama_print_timings:       total time =    2163.76 ms /    53 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Be careful not to get rid of whorephobia with this case! @astrasex https://t.co/5FnCS7g1Id\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.38 ms /    16 runs   (    0.59 ms per token,  1706.67 tokens per second)\n",
            "llama_print_timings: prompt eval time =     285.37 ms /    73 tokens (    3.91 ms per token,   255.81 tokens per second)\n",
            "llama_print_timings:        eval time =    1500.02 ms /    15 runs   (  100.00 ms per token,    10.00 tokens per second)\n",
            "llama_print_timings:       total time =    1998.31 ms /    88 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "If I were a woman who falls within their morals, my ailment would already be resolved. Be careful, I went for public and private healthcare and both are the same.#sexual work#whorephobia#Machista Violence https://t.co/1NV576s4k5\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.12 ms /    16 runs   (    0.57 ms per token,  1753.81 tokens per second)\n",
            "llama_print_timings: prompt eval time =     260.33 ms /    52 tokens (    5.01 ms per token,   199.75 tokens per second)\n",
            "llama_print_timings:        eval time =    1544.57 ms /    15 runs   (  102.97 ms per token,     9.71 tokens per second)\n",
            "llama_print_timings:       total time =    1981.01 ms /    67 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "How would they know that a girl whose TL consists of 100% transphobia, homophobia, whorephobia and racism was a bad person, my poor things, if they are only girls\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.50 ms /    16 runs   (    0.59 ms per token,  1684.39 tokens per second)\n",
            "llama_print_timings: prompt eval time =     261.85 ms /    50 tokens (    5.24 ms per token,   190.95 tokens per second)\n",
            "llama_print_timings:        eval time =    1507.31 ms /    15 runs   (  100.49 ms per token,     9.95 tokens per second)\n",
            "llama_print_timings:       total time =    1939.49 ms /    65 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@ArtemioLoG @rizzolva Don't be grateful bro. Additionally, Taylor placed a lot of emphasis on abusive relationships, and I don't think that's the case with him.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.80 ms /    16 runs   (    0.55 ms per token,  1817.15 tokens per second)\n",
            "llama_print_timings: prompt eval time =     250.81 ms /    46 tokens (    5.45 ms per token,   183.40 tokens per second)\n",
            "llama_print_timings:        eval time =    1687.78 ms /    15 runs   (  112.52 ms per token,     8.89 tokens per second)\n",
            "llama_print_timings:       total time =    2104.29 ms /    61 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "TO LAST IT WAS A RATING SERIES FOR CHILDREN. STOP ROMANTIZING ABUSIVE RELATIONSHIPS. STOP CHUN LING\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.54 ms /    16 runs   (    0.60 ms per token,  1676.62 tokens per second)\n",
            "llama_print_timings: prompt eval time =     272.94 ms /    69 tokens (    3.96 ms per token,   252.81 tokens per second)\n",
            "llama_print_timings:        eval time =    1563.77 ms /    15 runs   (  104.25 ms per token,     9.59 tokens per second)\n",
            "llama_print_timings:       total time =    2043.02 ms /    84 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Once again I seem like the badass clown but for me #PURPLEHEARTS is more of the same, they have me fed up with these \"romantic\" movies where they romanticize abusive relationships, update yourself. https://t.co/NECvxnM5uz\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.73 ms /    16 runs   (    0.61 ms per token,  1643.55 tokens per second)\n",
            "llama_print_timings: prompt eval time =     270.91 ms /    69 tokens (    3.93 ms per token,   254.69 tokens per second)\n",
            "llama_print_timings:        eval time =    1700.74 ms /    15 runs   (  113.38 ms per token,     8.82 tokens per second)\n",
            "llama_print_timings:       total time =    2183.62 ms /    84 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Believing that men are not aware of the damage they do to us in abusive relationships is underestimating them, it is not our role to show that they are doing wrong, to mother them. Our role is to get the hell out of that bond. We are not anyone's saviors.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.62 ms /    16 runs   (    0.60 ms per token,  1663.03 tokens per second)\n",
            "llama_print_timings: prompt eval time =     255.06 ms /    36 tokens (    7.08 ms per token,   141.15 tokens per second)\n",
            "llama_print_timings:        eval time =    1647.26 ms /    15 runs   (  109.82 ms per token,     9.11 tokens per second)\n",
            "llama_print_timings:       total time =    2117.84 ms /    51 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Plus her books are garbage and a total romanticization of abusive and violent relationships https://t.co/lnXGsjZH8o\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.92 ms /    16 runs   (    0.56 ms per token,  1793.72 tokens per second)\n",
            "llama_print_timings: prompt eval time =     801.57 ms /    31 tokens (   25.86 ms per token,    38.67 tokens per second)\n",
            "llama_print_timings:        eval time =    1522.63 ms /    15 runs   (  101.51 ms per token,     9.85 tokens per second)\n",
            "llama_print_timings:       total time =    2454.42 ms /    46 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Abusive relationships are definitely the order of the day. Women's lives in these times are more in danger than ever.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.29 ms /    16 runs   (    0.58 ms per token,  1722.65 tokens per second)\n",
            "llama_print_timings: prompt eval time =     284.63 ms /    78 tokens (    3.65 ms per token,   274.04 tokens per second)\n",
            "llama_print_timings:        eval time =    1574.76 ms /    15 runs   (  104.98 ms per token,     9.53 tokens per second)\n",
            "llama_print_timings:       total time =    2085.61 ms /    93 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "There is the Russian Vasili Rozanov, who held the theory that “repressed sodomy” was the key to the entire culture: the homosexual repressed himself and felt guilty, dedicated his energy to cultural creation, and at the same time repressed heterosexuals. .. https://t.co/1yKpjrzaQR\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      12.36 ms /    16 runs   (    0.77 ms per token,  1294.18 tokens per second)\n",
            "llama_print_timings: prompt eval time =     274.43 ms /    77 tokens (    3.56 ms per token,   280.58 tokens per second)\n",
            "llama_print_timings:        eval time =    1801.66 ms /    15 runs   (  120.11 ms per token,     8.33 tokens per second)\n",
            "llama_print_timings:       total time =    2325.74 ms /    92 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "\"Coming from a time as disastrous as this... I know that no one in the history of their country has had a process like the Guaraní experienced, a tremendously repressed, discriminated, degraded language. However, it is here, alive among us\" https: //t.co/abD8wOPAcu\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.01 ms /    16 runs   (    0.56 ms per token,  1775.80 tokens per second)\n",
            "llama_print_timings: prompt eval time =     286.28 ms /    81 tokens (    3.53 ms per token,   282.94 tokens per second)\n",
            "llama_print_timings:        eval time =    1536.50 ms /    15 runs   (  102.43 ms per token,     9.76 tokens per second)\n",
            "llama_print_timings:       total time =    2051.91 ms /    96 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "The president profited from the death of the #43deayotzinapa, lying to them that in the first year the case would have been resolved, and now the truth explodes in his face. Today #Ayotzinapa is repressed by the cherry authorities, that movement that at the time supported.#Ayotzinapa8Anos\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.87 ms /    16 runs   (    0.62 ms per token,  1621.40 tokens per second)\n",
            "llama_print_timings: prompt eval time =     260.71 ms /    63 tokens (    4.14 ms per token,   241.65 tokens per second)\n",
            "llama_print_timings:        eval time =    1633.15 ms /    15 runs   (  108.88 ms per token,     9.18 tokens per second)\n",
            "llama_print_timings:       total time =    2090.31 ms /    78 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Track 1 as they call it, pretty cool. Full of many things that revolved around London in the 70's, a lot of repressed fashion, abuse, alcohol and too much music. Damn, I loved it. We will continue to inform. 🥰\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.60 ms /    16 runs   (    0.66 ms per token,  1509.15 tokens per second)\n",
            "llama_print_timings: prompt eval time =     262.36 ms /    36 tokens (    7.29 ms per token,   137.21 tokens per second)\n",
            "llama_print_timings:        eval time =    1735.93 ms /    15 runs   (  115.73 ms per token,     8.64 tokens per second)\n",
            "llama_print_timings:       total time =    2210.21 ms /    51 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Burhanalierkam Already??? That's all???Grow up better, repressed crazy!!! 😂😂😂\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.36 ms /    16 runs   (    0.59 ms per token,  1709.04 tokens per second)\n",
            "llama_print_timings: prompt eval time =     273.88 ms /    74 tokens (    3.70 ms per token,   270.19 tokens per second)\n",
            "llama_print_timings:        eval time =    1582.63 ms /    15 runs   (  105.51 ms per token,     9.48 tokens per second)\n",
            "llama_print_timings:       total time =    2069.43 ms /    89 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@DePacotilla @petrogustavo You are not right, humanity needs to expand not contract, conquer the planet and the universe in search of new habitats, that requires resources and human ambition that can never be repressed, only in mediocre minds can there be a humanity that regresses in the history.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.79 ms /    16 runs   (    0.55 ms per token,  1820.25 tokens per second)\n",
            "llama_print_timings: prompt eval time =     257.82 ms /    41 tokens (    6.29 ms per token,   159.03 tokens per second)\n",
            "llama_print_timings:        eval time =    1604.35 ms /    15 runs   (  106.96 ms per token,     9.35 tokens per second)\n",
            "llama_print_timings:       total time =    2015.00 ms /    56 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@wordsworth1966 A sensitive intellect perfect for Joyce. Monroe was a very cultured woman. The dumb blonde was a carefully created working facade.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.83 ms /    16 runs   (    0.68 ms per token,  1476.97 tokens per second)\n",
            "llama_print_timings: prompt eval time =     689.38 ms /    25 tokens (   27.58 ms per token,    36.26 tokens per second)\n",
            "llama_print_timings:        eval time =    1850.87 ms /    15 runs   (  123.39 ms per token,     8.10 tokens per second)\n",
            "llama_print_timings:       total time =    2691.71 ms /    40 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "she pulls tw as if she can stand something the dumb blonde is aajja leave it🤣\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.29 ms /    16 runs   (    0.58 ms per token,  1722.10 tokens per second)\n",
            "llama_print_timings: prompt eval time =     251.05 ms /    39 tokens (    6.44 ms per token,   155.35 tokens per second)\n",
            "llama_print_timings:        eval time =    1577.73 ms /    15 runs   (  105.18 ms per token,     9.51 tokens per second)\n",
            "llama_print_timings:       total time =    1977.34 ms /    54 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "\"Hohoho~ dumb blonde...bring this little ass.!×\" https://t.co/OWZ3eJ6At6\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.44 ms /    16 runs   (    0.59 ms per token,  1695.81 tokens per second)\n",
            "llama_print_timings: prompt eval time =     259.30 ms /    50 tokens (    5.19 ms per token,   192.83 tokens per second)\n",
            "llama_print_timings:        eval time =    1491.37 ms /    15 runs   (   99.42 ms per token,    10.06 tokens per second)\n",
            "llama_print_timings:       total time =    1930.72 ms /    65 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@HrimInfos @liusivaya maluca ukraine, good russian, the terms change over time, before they called them \"dumb blonde\" now \"russian dumb blonde\"\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.91 ms /    16 runs   (    0.56 ms per token,  1794.93 tokens per second)\n",
            "llama_print_timings: prompt eval time =     245.37 ms /    33 tokens (    7.44 ms per token,   134.49 tokens per second)\n",
            "llama_print_timings:        eval time =    1578.70 ms /    15 runs   (  105.25 ms per token,     9.50 tokens per second)\n",
            "llama_print_timings:       total time =    1955.51 ms /    48 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@LaotraNata @danielchileno1 @mvacarezza Revived the myth of “the dumb blonde”\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.85 ms /    16 runs   (    0.68 ms per token,  1474.25 tokens per second)\n",
            "llama_print_timings: prompt eval time =     248.67 ms /    49 tokens (    5.07 ms per token,   197.05 tokens per second)\n",
            "llama_print_timings:        eval time =    1793.80 ms /    15 runs   (  119.59 ms per token,     8.36 tokens per second)\n",
            "llama_print_timings:       total time =    2230.88 ms /    64 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "From Marilyn to Barbie: rise and fall of the 'dumb' blonde in Hollywood cinema https://t.co/3sJKvMciCD via @elpais_america\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.25 ms /    16 runs   (    0.58 ms per token,  1729.73 tokens per second)\n",
            "llama_print_timings: prompt eval time =     804.89 ms /    30 tokens (   26.83 ms per token,    37.27 tokens per second)\n",
            "llama_print_timings:        eval time =    1556.53 ms /    15 runs   (  103.77 ms per token,     9.64 tokens per second)\n",
            "llama_print_timings:       total time =    2498.70 ms /    45 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@melisa__bh can't stop lying she doesn't get tired as you can tell she's a woman\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.09 ms /    16 runs   (    0.57 ms per token,  1759.98 tokens per second)\n",
            "llama_print_timings: prompt eval time =     237.70 ms /    35 tokens (    6.79 ms per token,   147.24 tokens per second)\n",
            "llama_print_timings:        eval time =    1590.93 ms /    15 runs   (  106.06 ms per token,     9.43 tokens per second)\n",
            "llama_print_timings:       total time =    1968.12 ms /    50 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Urresti and the figure of the woman, produced as if she were acting hahaha, it is clear that she is a military woman\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       2.85 ms /     5 runs   (    0.57 ms per token,  1753.16 tokens per second)\n",
            "llama_print_timings: prompt eval time =     290.86 ms /    92 tokens (    3.16 ms per token,   316.30 tokens per second)\n",
            "llama_print_timings:        eval time =     424.81 ms /     4 runs   (  106.20 ms per token,     9.42 tokens per second)\n",
            "llama_print_timings:       total time =     923.67 ms /    96 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@CoupleSex_KyE You can definitely tell that she is a very sensual woman, capable of raising any low passion. That dress suits her very well, not to mention her 🍑 that she gives 🔥, they are suggestive how by inviting the challenge it would be incredible to play with you and give you a battle to win or fall in the attempt 😈\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       2.98 ms /     5 runs   (    0.60 ms per token,  1678.98 tokens per second)\n",
            "llama_print_timings: prompt eval time =     237.44 ms /    57 tokens (    4.17 ms per token,   240.06 tokens per second)\n",
            "llama_print_timings:        eval time =     382.75 ms /     4 runs   (   95.69 ms per token,    10.45 tokens per second)\n",
            "llama_print_timings:       total time =     757.74 ms /    61 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Dagh211 @ultimominuto_22 @JP42076350 And whoever hits her the most, you can tell that she is a woman... cowardly and disrespectful assholes.. 😡\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.85 ms /    16 runs   (    0.68 ms per token,  1474.79 tokens per second)\n",
            "llama_print_timings: prompt eval time =     882.69 ms /    31 tokens (   28.47 ms per token,    35.12 tokens per second)\n",
            "llama_print_timings:        eval time =    1836.57 ms /    15 runs   (  122.44 ms per token,     8.17 tokens per second)\n",
            "llama_print_timings:       total time =    2933.59 ms /    46 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@CarmeBarcelo As you can tell she is a woman... wait, don't take me to jail, nooo\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.19 ms /    16 runs   (    0.57 ms per token,  1741.78 tokens per second)\n",
            "llama_print_timings: prompt eval time =     265.40 ms /    57 tokens (    4.66 ms per token,   214.77 tokens per second)\n",
            "llama_print_timings:        eval time =    1521.11 ms /    15 runs   (  101.41 ms per token,     9.86 tokens per second)\n",
            "llama_print_timings:       total time =    1974.01 ms /    72 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Luiscent111 @CarlosArizaArg @madorni She is a woman. She surely denies herself as a woman because she is mentally balled up, but being manly and everything shows that she is a woman.\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.59 ms /    16 runs   (    0.54 ms per token,  1863.72 tokens per second)\n",
            "llama_print_timings: prompt eval time =     246.09 ms /    51 tokens (    4.83 ms per token,   207.24 tokens per second)\n",
            "llama_print_timings:        eval time =    1528.92 ms /    15 runs   (  101.93 ms per token,     9.81 tokens per second)\n",
            "llama_print_timings:       total time =    1946.59 ms /    66 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "There is no difference between a woman who made a chub for lack of affection and a man who made a cat for a lack of affection. It's not sexism, it's the system of beliefs and values.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.74 ms /    16 runs   (    0.55 ms per token,  1829.83 tokens per second)\n",
            "llama_print_timings: prompt eval time =     250.13 ms /    41 tokens (    6.10 ms per token,   163.91 tokens per second)\n",
            "llama_print_timings:        eval time =    1504.01 ms /    15 runs   (  100.27 ms per token,     9.97 tokens per second)\n",
            "llama_print_timings:       total time =    1902.99 ms /    56 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Fighting racism is also fighting against the patriarchal system. Transphobia, ableism, racism, sexism... It's all in the same bag really\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      14.81 ms /    16 runs   (    0.93 ms per token,  1080.35 tokens per second)\n",
            "llama_print_timings: prompt eval time =     299.33 ms /   108 tokens (    2.77 ms per token,   360.81 tokens per second)\n",
            "llama_print_timings:        eval time =    1847.82 ms /    15 runs   (  123.19 ms per token,     8.12 tokens per second)\n",
            "llama_print_timings:       total time =    2653.10 ms /   123 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "#BreakingBarriers | At the EAAB we are committed to promoting a work environment of respect and equality. We say 🙅🏻‍♀️No to sexism 🙅🏻‍♂️No to discrimination 🙅🏻‍♀️No to workplace and sexual harassment! We build equal relationships # BetterTogether! #SomosAguaDeAllColors🌈 https://t.co/oy2ODe2Yry\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.26 ms /    16 runs   (    0.58 ms per token,  1728.42 tokens per second)\n",
            "llama_print_timings: prompt eval time =     259.83 ms /    64 tokens (    4.06 ms per token,   246.31 tokens per second)\n",
            "llama_print_timings:        eval time =    1561.00 ms /    15 runs   (  104.07 ms per token,     9.61 tokens per second)\n",
            "llama_print_timings:       total time =    2012.23 ms /    79 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@SrtaRancia Assuming that Hulk gets angry and does not control himself just because he is \"omvre\" instead of empowering feminism, is just another form of sexism, and one of the most outdated and stale. They already work at Disney.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.15 ms /    16 runs   (    0.57 ms per token,  1748.83 tokens per second)\n",
            "llama_print_timings: prompt eval time =     770.83 ms /    30 tokens (   25.69 ms per token,    38.92 tokens per second)\n",
            "llama_print_timings:        eval time =    1541.58 ms /    15 runs   (  102.77 ms per token,     9.73 tokens per second)\n",
            "llama_print_timings:       total time =    2448.33 ms /    45 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Benny_Metalhead Oh right, pulling out the old trusty sexism/racism card to justify everything.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.44 ms /    16 runs   (    0.59 ms per token,  1695.27 tokens per second)\n",
            "llama_print_timings: prompt eval time =     251.09 ms /    43 tokens (    5.84 ms per token,   171.26 tokens per second)\n",
            "llama_print_timings:        eval time =    1604.56 ms /    15 runs   (  106.97 ms per token,     9.35 tokens per second)\n",
            "llama_print_timings:       total time =    2012.27 ms /    58 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Asoc__Anavid Don't hesitate! Sexism in the Spanish justice system is TERRIBLE. https://t.co/Am394tjgtL\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.91 ms /    16 runs   (    0.62 ms per token,  1613.88 tokens per second)\n",
            "llama_print_timings: prompt eval time =     291.44 ms /    82 tokens (    3.55 ms per token,   281.36 tokens per second)\n",
            "llama_print_timings:        eval time =    1630.14 ms /    15 runs   (  108.68 ms per token,     9.20 tokens per second)\n",
            "llama_print_timings:       total time =    2284.07 ms /    97 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "The problem for all of you is that you reduce being a woman to: 1) biological sex (if it is not clear, biological sex ≠ gender identity) 2) perpetuating all the gender roles socially imposed on what should be “a good woman” (often imposed by men) https://t.co/MNoYZNKPSV\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.01 ms /    16 runs   (    0.63 ms per token,  1599.20 tokens per second)\n",
            "llama_print_timings: prompt eval time =     297.66 ms /    95 tokens (    3.13 ms per token,   319.16 tokens per second)\n",
            "llama_print_timings:        eval time =    1666.66 ms /    15 runs   (  111.11 ms per token,     9.00 tokens per second)\n",
            "llama_print_timings:       total time =    2224.15 ms /   110 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@MontserratVaNo @WDI_Es @WdiColombia @WDIMexico @ContraBorrado @aquelarre_xx @ConfluenciaMF @feministas_cong @SilviaCarrascoP And who believes that she is a Nobel Prize winner in biology to affirm that biological sex exists and that there are only two? How daring is ignorance 🤣\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.47 ms /    16 runs   (    0.59 ms per token,  1688.83 tokens per second)\n",
            "llama_print_timings: prompt eval time =     256.61 ms /    60 tokens (    4.28 ms per token,   233.82 tokens per second)\n",
            "llama_print_timings:        eval time =    1513.22 ms /    15 runs   (  100.88 ms per token,     9.91 tokens per second)\n",
            "llama_print_timings:       total time =    1954.01 ms /    75 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Joseph95916840 @Puentesbelt @IreneMontero That statistic, unfortunately, is not interesting. Just as violence between homosexual couples is of no interest, it does not matter what their biological sex was.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.10 ms /    16 runs   (    0.69 ms per token,  1441.18 tokens per second)\n",
            "llama_print_timings: prompt eval time =     275.74 ms /    64 tokens (    4.31 ms per token,   232.10 tokens per second)\n",
            "llama_print_timings:        eval time =    1829.60 ms /    15 runs   (  121.97 ms per token,     8.20 tokens per second)\n",
            "llama_print_timings:       total time =    2431.66 ms /    79 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@SoyElsaMendez She is a woman: with dysphoria (perhaps), she \"feels\" a man, she dresses like a man, hormoned to appear to be a man. But she will always be a woman. Biological sex is immutable.\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.90 ms /    16 runs   (    0.62 ms per token,  1615.35 tokens per second)\n",
            "llama_print_timings: prompt eval time =     268.78 ms /    63 tokens (    4.27 ms per token,   234.39 tokens per second)\n",
            "llama_print_timings:        eval time =    1586.04 ms /    15 runs   (  105.74 ms per token,     9.46 tokens per second)\n",
            "llama_print_timings:       total time =    2047.40 ms /    78 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Bravonotfound @gordotucumono More indoctrination than your gender ideology I don't think. You can't choose the gender either, it is closely linked to biological sex. Everything else is disorder. What you say has no scientific basis.\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.31 ms /    16 runs   (    0.58 ms per token,  1718.21 tokens per second)\n",
            "llama_print_timings: prompt eval time =     273.74 ms /    68 tokens (    4.03 ms per token,   248.41 tokens per second)\n",
            "llama_print_timings:        eval time =    1610.85 ms /    15 runs   (  107.39 ms per token,     9.31 tokens per second)\n",
            "llama_print_timings:       total time =    2083.04 ms /    83 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@CNNEE When gender is separated from biological sex, it doesn't matter how you perceive and dress, a matter of fashion, ratings and business; The problem is that there are a lot of brats doing the same thing for free, they are perceived as being on the wrong side and abused.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.93 ms /    16 runs   (    0.56 ms per token,  1792.11 tokens per second)\n",
            "llama_print_timings: prompt eval time =     298.76 ms /   102 tokens (    2.93 ms per token,   341.41 tokens per second)\n",
            "llama_print_timings:        eval time =    1590.49 ms /    15 runs   (  106.03 ms per token,     9.43 tokens per second)\n",
            "llama_print_timings:       total time =    2168.36 ms /   117 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@LilyBelisario @LluisRabell It is news that counts above all “a study” as it says, but I can't read the study. If you can link it to me, even better. So I take a look at it. Likewise, sex is not something that is assigned to you at birth. It is something that is recorded. Pure biology wow. For the rest, I'll keep an eye on it.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.08 ms /    16 runs   (    0.50 ms per token,  1981.18 tokens per second)\n",
            "llama_print_timings: prompt eval time =     238.09 ms /    40 tokens (    5.95 ms per token,   168.00 tokens per second)\n",
            "llama_print_timings:        eval time =    1603.22 ms /    15 runs   (  106.88 ms per token,     9.36 tokens per second)\n",
            "llama_print_timings:       total time =    1983.62 ms /    55 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Those of now if it's not sex it's fun. In the era of going out quietly, going to the movies, the classic details were totally lost.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.67 ms /    16 runs   (    0.60 ms per token,  1654.43 tokens per second)\n",
            "llama_print_timings: prompt eval time =     595.95 ms /    23 tokens (   25.91 ms per token,    38.59 tokens per second)\n",
            "llama_print_timings:        eval time =    1745.59 ms /    15 runs   (  116.37 ms per token,     8.59 tokens per second)\n",
            "llama_print_timings:       total time =    2472.62 ms /    38 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Sex? Beach ? What I want with you, wherever you say, I follow you\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.13 ms /    16 runs   (    0.57 ms per token,  1751.51 tokens per second)\n",
            "llama_print_timings: prompt eval time =     259.56 ms /    53 tokens (    4.90 ms per token,   204.20 tokens per second)\n",
            "llama_print_timings:        eval time =    1537.91 ms /    15 runs   (  102.53 ms per token,     9.75 tokens per second)\n",
            "llama_print_timings:       total time =    1966.70 ms /    68 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "The only thing the writers of @CW_Riverdale lacked was changing the sex of the characters. As if in another multiverse they were of the opposite gender. There's an idea for the seventh, Riverdale.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.12 ms /    16 runs   (    0.57 ms per token,  1754.77 tokens per second)\n",
            "llama_print_timings: prompt eval time =     521.03 ms /    19 tokens (   27.42 ms per token,    36.47 tokens per second)\n",
            "llama_print_timings:        eval time =    1577.73 ms /    15 runs   (  105.18 ms per token,     9.51 tokens per second)\n",
            "llama_print_timings:       total time =    2204.32 ms /    34 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "How annoying are people with that urgent need to always be talking about sex\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.43 ms /    16 runs   (    0.53 ms per token,  1897.76 tokens per second)\n",
            "llama_print_timings: prompt eval time =     248.12 ms /    43 tokens (    5.77 ms per token,   173.30 tokens per second)\n",
            "llama_print_timings:        eval time =    1571.52 ms /    15 runs   (  104.77 ms per token,     9.54 tokens per second)\n",
            "llama_print_timings:       total time =    1967.93 ms /    58 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@shuuliax @DanteDeu5 @Nuwyfps @t1tuu from super people, love, not sex, don't hit me anymore\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.27 ms /    16 runs   (    0.70 ms per token,  1419.45 tokens per second)\n",
            "llama_print_timings: prompt eval time =     261.19 ms /    47 tokens (    5.56 ms per token,   179.95 tokens per second)\n",
            "llama_print_timings:        eval time =    1741.28 ms /    15 runs   (  116.09 ms per token,     8.61 tokens per second)\n",
            "llama_print_timings:       total time =    2259.04 ms /    62 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Available for sexting and video calls all day 🤭😳https://t.co/fyktQKlBFQ https://t.co/CqPO1cuAWu\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.64 ms /    16 runs   (    0.54 ms per token,  1851.85 tokens per second)\n",
            "llama_print_timings: prompt eval time =     698.70 ms /    27 tokens (   25.88 ms per token,    38.64 tokens per second)\n",
            "llama_print_timings:        eval time =    1631.22 ms /    15 runs   (  108.75 ms per token,     9.20 tokens per second)\n",
            "llama_print_timings:       total time =    2451.00 ms /    42 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "wants to sext with your character https://t.co/tGwShg7Bnu\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.48 ms /    16 runs   (    0.53 ms per token,  1886.35 tokens per second)\n",
            "llama_print_timings: prompt eval time =     238.78 ms /    36 tokens (    6.63 ms per token,   150.77 tokens per second)\n",
            "llama_print_timings:        eval time =    1573.19 ms /    15 runs   (  104.88 ms per token,     9.53 tokens per second)\n",
            "llama_print_timings:       total time =    1951.92 ms /    51 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "very much in favor of returning to sexting and doggy filters, let's make 2022 the new 2014\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.14 ms /    16 runs   (    0.57 ms per token,  1750.74 tokens per second)\n",
            "llama_print_timings: prompt eval time =     254.81 ms /    45 tokens (    5.66 ms per token,   176.60 tokens per second)\n",
            "llama_print_timings:        eval time =    1510.01 ms /    15 runs   (  100.67 ms per token,     9.93 tokens per second)\n",
            "llama_print_timings:       total time =    1922.76 ms /    60 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "I don't know how slutty I look being fucked on all fours 😍❤️ lucky the one who bought those videos hehe #Sexting #NSFW #Nude\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.08 ms /    16 runs   (    0.63 ms per token,  1586.99 tokens per second)\n",
            "llama_print_timings: prompt eval time =     710.84 ms /    22 tokens (   32.31 ms per token,    30.95 tokens per second)\n",
            "llama_print_timings:        eval time =    1690.07 ms /    15 runs   (  112.67 ms per token,     8.88 tokens per second)\n",
            "llama_print_timings:       total time =    2565.19 ms /    37 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@NicoletteElf I feel like sexting with you dear 😳\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.92 ms /    16 runs   (    0.56 ms per token,  1794.12 tokens per second)\n",
            "llama_print_timings: prompt eval time =     379.95 ms /   139 tokens (    2.73 ms per token,   365.84 tokens per second)\n",
            "llama_print_timings:        eval time =    1511.99 ms /    15 runs   (  100.80 ms per token,     9.92 tokens per second)\n",
            "llama_print_timings:       total time =    2287.94 ms /   154 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "🇻🇪 I'm Your Chi.k Vip 🇻🇪Only Telegram Group that by participating you can win 🔥 In-Person Meetings 📸 Nude Photo 🎬 Hot Videos 📲 Video Call 💢 SextingThere are the best Girls and Couples of 🇻🇪Mem: 8 Bolivares Telegram:https:/ /t.co/QcVdHwcStC https://t.co/8A0sSAQnwM\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.19 ms /    16 runs   (    0.57 ms per token,  1740.64 tokens per second)\n",
            "llama_print_timings: prompt eval time =     247.54 ms /    46 tokens (    5.38 ms per token,   185.83 tokens per second)\n",
            "llama_print_timings:        eval time =    1599.38 ms /    15 runs   (  106.63 ms per token,     9.38 tokens per second)\n",
            "llama_print_timings:       total time =    2008.74 ms /    61 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Two arrested in Lugo for appropriating more than 65,000 euros through 'sextortion' https://t.co/bVf3Uhw2sF\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      12.13 ms /    16 runs   (    0.76 ms per token,  1318.93 tokens per second)\n",
            "llama_print_timings: prompt eval time =     281.91 ms /    74 tokens (    3.81 ms per token,   262.49 tokens per second)\n",
            "llama_print_timings:        eval time =    1930.92 ms /    15 runs   (  128.73 ms per token,     7.77 tokens per second)\n",
            "llama_print_timings:       total time =    2603.35 ms /    89 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "🔴 PDI_Magallanes @PDI_Magallanes 👉 Before sending that image, think twice. The effects of #Sextortion can be devastating for its victims and those close to them. #YouMayBeNext #YouCouldBeNext https://t.co/kVws49Y5wG\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.88 ms /    16 runs   (    0.55 ms per token,  1802.82 tokens per second)\n",
            "llama_print_timings: prompt eval time =     289.69 ms /    99 tokens (    2.93 ms per token,   341.75 tokens per second)\n",
            "llama_print_timings:        eval time =    1567.53 ms /    15 runs   (  104.50 ms per token,     9.57 tokens per second)\n",
            "llama_print_timings:       total time =    2122.54 ms /   114 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "The Civil Guard has arrested 10 people as alleged perpetrators of the crimes of extortion, usurpation of civil status, money laundering and membership in a criminal organization#EquiparacionYa24s#24sMovilizate@jusapol💙💚🇪🇦@CSIFnacional https://t.co/ rszrlIfkAd\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.17 ms /    16 runs   (    0.70 ms per token,  1432.02 tokens per second)\n",
            "llama_print_timings: prompt eval time =     255.70 ms /    57 tokens (    4.49 ms per token,   222.92 tokens per second)\n",
            "llama_print_timings:        eval time =    1540.98 ms /    15 runs   (  102.73 ms per token,     9.73 tokens per second)\n",
            "llama_print_timings:       total time =    1981.49 ms /    72 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Spokespeople for Eset, a brand specialized in cybersecurity, explain the most common types of scams in this app: sextortion; identity fraud; cryptocurrency scams; Tinder verification code; Fake profiles and catfishing.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       2.75 ms /     5 runs   (    0.55 ms per token,  1814.88 tokens per second)\n",
            "llama_print_timings: prompt eval time =     282.17 ms /    75 tokens (    3.76 ms per token,   265.80 tokens per second)\n",
            "llama_print_timings:        eval time =     442.01 ms /     4 runs   (  110.50 ms per token,     9.05 tokens per second)\n",
            "llama_print_timings:       total time =     947.94 ms /    79 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "I just read someone telling a skinny girl that she is a victim of death threats and sextortion, that this is so that she learns next time to choose a hard-working one. HAHAHAHAHAHAHAHAHAHAHAHAHAHAHAHAJOf course, Roberto, because surely that makes them good beings.\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.88 ms /    16 runs   (    0.62 ms per token,  1618.78 tokens per second)\n",
            "llama_print_timings: prompt eval time =     232.25 ms /    44 tokens (    5.28 ms per token,   189.45 tokens per second)\n",
            "llama_print_timings:        eval time =    1551.69 ms /    15 runs   (  103.45 ms per token,     9.67 tokens per second)\n",
            "llama_print_timings:       total time =    1945.88 ms /    59 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Abraham Romero, MyHyV's link in the criminal organization dedicated to sextortion https://t.co/wDjzh09Dem via @elespanolcom\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.82 ms /    16 runs   (    0.55 ms per token,  1814.26 tokens per second)\n",
            "llama_print_timings: prompt eval time =     274.01 ms /    79 tokens (    3.47 ms per token,   288.31 tokens per second)\n",
            "llama_print_timings:        eval time =    1616.60 ms /    15 runs   (  107.77 ms per token,     9.28 tokens per second)\n",
            "llama_print_timings:       total time =    2120.39 ms /    94 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Robert3ero @callodehacha And do you want a coffee too? Hahahahahaha like why would they have to talk about me. What if you kidnap me 😛? And poor mothers that you told them that the husband left them. Tssss you see who is the one who has problems with the society.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.88 ms /    16 runs   (    0.62 ms per token,  1620.25 tokens per second)\n",
            "llama_print_timings: prompt eval time =     280.40 ms /    77 tokens (    3.64 ms per token,   274.61 tokens per second)\n",
            "llama_print_timings:        eval time =    1582.93 ms /    15 runs   (  105.53 ms per token,     9.48 tokens per second)\n",
            "llama_print_timings:       total time =    2090.62 ms /    92 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@FrenteaFrenteHN (2) .... comes, if he did that back then, when he did not have any power under his command, what can we expect he would do, now that he was given power and in one of the sectors and/or areas most delicate and conflictive in society?, little by little they are becoming evident.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.11 ms /    16 runs   (    0.63 ms per token,  1582.43 tokens per second)\n",
            "llama_print_timings: prompt eval time =     288.12 ms /    67 tokens (    4.30 ms per token,   232.55 tokens per second)\n",
            "llama_print_timings:        eval time =    1724.02 ms /    15 runs   (  114.93 ms per token,     8.70 tokens per second)\n",
            "llama_print_timings:       total time =    2346.20 ms /    82 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "💥Viral: They were going to get married, the groom exposed an unexpected video and it all ended badly#Viral #Viral #Sociedad #amoryfuego#BuenJueveshttps://t.co/NpOgNvNJp8\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.78 ms /    16 runs   (    0.61 ms per token,  1636.16 tokens per second)\n",
            "llama_print_timings: prompt eval time =     269.12 ms /    81 tokens (    3.32 ms per token,   300.98 tokens per second)\n",
            "llama_print_timings:        eval time =    1538.27 ms /    15 runs   (  102.55 ms per token,     9.75 tokens per second)\n",
            "llama_print_timings:       total time =    2034.68 ms /    96 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@quintanapaz @Xiani_PCh @elmundoes Are you referring to the Taiwanese belonging to a mafia who gained strength in different modules of the Aranjuez CP, trying to control the rest of the prison inmates and even confronting the prison officials? https:// t.co/C7VcOUJsS9\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.29 ms /    16 runs   (    0.58 ms per token,  1722.84 tokens per second)\n",
            "llama_print_timings: prompt eval time =     303.22 ms /   126 tokens (    2.41 ms per token,   415.54 tokens per second)\n",
            "llama_print_timings:        eval time =    1482.38 ms /    15 runs   (   98.83 ms per token,    10.12 tokens per second)\n",
            "llama_print_timings:       total time =    2139.58 ms /   141 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "‼️TODAY‼️🎙 We are going to be talking: CURRENT EVENTS: Discussion of the 2023 national budget CHALLENGES: How does society choose its leaders? With Engineer Fernando Alonso.PROTAGONISTS: @luisnazer President of NZR📻👉 Listen to us on FM 89.5 or on https://t.co/ZKSXGZBBvF https://t.co/bozKt5Yxx0\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.39 ms /    16 runs   (    0.65 ms per token,  1540.09 tokens per second)\n",
            "llama_print_timings: prompt eval time =     246.49 ms /    49 tokens (    5.03 ms per token,   198.79 tokens per second)\n",
            "llama_print_timings:        eval time =    1725.33 ms /    15 runs   (  115.02 ms per token,     8.69 tokens per second)\n",
            "llama_print_timings:       total time =    2152.53 ms /    64 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "The organization continues to provide help to the most needy sectors of society #VocesCríticas #Argentina @ansesgob https://t.co/dt6VfoBt4X\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.63 ms /    16 runs   (    0.60 ms per token,  1661.13 tokens per second)\n",
            "llama_print_timings: prompt eval time =     793.08 ms /    29 tokens (   27.35 ms per token,    36.57 tokens per second)\n",
            "llama_print_timings:        eval time =    1598.96 ms /    15 runs   (  106.60 ms per token,     9.38 tokens per second)\n",
            "llama_print_timings:       total time =    2532.12 ms /    44 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@martintetaz Please don't let yourselves be sodomized, the only thing I ask of you\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.07 ms /    16 runs   (    0.57 ms per token,  1763.47 tokens per second)\n",
            "llama_print_timings: prompt eval time =     244.10 ms /    43 tokens (    5.68 ms per token,   176.16 tokens per second)\n",
            "llama_print_timings:        eval time =    1485.72 ms /    15 runs   (   99.05 ms per token,    10.10 tokens per second)\n",
            "llama_print_timings:       total time =    1885.91 ms /    58 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@berry_fergie Every time I see Parasoul online, I know I'm going to be sodomized https://t.co/D32UmQWCGe\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.43 ms /    16 runs   (    0.59 ms per token,  1697.07 tokens per second)\n",
            "llama_print_timings: prompt eval time =     245.61 ms /    41 tokens (    5.99 ms per token,   166.93 tokens per second)\n",
            "llama_print_timings:        eval time =    1674.59 ms /    15 runs   (  111.64 ms per token,     8.96 tokens per second)\n",
            "llama_print_timings:       total time =    2073.16 ms /    56 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "and the breeze of death will rot what is decent, come and let yourself be sodomized...! https://t.co/L6SDRFjR9z\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.05 ms /    16 runs   (    0.69 ms per token,  1447.70 tokens per second)\n",
            "llama_print_timings: prompt eval time =     263.38 ms /    53 tokens (    4.97 ms per token,   201.23 tokens per second)\n",
            "llama_print_timings:        eval time =    1851.77 ms /    15 runs   (  123.45 ms per token,     8.10 tokens per second)\n",
            "llama_print_timings:       total time =    2315.15 ms /    68 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@GARA_jiturria Very much agree. I wish more journalists would bring this issue to the fore. In my opinion, the “kambio klimatiko” seeks to further sodomize the population.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.15 ms /    16 runs   (    0.57 ms per token,  1749.02 tokens per second)\n",
            "llama_print_timings: prompt eval time =     292.08 ms /    82 tokens (    3.56 ms per token,   280.74 tokens per second)\n",
            "llama_print_timings:        eval time =    1476.82 ms /    15 runs   (   98.45 ms per token,    10.16 tokens per second)\n",
            "llama_print_timings:       total time =    2001.17 ms /    97 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@esCesarVidal They do dress them like whores, right? Zelensky should have handed the country over to Putin and at the same time allowed himself to be sodomized by his dog. If we have a hard time it is because we are a country of subsidized people. Those who work are not protected. The lazy and the criminal are protected.\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       3.26 ms /     5 runs   (    0.65 ms per token,  1533.74 tokens per second)\n",
            "llama_print_timings: prompt eval time =     296.85 ms /   107 tokens (    2.77 ms per token,   360.45 tokens per second)\n",
            "llama_print_timings:        eval time =     451.77 ms /     4 runs   (  112.94 ms per token,     8.85 tokens per second)\n",
            "llama_print_timings:       total time =    1008.92 ms /   111 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Kamalbimbini @potytoo @Hanan71443742 @FatimaHHossain Hahaha poor idiot, don't you have a better insult than not having said it to your mother before? Apart from being sexist, stupid. And just so you know, even when it comes to whoring, I like your men. Pigs are left out because it is zoophilia. Muslims are allowed to sodomize sheep, get busy\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.13 ms /    16 runs   (    0.63 ms per token,  1579.31 tokens per second)\n",
            "llama_print_timings: prompt eval time =     521.99 ms /    32 tokens (   16.31 ms per token,    61.30 tokens per second)\n",
            "llama_print_timings:        eval time =    1718.53 ms /    15 runs   (  114.57 ms per token,     8.73 tokens per second)\n",
            "llama_print_timings:       total time =    2471.43 ms /    47 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "I thought this tweet was about sorority until I finished reading https://t.co/h0YmxWDmnc\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.45 ms /    16 runs   (    0.59 ms per token,  1692.94 tokens per second)\n",
            "llama_print_timings: prompt eval time =     263.97 ms /    56 tokens (    4.71 ms per token,   212.15 tokens per second)\n",
            "llama_print_timings:        eval time =    1451.41 ms /    15 runs   (   96.76 ms per token,    10.33 tokens per second)\n",
            "llama_print_timings:       total time =    1894.62 ms /    71 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "The family seeing that you come and go, greet, you are friendly to everyone and that they cannot at least tell you out of sorority. WHAT THE SHIT. https://t.co/ci3dLZMIVV\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.79 ms /    16 runs   (    0.55 ms per token,  1820.46 tokens per second)\n",
            "llama_print_timings: prompt eval time =     769.08 ms /    31 tokens (   24.81 ms per token,    40.31 tokens per second)\n",
            "llama_print_timings:        eval time =    1474.76 ms /    15 runs   (   98.32 ms per token,    10.17 tokens per second)\n",
            "llama_print_timings:       total time =    2370.46 ms /    46 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@kiinkynasty @PAO_KARO @AmelieGranata Where was the sorority??\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.06 ms /    16 runs   (    0.69 ms per token,  1446.92 tokens per second)\n",
            "llama_print_timings: prompt eval time =     252.14 ms /    46 tokens (    5.48 ms per token,   182.44 tokens per second)\n",
            "llama_print_timings:        eval time =    1719.67 ms /    15 runs   (  114.64 ms per token,     8.72 tokens per second)\n",
            "llama_print_timings:       total time =    2149.72 ms /    61 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "It is unfortunate that at this point in the program no one has yet stopped the violent man from Matamoros and very sad the lack of sisterhood among those present. #DeluxeFriday\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.80 ms /    16 runs   (    0.55 ms per token,  1817.15 tokens per second)\n",
            "llama_print_timings: prompt eval time =     255.58 ms /    49 tokens (    5.22 ms per token,   191.72 tokens per second)\n",
            "llama_print_timings:        eval time =    1597.99 ms /    15 runs   (  106.53 ms per token,     9.39 tokens per second)\n",
            "llama_print_timings:       total time =    2027.25 ms /    64 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "We were at the party of our #Morena party with two great people. #Sorority #WomenAndDiversity https://t.co/rBZvPqyBQF\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.60 ms /    16 runs   (    0.54 ms per token,  1860.25 tokens per second)\n",
            "llama_print_timings: prompt eval time =     778.33 ms /    30 tokens (   25.94 ms per token,    38.54 tokens per second)\n",
            "llama_print_timings:        eval time =    1501.78 ms /    15 runs   (  100.12 ms per token,     9.99 tokens per second)\n",
            "llama_print_timings:       total time =    2405.32 ms /    45 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Carrion16981 incredible, it seems that sorority here is only when it is convenient.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.10 ms /    16 runs   (    0.57 ms per token,  1759.01 tokens per second)\n",
            "llama_print_timings: prompt eval time =     764.22 ms /    30 tokens (   25.47 ms per token,    39.26 tokens per second)\n",
            "llama_print_timings:        eval time =    1645.16 ms /    15 runs   (  109.68 ms per token,     9.12 tokens per second)\n",
            "llama_print_timings:       total time =    2539.27 ms /    45 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "The man who was in underwear and a bra as well as barefoot on the plains 🤝🏻\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.69 ms /    16 runs   (    0.67 ms per token,  1496.73 tokens per second)\n",
            "llama_print_timings: prompt eval time =     246.91 ms /    41 tokens (    6.02 ms per token,   166.05 tokens per second)\n",
            "llama_print_timings:        eval time =    1895.79 ms /    15 runs   (  126.39 ms per token,     7.91 tokens per second)\n",
            "llama_print_timings:       total time =    2323.12 ms /    56 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "I go running without a bra and it doesn't happen to me, advantages of not having one ✌️ https://t.co/6ny56ixvDb\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.51 ms /    16 runs   (    0.53 ms per token,  1879.48 tokens per second)\n",
            "llama_print_timings: prompt eval time =     250.45 ms /    44 tokens (    5.69 ms per token,   175.69 tokens per second)\n",
            "llama_print_timings:        eval time =    1583.32 ms /    15 runs   (  105.55 ms per token,     9.47 tokens per second)\n",
            "llama_print_timings:       total time =    1996.25 ms /    59 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Crazy hair, no bra, bright dress, on the way to the chalet... Boom, I crash into a car on a street full of people, what a look xd\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.85 ms /    16 runs   (    0.55 ms per token,  1807.09 tokens per second)\n",
            "llama_print_timings: prompt eval time =     253.70 ms /    35 tokens (    7.25 ms per token,   137.96 tokens per second)\n",
            "llama_print_timings:        eval time =    1632.30 ms /    15 runs   (  108.82 ms per token,     9.19 tokens per second)\n",
            "llama_print_timings:       total time =    2028.06 ms /    50 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "No, I never wear a bra, because if my boobs want to be the star point of the outfit, who am I to stop it?\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.68 ms /    16 runs   (    0.54 ms per token,  1843.96 tokens per second)\n",
            "llama_print_timings: prompt eval time =     532.27 ms /    18 tokens (   29.57 ms per token,    33.82 tokens per second)\n",
            "llama_print_timings:        eval time =    1591.75 ms /    15 runs   (  106.12 ms per token,     9.42 tokens per second)\n",
            "llama_print_timings:       total time =    2224.47 ms /    33 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Question for the girls; How often do you change your bra?\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.85 ms /    16 runs   (    0.68 ms per token,  1474.25 tokens per second)\n",
            "llama_print_timings: prompt eval time =     245.65 ms /    33 tokens (    7.44 ms per token,   134.34 tokens per second)\n",
            "llama_print_timings:        eval time =    1814.63 ms /    15 runs   (  120.98 ms per token,     8.27 tokens per second)\n",
            "llama_print_timings:       total time =    2243.37 ms /    48 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "ready to jump into a pool in my bra and panties because I realized I didn't pack my swimsuit in my suitcase!\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.23 ms /    16 runs   (    0.58 ms per token,  1733.29 tokens per second)\n",
            "llama_print_timings: prompt eval time =     255.26 ms /    47 tokens (    5.43 ms per token,   184.12 tokens per second)\n",
            "llama_print_timings:        eval time =    1558.77 ms /    15 runs   (  103.92 ms per token,     9.62 tokens per second)\n",
            "llama_print_timings:       total time =    1973.10 ms /    62 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Friend of Gotica No one is going to treat you as well as a man who wants to fuck you for the first time Follow me for more #BatiTruths 🦇😎😉\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.65 ms /    16 runs   (    0.54 ms per token,  1849.50 tokens per second)\n",
            "llama_print_timings: prompt eval time =     253.65 ms /    38 tokens (    6.68 ms per token,   149.81 tokens per second)\n",
            "llama_print_timings:        eval time =    1515.34 ms /    15 runs   (  101.02 ms per token,     9.90 tokens per second)\n",
            "llama_print_timings:       total time =    1908.52 ms /    53 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Nobody lies as well as a man who got a bad haircut and says he liked it so as not to make the barber feel bad hahaha\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.88 ms /    16 runs   (    0.55 ms per token,  1802.82 tokens per second)\n",
            "llama_print_timings: prompt eval time =     704.08 ms /    27 tokens (   26.08 ms per token,    38.35 tokens per second)\n",
            "llama_print_timings:        eval time =    1469.43 ms /    15 runs   (   97.96 ms per token,    10.21 tokens per second)\n",
            "llama_print_timings:       total time =    2297.15 ms /    42 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "No one is going to treat you as well as a man who wants to fuck you for the first time.\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.30 ms /    16 runs   (    0.64 ms per token,  1553.25 tokens per second)\n",
            "llama_print_timings: prompt eval time =     429.79 ms /    15 tokens (   28.65 ms per token,    34.90 tokens per second)\n",
            "llama_print_timings:        eval time =    1871.31 ms /    15 runs   (  124.75 ms per token,     8.02 tokens per second)\n",
            "llama_print_timings:       total time =    2434.34 ms /    30 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "No one is going to treat you as well as a man you don't want anything to do with.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.67 ms /    16 runs   (    0.54 ms per token,  1844.81 tokens per second)\n",
            "llama_print_timings: prompt eval time =     712.68 ms /    28 tokens (   25.45 ms per token,    39.29 tokens per second)\n",
            "llama_print_timings:        eval time =    1523.42 ms /    15 runs   (  101.56 ms per token,     9.85 tokens per second)\n",
            "llama_print_timings:       total time =    2358.79 ms /    43 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Nobody is going to treat you as well as a man who wants to eat you for the first time.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.41 ms /    16 runs   (    0.59 ms per token,  1700.14 tokens per second)\n",
            "llama_print_timings: prompt eval time =     242.31 ms /    43 tokens (    5.64 ms per token,   177.46 tokens per second)\n",
            "llama_print_timings:        eval time =    1590.99 ms /    15 runs   (  106.07 ms per token,     9.43 tokens per second)\n",
            "llama_print_timings:       total time =    1993.74 ms /    58 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "No one is going to treat you as well as a man who wants to fuck you. THERE IF THEY TELL YOU EVEN MY WIFE🤣🖕🏻\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.17 ms /    16 runs   (    0.57 ms per token,  1744.44 tokens per second)\n",
            "llama_print_timings: prompt eval time =     679.75 ms /    25 tokens (   27.19 ms per token,    36.78 tokens per second)\n",
            "llama_print_timings:        eval time =    1465.55 ms /    15 runs   (   97.70 ms per token,    10.24 tokens per second)\n",
            "llama_print_timings:       total time =    2265.72 ms /    40 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Aqu Ahora1 The same thing is the glass ceiling that the feminazis say exists\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      12.23 ms /    16 runs   (    0.76 ms per token,  1308.58 tokens per second)\n",
            "llama_print_timings: prompt eval time =     283.65 ms /    78 tokens (    3.64 ms per token,   274.98 tokens per second)\n",
            "llama_print_timings:        eval time =    1861.14 ms /    15 runs   (  124.08 ms per token,     8.06 tokens per second)\n",
            "llama_print_timings:       total time =    2557.74 ms /    93 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "4) Originally, in the novel, they tell you that even the daughters (in this case Kim's mother) went to work to pay for their own brother's college.5) The protagonist realizes that women are not promoted to the senior officials (glass ceiling). https://t.co/LL03CyN0fM\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.05 ms /    16 runs   (    0.63 ms per token,  1591.41 tokens per second)\n",
            "llama_print_timings: prompt eval time =     286.81 ms /    89 tokens (    3.22 ms per token,   310.31 tokens per second)\n",
            "llama_print_timings:        eval time =    1536.20 ms /    15 runs   (  102.41 ms per token,     9.76 tokens per second)\n",
            "llama_print_timings:       total time =    2067.89 ms /   104 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "I present to you the \"analyst\" of @WapaTV The one who calls everyone who doesn't think like him a fool. The one who criticizes that the police defend themselves against brick attacks but does not say a word about what is happening in Nicaragua. The one who has the glass ceiling but keeps throwing stones!! https://t.co/DUXIyfGCRR\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.44 ms /    16 runs   (    0.59 ms per token,  1695.45 tokens per second)\n",
            "llama_print_timings: prompt eval time =     259.00 ms /    51 tokens (    5.08 ms per token,   196.91 tokens per second)\n",
            "llama_print_timings:        eval time =    1543.05 ms /    15 runs   (  102.87 ms per token,     9.72 tokens per second)\n",
            "llama_print_timings:       total time =    1971.15 ms /    66 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@juandalmauPR @ElNuevoDia The corruption of the blues and reds is so bad as well as the cover-up of the sexist harassers in the greens... glass ceiling Juanito\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.79 ms /    16 runs   (    0.74 ms per token,  1356.51 tokens per second)\n",
            "llama_print_timings: prompt eval time =     281.35 ms /    67 tokens (    4.20 ms per token,   238.13 tokens per second)\n",
            "llama_print_timings:        eval time =    1821.22 ms /    15 runs   (  121.41 ms per token,     8.24 tokens per second)\n",
            "llama_print_timings:       total time =    2336.52 ms /    82 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Oh please, how difficult it will be for feminists to dismantle the glass ceiling discourse that makes us believe - among other things - that feminism is about women occupying positions of power while the people starve themselves https://t. co/OtQWvt95b1\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.23 ms /    16 runs   (    0.58 ms per token,  1734.23 tokens per second)\n",
            "llama_print_timings: prompt eval time =     264.69 ms /    53 tokens (    4.99 ms per token,   200.23 tokens per second)\n",
            "llama_print_timings:        eval time =    1547.06 ms /    15 runs   (  103.14 ms per token,     9.70 tokens per second)\n",
            "llama_print_timings:       total time =    1984.43 ms /    68 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Strelok_Pizza @Comandante_Alfa @Oviedo_78_ @MartaDeLosReyes @interiorgob @guardiacivil There is no glass ceiling here either.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.19 ms /    16 runs   (    0.57 ms per token,  1741.59 tokens per second)\n",
            "llama_print_timings: prompt eval time =     249.59 ms /    52 tokens (    4.80 ms per token,   208.34 tokens per second)\n",
            "llama_print_timings:        eval time =    1505.73 ms /    15 runs   (  100.38 ms per token,     9.96 tokens per second)\n",
            "llama_print_timings:       total time =    1938.39 ms /    67 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "I repudiate it to the core, but let's see...Putting the flag in your anus is wrong (yes), but massaging your tits with the flag is not...There seems to be a perception problem\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.45 ms /    16 runs   (    0.53 ms per token,  1893.04 tokens per second)\n",
            "llama_print_timings: prompt eval time =     783.39 ms /    30 tokens (   26.11 ms per token,    38.30 tokens per second)\n",
            "llama_print_timings:        eval time =    1490.42 ms /    15 runs   (   99.36 ms per token,    10.06 tokens per second)\n",
            "llama_print_timings:       total time =    2401.08 ms /    45 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "The only tits I ever had in my life. https://t.co/Y2bza1lGTh\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.92 ms /    16 runs   (    0.68 ms per token,  1465.74 tokens per second)\n",
            "llama_print_timings: prompt eval time =     446.20 ms /    11 tokens (   40.56 ms per token,    24.65 tokens per second)\n",
            "llama_print_timings:        eval time =    1827.75 ms /    15 runs   (  121.85 ms per token,     8.21 tokens per second)\n",
            "llama_print_timings:       total time =    2413.86 ms /    26 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Kidd__pizza\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.11 ms /    16 runs   (    0.57 ms per token,  1756.12 tokens per second)\n",
            "llama_print_timings: prompt eval time =     674.10 ms /    26 tokens (   25.93 ms per token,    38.57 tokens per second)\n",
            "llama_print_timings:        eval time =    1519.01 ms /    15 runs   (  101.27 ms per token,     9.87 tokens per second)\n",
            "llama_print_timings:       total time =    2313.24 ms /    41 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@SoulsTRK anything, getting some boobs and an onlyFans is always a good option\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.87 ms /    16 runs   (    0.55 ms per token,  1803.43 tokens per second)\n",
            "llama_print_timings: prompt eval time =     236.74 ms /    35 tokens (    6.76 ms per token,   147.84 tokens per second)\n",
            "llama_print_timings:        eval time =    1586.09 ms /    15 runs   (  105.74 ms per token,     9.46 tokens per second)\n",
            "llama_print_timings:       total time =    1958.00 ms /    50 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@TheLofyy Yes but if you show tits nothing happens right? If you catch the stream it's perfect and they recommend you xd\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.81 ms /    16 runs   (    0.55 ms per token,  1815.91 tokens per second)\n",
            "llama_print_timings: prompt eval time =     635.25 ms /    24 tokens (   26.47 ms per token,    37.78 tokens per second)\n",
            "llama_print_timings:        eval time =    1531.28 ms /    15 runs   (  102.09 ms per token,     9.80 tokens per second)\n",
            "llama_print_timings:       total time =    2281.46 ms /    39 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@StevePelon then why the hell are you telling me, suck both my tits\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.66 ms /    16 runs   (    0.73 ms per token,  1372.10 tokens per second)\n",
            "llama_print_timings: prompt eval time =     270.95 ms /    75 tokens (    3.61 ms per token,   276.80 tokens per second)\n",
            "llama_print_timings:        eval time =    1812.07 ms /    15 runs   (  120.80 ms per token,     8.28 tokens per second)\n",
            "llama_print_timings:       total time =    2459.98 ms /    90 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@carlosm0oerto already but the thing is that a few years ago I was super monarchist for example and now I'm not, and recently I was super in favor of sex work and gs and now it bothers me a lot, we all grow up it's part of life jajsjsj\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.68 ms /    16 runs   (    0.54 ms per token,  1842.68 tokens per second)\n",
            "llama_print_timings: prompt eval time =     810.19 ms /    31 tokens (   26.14 ms per token,    38.26 tokens per second)\n",
            "llama_print_timings:        eval time =    1511.02 ms /    15 runs   (  100.73 ms per token,     9.93 tokens per second)\n",
            "llama_print_timings:       total time =    2449.14 ms /    46 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Sex work in Chile: How to move from abolition to regulation https://t.co/lrpsQKTePh\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.65 ms /    16 runs   (    0.60 ms per token,  1657.52 tokens per second)\n",
            "llama_print_timings: prompt eval time =     255.41 ms /    54 tokens (    4.73 ms per token,   211.43 tokens per second)\n",
            "llama_print_timings:        eval time =    1611.58 ms /    15 runs   (  107.44 ms per token,     9.31 tokens per second)\n",
            "llama_print_timings:       total time =    2038.99 ms /    69 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "2nd mention about LGBTIQ people: trans women who do sex work. A reality, but there is much more that can be talked about... such as providing decent job opportunities or employability programs. Something that the current management did.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.98 ms /    16 runs   (    0.56 ms per token,  1780.94 tokens per second)\n",
            "llama_print_timings: prompt eval time =     285.32 ms /    74 tokens (    3.86 ms per token,   259.36 tokens per second)\n",
            "llama_print_timings:        eval time =    1491.88 ms /    15 runs   (   99.46 ms per token,    10.05 tokens per second)\n",
            "llama_print_timings:       total time =    2040.00 ms /    89 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Yesterday we saw: Good look to you, Leo Grande. And although JL fell asleep, I thought he was charming. The vindication of his position on sex work, the photography, the softness of the room, the actions of both. Cool, watch it. https://t.co/CDmygg2eu9\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.06 ms /    16 runs   (    0.57 ms per token,  1766.20 tokens per second)\n",
            "llama_print_timings: prompt eval time =     254.81 ms /    38 tokens (    6.71 ms per token,   149.13 tokens per second)\n",
            "llama_print_timings:        eval time =    1539.87 ms /    15 runs   (  102.66 ms per token,     9.74 tokens per second)\n",
            "llama_print_timings:       total time =    1938.21 ms /    53 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "That \"Sex Worker Union Association\" thing is really beyond me. It is unthinkable that a victim of sexual exploitation feels represented by these people.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.97 ms /    16 runs   (    0.56 ms per token,  1783.33 tokens per second)\n",
            "llama_print_timings: prompt eval time =     250.38 ms /    43 tokens (    5.82 ms per token,   171.74 tokens per second)\n",
            "llama_print_timings:        eval time =    1546.25 ms /    15 runs   (  103.08 ms per token,     9.70 tokens per second)\n",
            "llama_print_timings:       total time =    1963.67 ms /    58 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Friendly reminder whether you are for or against sex work. Being forced into prostitution is exploitation or trafficking, it is not sexual work because the work is VOLUNTARY.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.59 ms /    16 runs   (    0.72 ms per token,  1381.10 tokens per second)\n",
            "llama_print_timings: prompt eval time =     924.45 ms /    27 tokens (   34.24 ms per token,    29.21 tokens per second)\n",
            "llama_print_timings:        eval time =    1786.04 ms /    15 runs   (  119.07 ms per token,     8.40 tokens per second)\n",
            "llama_print_timings:       total time =    2920.57 ms /    42 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "It gave me a lot of gender dysphoria when I saw other trans boys who looked super manly.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.93 ms /    16 runs   (    0.56 ms per token,  1790.91 tokens per second)\n",
            "llama_print_timings: prompt eval time =     277.46 ms /    84 tokens (    3.30 ms per token,   302.75 tokens per second)\n",
            "llama_print_timings:        eval time =    1563.67 ms /    15 runs   (  104.24 ms per token,     9.59 tokens per second)\n",
            "llama_print_timings:       total time =    2075.62 ms /    99 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@GisselMorocha7 @Prdtvsaln @Transex_Mex @xlordxnergalx @mex_trans_elite @SweetModelsMx @NenasTransCom @OfficialTeamTNT @MxEncuentrosMx Delicious 🥵🍆😈🔥\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.86 ms /    16 runs   (    0.55 ms per token,  1805.26 tokens per second)\n",
            "llama_print_timings: prompt eval time =     610.02 ms /    21 tokens (   29.05 ms per token,    34.42 tokens per second)\n",
            "llama_print_timings:        eval time =    1485.47 ms /    15 runs   (   99.03 ms per token,    10.10 tokens per second)\n",
            "llama_print_timings:       total time =    2207.95 ms /    36 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@freddurstfanacc yes, I just go for the trans side and that\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.97 ms /    16 runs   (    0.56 ms per token,  1784.32 tokens per second)\n",
            "llama_print_timings: prompt eval time =     671.79 ms /    26 tokens (   25.84 ms per token,    38.70 tokens per second)\n",
            "llama_print_timings:        eval time =    1498.43 ms /    15 runs   (   99.90 ms per token,    10.01 tokens per second)\n",
            "llama_print_timings:       total time =    2291.92 ms /    41 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@draco_omega @balamdeamor I can confirm that KWS openly accepts trans people :)\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      12.52 ms /    16 runs   (    0.78 ms per token,  1277.96 tokens per second)\n",
            "llama_print_timings: prompt eval time =     268.25 ms /    42 tokens (    6.39 ms per token,   156.57 tokens per second)\n",
            "llama_print_timings:        eval time =    1811.54 ms /    15 runs   (  120.77 ms per token,     8.28 tokens per second)\n",
            "llama_print_timings:       total time =    2361.03 ms /    57 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@AccidentalSutep @cpsplimaycallao any volunteers to deal with that poor woman's fanaticism, low self-esteem and personal trans throne?\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.66 ms /    16 runs   (    0.60 ms per token,  1656.83 tokens per second)\n",
            "llama_print_timings: prompt eval time =     286.29 ms /    76 tokens (    3.77 ms per token,   265.47 tokens per second)\n",
            "llama_print_timings:        eval time =    1485.98 ms /    15 runs   (   99.07 ms per token,    10.09 tokens per second)\n",
            "llama_print_timings:       total time =    2011.31 ms /    91 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@astralemm @OphCourse @maurismos @JuntransFest @kikimagdalenamx @pachekunty @extraricaaa @LaJauriaTrans @FluxMexico @Mexico_Trans @LuchadorasMX Can you give me information about the event\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.72 ms /    16 runs   (    0.54 ms per token,  1835.07 tokens per second)\n",
            "llama_print_timings: prompt eval time =     239.89 ms /    34 tokens (    7.06 ms per token,   141.73 tokens per second)\n",
            "llama_print_timings:        eval time =    1535.36 ms /    15 runs   (  102.36 ms per token,     9.77 tokens per second)\n",
            "llama_print_timings:       total time =    1916.70 ms /    49 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Registration open for the course 'Training in gender mainstreaming for professionals' https://t.co/YWek9XjDLl\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.30 ms /    16 runs   (    0.58 ms per token,  1720.43 tokens per second)\n",
            "llama_print_timings: prompt eval time =     244.57 ms /    37 tokens (    6.61 ms per token,   151.29 tokens per second)\n",
            "llama_print_timings:        eval time =    1604.18 ms /    15 runs   (  106.95 ms per token,     9.35 tokens per second)\n",
            "llama_print_timings:       total time =    1993.27 ms /    52 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@pincheesqueda @ZorlakRules Some useless courses like: degree in gender transversality. And so, bagged and happy.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.11 ms /    16 runs   (    0.69 ms per token,  1440.40 tokens per second)\n",
            "llama_print_timings: prompt eval time =     260.58 ms /    38 tokens (    6.86 ms per token,   145.83 tokens per second)\n",
            "llama_print_timings:        eval time =    1820.71 ms /    15 runs   (  121.38 ms per token,     8.24 tokens per second)\n",
            "llama_print_timings:       total time =    2334.09 ms /    53 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "The seminar on the implementation of gender mainstreaming in military operations of the Armed Forces ends https://t.co/iVgmpvwPs5\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.49 ms /    16 runs   (    0.59 ms per token,  1685.99 tokens per second)\n",
            "llama_print_timings: prompt eval time =     285.94 ms /    88 tokens (    3.25 ms per token,   307.76 tokens per second)\n",
            "llama_print_timings:        eval time =    1583.12 ms /    15 runs   (  105.54 ms per token,     9.47 tokens per second)\n",
            "llama_print_timings:       total time =    2117.63 ms /   103 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "In our radio space \"Gender and Municipality\" the SDE Vice Mayor's Office and the Gender Equality Office provide guidance on \"Gender Mainstreaming in Municipal Work\" with the expert, Lic. Marianela Pinales. @voztrinitariasde#CiudadJustaYCreativa #ASDE https://t.co/Ge4rENrgpw\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.43 ms /    16 runs   (    0.59 ms per token,  1696.17 tokens per second)\n",
            "llama_print_timings: prompt eval time =     291.47 ms /    85 tokens (    3.43 ms per token,   291.62 tokens per second)\n",
            "llama_print_timings:        eval time =    1560.85 ms /    15 runs   (  104.06 ms per token,     9.61 tokens per second)\n",
            "llama_print_timings:       total time =    2093.62 ms /   100 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "The Provincial Directorate of @empleo_SEPE #Melilla publishes on its website the list of those selected for the program 'Employment, women and gender transversality in public policies to support activation for employment'. https://t.co/brvkxOxWZ3 https://t.co/PbCwhqc0TW\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.42 ms /    16 runs   (    0.59 ms per token,  1699.42 tokens per second)\n",
            "llama_print_timings: prompt eval time =     277.99 ms /    77 tokens (    3.61 ms per token,   276.99 tokens per second)\n",
            "llama_print_timings:        eval time =    1550.91 ms /    15 runs   (  103.39 ms per token,     9.67 tokens per second)\n",
            "llama_print_timings:       total time =    2054.88 ms /    92 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "💜💚 Accompany the UAQ Gender Equality Coordination to celebrate 10 years of Gender Mainstreaming at the UAQ, this Wednesday, September 7 at 10:00 am on the Rectory esplanade. https://t.co/i6F6RssXYN\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.86 ms /    16 runs   (    0.68 ms per token,  1472.75 tokens per second)\n",
            "llama_print_timings: prompt eval time =     274.06 ms /    62 tokens (    4.42 ms per token,   226.23 tokens per second)\n",
            "llama_print_timings:        eval time =    1652.90 ms /    15 runs   (  110.19 ms per token,     9.07 tokens per second)\n",
            "llama_print_timings:       total time =    2245.53 ms /    77 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Carolina_Roq_ @Pipe_Munoz_E @espinozacuellar If men asked for a day without women around, you would foam at the mouth alleging machismo, discrimination, misogyny and lack of gender equality\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.07 ms /    16 runs   (    0.57 ms per token,  1764.25 tokens per second)\n",
            "llama_print_timings: prompt eval time =     260.01 ms /    42 tokens (    6.19 ms per token,   161.53 tokens per second)\n",
            "llama_print_timings:        eval time =    1656.86 ms /    15 runs   (  110.46 ms per token,     9.05 tokens per second)\n",
            "llama_print_timings:       total time =    2081.31 ms /    57 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Argentina does not need a day without women or a day without men, only a society with Values! https://t.co/aFcpwe913w\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.14 ms /    16 runs   (    0.57 ms per token,  1750.16 tokens per second)\n",
            "llama_print_timings: prompt eval time =     251.18 ms /    42 tokens (    5.98 ms per token,   167.21 tokens per second)\n",
            "llama_print_timings:        eval time =    1461.57 ms /    15 runs   (   97.44 ms per token,    10.26 tokens per second)\n",
            "llama_print_timings:       total time =    1867.71 ms /    57 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "How did a day come about without women? Because we can't do anything to make the @PRI_Nacional send @alitomorenoc to hell, but now.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.85 ms /    16 runs   (    0.68 ms per token,  1475.06 tokens per second)\n",
            "llama_print_timings: prompt eval time =     257.38 ms /    41 tokens (    6.28 ms per token,   159.29 tokens per second)\n",
            "llama_print_timings:        eval time =    1840.25 ms /    15 runs   (  122.68 ms per token,     8.15 tokens per second)\n",
            "llama_print_timings:       total time =    2278.15 ms /    56 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@CTercermundista A sister distanced herself from me because of your comic about a day without women that takes place in an office and the atmosphere there was calmer.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.84 ms /    16 runs   (    0.55 ms per token,  1810.77 tokens per second)\n",
            "llama_print_timings: prompt eval time =     255.73 ms /    42 tokens (    6.09 ms per token,   164.24 tokens per second)\n",
            "llama_print_timings:        eval time =    1551.36 ms /    15 runs   (  103.42 ms per token,     9.67 tokens per second)\n",
            "llama_print_timings:       total time =    1972.62 ms /    57 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Viri_Rios Ijole just as in the one-day marches without women they point only to the 100 infiltrated by the government 😀\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.28 ms /    16 runs   (    0.58 ms per token,  1724.32 tokens per second)\n",
            "llama_print_timings: prompt eval time =     263.62 ms /    59 tokens (    4.47 ms per token,   223.80 tokens per second)\n",
            "llama_print_timings:        eval time =    1512.77 ms /    15 runs   (  100.85 ms per token,     9.92 tokens per second)\n",
            "llama_print_timings:       total time =    1964.93 ms /    74 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "In case you forgot Andrés Manuel López Obrador, tomorrow is Women's Day, tomorrow is International Women's Day, tomorrow is a day without women, remember it and I'll tell you now, women will take away your POWER.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.61 ms /    16 runs   (    0.60 ms per token,  1665.11 tokens per second)\n",
            "llama_print_timings: prompt eval time =     250.10 ms /    50 tokens (    5.00 ms per token,   199.92 tokens per second)\n",
            "llama_print_timings:        eval time =    1529.83 ms /    15 runs   (  101.99 ms per token,     9.81 tokens per second)\n",
            "llama_print_timings:       total time =    1950.72 ms /    65 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@victorg91 @malaga Listen, you already have pride week (which is basically a month) for all this victimhood, etc. For the rest of the year please, let us live in peace.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.73 ms /    16 runs   (    0.67 ms per token,  1490.73 tokens per second)\n",
            "llama_print_timings: prompt eval time =     258.00 ms /    47 tokens (    5.49 ms per token,   182.17 tokens per second)\n",
            "llama_print_timings:        eval time =    1833.30 ms /    15 runs   (  122.22 ms per token,     8.18 tokens per second)\n",
            "llama_print_timings:       total time =    2386.59 ms /    62 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Nobody is fishing for the old wool or the howl of victimhood. An empowered Chile is winning and has enough head level to envision futures. #RejectionOnSeptember4th\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.40 ms /    16 runs   (    0.59 ms per token,  1701.58 tokens per second)\n",
            "llama_print_timings: prompt eval time =     278.74 ms /    67 tokens (    4.16 ms per token,   240.37 tokens per second)\n",
            "llama_print_timings:        eval time =    1530.90 ms /    15 runs   (  102.06 ms per token,     9.80 tokens per second)\n",
            "llama_print_timings:       total time =    2017.94 ms /    82 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@olgarodriguezfr But what does the girl say, but if you are in the government... the victimhood that the Marquis of Galapagar tells her that they have to put... if they are not even made in a mold, they are posh children crying loudly. ..\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.62 ms /    16 runs   (    0.60 ms per token,  1662.68 tokens per second)\n",
            "llama_print_timings: prompt eval time =     262.79 ms /    57 tokens (    4.61 ms per token,   216.90 tokens per second)\n",
            "llama_print_timings:        eval time =    1512.60 ms /    15 runs   (  100.84 ms per token,     9.92 tokens per second)\n",
            "llama_print_timings:       total time =    1957.04 ms /    72 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@darkc26 @ManuRaulG @jtgazmuri The only way for women to become empowered is to change their mentality, leave victimhood and take control of their own life, work and support themselves, that is true independence\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.18 ms /    16 runs   (    0.57 ms per token,  1743.11 tokens per second)\n",
            "llama_print_timings: prompt eval time =     248.60 ms /    40 tokens (    6.21 ms per token,   160.90 tokens per second)\n",
            "llama_print_timings:        eval time =    1533.84 ms /    15 runs   (  102.26 ms per token,     9.78 tokens per second)\n",
            "llama_print_timings:       total time =    1938.70 ms /    55 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@GekkoYo I hope so. We need a hegemon with other values, because we crumble between complacency, victimhood and cowardice.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.98 ms /    16 runs   (    0.62 ms per token,  1603.37 tokens per second)\n",
            "llama_print_timings: prompt eval time =     257.95 ms /    35 tokens (    7.37 ms per token,   135.68 tokens per second)\n",
            "llama_print_timings:        eval time =    1685.90 ms /    15 runs   (  112.39 ms per token,     8.90 tokens per second)\n",
            "llama_print_timings:       total time =    2156.36 ms /    50 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@AzulEtilico It seems that acquiring certain self-care habits are just privileges. Mamera so much hpta victimhood.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.49 ms /    16 runs   (    0.59 ms per token,  1685.99 tokens per second)\n",
            "llama_print_timings: prompt eval time =     285.25 ms /    84 tokens (    3.40 ms per token,   294.48 tokens per second)\n",
            "llama_print_timings:        eval time =    1601.87 ms /    15 runs   (  106.79 ms per token,     9.36 tokens per second)\n",
            "llama_print_timings:       total time =    2120.20 ms /    99 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@_heymichu @blestal @Kuntenserven The book where there is a rape of an unconscious minor in the forest... I don't know where you got that version of Sleeping Beauty from, but... it promises, is it a detective story, for adults? By the way... I think you're confusing Snow White with Sleeping Beauty.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.61 ms /    16 runs   (    0.60 ms per token,  1664.93 tokens per second)\n",
            "llama_print_timings: prompt eval time =     277.98 ms /    82 tokens (    3.39 ms per token,   294.98 tokens per second)\n",
            "llama_print_timings:        eval time =    1584.01 ms /    15 runs   (  105.60 ms per token,     9.47 tokens per second)\n",
            "llama_print_timings:       total time =    2108.44 ms /    97 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "That \"adamism\" typical of the radical left, where they believe that a \"new era\" begins with them, delirious. What begins with them is repression, violation of natural rights, that is, LIFE, LIBERTY AND PRIVATE PROPERTY, and clearly MORE MISERY. LATAM will pay for so much ignorance\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.52 ms /    16 runs   (    0.72 ms per token,  1389.37 tokens per second)\n",
            "llama_print_timings: prompt eval time =     257.96 ms /    51 tokens (    5.06 ms per token,   197.71 tokens per second)\n",
            "llama_print_timings:        eval time =    1860.68 ms /    15 runs   (  124.05 ms per token,     8.06 tokens per second)\n",
            "llama_print_timings:       total time =    2395.48 ms /    66 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@letroblesrosa Constitutional Violation, article 20 section B section III, every accused has the right to be informed of his rights at the time of his arrest. The height of uncleanliness.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.41 ms /    16 runs   (    0.59 ms per token,  1700.86 tokens per second)\n",
            "llama_print_timings: prompt eval time =     251.83 ms /    42 tokens (    6.00 ms per token,   166.78 tokens per second)\n",
            "llama_print_timings:        eval time =    1564.38 ms /    15 runs   (  104.29 ms per token,     9.59 tokens per second)\n",
            "llama_print_timings:       total time =    1979.53 ms /    57 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Diego_Molano Hahaha and the biggest threat against Colombians was their government. They looted the treasury, committed massacres and violated human rights.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.36 ms /    16 runs   (    0.59 ms per token,  1709.04 tokens per second)\n",
            "llama_print_timings: prompt eval time =     257.33 ms /    51 tokens (    5.05 ms per token,   198.19 tokens per second)\n",
            "llama_print_timings:        eval time =    1529.30 ms /    15 runs   (  101.95 ms per token,     9.81 tokens per second)\n",
            "llama_print_timings:       total time =    1956.45 ms /    66 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Mara_pjc @BonitaMilana_ I am against the death penalty. But a life sentence for depending on what crimes would seem very good to me: terrorism, rape, murder... And without review.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.07 ms /    16 runs   (    0.57 ms per token,  1763.28 tokens per second)\n",
            "llama_print_timings: prompt eval time =     275.32 ms /    68 tokens (    4.05 ms per token,   246.99 tokens per second)\n",
            "llama_print_timings:        eval time =    1711.21 ms /    15 runs   (  114.08 ms per token,     8.77 tokens per second)\n",
            "llama_print_timings:       total time =    2191.57 ms /    83 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@oppenheimera @elnuevoherald What good are so many reports of human rights violations, murders, torture, if he is still in power, they are rhetorical reports, paper holds up to everything, surely he gives them to the soldiers he commands so they can use in the toilet\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.39 ms /    16 runs   (    0.71 ms per token,  1405.23 tokens per second)\n",
            "llama_print_timings: prompt eval time =     255.33 ms /    47 tokens (    5.43 ms per token,   184.07 tokens per second)\n",
            "llama_print_timings:        eval time =    1925.90 ms /    15 runs   (  128.39 ms per token,     7.79 tokens per second)\n",
            "llama_print_timings:       total time =    2451.74 ms /    62 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@VLADIMIR_CERRON You have to be very ignorant and idiotic to say something like that. The only ones who make money from the exploitation and violation of rights are the communists.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.08 ms /    16 runs   (    0.57 ms per token,  1762.89 tokens per second)\n",
            "llama_print_timings: prompt eval time =     257.87 ms /    46 tokens (    5.61 ms per token,   178.39 tokens per second)\n",
            "llama_print_timings:        eval time =    1573.15 ms /    15 runs   (  104.88 ms per token,     9.53 tokens per second)\n",
            "llama_print_timings:       total time =    1997.39 ms /    61 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@7ssssko @ElMaxideMexico @MelissaPurrs So it's okay to overlook a possible violation just so you can be on hand about posts from the past?\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.93 ms /    16 runs   (    0.56 ms per token,  1791.11 tokens per second)\n",
            "llama_print_timings: prompt eval time =     256.11 ms /    51 tokens (    5.02 ms per token,   199.13 tokens per second)\n",
            "llama_print_timings:        eval time =    1671.97 ms /    15 runs   (  111.46 ms per token,     8.97 tokens per second)\n",
            "llama_print_timings:       total time =    2098.63 ms /    66 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Freedom for @JuanRequesens and all political prisoners. No to repression and state terrorism. Enough of the violation of human rights. https://t.co/Nr4Avr5tzQ\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.79 ms /    16 runs   (    0.74 ms per token,  1356.51 tokens per second)\n",
            "llama_print_timings: prompt eval time =     278.35 ms /    81 tokens (    3.44 ms per token,   291.00 tokens per second)\n",
            "llama_print_timings:        eval time =    1764.10 ms /    15 runs   (  117.61 ms per token,     8.50 tokens per second)\n",
            "llama_print_timings:       total time =    2290.69 ms /    96 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@JuanPappierHRW We Salvadorans do not care that 21 or how many more looters from A L sign whatever they want, no one is going to come and tell us Salvadorans that having a better life is a violation of the democratic charter. Hypocrites, leave us alone, we won't mess with you.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.74 ms /    16 runs   (    0.61 ms per token,  1642.54 tokens per second)\n",
            "llama_print_timings: prompt eval time =     281.57 ms /    85 tokens (    3.31 ms per token,   301.87 tokens per second)\n",
            "llama_print_timings:        eval time =    1575.17 ms /    15 runs   (  105.01 ms per token,     9.52 tokens per second)\n",
            "llama_print_timings:       total time =    2092.24 ms /   100 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@papoaminCD @petrogustavo @AlvaroLeyva Just like you, those of the Democratic Center have to give an explanation to the country for 20 years of looting and violation of human rights. If you are going to talk about complicity, start with yourselves, who for 20 long years looked the other way while compatriots disappeared.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.56 ms /    16 runs   (    0.60 ms per token,  1673.47 tokens per second)\n",
            "llama_print_timings: prompt eval time =     284.35 ms /    70 tokens (    4.06 ms per token,   246.18 tokens per second)\n",
            "llama_print_timings:        eval time =    1534.56 ms /    15 runs   (  102.30 ms per token,     9.77 tokens per second)\n",
            "llama_print_timings:       total time =    2031.02 ms /    85 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Maybe I dreamed it or I hit my head hard, but wasn't this the network where a rape was condoned and the victim was exposed in public while the host of this same program commented on it as if it were nothing? Asked. https://t.co/udnV664Fdo\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.09 ms /    16 runs   (    0.63 ms per token,  1585.89 tokens per second)\n",
            "llama_print_timings: prompt eval time =     275.51 ms /    69 tokens (    3.99 ms per token,   250.44 tokens per second)\n",
            "llama_print_timings:        eval time =    1569.68 ms /    15 runs   (  104.65 ms per token,     9.56 tokens per second)\n",
            "llama_print_timings:       total time =    2066.54 ms /    84 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@ChicShion They only saw that those at the top could also end up in jail, they began to worry, now they are worried about violating human rights, when it is their pestilent corruption that has caused innocent people to be sentenced to more than 15 years without a sentence.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.71 ms /    16 runs   (    0.61 ms per token,  1648.46 tokens per second)\n",
            "llama_print_timings: prompt eval time =     815.91 ms /    28 tokens (   29.14 ms per token,    34.32 tokens per second)\n",
            "llama_print_timings:        eval time =    1503.78 ms /    15 runs   (  100.25 ms per token,     9.97 tokens per second)\n",
            "llama_print_timings:       total time =    2500.13 ms /    43 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@SIN24Horas Well done. Because the right to remain anonymous when doing good should never be violated\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.03 ms /    16 runs   (    0.63 ms per token,  1595.21 tokens per second)\n",
            "llama_print_timings: prompt eval time =     269.91 ms /    78 tokens (    3.46 ms per token,   288.98 tokens per second)\n",
            "llama_print_timings:        eval time =    1615.76 ms /    15 runs   (  107.72 ms per token,     9.28 tokens per second)\n",
            "llama_print_timings:       total time =    2114.06 ms /    93 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "🚨BAD NEWS 🚨 Padres star Fernando Tatis Jr has been suspended for 80 games for violating MLB's performance-enhancing policy.#MLB #TatisJr #BreakingNews #LaraDeportes https://t.co/KcHfm4KrRa\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.87 ms /    16 runs   (    0.62 ms per token,  1621.07 tokens per second)\n",
            "llama_print_timings: prompt eval time =     252.68 ms /    57 tokens (    4.43 ms per token,   225.58 tokens per second)\n",
            "llama_print_timings:        eval time =    1562.90 ms /    15 runs   (  104.19 ms per token,     9.60 tokens per second)\n",
            "llama_print_timings:       total time =    2002.49 ms /    72 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Once and for all... I am not going to stop for a moment from showing and criticizing what politicians in Mexico are and what they do wrong... My freedom of expression will not be violated or restricted by an INE commission with administrative fines. ..\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.15 ms /    16 runs   (    0.63 ms per token,  1575.89 tokens per second)\n",
            "llama_print_timings: prompt eval time =     288.74 ms /    76 tokens (    3.80 ms per token,   263.22 tokens per second)\n",
            "llama_print_timings:        eval time =    1503.89 ms /    15 runs   (  100.26 ms per token,     9.97 tokens per second)\n",
            "llama_print_timings:       total time =    2158.97 ms /    91 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Let's go to the ILO this time All the Union! Let's make an urgent alert about this monumental scam! They want to violate the collective contracts! The Ministries are in Silence waiting for what the Daughter of Terrorist Jorge Rodríguez says! #OnapreNosEstafa\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.67 ms /    16 runs   (    0.60 ms per token,  1653.92 tokens per second)\n",
            "llama_print_timings: prompt eval time =     283.63 ms /    77 tokens (    3.68 ms per token,   271.48 tokens per second)\n",
            "llama_print_timings:        eval time =    1595.16 ms /    15 runs   (  106.34 ms per token,     9.40 tokens per second)\n",
            "llama_print_timings:       total time =    2108.96 ms /    92 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@ChouzaResponde @insomnuuh As is. The right is just as socialist = violating private property. They both have ideal men and everything that goes outside the parameters has to be repressed even when it does not affect third parties. They are two groups very insecure about their identity, they cannot tolerate anything different.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.47 ms /    16 runs   (    0.59 ms per token,  1689.19 tokens per second)\n",
            "llama_print_timings: prompt eval time =     261.86 ms /    52 tokens (    5.04 ms per token,   198.58 tokens per second)\n",
            "llama_print_timings:        eval time =    1557.79 ms /    15 runs   (  103.85 ms per token,     9.63 tokens per second)\n",
            "llama_print_timings:       total time =    1992.93 ms /    67 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@luisfli I don't know but I think you are not fully informed...I do not justify any dead woman but the dimension of the problem must be limitedhttps://t.co/H1F2QuHOUS\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.00 ms /    16 runs   (    0.62 ms per token,  1600.00 tokens per second)\n",
            "llama_print_timings: prompt eval time =     307.24 ms /    98 tokens (    3.14 ms per token,   318.97 tokens per second)\n",
            "llama_print_timings:        eval time =    1634.22 ms /    15 runs   (  108.95 ms per token,     9.18 tokens per second)\n",
            "llama_print_timings:       total time =    2390.54 ms /   113 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "#LasCrónicas2022KUNG-FU ZOHRAA risky film because of how it deals with sexist violence. It has some trace of humor, martial arts, but it does not leave behind what is suffered from abuse, whether it is beatings, threats, the fear of saying it, using one's children, and false smiles https://t.co/QhVpnolhMb\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.35 ms /    16 runs   (    0.58 ms per token,  1711.05 tokens per second)\n",
            "llama_print_timings: prompt eval time =     264.06 ms /    54 tokens (    4.89 ms per token,   204.50 tokens per second)\n",
            "llama_print_timings:        eval time =    1516.13 ms /    15 runs   (  101.08 ms per token,     9.89 tokens per second)\n",
            "llama_print_timings:       total time =    1953.25 ms /    69 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@javiernegre10 @IreneMontero @vitoquiles Where do you see the loss of papers? Sexist violence, YES SEXIST, has killed more than ETA. Shame on you\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.19 ms /    16 runs   (    0.57 ms per token,  1741.97 tokens per second)\n",
            "llama_print_timings: prompt eval time =     255.61 ms /    44 tokens (    5.81 ms per token,   172.14 tokens per second)\n",
            "llama_print_timings:        eval time =    1518.43 ms /    15 runs   (  101.23 ms per token,     9.88 tokens per second)\n",
            "llama_print_timings:       total time =    1940.14 ms /    59 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@AGUSTIJIMENEZ @HuevoLocoMcGraw also known as ijopta https://t.co/te48S4w48o\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.40 ms /    16 runs   (    0.65 ms per token,  1538.91 tokens per second)\n",
            "llama_print_timings: prompt eval time =     752.38 ms /    26 tokens (   28.94 ms per token,    34.56 tokens per second)\n",
            "llama_print_timings:        eval time =    1854.18 ms /    15 runs   (  123.61 ms per token,     8.09 tokens per second)\n",
            "llama_print_timings:       total time =    2805.12 ms /    41 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Football violence + sexist violence https://t.co/0hNdokD6Ym\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.22 ms /    16 runs   (    0.64 ms per token,  1565.40 tokens per second)\n",
            "llama_print_timings: prompt eval time =     275.45 ms /    80 tokens (    3.44 ms per token,   290.43 tokens per second)\n",
            "llama_print_timings:        eval time =    1469.85 ms /    15 runs   (   97.99 ms per token,    10.21 tokens per second)\n",
            "llama_print_timings:       total time =    1972.30 ms /    95 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "To prevent sexist violence, we must understand that when a man expresses his feelings clearly and respectfully, it allows us to generate bonds of trust.✨Let's eradicate the sexist beliefs that repress a healthy coexistence and thus be able to #LiveWithoutFear. https://t.co/VBd93OeTif\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.15 ms /    16 runs   (    0.57 ms per token,  1749.40 tokens per second)\n",
            "llama_print_timings: prompt eval time =     242.81 ms /    33 tokens (    7.36 ms per token,   135.91 tokens per second)\n",
            "llama_print_timings:        eval time =    1540.01 ms /    15 runs   (  102.67 ms per token,     9.74 tokens per second)\n",
            "llama_print_timings:       total time =    1917.27 ms /    48 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Beautiful debates that emerged today: institutional symbolic violence and institutional pedagogical discourse as a neoliberal image.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.84 ms /    16 runs   (    0.55 ms per token,  1810.36 tokens per second)\n",
            "llama_print_timings: prompt eval time =     720.92 ms /    28 tokens (   25.75 ms per token,    38.84 tokens per second)\n",
            "llama_print_timings:        eval time =    1635.13 ms /    15 runs   (  109.01 ms per token,     9.17 tokens per second)\n",
            "llama_print_timings:       total time =    2477.92 ms /    43 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@edufeiok @vikidonda Your figure is an example of symbolic and discursive violence.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.64 ms /    16 runs   (    0.66 ms per token,  1504.04 tokens per second)\n",
            "llama_print_timings: prompt eval time =     772.71 ms /    23 tokens (   33.60 ms per token,    29.77 tokens per second)\n",
            "llama_print_timings:        eval time =    1866.29 ms /    15 runs   (  124.42 ms per token,     8.04 tokens per second)\n",
            "llama_print_timings:       total time =    2828.32 ms /    38 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "I'm going to dream about the word pedagogy and symbolic violence 😭\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.71 ms /    16 runs   (    0.61 ms per token,  1647.45 tokens per second)\n",
            "llama_print_timings: prompt eval time =     287.87 ms /    75 tokens (    3.84 ms per token,   260.53 tokens per second)\n",
            "llama_print_timings:        eval time =    1498.91 ms /    15 runs   (   99.93 ms per token,    10.01 tokens per second)\n",
            "llama_print_timings:       total time =    2008.46 ms /    90 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "City councils promote beauty contests; The Chamber of Deputies considers them “symbolic violence” #Colima #Zapotiltic #ZapotlánElGrande https://t.co/eB2k6b3RCP https://t.co/z13h0rIbd5\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.59 ms /    16 runs   (    0.60 ms per token,  1668.40 tokens per second)\n",
            "llama_print_timings: prompt eval time =     281.98 ms /    74 tokens (    3.81 ms per token,   262.43 tokens per second)\n",
            "llama_print_timings:        eval time =    1556.68 ms /    15 runs   (  103.78 ms per token,     9.64 tokens per second)\n",
            "llama_print_timings:       total time =    2060.36 ms /    89 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@WolffWaldo @JuanManzurOK Every time I see or hear WW, I regret the devaluation that our Congress suffered and suffers. When Florencia Peña was attacked, he should have been fired for being violent. Symbolic, verbal violence, as serious as any type of violence.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.81 ms /    16 runs   (    0.61 ms per token,  1630.49 tokens per second)\n",
            "llama_print_timings: prompt eval time =     784.05 ms /    31 tokens (   25.29 ms per token,    39.54 tokens per second)\n",
            "llama_print_timings:        eval time =    1568.40 ms /    15 runs   (  104.56 ms per token,     9.56 tokens per second)\n",
            "llama_print_timings:       total time =    2488.76 ms /    46 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@syzavel19 @INEMexico @TEPJF_informa It should say symbolic violence.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.06 ms /    16 runs   (    0.57 ms per token,  1766.20 tokens per second)\n",
            "llama_print_timings: prompt eval time =     987.82 ms /    29 tokens (   34.06 ms per token,    29.36 tokens per second)\n",
            "llama_print_timings:        eval time =    1466.02 ms /    15 runs   (   97.73 ms per token,    10.23 tokens per second)\n",
            "llama_print_timings:       total time =    2635.14 ms /    44 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@tdelarroz @Nacion321 @MetroCDMX Probably because I violate the rules :(\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.12 ms /    16 runs   (    0.57 ms per token,  1754.77 tokens per second)\n",
            "llama_print_timings: prompt eval time =     268.91 ms /    70 tokens (    3.84 ms per token,   260.31 tokens per second)\n",
            "llama_print_timings:        eval time =    1473.16 ms /    15 runs   (   98.21 ms per token,    10.18 tokens per second)\n",
            "llama_print_timings:       total time =    1966.64 ms /    85 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@oscar_contardo I wonder why I hate the Chilean Communists so much, I try to look in the history of Chile if the PC betrayed any president, if the PC murdered, disappeared, raped, tortured people in Chile and no, the right did that \" \"democratic\" of Chile.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.52 ms /    16 runs   (    0.59 ms per token,  1681.38 tokens per second)\n",
            "llama_print_timings: prompt eval time =     252.03 ms /    60 tokens (    4.20 ms per token,   238.07 tokens per second)\n",
            "llama_print_timings:        eval time =    1519.77 ms /    15 runs   (  101.32 ms per token,     9.87 tokens per second)\n",
            "llama_print_timings:       total time =    1967.38 ms /    75 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "I'm glad they changed the Homelander from the comics because it turns out that he doesn't have a disorder and Black Noir was actually a clone of him (he was the one who raped Becca) and he dies fighting him, very bad\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.60 ms /    16 runs   (    0.60 ms per token,  1667.19 tokens per second)\n",
            "llama_print_timings: prompt eval time =     248.09 ms /    42 tokens (    5.91 ms per token,   169.30 tokens per second)\n",
            "llama_print_timings:        eval time =    1661.88 ms /    15 runs   (  110.79 ms per token,     9.03 tokens per second)\n",
            "llama_print_timings:       total time =    2068.00 ms /    57 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "A subject who raped his stepdaughters aged 6 and 14 is arrested in Michoacán https://t.co/M9sezZyugB\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.74 ms /    16 runs   (    0.61 ms per token,  1643.39 tokens per second)\n",
            "llama_print_timings: prompt eval time =     263.73 ms /    44 tokens (    5.99 ms per token,   166.84 tokens per second)\n",
            "llama_print_timings:        eval time =    1573.99 ms /    15 runs   (  104.93 ms per token,     9.53 tokens per second)\n",
            "llama_print_timings:       total time =    2083.91 ms /    59 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@jlaloca001 @MashiRafael @LassoGuillermo He raped Villavicencio that's why that guy can't forget it\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.21 ms /    16 runs   (    0.58 ms per token,  1737.24 tokens per second)\n",
            "llama_print_timings: prompt eval time =     230.13 ms /    41 tokens (    5.61 ms per token,   178.16 tokens per second)\n",
            "llama_print_timings:        eval time =    1507.46 ms /    15 runs   (  100.50 ms per token,     9.95 tokens per second)\n",
            "llama_print_timings:       total time =    1891.94 ms /    56 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "He entered a warehouse, stole money and raped a minor; They sentenced him to 12 years https://t.co/BFJ3C1IYYl\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.05 ms /    16 runs   (    0.57 ms per token,  1767.37 tokens per second)\n",
            "llama_print_timings: prompt eval time =     244.58 ms /    35 tokens (    6.99 ms per token,   143.11 tokens per second)\n",
            "llama_print_timings:        eval time =    1596.78 ms /    15 runs   (  106.45 ms per token,     9.39 tokens per second)\n",
            "llama_print_timings:       total time =    1984.27 ms /    50 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@sugasfiIm @Just_Daaf like even if they aren't your guys, old bitch, stay away from the dino\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.77 ms /    16 runs   (    0.55 ms per token,  1823.57 tokens per second)\n",
            "llama_print_timings: prompt eval time =     243.01 ms /    38 tokens (    6.40 ms per token,   156.37 tokens per second)\n",
            "llama_print_timings:        eval time =    1542.91 ms /    15 runs   (  102.86 ms per token,     9.72 tokens per second)\n",
            "llama_print_timings:       total time =    1933.67 ms /    53 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "With the doubt if tomorrow there will be more of the bitch or there will be more \"security\" to enter (I'm going for the first one😂)\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.71 ms /    16 runs   (    0.61 ms per token,  1647.96 tokens per second)\n",
            "llama_print_timings: prompt eval time =     594.07 ms /    18 tokens (   33.00 ms per token,    30.30 tokens per second)\n",
            "llama_print_timings:        eval time =    1622.04 ms /    15 runs   (  108.14 ms per token,     9.25 tokens per second)\n",
            "llama_print_timings:       total time =    2362.79 ms /    33 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "I'm so outraged that no bitch talks to me\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.74 ms /    16 runs   (    0.55 ms per token,  1830.66 tokens per second)\n",
            "llama_print_timings: prompt eval time =     474.26 ms /    17 tokens (   27.90 ms per token,    35.85 tokens per second)\n",
            "llama_print_timings:        eval time =    1506.70 ms /    15 runs   (  100.45 ms per token,     9.96 tokens per second)\n",
            "llama_print_timings:       total time =    2079.81 ms /    32 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Craps of shit, life sapa bitch slut\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.84 ms /    16 runs   (    0.55 ms per token,  1809.75 tokens per second)\n",
            "llama_print_timings: prompt eval time =     239.05 ms /    38 tokens (    6.29 ms per token,   158.96 tokens per second)\n",
            "llama_print_timings:        eval time =    1492.09 ms /    15 runs   (   99.47 ms per token,    10.05 tokens per second)\n",
            "llama_print_timings:       total time =    1878.50 ms /    53 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@LORDEDGY_ @taylorswift133c and you, a bitch, can look at it, man, how angry\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.65 ms /    16 runs   (    0.60 ms per token,  1658.37 tokens per second)\n",
            "llama_print_timings: prompt eval time =     298.49 ms /    93 tokens (    3.21 ms per token,   311.57 tokens per second)\n",
            "llama_print_timings:        eval time =    1582.32 ms /    15 runs   (  105.49 ms per token,     9.48 tokens per second)\n",
            "llama_print_timings:       total time =    2136.55 ms /   108 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "The lie won, they are going to trample us, but I am going to recover and not give up. We will now see how the sector of rejection is dismembered, we will see, as Serrat says...\" Good and evil woke upThe poor bitch at the portalThe bitch rich to the rose bushAnd the miser to the currency\" https://t.co/gR34FXs4Ve\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.86 ms /    16 runs   (    0.55 ms per token,  1805.87 tokens per second)\n",
            "llama_print_timings: prompt eval time =     253.34 ms /    36 tokens (    7.04 ms per token,   142.10 tokens per second)\n",
            "llama_print_timings:        eval time =    1487.14 ms /    15 runs   (   99.14 ms per token,    10.09 tokens per second)\n",
            "llama_print_timings:       total time =    1897.15 ms /    51 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Now they are two bitches licking the same wound. Blinks.—Do I know you? —sounds in someone else's head.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.83 ms /    16 runs   (    0.55 ms per token,  1812.62 tokens per second)\n",
            "llama_print_timings: prompt eval time =     791.43 ms /    29 tokens (   27.29 ms per token,    36.64 tokens per second)\n",
            "llama_print_timings:        eval time =    1522.33 ms /    15 runs   (  101.49 ms per token,     9.85 tokens per second)\n",
            "llama_print_timings:       total time =    2437.72 ms /    44 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Many Bitches Wanted to Make Him Happy 😁And I Did It Dad🤷‍♀️🤭\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.83 ms /    16 runs   (    0.55 ms per token,  1812.62 tokens per second)\n",
            "llama_print_timings: prompt eval time =     743.08 ms /    30 tokens (   24.77 ms per token,    40.37 tokens per second)\n",
            "llama_print_timings:        eval time =    1486.12 ms /    15 runs   (   99.07 ms per token,    10.09 tokens per second)\n",
            "llama_print_timings:       total time =    2358.64 ms /    45 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@ibadbxtch__ @Citlaaaalic @emtzp21 more bitches every day\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.24 ms /    16 runs   (    0.64 ms per token,  1562.81 tokens per second)\n",
            "llama_print_timings: prompt eval time =     837.29 ms /    26 tokens (   32.20 ms per token,    31.05 tokens per second)\n",
            "llama_print_timings:        eval time =    1767.77 ms /    15 runs   (  117.85 ms per token,     8.49 tokens per second)\n",
            "llama_print_timings:       total time =    2790.17 ms /    41 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Hello bitches, I'm writing to you from the toilet at work. I'm shitting\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.93 ms /    16 runs   (    0.62 ms per token,  1611.60 tokens per second)\n",
            "llama_print_timings: prompt eval time =     288.85 ms /    91 tokens (    3.17 ms per token,   315.05 tokens per second)\n",
            "llama_print_timings:        eval time =    1610.73 ms /    15 runs   (  107.38 ms per token,     9.31 tokens per second)\n",
            "llama_print_timings:       total time =    2153.21 ms /   106 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@damaris12478454 @KarolCariola That's right, Allende is a great being!!! As was Gladys Marin too 👏👏!!! Not like you @KarolCariola @camila_vallejo Inconsequential, cowardly and corrupt bitches, how easy it is to get hung up on the image of Allende.\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.64 ms /    16 runs   (    0.60 ms per token,  1659.75 tokens per second)\n",
            "llama_print_timings: prompt eval time =     262.71 ms /    45 tokens (    5.84 ms per token,   171.29 tokens per second)\n",
            "llama_print_timings:        eval time =    1641.98 ms /    15 runs   (  109.47 ms per token,     9.14 tokens per second)\n",
            "llama_print_timings:       total time =    2070.82 ms /    60 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "I'm never wrong, volume 2.LONG LIVE OUR IMMORTAL NATION, BITCHES.https://t.co/kpGXaRGlee\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.61 ms /    16 runs   (    0.66 ms per token,  1507.73 tokens per second)\n",
            "llama_print_timings: prompt eval time =     292.20 ms /    75 tokens (    3.90 ms per token,   256.67 tokens per second)\n",
            "llama_print_timings:        eval time =    1659.21 ms /    15 runs   (  110.61 ms per token,     9.04 tokens per second)\n",
            "llama_print_timings:       total time =    2325.64 ms /    90 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@BrianRoemmele @profgalloway This is a BS, manosphere comment and I’m shocked to be seeing it. But maybe I shouldn’t be. https://t.co/7z0nqyqGwL @EverydaySexism has covered this nonsense in her new book.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       2.93 ms /     5 runs   (    0.59 ms per token,  1704.74 tokens per second)\n",
            "llama_print_timings: prompt eval time =     271.75 ms /    87 tokens (    3.12 ms per token,   320.14 tokens per second)\n",
            "llama_print_timings:        eval time =     390.10 ms /     4 runs   (   97.53 ms per token,    10.25 tokens per second)\n",
            "llama_print_timings:       total time =     857.47 ms /    91 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Cathy_TwoHalves @EverydaySexism That's why women have to stay at home, raise children and take care of the house.Nobody is going to assume that a woman is a leader among men since that's not how it is supposed to be in nature. Of course, you can try and fake it, but you will keep losing your feminine side.\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.03 ms /    16 runs   (    0.56 ms per token,  1771.87 tokens per second)\n",
            "llama_print_timings: prompt eval time =     279.21 ms /   109 tokens (    2.56 ms per token,   390.39 tokens per second)\n",
            "llama_print_timings:        eval time =    1477.52 ms /    15 runs   (   98.50 ms per token,    10.15 tokens per second)\n",
            "llama_print_timings:       total time =    2054.01 ms /   124 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@betweenstardust Please be our voice.@CNN @cnnbrk @CNNFrancePR @cnni @AlArabia_Eng @AlArabiya_Eng @FoxNews @euronews @5ogand @mehdi_eth @TheOnion @TIME @nytimes @BreakingNews @Newsweek @Reuters @CBSNews @UNHumanRights @EverydaySexism @unwomenchief @janetmock\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.75 ms /    16 runs   (    0.61 ms per token,  1640.86 tokens per second)\n",
            "llama_print_timings: prompt eval time =     258.61 ms /    39 tokens (    6.63 ms per token,   150.81 tokens per second)\n",
            "llama_print_timings:        eval time =    1459.50 ms /    15 runs   (   97.30 ms per token,    10.28 tokens per second)\n",
            "llama_print_timings:       total time =    1873.33 ms /    54 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@JonPincince @kmulvane @EverydaySexism, even after Roe v. Wade was overturned. Fun! /s\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       2.96 ms /     5 runs   (    0.59 ms per token,  1690.33 tokens per second)\n",
            "llama_print_timings: prompt eval time =     261.25 ms /    74 tokens (    3.53 ms per token,   283.26 tokens per second)\n",
            "llama_print_timings:        eval time =     418.50 ms /     4 runs   (  104.63 ms per token,     9.56 tokens per second)\n",
            "llama_print_timings:       total time =     851.25 ms /    78 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Seriously @JohnLewisRetail?  girls are pictured with ‘I’m a Stylist’ doll and the pizza oven - the boys get a robot and hot wheels garage. #EverydaySexism https://t.co/mKsbxaGgIV? # via @HPUKParents\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.70 ms /    16 runs   (    0.73 ms per token,  1367.76 tokens per second)\n",
            "llama_print_timings: prompt eval time =     228.12 ms /    34 tokens (    6.71 ms per token,   149.05 tokens per second)\n",
            "llama_print_timings:        eval time =    1808.91 ms /    15 runs   (  120.59 ms per token,     8.29 tokens per second)\n",
            "llama_print_timings:       total time =    2218.80 ms /    49 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "not a great look for the French Cycling Federation #everydaysexism https://t.co/Ts83OMDOgL\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.09 ms /    16 runs   (    0.57 ms per token,  1760.56 tokens per second)\n",
            "llama_print_timings: prompt eval time =     612.84 ms /    24 tokens (   25.53 ms per token,    39.16 tokens per second)\n",
            "llama_print_timings:        eval time =    1479.46 ms /    15 runs   (   98.63 ms per token,    10.14 tokens per second)\n",
            "llama_print_timings:       total time =    2209.20 ms /    39 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Any of y'all remember that law and order episode about gamergate? That was insane\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.52 ms /    16 runs   (    0.59 ms per token,  1680.67 tokens per second)\n",
            "llama_print_timings: prompt eval time =     244.46 ms /    49 tokens (    4.99 ms per token,   200.44 tokens per second)\n",
            "llama_print_timings:        eval time =    1550.76 ms /    15 runs   (  103.38 ms per token,     9.67 tokens per second)\n",
            "llama_print_timings:       total time =    1980.17 ms /    64 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "It's funny how you could replace 'Andrew Tate' with GamerGate or Jordan Peterson and this post would read the same https://t.co/iPnqcLCq5S\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.94 ms /    16 runs   (    0.62 ms per token,  1609.50 tokens per second)\n",
            "llama_print_timings: prompt eval time =     258.00 ms /    65 tokens (    3.97 ms per token,   251.94 tokens per second)\n",
            "llama_print_timings:        eval time =    1634.98 ms /    15 runs   (  109.00 ms per token,     9.17 tokens per second)\n",
            "llama_print_timings:       total time =    2104.91 ms /    80 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Bannon started with #GamerGate. @BrietbartNews. Then he #CambridgeAnalytica'ed the USA. Now, he's just trying to get paid before it all implodes. https://t.co/hrqeIfS4r5\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.64 ms /    16 runs   (    0.60 ms per token,  1660.27 tokens per second)\n",
            "llama_print_timings: prompt eval time =     686.61 ms /    25 tokens (   27.46 ms per token,    36.41 tokens per second)\n",
            "llama_print_timings:        eval time =    1653.35 ms /    15 runs   (  110.22 ms per token,     9.07 tokens per second)\n",
            "llama_print_timings:       total time =    2480.90 ms /    40 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@chrisfogIe man imagine being a teenager during the birth of Gamergate.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.61 ms /    16 runs   (    0.54 ms per token,  1857.44 tokens per second)\n",
            "llama_print_timings: prompt eval time =     840.25 ms /    28 tokens (   30.01 ms per token,    33.32 tokens per second)\n",
            "llama_print_timings:        eval time =    1567.59 ms /    15 runs   (  104.51 ms per token,     9.57 tokens per second)\n",
            "llama_print_timings:       total time =    2572.93 ms /    43 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "The complaints of going too far whenever a trans person simply defends themselves.Gamergate energy every single time.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.84 ms /    16 runs   (    0.55 ms per token,  1810.57 tokens per second)\n",
            "llama_print_timings: prompt eval time =     240.03 ms /    35 tokens (    6.86 ms per token,   145.81 tokens per second)\n",
            "llama_print_timings:        eval time =    1517.14 ms /    15 runs   (  101.14 ms per token,     9.89 tokens per second)\n",
            "llama_print_timings:       total time =    1910.23 ms /    50 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "I’m not gonna do it cos the design guy supported gamergate https://t.co/0PJ9zLaTUJ\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.45 ms /    16 runs   (    0.59 ms per token,  1693.84 tokens per second)\n",
            "llama_print_timings: prompt eval time =     280.64 ms /   104 tokens (    2.70 ms per token,   370.59 tokens per second)\n",
            "llama_print_timings:        eval time =    1643.69 ms /    15 runs   (  109.58 ms per token,     9.13 tokens per second)\n",
            "llama_print_timings:       total time =    2207.53 ms /   119 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@tired_of_debate @ScoutSleepe @ImWatson91 The fact that some men assault transwomen too is awful &amp; unacceptable.Having said that—being harassed by men does NOT render MtFs “women” (+men *do* harass other men sometimes, too…)+It is notable that—for ALL sexual harassment/assault victims—the abuser is almost always MALE!\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.12 ms /    16 runs   (    0.57 ms per token,  1753.42 tokens per second)\n",
            "llama_print_timings: prompt eval time =     258.75 ms /    66 tokens (    3.92 ms per token,   255.08 tokens per second)\n",
            "llama_print_timings:        eval time =    1540.68 ms /    15 runs   (  102.71 ms per token,     9.74 tokens per second)\n",
            "llama_print_timings:       total time =    1997.31 ms /    81 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "bipoc shouldn’t have to worry for their lives and be harassed off the internet. They shouldn’t have to defend themselves against this! If you see racism SHUT THAT SHIT DOWN! You have more power than you realize — Don’t be silent or you are the problem\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.48 ms /    16 runs   (    0.66 ms per token,  1525.99 tokens per second)\n",
            "llama_print_timings: prompt eval time =     252.28 ms /    44 tokens (    5.73 ms per token,   174.41 tokens per second)\n",
            "llama_print_timings:        eval time =    1743.33 ms /    15 runs   (  116.22 ms per token,     8.60 tokens per second)\n",
            "llama_print_timings:       total time =    2271.94 ms /    59 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@monstreline @tamalama67 I have never been harassed or  questioned, or even looked at. But I ever was, I'd laugh and move on.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.98 ms /    16 runs   (    0.56 ms per token,  1781.14 tokens per second)\n",
            "llama_print_timings: prompt eval time =     669.11 ms /    27 tokens (   24.78 ms per token,    40.35 tokens per second)\n",
            "llama_print_timings:        eval time =    1535.15 ms /    15 runs   (  102.34 ms per token,     9.77 tokens per second)\n",
            "llama_print_timings:       total time =    2326.09 ms /    42 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@yashar Yashar, can you translate the dialogue?  Is she being supported or harassed.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.37 ms /    16 runs   (    0.59 ms per token,  1707.40 tokens per second)\n",
            "llama_print_timings: prompt eval time =     266.07 ms /    84 tokens (    3.17 ms per token,   315.71 tokens per second)\n",
            "llama_print_timings:        eval time =    1533.63 ms /    15 runs   (  102.24 ms per token,     9.78 tokens per second)\n",
            "llama_print_timings:       total time =    2031.06 ms /    99 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@e_Glyde like for YEARS. im so glad ppl are believing jenette now but my god ppl had exposed him 10-15 years agobut they were all dismissed. the number of ppl harassed n bullied online not to mention the actors who were disbelieved when they came forward in the 2010s\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.04 ms /    16 runs   (    0.57 ms per token,  1769.91 tokens per second)\n",
            "llama_print_timings: prompt eval time =     236.88 ms /    40 tokens (    5.92 ms per token,   168.86 tokens per second)\n",
            "llama_print_timings:        eval time =    1506.00 ms /    15 runs   (  100.40 ms per token,     9.96 tokens per second)\n",
            "llama_print_timings:       total time =    1897.01 ms /    55 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "it’s not even 7pm and we are already being harassed by a drunk girl on the blue line and bonding with a fellow rider about it lmao\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.73 ms /    16 runs   (    0.73 ms per token,  1364.49 tokens per second)\n",
            "llama_print_timings: prompt eval time =     254.97 ms /    54 tokens (    4.72 ms per token,   211.79 tokens per second)\n",
            "llama_print_timings:        eval time =    1768.80 ms /    15 runs   (  117.92 ms per token,     8.48 tokens per second)\n",
            "llama_print_timings:       total time =    2250.99 ms /    69 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@nwob0t That's also The Feminist Calling The Person Who is a #MGTOW A Sexist, Sick, Misogynist, Who Need's to Get Professional \"Help\" !!!\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.86 ms /    16 runs   (    0.62 ms per token,  1623.38 tokens per second)\n",
            "llama_print_timings: prompt eval time =     288.82 ms /    75 tokens (    3.85 ms per token,   259.68 tokens per second)\n",
            "llama_print_timings:        eval time =    1657.16 ms /    15 runs   (  110.48 ms per token,     9.05 tokens per second)\n",
            "llama_print_timings:       total time =    2164.44 ms /    90 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "i'm surprised mgtow aren't more pro-transwhat could be better for mgtow than having the homie become the gfyou can never speak to another foid for the rest of your life, and still be a wife guytake the red pill https://t.co/1OFmMiFRre\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.10 ms /    16 runs   (    0.57 ms per token,  1758.05 tokens per second)\n",
            "llama_print_timings: prompt eval time =     241.97 ms /    48 tokens (    5.04 ms per token,   198.37 tokens per second)\n",
            "llama_print_timings:        eval time =    1607.79 ms /    15 runs   (  107.19 ms per token,     9.33 tokens per second)\n",
            "llama_print_timings:       total time =    2017.69 ms /    63 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "#MGTOW #incel #redpill I recommend you search and watch this YouTube channel, so good. 👇 https://t.co/5alAknK3QC\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.88 ms /    16 runs   (    0.55 ms per token,  1802.21 tokens per second)\n",
            "llama_print_timings: prompt eval time =     702.14 ms /    28 tokens (   25.08 ms per token,    39.88 tokens per second)\n",
            "llama_print_timings:        eval time =    1595.99 ms /    15 runs   (  106.40 ms per token,     9.40 tokens per second)\n",
            "llama_print_timings:       total time =    2433.30 ms /    43 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@KaitlynKitty9 Wisentius obsessively anti-astrology MGTOW arc\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.02 ms /    16 runs   (    0.69 ms per token,  1452.56 tokens per second)\n",
            "llama_print_timings: prompt eval time =     267.41 ms /    72 tokens (    3.71 ms per token,   269.25 tokens per second)\n",
            "llama_print_timings:        eval time =    1706.84 ms /    15 runs   (  113.79 ms per token,     8.79 tokens per second)\n",
            "llama_print_timings:       total time =    2209.40 ms /    87 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@GBNEWS Men are going MGTOW due to the fear of being divorce raped through the courts. So less marriages.Women have been told to follow their corporate careers, some leaving it to late &amp; you have the hook up culture.YouTube vids with people talking of how sour relationships have gone\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.90 ms /    16 runs   (    0.62 ms per token,  1615.84 tokens per second)\n",
            "llama_print_timings: prompt eval time =     255.48 ms /    48 tokens (    5.32 ms per token,   187.88 tokens per second)\n",
            "llama_print_timings:        eval time =    1596.10 ms /    15 runs   (  106.41 ms per token,     9.40 tokens per second)\n",
            "llama_print_timings:       total time =    2105.02 ms /    63 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@FlirtyMoomy Look at all these simps. It's pathetic. Good luck finding a new relationship in this day and age dummy. #MGTOW #AnotherOneHitsTheWall\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.41 ms /    16 runs   (    0.59 ms per token,  1699.96 tokens per second)\n",
            "llama_print_timings: prompt eval time =     592.25 ms /    32 tokens (   18.51 ms per token,    54.03 tokens per second)\n",
            "llama_print_timings:        eval time =    1575.25 ms /    15 runs   (  105.02 ms per token,     9.52 tokens per second)\n",
            "llama_print_timings:       total time =    2307.07 ms /    47 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Texarchivist i notallmen’d your experience not having children as you opined about the experience of couples with children?\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.76 ms /    16 runs   (    0.61 ms per token,  1639.68 tokens per second)\n",
            "llama_print_timings: prompt eval time =     272.66 ms /    88 tokens (    3.10 ms per token,   322.75 tokens per second)\n",
            "llama_print_timings:        eval time =    1582.22 ms /    15 runs   (  105.48 ms per token,     9.48 tokens per second)\n",
            "llama_print_timings:       total time =    2102.07 ms /   103 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Niall_Boylan The guy in Sligo hasn't been charged yet https://t.co/lAyHjPAcrC. Also Ashling murphy's murder caused every TD to tell men to ' do better' and gave out about #notallmen for weeks .  Yet none will tell Muslims to do the same about Homophobia in their community.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.74 ms /    16 runs   (    0.61 ms per token,  1642.54 tokens per second)\n",
            "llama_print_timings: prompt eval time =     261.30 ms /    75 tokens (    3.48 ms per token,   287.03 tokens per second)\n",
            "llama_print_timings:        eval time =    1565.99 ms /    15 runs   (  104.40 ms per token,     9.58 tokens per second)\n",
            "llama_print_timings:       total time =    2045.50 ms /    90 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "If a man tells you that he isn’t a feminist because men can’t be that, please be advised that they may be involved in ‘ideological grooming’ and manipulation!!#NotAllMen   💁🏼‍♀️🎣 https://t.co/MBaX2OMtf5\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.36 ms /    16 runs   (    0.71 ms per token,  1408.33 tokens per second)\n",
            "llama_print_timings: prompt eval time =     294.03 ms /    92 tokens (    3.20 ms per token,   312.89 tokens per second)\n",
            "llama_print_timings:        eval time =    1673.63 ms /    15 runs   (  111.58 ms per token,     8.96 tokens per second)\n",
            "llama_print_timings:       total time =    2384.91 ms /   107 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@AimeeMcLernon @EE @jono8686 3/3Most recently we had the horrific murder of a nine-year-old #LilliaValutyte in Boston, and #MadisonWright in Essex. This is why I would be part of the 63% (I guess the rest are unhelpful #NotAllMen-types 😏).\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.74 ms /    16 runs   (    0.61 ms per token,  1643.39 tokens per second)\n",
            "llama_print_timings: prompt eval time =     264.51 ms /    79 tokens (    3.35 ms per token,   298.66 tokens per second)\n",
            "llama_print_timings:        eval time =    1592.95 ms /    15 runs   (  106.20 ms per token,     9.42 tokens per second)\n",
            "llama_print_timings:       total time =    2086.19 ms /    94 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Ask men like Lebron if they’ll ever “let” their daughter date a T*ry Lane n watch them unabashedly say no but then ask why they support men like that irl and watch them perform cognitive dissonance to welp #notallmen. It’d be funny if this shxt didn’t have real life consequences\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.50 ms /    16 runs   (    0.59 ms per token,  1684.74 tokens per second)\n",
            "llama_print_timings: prompt eval time =     261.06 ms /    71 tokens (    3.68 ms per token,   271.97 tokens per second)\n",
            "llama_print_timings:        eval time =    1587.10 ms /    15 runs   (  105.81 ms per token,     9.45 tokens per second)\n",
            "llama_print_timings:       total time =    2061.24 ms /    86 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Now I want to point out a really serious aside here:Men hate it when we lump them all together, Hell, men even have a world wide harsh tag to protest this - #notallmen. But here you are doing it to boys. Don’t do to boys what you hate done to you, ok?\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.22 ms /    16 runs   (    0.58 ms per token,  1734.79 tokens per second)\n",
            "llama_print_timings: prompt eval time =     251.98 ms /    61 tokens (    4.13 ms per token,   242.08 tokens per second)\n",
            "llama_print_timings:        eval time =    1722.27 ms /    15 runs   (  114.82 ms per token,     8.71 tokens per second)\n",
            "llama_print_timings:       total time =    2185.05 ms /    76 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "They may say, even to themselves, that they are doing this out of fairness, but there is a strong aspect of self-preservation to this behavior. Women are aware of their precarious position under patriarchy, of how easy it is to fall from grace.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      12.02 ms /    16 runs   (    0.75 ms per token,  1331.45 tokens per second)\n",
            "llama_print_timings: prompt eval time =     264.04 ms /    77 tokens (    3.43 ms per token,   291.63 tokens per second)\n",
            "llama_print_timings:        eval time =    1855.97 ms /    15 runs   (  123.73 ms per token,     8.08 tokens per second)\n",
            "llama_print_timings:       total time =    2513.16 ms /    92 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "I’m attending Americans United for Separation of Church and State’s event, “An American Muslim Perspective on Religion, Politics, Patriotism, and Patriarchy by Ameena Mirza Qazi” – sign up now to join me! #americansunited https://t.co/EItm3mqsKz\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.83 ms /    16 runs   (    0.55 ms per token,  1811.18 tokens per second)\n",
            "llama_print_timings: prompt eval time =     728.09 ms /    28 tokens (   26.00 ms per token,    38.46 tokens per second)\n",
            "llama_print_timings:        eval time =    1514.49 ms /    15 runs   (  100.97 ms per token,     9.90 tokens per second)\n",
            "llama_print_timings:       total time =    2369.18 ms /    43 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@SensualCMT The wanton enforcement of the patriarchy makes me wet. 😑\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.87 ms /    16 runs   (    0.62 ms per token,  1621.24 tokens per second)\n",
            "llama_print_timings: prompt eval time =     241.88 ms /    50 tokens (    4.84 ms per token,   206.71 tokens per second)\n",
            "llama_print_timings:        eval time =    1500.19 ms /    15 runs   (  100.01 ms per token,    10.00 tokens per second)\n",
            "llama_print_timings:       total time =    1919.76 ms /    65 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "We should all do our best to acknowledge each other’s grievances.  Making it a team sports thing is playing into the patriarchy. https://t.co/0fhw5s32Nr\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.25 ms /    16 runs   (    0.58 ms per token,  1729.54 tokens per second)\n",
            "llama_print_timings: prompt eval time =     259.24 ms /    69 tokens (    3.76 ms per token,   266.17 tokens per second)\n",
            "llama_print_timings:        eval time =    1619.11 ms /    15 runs   (  107.94 ms per token,     9.26 tokens per second)\n",
            "llama_print_timings:       total time =    2090.01 ms /    84 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@ambernoelle An iron rule of patriarchy is that whatever the partners in a het relationship are doing, the man is the main character, and the woman is the principal supporting character.So if a husband says “my wife is awesome,” his statement is more important than the wife’s awesomeness.\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.15 ms /    16 runs   (    0.70 ms per token,  1435.11 tokens per second)\n",
            "llama_print_timings: prompt eval time =     282.49 ms /   106 tokens (    2.67 ms per token,   375.23 tokens per second)\n",
            "llama_print_timings:        eval time =    1749.15 ms /    15 runs   (  116.61 ms per token,     8.58 tokens per second)\n",
            "llama_print_timings:       total time =    2342.22 ms /   121 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Dr. Anthea Butler (@AntheaButler) spoke with @haleandy on examining the intersection of Roe V. Wade, Toxic Patriarchy, and White Evangelical on this week’s Podcast Conversation, sponsored by @CBTSKansas, @ChurchBenefits1, &amp; https://t.co/mMeMkP2Hnp:https://t.co/gVUvaSvH7A\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.35 ms /    16 runs   (    0.58 ms per token,  1711.96 tokens per second)\n",
            "llama_print_timings: prompt eval time =     264.68 ms /    44 tokens (    6.02 ms per token,   166.24 tokens per second)\n",
            "llama_print_timings:        eval time =    1474.72 ms /    15 runs   (   98.31 ms per token,    10.17 tokens per second)\n",
            "llama_print_timings:       total time =    1986.29 ms /    59 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@AlepsHasAnxiety @SheBePamella @Coll3enG https://t.co/26P9U4mAMx this is worth a read\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.78 ms /    16 runs   (    0.55 ms per token,  1821.70 tokens per second)\n",
            "llama_print_timings: prompt eval time =     247.44 ms /    38 tokens (    6.51 ms per token,   153.58 tokens per second)\n",
            "llama_print_timings:        eval time =    1573.76 ms /    15 runs   (  104.92 ms per token,     9.53 tokens per second)\n",
            "llama_print_timings:       total time =    1968.05 ms /    53 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Talk Back to Your Harasser with These Cards! | Stop Street Harassment https://t.co/1LawQRgeK0\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.34 ms /    16 runs   (    0.58 ms per token,  1712.51 tokens per second)\n",
            "llama_print_timings: prompt eval time =     239.89 ms /    49 tokens (    4.90 ms per token,   204.26 tokens per second)\n",
            "llama_print_timings:        eval time =    1497.56 ms /    15 runs   (   99.84 ms per token,    10.02 tokens per second)\n",
            "llama_print_timings:       total time =    1930.91 ms /    64 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Actually more realistically on your way to school since you're more likely to be cat called if you're under 18.https://t.co/v6jPBIuvNl.\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.31 ms /    16 runs   (    0.58 ms per token,  1718.21 tokens per second)\n",
            "llama_print_timings: prompt eval time =     251.75 ms /    58 tokens (    4.34 ms per token,   230.39 tokens per second)\n",
            "llama_print_timings:        eval time =    1571.32 ms /    15 runs   (  104.75 ms per token,     9.55 tokens per second)\n",
            "llama_print_timings:       total time =    2007.76 ms /    73 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@MomTuckers @EFREM_I_AM @MikeDud82789251 Oh really?  Not if they do THIS SHIThttps://t.co/8BcUvjp5re\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.93 ms /    16 runs   (    0.75 ms per token,  1340.93 tokens per second)\n",
            "llama_print_timings: prompt eval time =     255.15 ms /    52 tokens (    4.91 ms per token,   203.80 tokens per second)\n",
            "llama_print_timings:        eval time =    1832.92 ms /    15 runs   (  122.19 ms per token,     8.18 tokens per second)\n",
            "llama_print_timings:       total time =    2390.44 ms /    67 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@EmmelineWyndham @nicolajohn8 Boys should be educated about this as part of the school curriculum, when they are they mostly respond positively https://t.co/5ZoatGnitb\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.32 ms /    16 runs   (    0.58 ms per token,  1717.11 tokens per second)\n",
            "llama_print_timings: prompt eval time =     257.19 ms /    57 tokens (    4.51 ms per token,   221.63 tokens per second)\n",
            "llama_print_timings:        eval time =    1628.91 ms /    15 runs   (  108.59 ms per token,     9.21 tokens per second)\n",
            "llama_print_timings:       total time =    2071.23 ms /    72 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@OccamLightsaber @maxwasnotfound @Troysweezey1 @BGaloot44 @NPR The adult teenager appears to be breaking the local laws https://t.co/CFNp1FrRlk\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.21 ms /    16 runs   (    0.58 ms per token,  1736.30 tokens per second)\n",
            "llama_print_timings: prompt eval time =     264.25 ms /    73 tokens (    3.62 ms per token,   276.25 tokens per second)\n",
            "llama_print_timings:        eval time =    1506.85 ms /    15 runs   (  100.46 ms per token,     9.95 tokens per second)\n",
            "llama_print_timings:       total time =    1980.88 ms /    88 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "3/3This show of extreme wealth and privilege is an absolute kick in the face to this amazing generation that struggled all their lives.We need to cherish those of them that are still with us as much as we can. #Precious #AbolishTheMonachy #SpreadTheWealth#WeAreEqual\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.85 ms /    16 runs   (    0.62 ms per token,  1624.20 tokens per second)\n",
            "llama_print_timings: prompt eval time =     257.82 ms /    65 tokens (    3.97 ms per token,   252.11 tokens per second)\n",
            "llama_print_timings:        eval time =    1574.01 ms /    15 runs   (  104.93 ms per token,     9.53 tokens per second)\n",
            "llama_print_timings:       total time =    2032.30 ms /    80 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "In no particular order:• Rethabile Moabi from ROM Cleaning Service• Marie Sebueng from IAMS Powerhouse Consulting• Rosharon Morgan from GM Boiler and Steam Engineering #WeAreEqual https://t.co/7gEYxyoY4E\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.38 ms /    16 runs   (    0.71 ms per token,  1406.22 tokens per second)\n",
            "llama_print_timings: prompt eval time =     248.74 ms /    56 tokens (    4.44 ms per token,   225.13 tokens per second)\n",
            "llama_print_timings:        eval time =    1709.49 ms /    15 runs   (  113.97 ms per token,     8.77 tokens per second)\n",
            "llama_print_timings:       total time =    2184.83 ms /    71 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@PitsoD2 @kabelodick It’s not about go Sheba morago but about equality before the law, we use the previous solutions to solve the future problems and not without expecting favors or prejudices#Weareequal\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.44 ms /    16 runs   (    0.59 ms per token,  1694.92 tokens per second)\n",
            "llama_print_timings: prompt eval time =     295.31 ms /    70 tokens (    4.22 ms per token,   237.04 tokens per second)\n",
            "llama_print_timings:        eval time =    1557.36 ms /    15 runs   (  103.82 ms per token,     9.63 tokens per second)\n",
            "llama_print_timings:       total time =    2073.08 ms /    85 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@RossKneeDeep I was told by African American Men that they do not like Black American Men&amp;the Arabic Men classified themselves on their employment app. as Black. I listened to their concerns never judged them or their opinions. I qualified each person the same regardless of color.#weareequal\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.55 ms /    16 runs   (    0.60 ms per token,  1675.92 tokens per second)\n",
            "llama_print_timings: prompt eval time =     238.79 ms /    41 tokens (    5.82 ms per token,   171.70 tokens per second)\n",
            "llama_print_timings:        eval time =    1561.31 ms /    15 runs   (  104.09 ms per token,     9.61 tokens per second)\n",
            "llama_print_timings:       total time =    1962.64 ms /    56 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "The people who wished for the death of Queen Elizabeth II and are currently celebrating:Karma always finds a way. #WeAreEqual #RIPQueenElizabeth\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.29 ms /    16 runs   (    0.58 ms per token,  1723.02 tokens per second)\n",
            "llama_print_timings: prompt eval time =     275.78 ms /   105 tokens (    2.63 ms per token,   380.74 tokens per second)\n",
            "llama_print_timings:        eval time =    1498.06 ms /    15 runs   (   99.87 ms per token,    10.01 tokens per second)\n",
            "llama_print_timings:       total time =    2060.27 ms /   120 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Happy Women's Equality Day! Here’s to all Strong Women: May We Know Them, May We Be Them, May We Raise Them!If you like to see the replay of our event on IWD last March, just click here - https://t.co/oxeMXZrNIR  #Braintree #WomensEquality #WeAreEqual https://t.co/kXIdaP43wH\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.53 ms /    16 runs   (    0.60 ms per token,  1679.26 tokens per second)\n",
            "llama_print_timings: prompt eval time =     246.84 ms /    55 tokens (    4.49 ms per token,   222.81 tokens per second)\n",
            "llama_print_timings:        eval time =    1575.48 ms /    15 runs   (  105.03 ms per token,     9.52 tokens per second)\n",
            "llama_print_timings:       total time =    2007.11 ms /    70 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Iloveavos #addanavo #natutesmiracles #womensdayI love ❤💞😍 avo🙌👏🙏🙇 https://t.co/rGuvkxffIQ\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.57 ms /    16 runs   (    0.60 ms per token,  1671.89 tokens per second)\n",
            "llama_print_timings: prompt eval time =     287.40 ms /    94 tokens (    3.06 ms per token,   327.07 tokens per second)\n",
            "llama_print_timings:        eval time =    1728.95 ms /    15 runs   (  115.26 ms per token,     8.68 tokens per second)\n",
            "llama_print_timings:       total time =    2448.58 ms /   109 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "could do justice for me as I became a laughing stock after being kidnapped and raped.#women #WomensRightsAreHumanRights #WomenSupportingWomen #WomensRights #WomensWorlds #womensday #womenempowerment #family #humananatomy #EndViolenceAgainstWomen #endviolenceagainstgirls #woman\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.49 ms /    16 runs   (    0.53 ms per token,  1885.01 tokens per second)\n",
            "llama_print_timings: prompt eval time =     282.45 ms /   105 tokens (    2.69 ms per token,   371.75 tokens per second)\n",
            "llama_print_timings:        eval time =    1631.61 ms /    15 runs   (  108.77 ms per token,     9.19 tokens per second)\n",
            "llama_print_timings:       total time =    2205.18 ms /   120 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "NEW LISTING: Rare Antique American Occupational ID'd Female Medical Gymnast CDV Photo! CT! US https://t.co/GvZc0qdlI0 #eBay #Original #Historical #Art #LaborDay #Photography #Gymnast #Medical #Fitness #Athletics #Connecticut #CT #Women #womensday #Gymnastics #Photos\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.19 ms /    16 runs   (    0.57 ms per token,  1740.45 tokens per second)\n",
            "llama_print_timings: prompt eval time =     288.48 ms /   114 tokens (    2.53 ms per token,   395.18 tokens per second)\n",
            "llama_print_timings:        eval time =    1585.98 ms /    15 runs   (  105.73 ms per token,     9.46 tokens per second)\n",
            "llama_print_timings:       total time =    2188.35 ms /   129 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "#AmericanNeedlework #WomensDay - #1960s - #Embroidery #crewel #crossstitch #needlepoint #patchwork #appliqué #quilting #rugmaking #needlecraft #sewing #stitchery #needlework #handycrafts #crafs #traditionalcrafts #craftpatterns #patterns link: https://t.co/ZPAt8wRb2X via @Etsy\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.37 ms /    16 runs   (    0.59 ms per token,  1707.21 tokens per second)\n",
            "llama_print_timings: prompt eval time =     299.57 ms /   108 tokens (    2.77 ms per token,   360.52 tokens per second)\n",
            "llama_print_timings:        eval time =    1648.13 ms /    15 runs   (  109.88 ms per token,     9.10 tokens per second)\n",
            "llama_print_timings:       total time =    2236.93 ms /   123 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Can you imagine a #gender #equal world? Julie Burke from the #UnitedKingdom is striking the #IWD2022 #BreakTheBias 🙅🏼‍♀️ pose to champion a #society free from #bias #discrimination and #inequality 👏🏻 How are you still helping to #BreakTheBias ahead of #IWD2023 ? https://t.co/Td9H13tDXI\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.20 ms /    16 runs   (    0.70 ms per token,  1428.70 tokens per second)\n",
            "llama_print_timings: prompt eval time =     281.90 ms /    85 tokens (    3.32 ms per token,   301.53 tokens per second)\n",
            "llama_print_timings:        eval time =    1770.00 ms /    15 runs   (  118.00 ms per token,     8.47 tokens per second)\n",
            "llama_print_timings:       total time =    2465.45 ms /   100 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Buffelsdale women celebrate their powerFull story here https://t.co/EqBBhPaU8p#tongaatverulamtabloid #tabloidnewspapers #communitynews #TheRestorationMinistries #BuffelsdaleSecondarySchool #WomensDay https://t.co/Y22A9MuIw5\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.33 ms /    16 runs   (    0.58 ms per token,  1714.35 tokens per second)\n",
            "llama_print_timings: prompt eval time =     268.63 ms /    88 tokens (    3.05 ms per token,   327.59 tokens per second)\n",
            "llama_print_timings:        eval time =    1556.15 ms /    15 runs   (  103.74 ms per token,     9.64 tokens per second)\n",
            "llama_print_timings:       total time =    2070.55 ms /   103 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "#Vintage #Halloween, Skull Car Coasters, Creepy Vibes, Halloween ̔Car Accessory 👐#graceful #fashionhistory #bodycon #womenwhocode #womensrights #womenshealth #chicme #localscenes https://t.co/Sn6QX84Y0i\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.77 ms /    16 runs   (    0.61 ms per token,  1637.16 tokens per second)\n",
            "llama_print_timings: prompt eval time =     248.79 ms /    57 tokens (    4.36 ms per token,   229.11 tokens per second)\n",
            "llama_print_timings:        eval time =    1541.90 ms /    15 runs   (  102.79 ms per token,     9.73 tokens per second)\n",
            "llama_print_timings:       total time =    1973.79 ms /    72 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Lesbians love sex but we don't like being politically fcked!#Lesbian #Women #Trans @labour @Conservatives #WomensRights https://t.co/vac3ewai4h\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.76 ms /    16 runs   (    0.61 ms per token,  1639.34 tokens per second)\n",
            "llama_print_timings: prompt eval time =     243.65 ms /    55 tokens (    4.43 ms per token,   225.74 tokens per second)\n",
            "llama_print_timings:        eval time =    1520.29 ms /    15 runs   (  101.35 ms per token,     9.87 tokens per second)\n",
            "llama_print_timings:       total time =    1944.57 ms /    70 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Hi @samoosterhoff.  I met your father recently, nice enough of a guy but weird. Was it him or your mother who trained you to hate women?  #onpoli #WomensRights #prochoice\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.66 ms /    16 runs   (    0.73 ms per token,  1372.33 tokens per second)\n",
            "llama_print_timings: prompt eval time =     240.36 ms /    50 tokens (    4.81 ms per token,   208.02 tokens per second)\n",
            "llama_print_timings:        eval time =    1762.53 ms /    15 runs   (  117.50 ms per token,     8.51 tokens per second)\n",
            "llama_print_timings:       total time =    2197.31 ms /    65 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Since when have Republicans of the 21st century done anything helpful for #WomensRights ?I’ll wait…/6 https://t.co/qy306tSZc1\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.74 ms /    16 runs   (    0.61 ms per token,  1642.37 tokens per second)\n",
            "llama_print_timings: prompt eval time =     283.42 ms /    78 tokens (    3.63 ms per token,   275.21 tokens per second)\n",
            "llama_print_timings:        eval time =    1503.33 ms /    15 runs   (  100.22 ms per token,     9.98 tokens per second)\n",
            "llama_print_timings:       total time =    2074.03 ms /    93 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "But, but, but..... I thought that #Moleg/#MOSen were all about #prolifeWas I mistaken? F*ckin' #RepublicansAreTheProblem.#Women #WomensRights#VoteBlue2022 https://t.co/Z10W37T1xy\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.61 ms /    16 runs   (    0.54 ms per token,  1857.66 tokens per second)\n",
            "llama_print_timings: prompt eval time =     239.70 ms /    39 tokens (    6.15 ms per token,   162.70 tokens per second)\n",
            "llama_print_timings:        eval time =    1562.86 ms /    15 runs   (  104.19 ms per token,     9.60 tokens per second)\n",
            "llama_print_timings:       total time =    1952.62 ms /    54 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@CBSNews @finnygo No it’s about abortion rights stupid. #AbortionIsHealthcare #AbortionRights #WomensRights\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.58 ms /    16 runs   (    0.54 ms per token,  1864.80 tokens per second)\n",
            "llama_print_timings: prompt eval time =     691.16 ms /    27 tokens (   25.60 ms per token,    39.06 tokens per second)\n",
            "llama_print_timings:        eval time =    1527.92 ms /    15 runs   (  101.86 ms per token,     9.82 tokens per second)\n",
            "llama_print_timings:       total time =    2340.17 ms /    42 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "A day without women's football https://t.co/5cQ1ynP4TG\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.70 ms /    16 runs   (    0.61 ms per token,  1649.99 tokens per second)\n",
            "llama_print_timings: prompt eval time =     240.52 ms /    47 tokens (    5.12 ms per token,   195.41 tokens per second)\n",
            "llama_print_timings:        eval time =    1546.70 ms /    15 runs   (  103.11 ms per token,     9.70 tokens per second)\n",
            "llama_print_timings:       total time =    1968.50 ms /    62 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@covie_93 This was supposed to be about states' rights! So our state allows abortion! WTH? Is it time for National Strike? A Day Without Women? WHAT???\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.18 ms /    16 runs   (    0.64 ms per token,  1571.86 tokens per second)\n",
            "llama_print_timings: prompt eval time =     801.53 ms /    25 tokens (   32.06 ms per token,    31.19 tokens per second)\n",
            "llama_print_timings:        eval time =    1581.68 ms /    15 runs   (  105.45 ms per token,     9.48 tokens per second)\n",
            "llama_print_timings:       total time =    2558.87 ms /    40 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "What happened to the “A day without women” thingy? I slick need that back.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.95 ms /    16 runs   (    0.62 ms per token,  1607.72 tokens per second)\n",
            "llama_print_timings: prompt eval time =     264.11 ms /    79 tokens (    3.34 ms per token,   299.12 tokens per second)\n",
            "llama_print_timings:        eval time =    1647.42 ms /    15 runs   (  109.83 ms per token,     9.11 tokens per second)\n",
            "llama_print_timings:       total time =    2138.97 ms /    94 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Felt the same about “a day without women” a few years ago… all the teachers call out sick to prove a point, forcing other working moms who don’t necessarily agree or can’t afford it to take time off of work to stay at home with their small children. https://t.co/MwewC5n8mW\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.50 ms /    16 runs   (    0.53 ms per token,  1883.02 tokens per second)\n",
            "llama_print_timings: prompt eval time =     779.95 ms /    30 tokens (   26.00 ms per token,    38.46 tokens per second)\n",
            "llama_print_timings:        eval time =    1511.92 ms /    15 runs   (  100.79 ms per token,     9.92 tokens per second)\n",
            "llama_print_timings:       total time =    2415.54 ms /    45 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@ImSpeaking13 Red states wouldn't survive a day without women, blue states, or the federal government.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.19 ms /    16 runs   (    0.57 ms per token,  1740.27 tokens per second)\n",
            "llama_print_timings: prompt eval time =     261.48 ms /    70 tokens (    3.74 ms per token,   267.71 tokens per second)\n",
            "llama_print_timings:        eval time =    1504.22 ms /    15 runs   (  100.28 ms per token,     9.97 tokens per second)\n",
            "llama_print_timings:       total time =    1972.86 ms /    85 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@PastorJohnHagee God didn't bother to even make a woman until he realized a man wouldn't last a day without women.And then he apparently made more women (Cain and Abel's wives) because he failed to calculate how sexual reproduction works.Your source material is stupid.\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.79 ms /    16 runs   (    0.74 ms per token,  1356.51 tokens per second)\n",
            "llama_print_timings: prompt eval time =     269.24 ms /    75 tokens (    3.59 ms per token,   278.56 tokens per second)\n",
            "llama_print_timings:        eval time =    1765.67 ms /    15 runs   (  117.71 ms per token,     8.50 tokens per second)\n",
            "llama_print_timings:       total time =    2418.43 ms /    90 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@chris_okagbue Good Morning o.This is an example of a Sheggz's fan .They are victims of abuse &amp; they want Bella to join in their misery.Chris, ima nu ife anako. https://t.co/X4uQW5k91X\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.49 ms /    16 runs   (    0.53 ms per token,  1884.13 tokens per second)\n",
            "llama_print_timings: prompt eval time =     274.01 ms /    84 tokens (    3.26 ms per token,   306.56 tokens per second)\n",
            "llama_print_timings:        eval time =    1637.00 ms /    15 runs   (  109.13 ms per token,     9.16 tokens per second)\n",
            "llama_print_timings:       total time =    2149.80 ms /    99 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@NoSup4u @johnnarae White people really don’t know what abuse is because they haven’t really experience want abuse is. So if someone disagrees with you, you call it abuse. If someone takes your job b/c you don’t want to do it, you call ir abuse. If someone stands up to you, you call ir abuse smh\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.61 ms /    16 runs   (    0.60 ms per token,  1664.59 tokens per second)\n",
            "llama_print_timings: prompt eval time =     259.49 ms /    51 tokens (    5.09 ms per token,   196.54 tokens per second)\n",
            "llama_print_timings:        eval time =    1493.80 ms /    15 runs   (   99.59 ms per token,    10.04 tokens per second)\n",
            "llama_print_timings:       total time =    1938.09 ms /    66 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@SteveWilkosTV Any mother would take their own child to a hospital to get treated for burns she’s clearly not cutout to be a mom at all and needs to be in jail for child abuse.\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.06 ms /    16 runs   (    0.57 ms per token,  1765.61 tokens per second)\n",
            "llama_print_timings: prompt eval time =     545.22 ms /    32 tokens (   17.04 ms per token,    58.69 tokens per second)\n",
            "llama_print_timings:        eval time =    1592.16 ms /    15 runs   (  106.14 ms per token,     9.42 tokens per second)\n",
            "llama_print_timings:       total time =    2270.36 ms /    47 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@SkySportsNews can you put in the percentage of abuse jack grealish gave miggy had from him? #NUFC\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      12.64 ms /    16 runs   (    0.79 ms per token,  1266.12 tokens per second)\n",
            "llama_print_timings: prompt eval time =     257.33 ms /    69 tokens (    3.73 ms per token,   268.14 tokens per second)\n",
            "llama_print_timings:        eval time =    1772.98 ms /    15 runs   (  118.20 ms per token,     8.46 tokens per second)\n",
            "llama_print_timings:       total time =    2270.05 ms /    84 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Nope! His actions were politically motivated, too broad, and criminal in timing and construct. He will be fired in 2025, and should be incarcerated before that, for abuse of power. Stand by! https://t.co/mKFMP3sTiN\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.06 ms /    16 runs   (    0.57 ms per token,  1766.20 tokens per second)\n",
            "llama_print_timings: prompt eval time =     249.70 ms /    33 tokens (    7.57 ms per token,   132.16 tokens per second)\n",
            "llama_print_timings:        eval time =    1542.79 ms /    15 runs   (  102.85 ms per token,     9.72 tokens per second)\n",
            "llama_print_timings:       total time =    1928.93 ms /    48 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "CW: Digital child sexual abuse and sexploitationPart2:https://t.co/1dfzpkOuqB\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.37 ms /    16 runs   (    0.59 ms per token,  1707.03 tokens per second)\n",
            "llama_print_timings: prompt eval time =     245.11 ms /    47 tokens (    5.22 ms per token,   191.75 tokens per second)\n",
            "llama_print_timings:        eval time =    1542.38 ms /    15 runs   (  102.83 ms per token,     9.73 tokens per second)\n",
            "llama_print_timings:       total time =    1952.01 ms /    62 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Kaichan10425470 @owennoro This is a real thing actually! It's called androcentrism and it answers lots of bad female cast writing\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.11 ms /    16 runs   (    0.63 ms per token,  1582.12 tokens per second)\n",
            "llama_print_timings: prompt eval time =     283.06 ms /    90 tokens (    3.15 ms per token,   317.95 tokens per second)\n",
            "llama_print_timings:        eval time =    1495.52 ms /    15 runs   (   99.70 ms per token,    10.03 tokens per second)\n",
            "llama_print_timings:       total time =    2029.79 ms /   105 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "It allows us to question our own androcentrism and think of a world in which justice is a concrete and attainable goal.  Happy #InternationalTranslationDay! 💛🏳️‍🌈 Read @Tradoctas manifesto (in Spanish) on non-binary language: https://t.co/fqqm1PwX4J\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.40 ms /    16 runs   (    0.59 ms per token,  1702.13 tokens per second)\n",
            "llama_print_timings: prompt eval time =     238.38 ms /    48 tokens (    4.97 ms per token,   201.36 tokens per second)\n",
            "llama_print_timings:        eval time =    1498.10 ms /    15 runs   (   99.87 ms per token,    10.01 tokens per second)\n",
            "llama_print_timings:       total time =    1912.08 ms /    63 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "androcentrism definition: The tendency to place the male or masculine viewpoint and experience at the center of a society or culture. https://t.co/rMxXrt9kFG\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      16.21 ms /    16 runs   (    1.01 ms per token,   987.05 tokens per second)\n",
            "llama_print_timings: prompt eval time =     257.06 ms /    50 tokens (    5.14 ms per token,   194.51 tokens per second)\n",
            "llama_print_timings:        eval time =    1706.78 ms /    15 runs   (  113.79 ms per token,     8.79 tokens per second)\n",
            "llama_print_timings:       total time =    2244.87 ms /    65 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "\"Our problem is not only eurocentrism but also androcentrism.\"Male-bias, male-bias everywhere 👀 https://t.co/hkFy87lPr3\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.53 ms /    16 runs   (    0.60 ms per token,  1678.20 tokens per second)\n",
            "llama_print_timings: prompt eval time =     268.81 ms /    90 tokens (    2.99 ms per token,   334.81 tokens per second)\n",
            "llama_print_timings:        eval time =    1506.50 ms /    15 runs   (  100.43 ms per token,     9.96 tokens per second)\n",
            "llama_print_timings:       total time =    2033.05 ms /   105 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@__TweetinChar__ @simonw @j2bryson @OpenUniversity But I still like the concept of masculine and feminine as orthogonal, not opposites. And Bem’s critiques of biological essentialism and androcentrism are still powerful today. Possibly more powerful today, in that we are seeing a dramatic resurgence of biological essentialism.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.65 ms /    16 runs   (    0.54 ms per token,  1850.57 tokens per second)\n",
            "llama_print_timings: prompt eval time =     233.52 ms /    36 tokens (    6.49 ms per token,   154.16 tokens per second)\n",
            "llama_print_timings:        eval time =    1614.37 ms /    15 runs   (  107.62 ms per token,     9.29 tokens per second)\n",
            "llama_print_timings:       total time =    2002.06 ms /    51 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@fcomms Riiiiight! Talk about androcentrism! Perhaps they needed the extra room to house their oversided egos?!🤔\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.76 ms /    16 runs   (    0.55 ms per token,  1825.86 tokens per second)\n",
            "llama_print_timings: prompt eval time =     602.68 ms /    24 tokens (   25.11 ms per token,    39.82 tokens per second)\n",
            "llama_print_timings:        eval time =    1531.20 ms /    15 runs   (  102.08 ms per token,     9.80 tokens per second)\n",
            "llama_print_timings:       total time =    2250.24 ms /    39 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "u should all listen to androgynous mind by sonic youth literally such a banger\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.03 ms /    16 runs   (    0.69 ms per token,  1450.59 tokens per second)\n",
            "llama_print_timings: prompt eval time =     766.80 ms /    25 tokens (   30.67 ms per token,    32.60 tokens per second)\n",
            "llama_print_timings:        eval time =    1877.03 ms /    15 runs   (  125.14 ms per token,     7.99 tokens per second)\n",
            "llama_print_timings:       total time =    2846.47 ms /    40 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "You are playing a androgynous Mind Breaker Magnetic. #dnd #gammaworld\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.87 ms /    16 runs   (    0.55 ms per token,  1803.22 tokens per second)\n",
            "llama_print_timings: prompt eval time =     252.96 ms /    40 tokens (    6.32 ms per token,   158.13 tokens per second)\n",
            "llama_print_timings:        eval time =    1473.77 ms /    15 runs   (   98.25 ms per token,    10.18 tokens per second)\n",
            "llama_print_timings:       total time =    1886.96 ms /    55 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@emilynezz 1. Total Trash2. Sunday3. Androgynous Mind4. Cross the Breeze5. Youth Against Fascism\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.31 ms /    16 runs   (    0.58 ms per token,  1717.84 tokens per second)\n",
            "llama_print_timings: prompt eval time =     273.23 ms /    91 tokens (    3.00 ms per token,   333.05 tokens per second)\n",
            "llama_print_timings:        eval time =    1485.00 ms /    15 runs   (   99.00 ms per token,    10.10 tokens per second)\n",
            "llama_print_timings:       total time =    2015.08 ms /   106 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Our first paper by @Suparna60380317 is entitled “Urgency of Female Writing and Authorship: Re-reading Woolf’s A Room of One’s Own in the Age of Transition,” &amp; aims to show how the patriarchally fabled definition of a woman was challenged by Woolf’s concept of ‘androgynous mind’.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.90 ms /    16 runs   (    0.62 ms per token,  1616.16 tokens per second)\n",
            "llama_print_timings: prompt eval time =     271.32 ms /   101 tokens (    2.69 ms per token,   372.26 tokens per second)\n",
            "llama_print_timings:        eval time =    1584.33 ms /    15 runs   (  105.62 ms per token,     9.47 tokens per second)\n",
            "llama_print_timings:       total time =    2128.02 ms /   116 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@melnickjeffrey1 Nirvana, “Been a Son” (I was 11, foundational), Sonic Youth, “Androgynous Mind” (I was 13, fucked me up) &amp; every song Kim Gordon sang ever but especially “Shoot” (“And I won’t be asking not to have this baby, please”), Bikini Kill, Singles cd comp (every note of it).\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.05 ms /    16 runs   (    0.69 ms per token,  1447.44 tokens per second)\n",
            "llama_print_timings: prompt eval time =     280.46 ms /   105 tokens (    2.67 ms per token,   374.38 tokens per second)\n",
            "llama_print_timings:        eval time =    1614.72 ms /    15 runs   (  107.65 ms per token,     9.29 tokens per second)\n",
            "llama_print_timings:       total time =    2203.32 ms /   120 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "“…the #androgynous #mind is resonant and porous; that it transmits #emotion without impediment; that it is #naturally #creative, incandescent, and #undivided.” (A Room of One’s Own by #VirginiaWoolf, Sept. 1929).....📸: @bywayofiker https://t.co/0eMGyUSsTL\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.44 ms /    16 runs   (    0.59 ms per token,  1695.27 tokens per second)\n",
            "llama_print_timings: prompt eval time =     251.90 ms /    40 tokens (    6.30 ms per token,   158.79 tokens per second)\n",
            "llama_print_timings:        eval time =    1584.90 ms /    15 runs   (  105.66 ms per token,     9.46 tokens per second)\n",
            "llama_print_timings:       total time =    2064.07 ms /    55 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@CHSommers I guess it depends on the “sport”…no reason a woman darts player can’t be as good as a man darts player…\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.40 ms /    16 runs   (    0.59 ms per token,  1701.95 tokens per second)\n",
            "llama_print_timings: prompt eval time =     260.58 ms /    65 tokens (    4.01 ms per token,   249.45 tokens per second)\n",
            "llama_print_timings:        eval time =    1494.51 ms /    15 runs   (   99.63 ms per token,    10.04 tokens per second)\n",
            "llama_print_timings:       total time =    1962.15 ms /    80 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@LiamWATP He’s as fit as me ffs, he wouldn’t last 15 minutes, what goods that? If his heads in the wrong place he’s as good as a man down, do u honestly think the manager would leave him out for no good reason\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.24 ms /    16 runs   (    0.64 ms per token,  1561.89 tokens per second)\n",
            "llama_print_timings: prompt eval time =     251.93 ms /    63 tokens (    4.00 ms per token,   250.07 tokens per second)\n",
            "llama_print_timings:        eval time =    1487.65 ms /    15 runs   (   99.18 ms per token,    10.08 tokens per second)\n",
            "llama_print_timings:       total time =    1935.79 ms /    78 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Is casual sex with multiple casual partners really as good as a man can hope for in this day and age?No.There's a much better option.The goal is a ride or die woman who is by your side, like a wife, but without the legal system getting involved.\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.37 ms /    16 runs   (    0.59 ms per token,  1708.12 tokens per second)\n",
            "llama_print_timings: prompt eval time =     263.98 ms /    82 tokens (    3.22 ms per token,   310.63 tokens per second)\n",
            "llama_print_timings:        eval time =    1543.40 ms /    15 runs   (  102.89 ms per token,     9.72 tokens per second)\n",
            "llama_print_timings:       total time =    2039.41 ms /    97 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@GardenGirl1936 @TraceyDelaney if a woman is as good as a man why should she settle for being a helper rather than a decision maker or equal partner? I’m confused- helper is not the same hierarchy as final decision maker who can get inputs but has the final say. I guess you are taught to go by the bible\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.79 ms /    16 runs   (    0.67 ms per token,  1483.54 tokens per second)\n",
            "llama_print_timings: prompt eval time =     244.76 ms /    43 tokens (    5.69 ms per token,   175.68 tokens per second)\n",
            "llama_print_timings:        eval time =    1879.85 ms /    15 runs   (  125.32 ms per token,     7.98 tokens per second)\n",
            "llama_print_timings:       total time =    2389.29 ms /    58 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@TheBlackCat02 Living as a woman to me meaning being invisible or having to be 10x as good as a man at something in order to be seen as adequate at it\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.70 ms /    16 runs   (    0.54 ms per token,  1839.50 tokens per second)\n",
            "llama_print_timings: prompt eval time =     251.75 ms /    35 tokens (    7.19 ms per token,   139.03 tokens per second)\n",
            "llama_print_timings:        eval time =    1533.52 ms /    15 runs   (  102.23 ms per token,     9.78 tokens per second)\n",
            "llama_print_timings:       total time =    1927.24 ms /    50 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Girls, don't let anyone ever tell you, you're not as good as a man #gender #girlpower #equity\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.80 ms /    16 runs   (    0.55 ms per token,  1817.56 tokens per second)\n",
            "llama_print_timings: prompt eval time =     492.05 ms /    20 tokens (   24.60 ms per token,    40.65 tokens per second)\n",
            "llama_print_timings:        eval time =    1584.90 ms /    15 runs   (  105.66 ms per token,     9.46 tokens per second)\n",
            "llama_print_timings:       total time =    2185.18 ms /    35 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "grown adults not washing their ass perplexes me GREATLY\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.89 ms /    16 runs   (    0.56 ms per token,  1800.59 tokens per second)\n",
            "llama_print_timings: prompt eval time =     590.26 ms /    24 tokens (   24.59 ms per token,    40.66 tokens per second)\n",
            "llama_print_timings:        eval time =    1629.46 ms /    15 runs   (  108.63 ms per token,     9.21 tokens per second)\n",
            "llama_print_timings:       total time =    2339.14 ms /    39 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "i still aint forget abt that weird ass tweet theericklouis made\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.98 ms /    16 runs   (    0.62 ms per token,  1602.56 tokens per second)\n",
            "llama_print_timings: prompt eval time =     237.46 ms /    37 tokens (    6.42 ms per token,   155.82 tokens per second)\n",
            "llama_print_timings:        eval time =    1832.79 ms /    15 runs   (  122.19 ms per token,     8.18 tokens per second)\n",
            "llama_print_timings:       total time =    2237.24 ms /    52 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Holy crickies…. I peed my pants laughing my ass off! https://t.co/9yMwjh9YEK\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.50 ms /    16 runs   (    0.59 ms per token,  1683.86 tokens per second)\n",
            "llama_print_timings: prompt eval time =     265.91 ms /    42 tokens (    6.33 ms per token,   157.95 tokens per second)\n",
            "llama_print_timings:        eval time =    1524.13 ms /    15 runs   (  101.61 ms per token,     9.84 tokens per second)\n",
            "llama_print_timings:       total time =    2037.86 ms /    57 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "$25 for a plate of jollof that taste like ass is crazy… I’m tired of these Nigerian restaurants. $50 for three snails?..\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.44 ms /    16 runs   (    0.59 ms per token,  1694.56 tokens per second)\n",
            "llama_print_timings: prompt eval time =     249.55 ms /    51 tokens (    4.89 ms per token,   204.37 tokens per second)\n",
            "llama_print_timings:        eval time =    1577.55 ms /    15 runs   (  105.17 ms per token,     9.51 tokens per second)\n",
            "llama_print_timings:       total time =    2000.57 ms /    66 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "why kelis raggedy ass couldn't just shut the fuck up after her 18 min video? why you had to call that lady a satanist? that was easily my favorite damn transition on the album\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.31 ms /    16 runs   (    0.58 ms per token,  1718.58 tokens per second)\n",
            "llama_print_timings: prompt eval time =     248.13 ms /    40 tokens (    6.20 ms per token,   161.21 tokens per second)\n",
            "llama_print_timings:        eval time =    1574.59 ms /    15 runs   (  104.97 ms per token,     9.53 tokens per second)\n",
            "llama_print_timings:       total time =    1971.49 ms /    55 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "My weight up and now I got the power #Homeowner worked my ass off for this 💪🏾💯 https://t.co/PiHvwsFoac\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.01 ms /    16 runs   (    0.63 ms per token,  1598.72 tokens per second)\n",
            "llama_print_timings: prompt eval time =     265.18 ms /    64 tokens (    4.14 ms per token,   241.34 tokens per second)\n",
            "llama_print_timings:        eval time =    1652.35 ms /    15 runs   (  110.16 ms per token,     9.08 tokens per second)\n",
            "llama_print_timings:       total time =    2118.97 ms /    79 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@seuIgitron maam how is that behaviour attractive? you equating it to mommy issues/behaviours is honestly weird too im breaking up with you! dayoung and I are moving out https://t.co/aYKUHDGutB\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.44 ms /    16 runs   (    0.71 ms per token,  1399.21 tokens per second)\n",
            "llama_print_timings: prompt eval time =     265.10 ms /    59 tokens (    4.49 ms per token,   222.55 tokens per second)\n",
            "llama_print_timings:        eval time =    1738.17 ms /    15 runs   (  115.88 ms per token,     8.63 tokens per second)\n",
            "llama_print_timings:       total time =    2325.35 ms /    74 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@MrAustinShow did you find her attractive? or were you attracted to her? i find women aesthetically attractive and pretty all the time, I'm just not interested in a relationship with them, sexual or otherwise. I'm very much so gay\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.90 ms /    16 runs   (    0.56 ms per token,  1796.74 tokens per second)\n",
            "llama_print_timings: prompt eval time =     237.38 ms /    36 tokens (    6.59 ms per token,   151.66 tokens per second)\n",
            "llama_print_timings:        eval time =    1640.80 ms /    15 runs   (  109.39 ms per token,     9.14 tokens per second)\n",
            "llama_print_timings:       total time =    2022.73 ms /    51 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@mannukxo Theres probably 100 other things that could be way more attractive about us and you chose THAT nonsense trait.   GN\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.71 ms /    16 runs   (    0.54 ms per token,  1837.39 tokens per second)\n",
            "llama_print_timings: prompt eval time =     681.36 ms /    27 tokens (   25.24 ms per token,    39.63 tokens per second)\n",
            "llama_print_timings:        eval time =    1416.64 ms /    15 runs   (   94.44 ms per token,    10.59 tokens per second)\n",
            "llama_print_timings:       total time =    2219.42 ms /    42 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "avan jogia is so annoyingly attractive https://t.co/3yzLMfT4lj\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.81 ms /    16 runs   (    0.55 ms per token,  1815.50 tokens per second)\n",
            "llama_print_timings: prompt eval time =     642.80 ms /    26 tokens (   24.72 ms per token,    40.45 tokens per second)\n",
            "llama_print_timings:        eval time =    1492.62 ms /    15 runs   (   99.51 ms per token,    10.05 tokens per second)\n",
            "llama_print_timings:       total time =    2253.53 ms /    41 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@bootheelposting what a shame that being ungodly attractive doesnt actually make life better\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.66 ms /    16 runs   (    0.67 ms per token,  1500.94 tokens per second)\n",
            "llama_print_timings: prompt eval time =     237.06 ms /    33 tokens (    7.18 ms per token,   139.20 tokens per second)\n",
            "llama_print_timings:        eval time =    1792.71 ms /    15 runs   (  119.51 ms per token,     8.37 tokens per second)\n",
            "llama_print_timings:       total time =    2250.45 ms /    48 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "simu liu and paul rudd being the most attractive AND funniest mcu men must make chris pratt so angry\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.65 ms /    16 runs   (    0.54 ms per token,  1849.50 tokens per second)\n",
            "llama_print_timings: prompt eval time =     689.17 ms /    27 tokens (   25.52 ms per token,    39.18 tokens per second)\n",
            "llama_print_timings:        eval time =    1590.20 ms /    15 runs   (  106.01 ms per token,     9.43 tokens per second)\n",
            "llama_print_timings:       total time =    2404.12 ms /    42 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@RemyLaCroixxxxx So so glad to see you Remy! Never more beautiful!\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.52 ms /    16 runs   (    0.59 ms per token,  1680.67 tokens per second)\n",
            "llama_print_timings: prompt eval time =     241.32 ms /    48 tokens (    5.03 ms per token,   198.90 tokens per second)\n",
            "llama_print_timings:        eval time =    1485.41 ms /    15 runs   (   99.03 ms per token,    10.10 tokens per second)\n",
            "llama_print_timings:       total time =    1900.00 ms /    63 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Jasmine_BlackXX Looking so beautiful 🤩🤩🔥🔥🔥🔥  love the post btw.  We are only here for a limited rime so make it count\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.67 ms /    16 runs   (    0.54 ms per token,  1845.87 tokens per second)\n",
            "llama_print_timings: prompt eval time =     650.68 ms /    27 tokens (   24.10 ms per token,    41.50 tokens per second)\n",
            "llama_print_timings:        eval time =    1496.06 ms /    15 runs   (   99.74 ms per token,    10.03 tokens per second)\n",
            "llama_print_timings:       total time =    2267.66 ms /    42 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "beautiful thing about life… soon as I realized I fucked up, I get back up on that horse\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.87 ms /    16 runs   (    0.62 ms per token,  1621.24 tokens per second)\n",
            "llama_print_timings: prompt eval time =     240.04 ms /    44 tokens (    5.46 ms per token,   183.30 tokens per second)\n",
            "llama_print_timings:        eval time =    1737.13 ms /    15 runs   (  115.81 ms per token,     8.63 tokens per second)\n",
            "llama_print_timings:       total time =    2160.59 ms /    59 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Good evening you beautiful peoples!!! 💙I hope you all had an amazing day. 🥹 https://t.co/T9nfUBBHkM\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.59 ms /    16 runs   (    0.54 ms per token,  1862.63 tokens per second)\n",
            "llama_print_timings: prompt eval time =     830.91 ms /    30 tokens (   27.70 ms per token,    36.10 tokens per second)\n",
            "llama_print_timings:        eval time =    1563.26 ms /    15 runs   (  104.22 ms per token,     9.60 tokens per second)\n",
            "llama_print_timings:       total time =    2524.46 ms /    45 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@JeanHatchet @StandingforXX I forgot to say, the dog is fantastic. Absolutely beautiful.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.48 ms /    16 runs   (    0.59 ms per token,  1688.30 tokens per second)\n",
            "llama_print_timings: prompt eval time =     266.28 ms /    83 tokens (    3.21 ms per token,   311.70 tokens per second)\n",
            "llama_print_timings:        eval time =    1523.96 ms /    15 runs   (  101.60 ms per token,     9.84 tokens per second)\n",
            "llama_print_timings:       total time =    2032.61 ms /    98 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Took me by shock &amp; then awe seeing this beautiful girl Diyara braving through the whole very tough &amp; expensive treatment process. Her family is doing everything they can to help her battle &amp; defeat this cancer! Please contribute to the campaign to help this little one to victory. https://t.co/4q1rEvjVWg\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.62 ms /    16 runs   (    0.54 ms per token,  1855.29 tokens per second)\n",
            "llama_print_timings: prompt eval time =     236.09 ms /    39 tokens (    6.05 ms per token,   165.19 tokens per second)\n",
            "llama_print_timings:        eval time =    1518.32 ms /    15 runs   (  101.22 ms per token,     9.88 tokens per second)\n",
            "llama_print_timings:       total time =    1931.74 ms /    54 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Elatorre9 @GlobalGamer0 @VioletWanderers Facts. It’s either good or bad. Binary thinking helps no one.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.24 ms /    16 runs   (    0.64 ms per token,  1562.81 tokens per second)\n",
            "llama_print_timings: prompt eval time =     255.03 ms /    57 tokens (    4.47 ms per token,   223.50 tokens per second)\n",
            "llama_print_timings:        eval time =    1512.92 ms /    15 runs   (  100.86 ms per token,     9.91 tokens per second)\n",
            "llama_print_timings:       total time =    1952.76 ms /    72 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@monkeytroIl @IcyAlChad You trying to own me for my take being wrong is binary thinking. It also isn’t the sunk cost fallacy because I still think the cardinals are objectively not a top three offense.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.17 ms /    16 runs   (    0.70 ms per token,  1432.28 tokens per second)\n",
            "llama_print_timings: prompt eval time =     249.85 ms /    57 tokens (    4.38 ms per token,   228.14 tokens per second)\n",
            "llama_print_timings:        eval time =    1700.45 ms /    15 runs   (  113.36 ms per token,     8.82 tokens per second)\n",
            "llama_print_timings:       total time =    2246.94 ms /    72 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@YukariMAiG @autistic_muse Which is where the irony lies. Binary thinking is bad according to them, but everything falls under the label of good/evil. Often to the extremes only, never any gray.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.27 ms /    16 runs   (    0.58 ms per token,  1726.00 tokens per second)\n",
            "llama_print_timings: prompt eval time =     285.94 ms /   107 tokens (    2.67 ms per token,   374.20 tokens per second)\n",
            "llama_print_timings:        eval time =    1496.15 ms /    15 runs   (   99.74 ms per token,    10.03 tokens per second)\n",
            "llama_print_timings:       total time =    2078.85 ms /   122 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "ICYMI Wild Ones Salon is on Wed 28th Sept @ Maureen'sTheme: I #ChooseToChallenge Binary Thinking!There's #OpenMic + wild inter sectional chats about 'is it always just this or that?' https://t.co/cV3EBAGPw0#ChangeTheNarrative #GoodDayCork PLS RT @LauraMoon_Ken @dottymurf\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.16 ms /    16 runs   (    0.57 ms per token,  1745.96 tokens per second)\n",
            "llama_print_timings: prompt eval time =     259.05 ms /    66 tokens (    3.92 ms per token,   254.78 tokens per second)\n",
            "llama_print_timings:        eval time =    1504.87 ms /    15 runs   (  100.32 ms per token,     9.97 tokens per second)\n",
            "llama_print_timings:       total time =    1964.43 ms /    81 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@benshapiro \"Sleeping with me is a privilege.\" Okay, that is something that I expect to hear from a high-class escort, not a recovering slut...She seems to be caught up in this binary thinking that sex is all about men vs women...1/\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.83 ms /    16 runs   (    0.55 ms per token,  1812.83 tokens per second)\n",
            "llama_print_timings: prompt eval time =     579.32 ms /    21 tokens (   27.59 ms per token,    36.25 tokens per second)\n",
            "llama_print_timings:        eval time =    1585.54 ms /    15 runs   (  105.70 ms per token,     9.46 tokens per second)\n",
            "llama_print_timings:       total time =    2272.99 ms /    36 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@mc2mc5 Correct. You're still stuck in binary thinking.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.85 ms /    16 runs   (    0.74 ms per token,  1349.98 tokens per second)\n",
            "llama_print_timings: prompt eval time =     240.48 ms /    43 tokens (    5.59 ms per token,   178.81 tokens per second)\n",
            "llama_print_timings:        eval time =    1802.53 ms /    15 runs   (  120.17 ms per token,     8.32 tokens per second)\n",
            "llama_print_timings:       total time =    2288.18 ms /    58 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@MoneyMaseMount Nursing has always been a traditionally feminine profession and the oldest. Rufidah bint Sa’ad was the first known nurse in Islamic history\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.58 ms /    16 runs   (    0.54 ms per token,  1865.02 tokens per second)\n",
            "llama_print_timings: prompt eval time =     256.85 ms /    35 tokens (    7.34 ms per token,   136.26 tokens per second)\n",
            "llama_print_timings:        eval time =    1571.12 ms /    15 runs   (  104.74 ms per token,     9.55 tokens per second)\n",
            "llama_print_timings:       total time =    1969.98 ms /    50 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@bint_zarah @Teeenau Aswear da gudu I will quickly buy shawarma with the 3k\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.60 ms /    16 runs   (    0.54 ms per token,  1860.03 tokens per second)\n",
            "llama_print_timings: prompt eval time =     548.29 ms /    32 tokens (   17.13 ms per token,    58.36 tokens per second)\n",
            "llama_print_timings:        eval time =    1502.38 ms /    15 runs   (  100.16 ms per token,     9.98 tokens per second)\n",
            "llama_print_timings:       total time =    2194.35 ms /    47 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@the_ggc1 @bint_zarah O ti ye e 🌝..... Garage money is sweet\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.37 ms /    16 runs   (    0.59 ms per token,  1707.58 tokens per second)\n",
            "llama_print_timings: prompt eval time =     264.32 ms /    83 tokens (    3.18 ms per token,   314.01 tokens per second)\n",
            "llama_print_timings:        eval time =    1532.86 ms /    15 runs   (  102.19 ms per token,     9.79 tokens per second)\n",
            "llama_print_timings:       total time =    2036.65 ms /    98 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Further disturbing details have emerged regarding the recent sentencing of Nourah bint Saeed al-Qahtani to 45 years in prison for her social media activity. Read more in today's Gulf Update - https://t.co/lQYVjxAHPd https://t.co/bUWKQUMsIL\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.78 ms /    16 runs   (    0.61 ms per token,  1636.66 tokens per second)\n",
            "llama_print_timings: prompt eval time =     672.80 ms /    28 tokens (   24.03 ms per token,    41.62 tokens per second)\n",
            "llama_print_timings:        eval time =    1808.93 ms /    15 runs   (  120.60 ms per token,     8.29 tokens per second)\n",
            "llama_print_timings:       total time =    2625.18 ms /    43 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Simon109668 Yeah. All started when he called some bint \"Rover\".\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.38 ms /    16 runs   (    0.71 ms per token,  1406.10 tokens per second)\n",
            "llama_print_timings: prompt eval time =     287.81 ms /    82 tokens (    3.51 ms per token,   284.91 tokens per second)\n",
            "llama_print_timings:        eval time =    1542.29 ms /    15 runs   (  102.82 ms per token,     9.73 tokens per second)\n",
            "llama_print_timings:       total time =    2206.17 ms /    97 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@bint_haramm The national dish of Ukraine is Borscht, the famous beet soup, of which a wide array exists. However, Varenyky (boiled dumplings similar to Pierogi) and a cabbage roll known as Holubtsi are also national favorites and typical meals in traditional Ukrainian homes. I hope it helps?\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.80 ms /    16 runs   (    0.55 ms per token,  1817.77 tokens per second)\n",
            "llama_print_timings: prompt eval time =     769.46 ms /    30 tokens (   25.65 ms per token,    38.99 tokens per second)\n",
            "llama_print_timings:        eval time =    1555.68 ms /    15 runs   (  103.71 ms per token,     9.64 tokens per second)\n",
            "llama_print_timings:       total time =    2450.98 ms /    45 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "A bitch was so mad today that I pulled  , payed for gas… and drove off without it 🤣🤣🤣\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.69 ms /    16 runs   (    0.54 ms per token,  1841.83 tokens per second)\n",
            "llama_print_timings: prompt eval time =     475.92 ms /    17 tokens (   28.00 ms per token,    35.72 tokens per second)\n",
            "llama_print_timings:        eval time =    1581.33 ms /    15 runs   (  105.42 ms per token,     9.49 tokens per second)\n",
            "llama_print_timings:       total time =    2158.15 ms /    32 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@humphreyzinho Category sexy bitch Im the bar\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.29 ms /    16 runs   (    0.58 ms per token,  1722.84 tokens per second)\n",
            "llama_print_timings: prompt eval time =     756.28 ms /    30 tokens (   25.21 ms per token,    39.67 tokens per second)\n",
            "llama_print_timings:        eval time =    1712.40 ms /    15 runs   (  114.16 ms per token,     8.76 tokens per second)\n",
            "llama_print_timings:       total time =    2609.64 ms /    45 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "You think we could be cool one day? NO BITCH … you think we could be honest one day? WTF🙄\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.81 ms /    16 runs   (    0.55 ms per token,  1816.74 tokens per second)\n",
            "llama_print_timings: prompt eval time =     772.67 ms /    22 tokens (   35.12 ms per token,    28.47 tokens per second)\n",
            "llama_print_timings:        eval time =    1553.46 ms /    15 runs   (  103.56 ms per token,     9.66 tokens per second)\n",
            "llama_print_timings:       total time =    2473.39 ms /    37 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@ripsoshi Now we need to work on the next bitch to get the chop\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.21 ms /    16 runs   (    0.58 ms per token,  1736.86 tokens per second)\n",
            "llama_print_timings: prompt eval time =     259.58 ms /    68 tokens (    3.82 ms per token,   261.96 tokens per second)\n",
            "llama_print_timings:        eval time =    1479.25 ms /    15 runs   (   98.62 ms per token,    10.14 tokens per second)\n",
            "llama_print_timings:       total time =    1943.41 ms /    83 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@x3r0gxx @baroque_bitch I think the people I have in mind, who aren’t my direct family, probably would. No one I associate with is downplaying covid,but there are things we need to do. We can’t abide perpetual isolation\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.38 ms /    16 runs   (    0.59 ms per token,  1705.03 tokens per second)\n",
            "llama_print_timings: prompt eval time =     258.73 ms /    68 tokens (    3.80 ms per token,   262.82 tokens per second)\n",
            "llama_print_timings:        eval time =    1447.31 ms /    15 runs   (   96.49 ms per token,    10.36 tokens per second)\n",
            "llama_print_timings:       total time =    1920.35 ms /    83 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "This tik toker mama riles or some shit idk I cannot stand her and I’ve blocked multiple of her tik toks so she doesn’t show up on my fyp anymore Bitch tell me why her baby daddy now on my damn fyp like is this fuckin fr\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.74 ms /    16 runs   (    0.55 ms per token,  1831.29 tokens per second)\n",
            "llama_print_timings: prompt eval time =     750.72 ms /    31 tokens (   24.22 ms per token,    41.29 tokens per second)\n",
            "llama_print_timings:        eval time =    1442.16 ms /    15 runs   (   96.14 ms per token,    10.40 tokens per second)\n",
            "llama_print_timings:       total time =    2326.69 ms /    46 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "i miss it 😭 these bitches be boring asl yo https://t.co/bwdKzOhSw1\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.97 ms /    16 runs   (    0.69 ms per token,  1458.66 tokens per second)\n",
            "llama_print_timings: prompt eval time =     243.37 ms /    37 tokens (    6.58 ms per token,   152.03 tokens per second)\n",
            "llama_print_timings:        eval time =    1700.97 ms /    15 runs   (  113.40 ms per token,     8.82 tokens per second)\n",
            "llama_print_timings:       total time =    2190.53 ms /    52 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "i keep thinking about that list of words #they want us to change cause it’s “offensive”. ima just call you bitches remedial.\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.45 ms /    16 runs   (    0.53 ms per token,  1893.04 tokens per second)\n",
            "llama_print_timings: prompt eval time =     253.54 ms /    43 tokens (    5.90 ms per token,   169.60 tokens per second)\n",
            "llama_print_timings:        eval time =    1631.36 ms /    15 runs   (  108.76 ms per token,     9.19 tokens per second)\n",
            "llama_print_timings:       total time =    2039.35 ms /    58 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "every time I turn around she always involved or doing something. damn she worse than the bitches from ISS… I would know cause I was one of the bitches from ISS.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.08 ms /    16 runs   (    0.57 ms per token,  1761.92 tokens per second)\n",
            "llama_print_timings: prompt eval time =     242.88 ms /    34 tokens (    7.14 ms per token,   139.99 tokens per second)\n",
            "llama_print_timings:        eval time =    1582.81 ms /    15 runs   (  105.52 ms per token,     9.48 tokens per second)\n",
            "llama_print_timings:       total time =    1966.16 ms /    49 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "DAILY REMINDER TO EAT LIMES BITCHES https://t.co/XzPQtfhint\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.83 ms /    16 runs   (    0.55 ms per token,  1811.18 tokens per second)\n",
            "llama_print_timings: prompt eval time =     233.05 ms /    34 tokens (    6.85 ms per token,   145.89 tokens per second)\n",
            "llama_print_timings:        eval time =    1533.94 ms /    15 runs   (  102.26 ms per token,     9.78 tokens per second)\n",
            "llama_print_timings:       total time =    1922.25 ms /    49 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Anyways I’m jealous of you bitches wit strong ass knees. Soon as I pop a squat all I hear is cracking\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.65 ms /    16 runs   (    0.67 ms per token,  1501.78 tokens per second)\n",
            "llama_print_timings: prompt eval time =     248.92 ms /    42 tokens (    5.93 ms per token,   168.73 tokens per second)\n",
            "llama_print_timings:        eval time =    1816.25 ms /    15 runs   (  121.08 ms per token,     8.26 tokens per second)\n",
            "llama_print_timings:       total time =    2247.30 ms /    57 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Bitches don’t be having no car or job and wanna have another woman man 🤣🤣 thinking small gotta think bigger grasshopper 🧘🏽‍♀️\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.43 ms /    16 runs   (    0.59 ms per token,  1697.07 tokens per second)\n",
            "llama_print_timings: prompt eval time =     293.60 ms /    70 tokens (    4.19 ms per token,   238.42 tokens per second)\n",
            "llama_print_timings:        eval time =    1528.56 ms /    15 runs   (  101.90 ms per token,     9.81 tokens per second)\n",
            "llama_print_timings:       total time =    2049.88 ms /    85 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Nineteen8OFour That same sex has the predisposition for protecting women and children from the (about 7%) of men who cross that line.If we were going to hold entire groups accountable for the statistical behaviour of a minority, then we'd blame ALL women for infanticide.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.77 ms /    16 runs   (    0.61 ms per token,  1637.16 tokens per second)\n",
            "llama_print_timings: prompt eval time =     282.73 ms /   112 tokens (    2.52 ms per token,   396.14 tokens per second)\n",
            "llama_print_timings:        eval time =    1521.19 ms /    15 runs   (  101.41 ms per token,     9.86 tokens per second)\n",
            "llama_print_timings:       total time =    2111.05 ms /   127 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Spammys54954642 @Noah_185 @eidas007 @ADHD_OW @SwagTortoiseOW @OW_SVB Women have gone to jail for falsely accusing men. Do you live under a rock? You can Google it too 💀💀 you’re trying SO HARD to blame all women rather than admitting that this entire thing is sad and contributes to causing more harm to women who actually deal with this stuff\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.57 ms /    16 runs   (    0.60 ms per token,  1671.89 tokens per second)\n",
            "llama_print_timings: prompt eval time =     249.33 ms /    59 tokens (    4.23 ms per token,   236.64 tokens per second)\n",
            "llama_print_timings:        eval time =    1585.20 ms /    15 runs   (  105.68 ms per token,     9.46 tokens per second)\n",
            "llama_print_timings:       total time =    2023.35 ms /    74 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@I_am_Rebah Only a very stupid man will blame all women for the failure of his marriage. Of course if you fail to choose at the beginning you will pay the price i the end.The type of person one marry will dictate one’s life\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.12 ms /    16 runs   (    0.57 ms per token,  1753.42 tokens per second)\n",
            "llama_print_timings: prompt eval time =     236.77 ms /    39 tokens (    6.07 ms per token,   164.71 tokens per second)\n",
            "llama_print_timings:        eval time =    1517.29 ms /    15 runs   (  101.15 ms per token,     9.89 tokens per second)\n",
            "llama_print_timings:       total time =    1906.29 ms /    54 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@pedwards_phil @stu_fraser Shut up you pathetic little wiener. Don't blame all women because you are unappealing\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.66 ms /    16 runs   (    0.67 ms per token,  1501.36 tokens per second)\n",
            "llama_print_timings: prompt eval time =     260.98 ms /    47 tokens (    5.55 ms per token,   180.09 tokens per second)\n",
            "llama_print_timings:        eval time =    1713.29 ms /    15 runs   (  114.22 ms per token,     8.76 tokens per second)\n",
            "llama_print_timings:       total time =    2235.55 ms /    62 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@TheRealTXRed @utismcel333 @LilithWon_FDS So, can we blame all women for all the paternity frauds committed? false rape allegations?\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.60 ms /    16 runs   (    0.60 ms per token,  1666.84 tokens per second)\n",
            "llama_print_timings: prompt eval time =     251.18 ms /    63 tokens (    3.99 ms per token,   250.82 tokens per second)\n",
            "llama_print_timings:        eval time =    1535.76 ms /    15 runs   (  102.38 ms per token,     9.77 tokens per second)\n",
            "llama_print_timings:       total time =    1996.44 ms /    78 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "It is illegal to blame all women for Eves crime in Timothy 2:11-15 in the Bible. Judas (male) sinned too. Trans male has got to be one of the most brilliant ideas to circumvent the stupid parts of the Bible.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.00 ms /    16 runs   (    0.56 ms per token,  1778.17 tokens per second)\n",
            "llama_print_timings: prompt eval time =     236.53 ms /    43 tokens (    5.50 ms per token,   181.80 tokens per second)\n",
            "llama_print_timings:        eval time =    1453.06 ms /    15 runs   (   96.87 ms per token,    10.32 tokens per second)\n",
            "llama_print_timings:       total time =    1846.27 ms /    58 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "The brightest star ⭐️ Can’t wait for you to be my boss in the next 3! https://t.co/Qn1QqKxF60\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.35 ms /    16 runs   (    0.58 ms per token,  1710.68 tokens per second)\n",
            "llama_print_timings: prompt eval time =     240.10 ms /    39 tokens (    6.16 ms per token,   162.43 tokens per second)\n",
            "llama_print_timings:        eval time =    1621.81 ms /    15 runs   (  108.12 ms per token,     9.25 tokens per second)\n",
            "llama_print_timings:       total time =    2018.26 ms /    54 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Cougar_Boss Must be high contact wrestling with how red of their faces are and how the one on the bottom is enjoined it 👀👀\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.38 ms /    16 runs   (    0.71 ms per token,  1406.35 tokens per second)\n",
            "llama_print_timings: prompt eval time =     259.61 ms /    54 tokens (    4.81 ms per token,   208.00 tokens per second)\n",
            "llama_print_timings:        eval time =    1792.20 ms /    15 runs   (  119.48 ms per token,     8.37 tokens per second)\n",
            "llama_print_timings:       total time =    2267.31 ms /    69 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@FloppyAdult @BeguiledGamer You legit don’t have a valid argument, eh? All you can come up with is fuck off. Maybe if you were a better boss, you’d still be there.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.15 ms /    16 runs   (    0.57 ms per token,  1747.68 tokens per second)\n",
            "llama_print_timings: prompt eval time =     254.36 ms /    42 tokens (    6.06 ms per token,   165.12 tokens per second)\n",
            "llama_print_timings:        eval time =    1537.08 ms /    15 runs   (  102.47 ms per token,     9.76 tokens per second)\n",
            "llama_print_timings:       total time =    1947.43 ms /    57 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@averyjbyrd I emailed my boss some suggestions for a change in schedule but 😬 have yet to hear anything. Soooo we’ll see how it goes.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.04 ms /    16 runs   (    0.57 ms per token,  1769.32 tokens per second)\n",
            "llama_print_timings: prompt eval time =     263.54 ms /    63 tokens (    4.18 ms per token,   239.06 tokens per second)\n",
            "llama_print_timings:        eval time =    1505.67 ms /    15 runs   (  100.38 ms per token,     9.96 tokens per second)\n",
            "llama_print_timings:       total time =    1959.71 ms /    78 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@dhesi_trades No problem boss. Props to you for the review. You will not see improvement in your trading if you are not reviewing what went wrong on your losers and what went right on your winners, plain and simple. You goin places ♥️\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.09 ms /    16 runs   (    0.57 ms per token,  1759.98 tokens per second)\n",
            "llama_print_timings: prompt eval time =     278.73 ms /    97 tokens (    2.87 ms per token,   348.00 tokens per second)\n",
            "llama_print_timings:        eval time =    1621.43 ms /    15 runs   (  108.10 ms per token,     9.25 tokens per second)\n",
            "llama_print_timings:       total time =    2160.09 ms /   112 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Alhamdulillah my boss my mentor, one of the simple leader I have ever knw in my entire life, words can express hw happy I am with u, u are a true leader @MafiMishkila_  may Almighty Allah bless guide,  ad protect u we are proud of u sir🙏🏽🙏🏽🙏🏽🙏🏽 https://t.co/jEWEsr74BA\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.63 ms /    16 runs   (    0.60 ms per token,  1661.30 tokens per second)\n",
            "llama_print_timings: prompt eval time =     796.84 ms /    31 tokens (   25.70 ms per token,    38.90 tokens per second)\n",
            "llama_print_timings:        eval time =    1631.85 ms /    15 runs   (  108.79 ms per token,     9.19 tokens per second)\n",
            "llama_print_timings:       total time =    2565.04 ms /    46 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Deji you’re doing well, see hin face like Biggie bullied him to do it #BBNaija\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.62 ms /    16 runs   (    0.66 ms per token,  1506.17 tokens per second)\n",
            "llama_print_timings: prompt eval time =     270.89 ms /    61 tokens (    4.44 ms per token,   225.19 tokens per second)\n",
            "llama_print_timings:        eval time =    1650.10 ms /    15 runs   (  110.01 ms per token,     9.09 tokens per second)\n",
            "llama_print_timings:       total time =    2219.27 ms /    76 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "It was showing from my style. But so we had really different styles, but he got so much praise while I was being bullied for drawing \"anime\". So on the seventh grade I quit more or less, because I ended up to the same class with the same guy\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.45 ms /    16 runs   (    0.59 ms per token,  1692.94 tokens per second)\n",
            "llama_print_timings: prompt eval time =     284.39 ms /   107 tokens (    2.66 ms per token,   376.24 tokens per second)\n",
            "llama_print_timings:        eval time =    1514.10 ms /    15 runs   (  100.94 ms per token,     9.91 tokens per second)\n",
            "llama_print_timings:       total time =    2091.84 ms /   122 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@LilyLilyMaynard @gwpurnell Mermaid's poster kid's Mum speaks about intervention from Mermaids (school, aged 7/8 &amp; meetings at 9/10). Sadly, another sensitive wee boy bullied for wanting to play with girls etc. &amp; who wasn't allowed to play dress up in 'girl' clothes/grow his hair.https://t.co/rCVxxVSLsE\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.13 ms /    16 runs   (    0.57 ms per token,  1751.51 tokens per second)\n",
            "llama_print_timings: prompt eval time =     242.34 ms /    48 tokens (    5.05 ms per token,   198.07 tokens per second)\n",
            "llama_print_timings:        eval time =    1484.73 ms /    15 runs   (   98.98 ms per token,    10.10 tokens per second)\n",
            "llama_print_timings:       total time =    1901.01 ms /    63 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@avatarkaty3 @nickianaswoo little monsters bullied her off the internet and were throwing slvrs around because she didnt like chromatica🫤🫤\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.36 ms /    16 runs   (    0.58 ms per token,  1709.58 tokens per second)\n",
            "llama_print_timings: prompt eval time =     248.92 ms /    62 tokens (    4.01 ms per token,   249.08 tokens per second)\n",
            "llama_print_timings:        eval time =    1513.73 ms /    15 runs   (  100.92 ms per token,     9.91 tokens per second)\n",
            "llama_print_timings:       total time =    1964.50 ms /    77 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Most women runners are routinely harassed - or worse. Freedom if movement is a basic human right. This right is regularly denied to women when we are bullied into feeling unsafe on the streets.  https://t.co/5JvMWGrJNt\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.72 ms /    16 runs   (    0.73 ms per token,  1365.07 tokens per second)\n",
            "llama_print_timings: prompt eval time =     252.39 ms /    47 tokens (    5.37 ms per token,   186.22 tokens per second)\n",
            "llama_print_timings:        eval time =    1848.28 ms /    15 runs   (  123.22 ms per token,     8.12 tokens per second)\n",
            "llama_print_timings:       total time =    2409.96 ms /    62 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "When a person who bullied you for calling out the shady behaviors of the EDM and festival culture posts this on Day 2. https://t.co/sCfkc4e9DD\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.55 ms /    16 runs   (    0.53 ms per token,  1870.25 tokens per second)\n",
            "llama_print_timings: prompt eval time =     254.38 ms /    34 tokens (    7.48 ms per token,   133.66 tokens per second)\n",
            "llama_print_timings:        eval time =    1577.27 ms /    15 runs   (  105.15 ms per token,     9.51 tokens per second)\n",
            "llama_print_timings:       total time =    1970.08 ms /    49 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Call me sexist but every time I look up cooking vids on YouTube, I only click when it’s a woman not a man.\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.38 ms /    16 runs   (    0.52 ms per token,  1908.85 tokens per second)\n",
            "llama_print_timings: prompt eval time =     674.71 ms /    28 tokens (   24.10 ms per token,    41.50 tokens per second)\n",
            "llama_print_timings:        eval time =    1474.33 ms /    15 runs   (   98.29 ms per token,    10.17 tokens per second)\n",
            "llama_print_timings:       total time =    2274.51 ms /    43 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Call me sexist but girl yanderes are clingy and annoying but boy yanderes are cute and just love you so much\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.86 ms /    16 runs   (    0.55 ms per token,  1806.68 tokens per second)\n",
            "llama_print_timings: prompt eval time =     578.35 ms /    24 tokens (   24.10 ms per token,    41.50 tokens per second)\n",
            "llama_print_timings:        eval time =    1564.15 ms /    15 runs   (  104.28 ms per token,     9.59 tokens per second)\n",
            "llama_print_timings:       total time =    2257.14 ms /    39 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Call me sexist but 95% of millennial and gen z women are a threat to public safety while driving\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.42 ms /    16 runs   (    0.65 ms per token,  1535.80 tokens per second)\n",
            "llama_print_timings: prompt eval time =     692.60 ms /    28 tokens (   24.74 ms per token,    40.43 tokens per second)\n",
            "llama_print_timings:        eval time =    1827.69 ms /    15 runs   (  121.85 ms per token,     8.21 tokens per second)\n",
            "llama_print_timings:       total time =    2674.04 ms /    43 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@AltonMaine @murdockspov You call me sexist but you are simply ignorant and dangerous\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.70 ms /    16 runs   (    0.54 ms per token,  1838.45 tokens per second)\n",
            "llama_print_timings: prompt eval time =     536.88 ms /    18 tokens (   29.83 ms per token,    33.53 tokens per second)\n",
            "llama_print_timings:        eval time =    1460.97 ms /    15 runs   (   97.40 ms per token,    10.27 tokens per second)\n",
            "llama_print_timings:       total time =    2104.37 ms /    33 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "call me sexist but why do straight men sneeze so loud\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.69 ms /    16 runs   (    0.61 ms per token,  1652.04 tokens per second)\n",
            "llama_print_timings: prompt eval time =     268.89 ms /    86 tokens (    3.13 ms per token,   319.83 tokens per second)\n",
            "llama_print_timings:        eval time =    1526.37 ms /    15 runs   (  101.76 ms per token,     9.83 tokens per second)\n",
            "llama_print_timings:       total time =    2035.27 ms /   101 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@HeatherIsAuDHD It's incredible to me that we say we value children when we very literally and obviously do not. And people call me sexist but my dad stayed home with me for the first five years and he paid the same unjust tax you and I did. I feel like I'm screaming underwater about this.😵‍💫\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.36 ms /    16 runs   (    0.58 ms per token,  1709.58 tokens per second)\n",
            "llama_print_timings: prompt eval time =     259.90 ms /    74 tokens (    3.51 ms per token,   284.72 tokens per second)\n",
            "llama_print_timings:        eval time =    1518.27 ms /    15 runs   (  101.22 ms per token,     9.88 tokens per second)\n",
            "llama_print_timings:       total time =    1991.67 ms /    89 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@LexiTalksComix All I said was that this ep was ok, only problems I had was the fast pasting and hit or miss jokes that didn't land for me, and yall call me sexist for that? Like seriously this is the type of stuff that be breaking my heart man💔.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.58 ms /    16 runs   (    0.60 ms per token,  1670.67 tokens per second)\n",
            "llama_print_timings: prompt eval time =     238.03 ms /    46 tokens (    5.17 ms per token,   193.25 tokens per second)\n",
            "llama_print_timings:        eval time =    1572.90 ms /    15 runs   (  104.86 ms per token,     9.54 tokens per second)\n",
            "llama_print_timings:       total time =    1982.56 ms /    61 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@eatshopdoatl Bahahaha since you can’t call me racist you call me sexist. And let me guess BLACK PEOPLE CANT BE RACIST 😂🤡\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.88 ms /    16 runs   (    0.68 ms per token,  1470.32 tokens per second)\n",
            "llama_print_timings: prompt eval time =     298.04 ms /    98 tokens (    3.04 ms per token,   328.82 tokens per second)\n",
            "llama_print_timings:        eval time =    1665.23 ms /    15 runs   (  111.02 ms per token,     9.01 tokens per second)\n",
            "llama_print_timings:       total time =    2397.50 ms /   113 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "the most recent episode of #SheHulk really sums up modern dating, so kudos to the writing. some women need to get over the stigma of the 'double-text'. dont stress out, just send another. most dudes like it. shows interest... imo(pls dont call me sexist in the replies 👉👈 lol) https://t.co/e5IdtdFiG8\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.39 ms /    16 runs   (    0.52 ms per token,  1907.94 tokens per second)\n",
            "llama_print_timings: prompt eval time =     563.59 ms /    22 tokens (   25.62 ms per token,    39.04 tokens per second)\n",
            "llama_print_timings:        eval time =    1570.73 ms /    15 runs   (  104.72 ms per token,     9.55 tokens per second)\n",
            "llama_print_timings:       total time =    2244.57 ms /    37 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Don't call me sexistI ve never had sex in my entire life.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.96 ms /    16 runs   (    0.62 ms per token,  1605.78 tokens per second)\n",
            "llama_print_timings: prompt eval time =     265.00 ms /    81 tokens (    3.27 ms per token,   305.66 tokens per second)\n",
            "llama_print_timings:        eval time =    1509.32 ms /    15 runs   (  100.62 ms per token,     9.94 tokens per second)\n",
            "llama_print_timings:       total time =    2011.55 ms /    96 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "This is the exact reason I would NEVER let my daughter engage in these groups. These cheer that plaster make-up on kids and pre-teens for competition has always been suspect…. Call me sexist if you want but I’ve always had the feeling something was always up w/ these teams.. https://t.co/4FIcCGAr91\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.34 ms /    16 runs   (    0.58 ms per token,  1713.25 tokens per second)\n",
            "llama_print_timings: prompt eval time =     274.69 ms /    98 tokens (    2.80 ms per token,   356.77 tokens per second)\n",
            "llama_print_timings:        eval time =    1476.67 ms /    15 runs   (   98.44 ms per token,    10.16 tokens per second)\n",
            "llama_print_timings:       total time =    2017.06 ms /   113 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@DanielElements @ohsnapitysnapz @EASPORTSNHL @nursey16 It's super ignorant to actually think high level woman players are even close too NHL players. She is a 90 overall for sure... compared to other women. But on an even coed scale... she's realistically a 40? But the only people who will call me sexist or whatever never played🤷‍♂️\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.01 ms /    16 runs   (    0.69 ms per token,  1452.96 tokens per second)\n",
            "llama_print_timings: prompt eval time =     242.45 ms /    41 tokens (    5.91 ms per token,   169.11 tokens per second)\n",
            "llama_print_timings:        eval time =    1757.20 ms /    15 runs   (  117.15 ms per token,     8.54 tokens per second)\n",
            "llama_print_timings:       total time =    2258.58 ms /    56 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@myybelovd @quackupdates ONLY LORE CAN TAKE THIS FROM ME AND EVEN THEN MY HEADCANON IS CANON FOR ME\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.48 ms /    16 runs   (    0.59 ms per token,  1687.05 tokens per second)\n",
            "llama_print_timings: prompt eval time =     264.39 ms /    78 tokens (    3.39 ms per token,   295.02 tokens per second)\n",
            "llama_print_timings:        eval time =    1449.99 ms /    15 runs   (   96.67 ms per token,    10.34 tokens per second)\n",
            "llama_print_timings:       total time =    1934.09 ms /    93 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@simonmacmichael I spent £350 on a Canon 35mm SLR as digital cameras were getting better but \"not good enough yet\" as I think the feelings were at the time.When I finally ditched it about 2 years after getting my first DSLR, I remember feeling lucky to get £5 for it!\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.35 ms /    16 runs   (    0.58 ms per token,  1711.41 tokens per second)\n",
            "llama_print_timings: prompt eval time =     260.60 ms /    69 tokens (    3.78 ms per token,   264.77 tokens per second)\n",
            "llama_print_timings:        eval time =    1636.32 ms /    15 runs   (  109.09 ms per token,     9.17 tokens per second)\n",
            "llama_print_timings:       total time =    2102.34 ms /    84 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@EdeBorrett She was burned by the English, having been held as a political prisoner in an English jail with a large number of English soldiers surrounding her, against all precepts of canon law, under the judgment of the king of England's councellor and Bedford's henchman.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.63 ms /    16 runs   (    0.60 ms per token,  1661.47 tokens per second)\n",
            "llama_print_timings: prompt eval time =     244.45 ms /    49 tokens (    4.99 ms per token,   200.45 tokens per second)\n",
            "llama_print_timings:        eval time =    1517.49 ms /    15 runs   (  101.17 ms per token,     9.88 tokens per second)\n",
            "llama_print_timings:       total time =    1943.74 ms /    64 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@garlander3 If there is it won’t be canon with mine or Melkors universe. But there is a type of crossover happening very soon before the comics resume so keep an eye out\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.97 ms /    16 runs   (    0.62 ms per token,  1605.46 tokens per second)\n",
            "llama_print_timings: prompt eval time =     540.01 ms /    32 tokens (   16.88 ms per token,    59.26 tokens per second)\n",
            "llama_print_timings:        eval time =    1745.48 ms /    15 runs   (  116.37 ms per token,     8.59 tokens per second)\n",
            "llama_print_timings:       total time =    2443.63 ms /    47 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Sorry, just rereading canon material atm and all the bad takes I've suffered with for years are just surfacing again.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.40 ms /    16 runs   (    0.59 ms per token,  1701.22 tokens per second)\n",
            "llama_print_timings: prompt eval time =     268.18 ms /    64 tokens (    4.19 ms per token,   238.65 tokens per second)\n",
            "llama_print_timings:        eval time =    1556.37 ms /    15 runs   (  103.76 ms per token,     9.64 tokens per second)\n",
            "llama_print_timings:       total time =    2134.51 ms /    79 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "send me some femblem guys i’ll do this when i get off work…1. my favorite canon ending for them2. my favorite non-canon ship for them3. my favorite support chain with them4. a character I wish they had gotten supports with but didn’t\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.92 ms /    16 runs   (    0.62 ms per token,  1612.90 tokens per second)\n",
            "llama_print_timings: prompt eval time =     266.25 ms /    82 tokens (    3.25 ms per token,   307.98 tokens per second)\n",
            "llama_print_timings:        eval time =    1500.55 ms /    15 runs   (  100.04 ms per token,    10.00 tokens per second)\n",
            "llama_print_timings:       total time =    2001.60 ms /    97 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@hullhopper @RachelG21879460 @fkcream @Otto_English I shall find it and enjoy it as an antidote to BBC #WATO which I switched off early three times this week. The sycophantic mewling turned my stomach. They're virtually calling for his canonization.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.94 ms /    16 runs   (    0.62 ms per token,  1609.01 tokens per second)\n",
            "llama_print_timings: prompt eval time =     257.45 ms /    58 tokens (    4.44 ms per token,   225.28 tokens per second)\n",
            "llama_print_timings:        eval time =    1467.67 ms /    15 runs   (   97.84 ms per token,    10.22 tokens per second)\n",
            "llama_print_timings:       total time =    1915.99 ms /    73 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "“Now with her canonization coming up, we feel that Staten Island—along with the rest of the world—is much in need of the Catholic Worker movement.” https://t.co/gybdTybyGA via @americamag\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.96 ms /    16 runs   (    0.56 ms per token,  1784.72 tokens per second)\n",
            "llama_print_timings: prompt eval time =     268.47 ms /    80 tokens (    3.36 ms per token,   297.99 tokens per second)\n",
            "llama_print_timings:        eval time =    1632.61 ms /    15 runs   (  108.84 ms per token,     9.19 tokens per second)\n",
            "llama_print_timings:       total time =    2148.17 ms /    95 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@GregoryPalamas @WasLuther @MedWhiteAcolyte Be careful here. The distinction between Essence and Energy is *not* real. St Philotheos Kokkinos, the man responsible for pushing for St Gregory Palamas' canonization and a student of his, says the E/E distinction is conceptual and not real.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.82 ms /    16 runs   (    0.74 ms per token,  1353.41 tokens per second)\n",
            "llama_print_timings: prompt eval time =     297.20 ms /    77 tokens (    3.86 ms per token,   259.09 tokens per second)\n",
            "llama_print_timings:        eval time =    1735.90 ms /    15 runs   (  115.73 ms per token,     8.64 tokens per second)\n",
            "llama_print_timings:       total time =    2420.30 ms /    92 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "\"It is this statement, from a Vatican theologian ..... that tells us everything we need to know about an increasingly out-of-touch Vatican bureaucracy that seems to be attempting to destroy everything that is good and true in the Church—and beyond.\" https://t.co/CP70Utd8lX\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.32 ms /    16 runs   (    0.58 ms per token,  1717.11 tokens per second)\n",
            "llama_print_timings: prompt eval time =     271.16 ms /    85 tokens (    3.19 ms per token,   313.47 tokens per second)\n",
            "llama_print_timings:        eval time =    1550.03 ms /    15 runs   (  103.34 ms per token,     9.68 tokens per second)\n",
            "llama_print_timings:       total time =    2053.15 ms /   100 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@beginnercathol1 @TheNigerianTrad @FlatCath And before the canonization of Saint Galgano the process arose much the same way that Sheen's has: folk Catholicism and a local cult. Sheen's miracle is not to be taken lightly and every Saint was once a regular, flawed person (except Mary, of course)\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.14 ms /    16 runs   (    0.63 ms per token,  1577.91 tokens per second)\n",
            "llama_print_timings: prompt eval time =     294.08 ms /   115 tokens (    2.56 ms per token,   391.04 tokens per second)\n",
            "llama_print_timings:        eval time =    1534.22 ms /    15 runs   (  102.28 ms per token,     9.78 tokens per second)\n",
            "llama_print_timings:       total time =    2144.85 ms /   130 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@rcurry95 @Giovann73764108 @geostylegeo No it is NOT a \"fact\" that Athanasius \"compiled the Bible\" in 367 AD. Ratger, he set the Canon FOR THE DIOCESE OF ALEXANDRIA ONLY in 367 AD.It is also a fact that the Canonization process began centuries BEFORE Nicaea &amp; wasn't complete until well into the 5th Century\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.03 ms /    16 runs   (    0.63 ms per token,  1596.01 tokens per second)\n",
            "llama_print_timings: prompt eval time =     247.60 ms /    50 tokens (    4.95 ms per token,   201.94 tokens per second)\n",
            "llama_print_timings:        eval time =    1592.02 ms /    15 runs   (  106.13 ms per token,     9.42 tokens per second)\n",
            "llama_print_timings:       total time =    2016.94 ms /    65 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@mythomorphosis Wish you would’ve mentioned the Mayan influence on the modern day breach cloth, the tan-ta-rans: https://t.co/g3UB6cZmdK\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.17 ms /    16 runs   (    0.70 ms per token,  1432.66 tokens per second)\n",
            "llama_print_timings: prompt eval time =     248.12 ms /    59 tokens (    4.21 ms per token,   237.79 tokens per second)\n",
            "llama_print_timings:        eval time =    1884.23 ms /    15 runs   (  125.62 ms per token,     7.96 tokens per second)\n",
            "llama_print_timings:       total time =    2411.61 ms /    74 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@DashDobrofsky Hillary Clinton Jokes About Wiping Email Server 'With A Cloth Or Something'Clinton jokes about her private email server she used as secretary of state.https://t.co/5qajvxlo1j\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.83 ms /    16 runs   (    0.55 ms per token,  1811.18 tokens per second)\n",
            "llama_print_timings: prompt eval time =     530.53 ms /    19 tokens (   27.92 ms per token,    35.81 tokens per second)\n",
            "llama_print_timings:        eval time =    1633.26 ms /    15 runs   (  108.88 ms per token,     9.18 tokens per second)\n",
            "llama_print_timings:       total time =    2266.41 ms /    34 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "By now GTP is busy designing a funeral cloth dendeeenden\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.79 ms /    16 runs   (    0.55 ms per token,  1819.42 tokens per second)\n",
            "llama_print_timings: prompt eval time =     257.92 ms /    66 tokens (    3.91 ms per token,   255.90 tokens per second)\n",
            "llama_print_timings:        eval time =    1515.07 ms /    15 runs   (  101.00 ms per token,     9.90 tokens per second)\n",
            "llama_print_timings:       total time =    1971.10 ms /    81 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@RepMeuser @HouseGOP Did Biden just drop them off a few miles from anywhere? Did he lure them onto a plane with false promises?  Are they working as their advocates?  Did they abandon them? Did they feed them? Did they cloth them?WWJD\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.33 ms /    16 runs   (    0.58 ms per token,  1715.45 tokens per second)\n",
            "llama_print_timings: prompt eval time =     261.99 ms /    77 tokens (    3.40 ms per token,   293.91 tokens per second)\n",
            "llama_print_timings:        eval time =    1591.99 ms /    15 runs   (  106.13 ms per token,     9.42 tokens per second)\n",
            "llama_print_timings:       total time =    2077.83 ms /    92 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@ClaudetteGGibs1 He looks exactly like a little Nazi.  He and Stephen Miller are both cut from Nazi cloth.  He is also the guy that let the “Kooks” into the White House on the eve of the 1/6 Insurrection according to Pat Cipollone, his White House Counsel.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.92 ms /    16 runs   (    0.62 ms per token,  1613.23 tokens per second)\n",
            "llama_print_timings: prompt eval time =     286.16 ms /   114 tokens (    2.51 ms per token,   398.38 tokens per second)\n",
            "llama_print_timings:        eval time =    1764.71 ms /    15 runs   (  117.65 ms per token,     8.50 tokens per second)\n",
            "llama_print_timings:       total time =    2369.97 ms /   129 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Great MPG!!! 2004 Hyundai Elantra, ONLY 99,300 miles, automatic, climate control, cloth interior, power windows &amp; locks. No rust! Great affordable transportation at $3,995. Call 507-430-2200 or visit: https://t.co/2SKVQEscvG#hyundai #mpg https://t.co/dtIg9uKaB9\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.71 ms /    16 runs   (    0.61 ms per token,  1647.79 tokens per second)\n",
            "llama_print_timings: prompt eval time =     593.89 ms /    32 tokens (   18.56 ms per token,    53.88 tokens per second)\n",
            "llama_print_timings:        eval time =    1427.14 ms /    15 runs   (   95.14 ms per token,    10.51 tokens per second)\n",
            "llama_print_timings:       total time =    2219.52 ms /    47 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "note to self: don’t go to a strip club with your older overprotective cousin, she will in fact cock block\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.57 ms /    16 runs   (    0.54 ms per token,  1866.11 tokens per second)\n",
            "llama_print_timings: prompt eval time =     237.59 ms /    40 tokens (    5.94 ms per token,   168.35 tokens per second)\n",
            "llama_print_timings:        eval time =    1519.49 ms /    15 runs   (  101.30 ms per token,     9.87 tokens per second)\n",
            "llama_print_timings:       total time =    1906.45 ms /    55 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Cdrumm5448 @Da_Nasty_Man @DanieruSan3 @TheAngelKing47 You prolly cock block yourself\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.10 ms /    16 runs   (    0.57 ms per token,  1759.01 tokens per second)\n",
            "llama_print_timings: prompt eval time =     246.23 ms /    48 tokens (    5.13 ms per token,   194.94 tokens per second)\n",
            "llama_print_timings:        eval time =    1537.70 ms /    15 runs   (  102.51 ms per token,     9.75 tokens per second)\n",
            "llama_print_timings:       total time =    1961.74 ms /    63 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "No matter how many girls my parents point out to. I will always refuse to spit game in front of them. Simply because my mom would cock block tf out of me, and my father would make it awkward\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.59 ms /    16 runs   (    0.54 ms per token,  1863.28 tokens per second)\n",
            "llama_print_timings: prompt eval time =     237.31 ms /    39 tokens (    6.08 ms per token,   164.34 tokens per second)\n",
            "llama_print_timings:        eval time =    1524.55 ms /    15 runs   (  101.64 ms per token,     9.84 tokens per second)\n",
            "llama_print_timings:       total time =    1916.89 ms /    54 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "this court date on the 27th is the biggest cock block of my LIFE. i would be golden for lost lands if i didn’t 😭\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      12.05 ms /    16 runs   (    0.75 ms per token,  1327.58 tokens per second)\n",
            "llama_print_timings: prompt eval time =     265.99 ms /    66 tokens (    4.03 ms per token,   248.13 tokens per second)\n",
            "llama_print_timings:        eval time =    1868.08 ms /    15 runs   (  124.54 ms per token,     8.03 tokens per second)\n",
            "llama_print_timings:       total time =    2477.51 ms /    81 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@BigDefi @GymRatsNFT were only available in holoplex and then digital eyes, talk about OG. There were like 5 projects to choose from at time, and it turns out the cool kids tried to cock block the project bc they knew you had something special.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.39 ms /    16 runs   (    0.59 ms per token,  1703.58 tokens per second)\n",
            "llama_print_timings: prompt eval time =     264.38 ms /    51 tokens (    5.18 ms per token,   192.90 tokens per second)\n",
            "llama_print_timings:        eval time =    1543.64 ms /    15 runs   (  102.91 ms per token,     9.72 tokens per second)\n",
            "llama_print_timings:       total time =    1982.65 ms /    66 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@LoadingCrew @craftinghamster I always cock block my own sex dreams. Like it will just be about to get good and dream me goes “I can’t do this 😭” and I wake up PISSED\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.10 ms /    16 runs   (    0.57 ms per token,  1757.47 tokens per second)\n",
            "llama_print_timings: prompt eval time =     235.94 ms /    37 tokens (    6.38 ms per token,   156.82 tokens per second)\n",
            "llama_print_timings:        eval time =    1590.23 ms /    15 runs   (  106.02 ms per token,     9.43 tokens per second)\n",
            "llama_print_timings:       total time =    1975.53 ms /    52 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Redjay16901435 @RichardBSpencer She's not gonna date anybody, she is on the cock carousel\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.04 ms /    16 runs   (    0.57 ms per token,  1769.13 tokens per second)\n",
            "llama_print_timings: prompt eval time =     687.81 ms /    25 tokens (   27.51 ms per token,    36.35 tokens per second)\n",
            "llama_print_timings:        eval time =    1529.28 ms /    15 runs   (  101.95 ms per token,     9.81 tokens per second)\n",
            "llama_print_timings:       total time =    2336.37 ms /    40 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@ask_aubry Separately, where do I buy tickets for the cock carousel?\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.85 ms /    16 runs   (    0.68 ms per token,  1475.33 tokens per second)\n",
            "llama_print_timings: prompt eval time =     239.00 ms /    41 tokens (    5.83 ms per token,   171.55 tokens per second)\n",
            "llama_print_timings:        eval time =    1759.12 ms /    15 runs   (  117.28 ms per token,     8.53 tokens per second)\n",
            "llama_print_timings:       total time =    2175.78 ms /    56 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@ask_aubry 🎶Mom rode the cock carousel, and it did not end well.Thanks to Mom's hormones, baby, I was born this way.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.13 ms /    16 runs   (    0.57 ms per token,  1753.04 tokens per second)\n",
            "llama_print_timings: prompt eval time =     264.72 ms /    40 tokens (    6.62 ms per token,   151.10 tokens per second)\n",
            "llama_print_timings:        eval time =    1501.47 ms /    15 runs   (  100.10 ms per token,     9.99 tokens per second)\n",
            "llama_print_timings:       total time =    2006.29 ms /    55 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@ask_aubry 3...2...1 until a mention of The Cock Carousel these chodes always bring up. https://t.co/lDubvIMYFx\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.86 ms /    16 runs   (    0.55 ms per token,  1806.68 tokens per second)\n",
            "llama_print_timings: prompt eval time =     245.83 ms /    56 tokens (    4.39 ms per token,   227.80 tokens per second)\n",
            "llama_print_timings:        eval time =    1575.89 ms /    15 runs   (  105.06 ms per token,     9.52 tokens per second)\n",
            "llama_print_timings:       total time =    2014.07 ms /    71 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Forget her bro, it's time to move on. She's riding the cock carousel now. She's screaming on the cock coaster. She's buying cocken candy from the cockcession stand. It's over\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.77 ms /    16 runs   (    0.61 ms per token,  1637.50 tokens per second)\n",
            "llama_print_timings: prompt eval time =     279.58 ms /    84 tokens (    3.33 ms per token,   300.45 tokens per second)\n",
            "llama_print_timings:        eval time =    1480.30 ms /    15 runs   (   98.69 ms per token,    10.13 tokens per second)\n",
            "llama_print_timings:       total time =    1990.97 ms /    99 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "(8) After being on the cock carousel in her 20's, what are the chances of her having an STD?(9) If a man is stupid enough to marry a 30+ year old modern woman, she will divorce him within 5 years and take half of his resources, take the kids, he has to pay alimony/child support.\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.04 ms /    16 runs   (    0.56 ms per token,  1770.30 tokens per second)\n",
            "llama_print_timings: prompt eval time =     656.92 ms /    26 tokens (   25.27 ms per token,    39.58 tokens per second)\n",
            "llama_print_timings:        eval time =    1682.59 ms /    15 runs   (  112.17 ms per token,     8.91 tokens per second)\n",
            "llama_print_timings:       total time =    2460.33 ms /    41 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@AlmKornKid Besides being a cock tease she’s one of my favorite characters\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.31 ms /    16 runs   (    0.64 ms per token,  1551.44 tokens per second)\n",
            "llama_print_timings: prompt eval time =     909.28 ms /    29 tokens (   31.35 ms per token,    31.89 tokens per second)\n",
            "llama_print_timings:        eval time =    1616.94 ms /    15 runs   (  107.80 ms per token,     9.28 tokens per second)\n",
            "llama_print_timings:       total time =    2716.20 ms /    44 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "how you cock tease without making it sexual https://t.co/9Uye8dQWwH\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.18 ms /    16 runs   (    0.57 ms per token,  1742.73 tokens per second)\n",
            "llama_print_timings: prompt eval time =     297.51 ms /   121 tokens (    2.46 ms per token,   406.71 tokens per second)\n",
            "llama_print_timings:        eval time =    1518.42 ms /    15 runs   (  101.23 ms per token,     9.88 tokens per second)\n",
            "llama_print_timings:       total time =    2155.98 ms /   136 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "We are going to try and cum together, at the same time!Cock Tease 10: I'm Cumming Overhttps://t.co/Oe0G9sEBEThttps://t.co/fP3uLkm64Qhttps://t.co/gh15zvLnv5Follow@cum4jenhttps://t.co/lgrRopAdgA#cumslut #camgirlِ #cocktease https://t.co/mi5TSFHOLO\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.97 ms /    16 runs   (    0.56 ms per token,  1784.12 tokens per second)\n",
            "llama_print_timings: prompt eval time =     240.56 ms /    46 tokens (    5.23 ms per token,   191.22 tokens per second)\n",
            "llama_print_timings:        eval time =    1645.01 ms /    15 runs   (  109.67 ms per token,     9.12 tokens per second)\n",
            "llama_print_timings:       total time =    2056.81 ms /    61 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@spiderlou2099 No such thing as a cock tease, anyone is welcome to say no at anytime for any reason, a tease is only a result of someone assuming something\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.00 ms /    16 runs   (    0.56 ms per token,  1777.78 tokens per second)\n",
            "llama_print_timings: prompt eval time =     238.58 ms /    35 tokens (    6.82 ms per token,   146.70 tokens per second)\n",
            "llama_print_timings:        eval time =    1579.56 ms /    15 runs   (  105.30 ms per token,     9.50 tokens per second)\n",
            "llama_print_timings:       total time =    1970.08 ms /    50 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@chamibii Look. You know I'm horny for cock tease trans guys domming their bara-esque boyfriends.\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.53 ms /    16 runs   (    0.66 ms per token,  1519.04 tokens per second)\n",
            "llama_print_timings: prompt eval time =     978.74 ms /    30 tokens (   32.62 ms per token,    30.65 tokens per second)\n",
            "llama_print_timings:        eval time =    1849.48 ms /    15 runs   (  123.30 ms per token,     8.11 tokens per second)\n",
            "llama_print_timings:       total time =    3034.52 ms /    45 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@LouiseWackett1 @Vroom101 Like a cock tease. But on the Internet I guess.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.59 ms /    16 runs   (    0.60 ms per token,  1667.71 tokens per second)\n",
            "llama_print_timings: prompt eval time =     270.98 ms /    69 tokens (    3.93 ms per token,   254.63 tokens per second)\n",
            "llama_print_timings:        eval time =    1531.16 ms /    15 runs   (  102.08 ms per token,     9.80 tokens per second)\n",
            "llama_print_timings:       total time =    2005.81 ms /    84 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@ScottRogowsky How about the SpongeBob “ugly” holiday sweater?  I looked for it for quite some time for my daughter but could never find it in stock anywhere.  Name your price! (Not really…that just sounded like a cool closing comment in my head)\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.36 ms /    16 runs   (    0.52 ms per token,  1915.02 tokens per second)\n",
            "llama_print_timings: prompt eval time =     753.55 ms /    31 tokens (   24.31 ms per token,    41.14 tokens per second)\n",
            "llama_print_timings:        eval time =    1531.98 ms /    15 runs   (  102.13 ms per token,     9.79 tokens per second)\n",
            "llama_print_timings:       total time =    2413.44 ms /    46 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@2Generalrusty78 @lefteagle510121 @videotech_ Still a dumb comment\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.33 ms /    16 runs   (    0.58 ms per token,  1715.08 tokens per second)\n",
            "llama_print_timings: prompt eval time =     253.69 ms /    66 tokens (    3.84 ms per token,   260.15 tokens per second)\n",
            "llama_print_timings:        eval time =    1561.88 ms /    15 runs   (  104.13 ms per token,     9.60 tokens per second)\n",
            "llama_print_timings:       total time =    2015.64 ms /    81 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@FawningStag @ReduxxMag I just weighed in on an ongoing global issue. I've got Canadians trying to protest and influence laws in my own country. I simply replied to a comment in a PUBLIC forum. You're the one bent out of shape.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      12.53 ms /    16 runs   (    0.78 ms per token,  1276.63 tokens per second)\n",
            "llama_print_timings: prompt eval time =     267.36 ms /    74 tokens (    3.61 ms per token,   276.78 tokens per second)\n",
            "llama_print_timings:        eval time =    1822.25 ms /    15 runs   (  121.48 ms per token,     8.23 tokens per second)\n",
            "llama_print_timings:       total time =    2370.74 ms /    89 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "BRENDAN V MIKE | SEMI-FINALS (Brendan !! Championship Tournament) https://t.co/ZTsWYo5bd0 via @YouTubeMe v Mike Moreland! Crazy match! Please go watch, like, SHARE, comment, and find out who wins!!!!\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.99 ms /    16 runs   (    0.56 ms per token,  1779.16 tokens per second)\n",
            "llama_print_timings: prompt eval time =     252.97 ms /    49 tokens (    5.16 ms per token,   193.70 tokens per second)\n",
            "llama_print_timings:        eval time =    1572.90 ms /    15 runs   (  104.86 ms per token,     9.54 tokens per second)\n",
            "llama_print_timings:       total time =    1994.09 ms /    64 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@MStine_4 @Bentodd33 @77Testarossa That’s like me saying Baylor would of beaten you last year, see how Irrelevant of a comment that is\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.98 ms /    16 runs   (    0.56 ms per token,  1782.53 tokens per second)\n",
            "llama_print_timings: prompt eval time =     252.36 ms /    47 tokens (    5.37 ms per token,   186.24 tokens per second)\n",
            "llama_print_timings:        eval time =    1563.45 ms /    15 runs   (  104.23 ms per token,     9.59 tokens per second)\n",
            "llama_print_timings:       total time =    1979.01 ms /    62 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@JackBenjaminz @mikelord821 My comment on @TheDoctorGamble tweet needs the 1000 RTs, the comment I Quote Tweeted\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.77 ms /    16 runs   (    0.61 ms per token,  1638.34 tokens per second)\n",
            "llama_print_timings: prompt eval time =     262.68 ms /    73 tokens (    3.60 ms per token,   277.91 tokens per second)\n",
            "llama_print_timings:        eval time =    1514.08 ms /    15 runs   (  100.94 ms per token,     9.91 tokens per second)\n",
            "llama_print_timings:       total time =    1988.88 ms /    88 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Our final Annual Research Showcase post, a reflection by @gabrielaslou on her research into feminism, hashtags and digital consciousness-raising in Brazil, is up on the blog now! ✍️Read it here 👉https://t.co/KVnIHr9tyl\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.87 ms /    16 runs   (    0.62 ms per token,  1621.24 tokens per second)\n",
            "llama_print_timings: prompt eval time =     273.89 ms /    93 tokens (    2.95 ms per token,   339.55 tokens per second)\n",
            "llama_print_timings:        eval time =    1518.61 ms /    15 runs   (  101.24 ms per token,     9.88 tokens per second)\n",
            "llama_print_timings:       total time =    2057.54 ms /   108 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "\"My hope is that we don’t abandon the consciousness-raising and shift [back] to the mentality that everyone has to figure it out for themselves.” What, then, can employers do to resist the backslide? @colleenammerman &amp; @callumborchers discuss. #FD1Conference #FD1JulyVirtual https://t.co/dRJmGzPEpi\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.94 ms /    16 runs   (    0.62 ms per token,  1609.01 tokens per second)\n",
            "llama_print_timings: prompt eval time =     259.56 ms /    39 tokens (    6.66 ms per token,   150.26 tokens per second)\n",
            "llama_print_timings:        eval time =    1630.60 ms /    15 runs   (  108.71 ms per token,     9.20 tokens per second)\n",
            "llama_print_timings:       total time =    2119.26 ms /    54 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@WadeMiller_USMC I remember \"consciousness raising\" at university in the 70s. Same thing. Also Marxists at bottom though.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.09 ms /    16 runs   (    0.63 ms per token,  1586.04 tokens per second)\n",
            "llama_print_timings: prompt eval time =     272.54 ms /    84 tokens (    3.24 ms per token,   308.22 tokens per second)\n",
            "llama_print_timings:        eval time =    1523.43 ms /    15 runs   (  101.56 ms per token,     9.85 tokens per second)\n",
            "llama_print_timings:       total time =    2032.25 ms /    99 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "\"A consciousness-raising play about homophobic persecution, racism within the gay community and Britain’s hostile asylum system.\"Great review for @Waleedakhtar's The P Word @bushtheatre until OctNot religious per se but explores humanity &amp; connectionshttps://t.co/WYtyCfzxT9\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.82 ms /    16 runs   (    0.61 ms per token,  1628.83 tokens per second)\n",
            "llama_print_timings: prompt eval time =     269.13 ms /    84 tokens (    3.20 ms per token,   312.12 tokens per second)\n",
            "llama_print_timings:        eval time =    1615.98 ms /    15 runs   (  107.73 ms per token,     9.28 tokens per second)\n",
            "llama_print_timings:       total time =    2126.69 ms /    99 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Alongside the DNC/NeoLiberal Establishment’s 2012 political decision to begin actively demonizing, demoralizing, and running against males was the strategy to radicalize females with relentless catastrophism, misandry, and Marxist “consciousness raising.” https://t.co/vob4LPqLA1\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.78 ms /    16 runs   (    0.55 ms per token,  1821.91 tokens per second)\n",
            "llama_print_timings: prompt eval time =     238.49 ms /    33 tokens (    7.23 ms per token,   138.37 tokens per second)\n",
            "llama_print_timings:        eval time =    1668.29 ms /    15 runs   (  111.22 ms per token,     8.99 tokens per second)\n",
            "llama_print_timings:       total time =    2046.10 ms /    48 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@mg_xiong Gonna see if I can do a little consciousness raising! And hi! Hope you’re doing ok…\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      12.07 ms /    16 runs   (    0.75 ms per token,  1326.04 tokens per second)\n",
            "llama_print_timings: prompt eval time =     258.29 ms /    52 tokens (    4.97 ms per token,   201.32 tokens per second)\n",
            "llama_print_timings:        eval time =    1905.88 ms /    15 runs   (  127.06 ms per token,     7.87 tokens per second)\n",
            "llama_print_timings:       total time =    2469.35 ms /    67 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Bi Mswafari alisema your house help should never cook for your husband,wash or iron his clothes or even open the door for https://t.co/IHHq8Rgz5N you agree?\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.04 ms /    16 runs   (    0.57 ms per token,  1769.13 tokens per second)\n",
            "llama_print_timings: prompt eval time =     246.40 ms /    36 tokens (    6.84 ms per token,   146.10 tokens per second)\n",
            "llama_print_timings:        eval time =    1638.19 ms /    15 runs   (  109.21 ms per token,     9.16 tokens per second)\n",
            "llama_print_timings:       total time =    2028.88 ms /    51 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "You can’t cook for your husband ?Na why our old daddies say women no suppose Dey go school they only belong to the kitchen.\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.84 ms /    16 runs   (    0.55 ms per token,  1809.95 tokens per second)\n",
            "llama_print_timings: prompt eval time =     588.74 ms /    23 tokens (   25.60 ms per token,    39.07 tokens per second)\n",
            "llama_print_timings:        eval time =    1488.07 ms /    15 runs   (   99.20 ms per token,    10.08 tokens per second)\n",
            "llama_print_timings:       total time =    2193.15 ms /    38 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@itscarmeeen No but it would be nice to cook for your husband sometimes.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.85 ms /    16 runs   (    0.55 ms per token,  1808.52 tokens per second)\n",
            "llama_print_timings: prompt eval time =     558.85 ms /    22 tokens (   25.40 ms per token,    39.37 tokens per second)\n",
            "llama_print_timings:        eval time =    1588.11 ms /    15 runs   (  105.87 ms per token,     9.45 tokens per second)\n",
            "llama_print_timings:       total time =    2258.48 ms /    37 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@iretiayo_queen Aunt go cook for your husband leave us alone😂\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.59 ms /    16 runs   (    0.66 ms per token,  1510.43 tokens per second)\n",
            "llama_print_timings: prompt eval time =     257.87 ms /    73 tokens (    3.53 ms per token,   283.09 tokens per second)\n",
            "llama_print_timings:        eval time =    1718.85 ms /    15 runs   (  114.59 ms per token,     8.73 tokens per second)\n",
            "llama_print_timings:       total time =    2211.91 ms /    88 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "\"Cook for your husband o, don’t you know that it's only food men know. A cook can snatch your husband o\".Shey he is waist that they are snatching, because of Pounded yam and egusi???😒😒😒\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.95 ms /    16 runs   (    0.56 ms per token,  1786.91 tokens per second)\n",
            "llama_print_timings: prompt eval time =     282.84 ms /    74 tokens (    3.82 ms per token,   261.63 tokens per second)\n",
            "llama_print_timings:        eval time =    1607.14 ms /    15 runs   (  107.14 ms per token,     9.33 tokens per second)\n",
            "llama_print_timings:       total time =    2215.63 ms /    89 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@GeorgeTakei I'd add in, \"but if you feel men should dictate to you what you can &amp; can not do with your body, then by all means stay home &amp; cook for your husband. Let his vote be your voice &amp; do not vote on your own behalf. I understand.\"\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.67 ms /    16 runs   (    0.54 ms per token,  1845.02 tokens per second)\n",
            "llama_print_timings: prompt eval time =     256.64 ms /    37 tokens (    6.94 ms per token,   144.17 tokens per second)\n",
            "llama_print_timings:        eval time =    1579.56 ms /    15 runs   (  105.30 ms per token,     9.50 tokens per second)\n",
            "llama_print_timings:       total time =    1979.38 ms /    52 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@inquirerdotnet @MAgerINQ You don't deserve any respect. Don't delude yourself. You're not respectable.\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.52 ms /    16 runs   (    0.60 ms per token,  1680.50 tokens per second)\n",
            "llama_print_timings: prompt eval time =     241.75 ms /    53 tokens (    4.56 ms per token,   219.23 tokens per second)\n",
            "llama_print_timings:        eval time =    1602.98 ms /    15 runs   (  106.87 ms per token,     9.36 tokens per second)\n",
            "llama_print_timings:       total time =    2026.42 ms /    68 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@laurenboebert Boeboe, what the fuck? Are you a snarky 15 year old? What the fuck did Colorado ever do to deserve you? Go take your husband to a bowling alley or something!\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.34 ms /    16 runs   (    0.65 ms per token,  1547.39 tokens per second)\n",
            "llama_print_timings: prompt eval time =     269.40 ms /    78 tokens (    3.45 ms per token,   289.54 tokens per second)\n",
            "llama_print_timings:        eval time =    1702.87 ms /    15 runs   (  113.52 ms per token,     8.81 tokens per second)\n",
            "llama_print_timings:       total time =    2203.66 ms /    93 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "She tired of him &amp; his shit🤣keep knocking sense into his head girl ion even condone bad behavior but he deserve every punch for making her look dumb all the time🤣this girl got him tatted I bet she is punching him tf up😌 https://t.co/3Tj8VU3jyq\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.10 ms /    16 runs   (    0.63 ms per token,  1583.53 tokens per second)\n",
            "llama_print_timings: prompt eval time =     258.16 ms /    35 tokens (    7.38 ms per token,   135.58 tokens per second)\n",
            "llama_print_timings:        eval time =    1709.21 ms /    15 runs   (  113.95 ms per token,     8.78 tokens per second)\n",
            "llama_print_timings:       total time =    2195.34 ms /    50 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@brsinmuffin HAHAHAHA 🤣 I think after all this time of you talking to me about him I deserve some rights...\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.14 ms /    16 runs   (    0.57 ms per token,  1749.59 tokens per second)\n",
            "llama_print_timings: prompt eval time =     241.59 ms /    47 tokens (    5.14 ms per token,   194.55 tokens per second)\n",
            "llama_print_timings:        eval time =    1543.72 ms /    15 runs   (  102.91 ms per token,     9.72 tokens per second)\n",
            "llama_print_timings:       total time =    1961.41 ms /    62 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "THE TRUTH UNTOLD LISTEDE YOKSA IKI ELIM YAKANIZDA OLUR TURKISH ARMY TTH DESERVE EVERYTHING\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.51 ms /    16 runs   (    0.53 ms per token,  1881.25 tokens per second)\n",
            "llama_print_timings: prompt eval time =     509.41 ms /    19 tokens (   26.81 ms per token,    37.30 tokens per second)\n",
            "llama_print_timings:        eval time =    1425.05 ms /    15 runs   (   95.00 ms per token,    10.53 tokens per second)\n",
            "llama_print_timings:       total time =    2040.16 ms /    34 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Good day today I deserve every shot I'm finna take.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.92 ms /    16 runs   (    0.56 ms per token,  1793.32 tokens per second)\n",
            "llama_print_timings: prompt eval time =     264.76 ms /    78 tokens (    3.39 ms per token,   294.61 tokens per second)\n",
            "llama_print_timings:        eval time =    1504.75 ms /    15 runs   (  100.32 ms per token,     9.97 tokens per second)\n",
            "llama_print_timings:       total time =    2006.84 ms /    93 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@JosephKindnessE @Ayotech11 @Only1Zat Respectfully you don’t know anything understand feminism, because you choose not to. It’s clear you don’t know the difference feminism and misandry. Feminism is what the guy explained misandry is what you are explaining.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.67 ms /    16 runs   (    0.73 ms per token,  1370.68 tokens per second)\n",
            "llama_print_timings: prompt eval time =     263.59 ms /    86 tokens (    3.06 ms per token,   326.27 tokens per second)\n",
            "llama_print_timings:        eval time =    1747.28 ms /    15 runs   (  116.49 ms per token,     8.58 tokens per second)\n",
            "llama_print_timings:       total time =    2272.14 ms /   101 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Questionhttps://t.co/p1kihfI1lmSlapped for a telling a joke on TV then body shamedWhere was the outrage and apologies The cancellation of careersWhat possible could be the difference? #Feminism #Feminists #USPolitics #MeToo @Oneiorosgrip @HoneyBadgerBite @anti_fembot\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.51 ms /    16 runs   (    0.59 ms per token,  1681.73 tokens per second)\n",
            "llama_print_timings: prompt eval time =     275.45 ms /    64 tokens (    4.30 ms per token,   232.34 tokens per second)\n",
            "llama_print_timings:        eval time =    1591.99 ms /    15 runs   (  106.13 ms per token,     9.42 tokens per second)\n",
            "llama_print_timings:       total time =    2108.43 ms /    79 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Lesboratory @Peri_Pango @SolientArt @An_Aria_Blooms \"All of these questions were settled in the 70s/80s\"😂So how was the debate over \"difference feminism\" solved?Who won?\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.75 ms /    16 runs   (    0.55 ms per token,  1829.20 tokens per second)\n",
            "llama_print_timings: prompt eval time =     278.19 ms /    92 tokens (    3.02 ms per token,   330.71 tokens per second)\n",
            "llama_print_timings:        eval time =    1655.39 ms /    15 runs   (  110.36 ms per token,     9.06 tokens per second)\n",
            "llama_print_timings:       total time =    2182.66 ms /   107 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "📣 New Podcast! \"Avoid the postmodernist doctrine of the difference feminism that allots innate and intrinsic qualities to the feminine gender\" on @Spreaker #a #allots #and #avoid #collective #difference #doctrine #establish #feminine #feminism #of https://t.co/VA7ON7DoLc\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.65 ms /    16 runs   (    0.60 ms per token,  1657.34 tokens per second)\n",
            "llama_print_timings: prompt eval time =     262.97 ms /    72 tokens (    3.65 ms per token,   273.80 tokens per second)\n",
            "llama_print_timings:        eval time =    1495.94 ms /    15 runs   (   99.73 ms per token,    10.03 tokens per second)\n",
            "llama_print_timings:       total time =    1972.88 ms /    87 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@lisakabous gereksiz age difference. feminism leaving the door when that old idiot shows up. the psycho locking his ex in the attic ?? manipulating jane into marriage by using another woman ?? jane being rich &amp; independent and still returning to that disgusting predator ?? no\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.46 ms /    16 runs   (    0.65 ms per token,  1529.34 tokens per second)\n",
            "llama_print_timings: prompt eval time =     268.08 ms /    79 tokens (    3.39 ms per token,   294.69 tokens per second)\n",
            "llama_print_timings:        eval time =    1547.17 ms /    15 runs   (  103.14 ms per token,     9.70 tokens per second)\n",
            "llama_print_timings:       total time =    2047.78 ms /    94 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "WoLF membership is now open - join other radical feminists, fight for #WomensRights, and support our legal work! YOUR membership makes some of WoLF's legal activities possible - YOU make a difference!#Feminism#SexNotGenderhttps://t.co/d3beL9PgEs\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.92 ms /    16 runs   (    0.68 ms per token,  1465.60 tokens per second)\n",
            "llama_print_timings: prompt eval time =     283.69 ms /    65 tokens (    4.36 ms per token,   229.12 tokens per second)\n",
            "llama_print_timings:        eval time =    1758.12 ms /    15 runs   (  117.21 ms per token,     8.53 tokens per second)\n",
            "llama_print_timings:       total time =    2370.00 ms /    80 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@susangarnett11 @PastorAdamB @ScottAdamsSays @nhannahjones @ijbailey This is what all politicians did, do and will do. It’s not a discrimination but lead of a policy he was elected for.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.43 ms /    16 runs   (    0.59 ms per token,  1695.99 tokens per second)\n",
            "llama_print_timings: prompt eval time =     264.15 ms /    69 tokens (    3.83 ms per token,   261.22 tokens per second)\n",
            "llama_print_timings:        eval time =    1487.61 ms /    15 runs   (   99.17 ms per token,    10.08 tokens per second)\n",
            "llama_print_timings:       total time =    1960.57 ms /    84 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Yeshiva’s administration previously admitted the university is subject to NY’s anti-discrimination law. Yeshiva’s affiliated law school &amp; med school have LGBTQ student clubs. And when seeking pubic funding, the school categorizes itself as an educational, not religious, entity.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.59 ms /    16 runs   (    0.60 ms per token,  1668.75 tokens per second)\n",
            "llama_print_timings: prompt eval time =     260.12 ms /    70 tokens (    3.72 ms per token,   269.10 tokens per second)\n",
            "llama_print_timings:        eval time =    1525.11 ms /    15 runs   (  101.67 ms per token,     9.84 tokens per second)\n",
            "llama_print_timings:       total time =    2008.29 ms /    85 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@SarahLDavis74 @openDemocracy Are you opposed to discrimination protection?  I understand you \"hate\" our worldview but it brings us joy and freedom from regressive sexism. Take your \"hate\" elsewhere.  Maybe you could target child molesters or something.\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.27 ms /    16 runs   (    0.58 ms per token,  1726.37 tokens per second)\n",
            "llama_print_timings: prompt eval time =     253.42 ms /    46 tokens (    5.51 ms per token,   181.52 tokens per second)\n",
            "llama_print_timings:        eval time =    1487.10 ms /    15 runs   (   99.14 ms per token,    10.09 tokens per second)\n",
            "llama_print_timings:       total time =    1913.77 ms /    61 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Victorian Pride Lobby calls on Real Estate Institute of Victoria to tackle LGBTIQ+ housing discrimination - ABC News https://t.co/S3FyseMYQo\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.29 ms /    16 runs   (    0.64 ms per token,  1555.36 tokens per second)\n",
            "llama_print_timings: prompt eval time =     232.59 ms /    33 tokens (    7.05 ms per token,   141.88 tokens per second)\n",
            "llama_print_timings:        eval time =    1903.58 ms /    15 runs   (  126.91 ms per token,     7.88 tokens per second)\n",
            "llama_print_timings:       total time =    2368.76 ms /    48 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Native American, LGBTQ communities grapple with homelessness, housing discrimination https://t.co/bpmKTr0fOI\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.70 ms /    16 runs   (    0.61 ms per token,  1648.97 tokens per second)\n",
            "llama_print_timings: prompt eval time =     303.54 ms /   106 tokens (    2.86 ms per token,   349.21 tokens per second)\n",
            "llama_print_timings:        eval time =    1564.94 ms /    15 runs   (  104.33 ms per token,     9.59 tokens per second)\n",
            "llama_print_timings:       total time =    2149.00 ms /   121 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "For example, caste crusaders scream that it is discrimination for śūdras to be proscribed from doing brāhmaṇa dharma. Well, here is brāhmaṇa-dharma: living in poverty, studying Vedas, living off alms. Will anyone with half a brain think this austerity is the \"good life?\" (20/n) https://t.co/vVyyTdqAQa\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.14 ms /    16 runs   (    0.57 ms per token,  1749.59 tokens per second)\n",
            "llama_print_timings: prompt eval time =     240.22 ms /    37 tokens (    6.49 ms per token,   154.02 tokens per second)\n",
            "llama_print_timings:        eval time =    1606.59 ms /    15 runs   (  107.11 ms per token,     9.34 tokens per second)\n",
            "llama_print_timings:       total time =    1999.46 ms /    52 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@camrynbaylee You’re just the kind of adoring dumb blonde trump would love.  Maybe you can be his prison press Secretary.\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.37 ms /    16 runs   (    0.59 ms per token,  1708.12 tokens per second)\n",
            "llama_print_timings: prompt eval time =     254.15 ms /    61 tokens (    4.17 ms per token,   240.02 tokens per second)\n",
            "llama_print_timings:        eval time =    1464.80 ms /    15 runs   (   97.65 ms per token,    10.24 tokens per second)\n",
            "llama_print_timings:       total time =    1911.79 ms /    76 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "I have a fear of not asking questions in case I look stupid so now it’ll be my goal to look as stupid as I possibly can in order for me to live my comedy dumb blonde 00’s movie (I WILL be the next Elle Woods)\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.78 ms /    16 runs   (    0.61 ms per token,  1635.99 tokens per second)\n",
            "llama_print_timings: prompt eval time =     244.65 ms /    45 tokens (    5.44 ms per token,   183.94 tokens per second)\n",
            "llama_print_timings:        eval time =    1548.55 ms /    15 runs   (  103.24 ms per token,     9.69 tokens per second)\n",
            "llama_print_timings:       total time =    1966.11 ms /    60 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@IsabellaMDeLuca Do you all just pick numbers out of a hat to see who is going to be the next dumb blonde looking for her 15 minutes of fame?\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.16 ms /    16 runs   (    0.63 ms per token,  1575.27 tokens per second)\n",
            "llama_print_timings: prompt eval time =     248.97 ms /    36 tokens (    6.92 ms per token,   144.60 tokens per second)\n",
            "llama_print_timings:        eval time =    1794.30 ms /    15 runs   (  119.62 ms per token,     8.36 tokens per second)\n",
            "llama_print_timings:       total time =    2271.04 ms /    51 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "see, u can have your dumb blonde representation in percy lmao https://t.co/W5hD1uZYc2\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.82 ms /    16 runs   (    0.61 ms per token,  1629.66 tokens per second)\n",
            "llama_print_timings: prompt eval time =     254.59 ms /    54 tokens (    4.71 ms per token,   212.11 tokens per second)\n",
            "llama_print_timings:        eval time =    1541.54 ms /    15 runs   (  102.77 ms per token,     9.73 tokens per second)\n",
            "llama_print_timings:       total time =    1973.91 ms /    69 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@mippy @JReadingAloud87 @eraseresk @AndyinBrum @looksunfamiliar @MysteriosoX Susan certainly wasn't a \"dumb blonde\" stereotype, though.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.15 ms /    16 runs   (    0.51 ms per token,  1964.15 tokens per second)\n",
            "llama_print_timings: prompt eval time =     248.40 ms /    40 tokens (    6.21 ms per token,   161.03 tokens per second)\n",
            "llama_print_timings:        eval time =    1489.10 ms /    15 runs   (   99.27 ms per token,    10.07 tokens per second)\n",
            "llama_print_timings:       total time =    1889.34 ms /    55 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "tell me you’re a dumb blonde without actually telling me you’re a dumb blonde https://t.co/xRHtIpdo0x\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.36 ms /    16 runs   (    0.52 ms per token,  1914.56 tokens per second)\n",
            "llama_print_timings: prompt eval time =     555.90 ms /    21 tokens (   26.47 ms per token,    37.78 tokens per second)\n",
            "llama_print_timings:        eval time =    1546.32 ms /    15 runs   (  103.09 ms per token,     9.70 tokens per second)\n",
            "llama_print_timings:       total time =    2213.16 ms /    36 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "I'm so embarrassed 😭😭😭😭 I gotta change schools pls\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.57 ms /    16 runs   (    0.72 ms per token,  1383.37 tokens per second)\n",
            "llama_print_timings: prompt eval time =     243.32 ms /    51 tokens (    4.77 ms per token,   209.60 tokens per second)\n",
            "llama_print_timings:        eval time =    1830.43 ms /    15 runs   (  122.03 ms per token,     8.19 tokens per second)\n",
            "llama_print_timings:       total time =    2362.72 ms /    66 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "It’s official I’m embarrassed. I just told a whole grown ass man that he smelled like chicken after sniffing him. This has taken fat to a whole new level to far who going to the gym with me.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.93 ms /    16 runs   (    0.56 ms per token,  1791.51 tokens per second)\n",
            "llama_print_timings: prompt eval time =     695.47 ms /    26 tokens (   26.75 ms per token,    37.38 tokens per second)\n",
            "llama_print_timings:        eval time =    1569.93 ms /    15 runs   (  104.66 ms per token,     9.55 tokens per second)\n",
            "llama_print_timings:       total time =    2383.52 ms /    41 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "why is this man asking for another man’s permission to talk to me?? im embarrassed 4u\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.01 ms /    16 runs   (    0.56 ms per token,  1775.02 tokens per second)\n",
            "llama_print_timings: prompt eval time =     594.53 ms /    23 tokens (   25.85 ms per token,    38.69 tokens per second)\n",
            "llama_print_timings:        eval time =    1580.98 ms /    15 runs   (  105.40 ms per token,     9.49 tokens per second)\n",
            "llama_print_timings:       total time =    2291.88 ms /    38 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@LongshotFN I’ve done that before then u feel embarrassed as shit 😂\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.67 ms /    16 runs   (    0.54 ms per token,  1846.30 tokens per second)\n",
            "llama_print_timings: prompt eval time =     736.82 ms /    29 tokens (   25.41 ms per token,    39.36 tokens per second)\n",
            "llama_print_timings:        eval time =    1545.40 ms /    15 runs   (  103.03 ms per token,     9.71 tokens per second)\n",
            "llama_print_timings:       total time =    2406.86 ms /    44 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@BarbMcQuade @freep I am embarrassed for SCUM…having their school associated with your tweets\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.91 ms /    16 runs   (    0.74 ms per token,  1342.96 tokens per second)\n",
            "llama_print_timings: prompt eval time =     244.41 ms /    49 tokens (    4.99 ms per token,   200.48 tokens per second)\n",
            "llama_print_timings:        eval time =    1835.12 ms /    15 runs   (  122.34 ms per token,     8.17 tokens per second)\n",
            "llama_print_timings:       total time =    2280.88 ms /    64 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "I went and saw More Fun Stuff last night and essentially reacted as if I’d never seen the movie before, and absolutely embarrassed everyone I saw the film with full-on Supes screaming when Andrew showed up\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.89 ms /    16 runs   (    0.56 ms per token,  1798.76 tokens per second)\n",
            "llama_print_timings: prompt eval time =     285.40 ms /    94 tokens (    3.04 ms per token,   329.36 tokens per second)\n",
            "llama_print_timings:        eval time =    1482.94 ms /    15 runs   (   98.86 ms per token,    10.12 tokens per second)\n",
            "llama_print_timings:       total time =    2025.58 ms /   109 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Well, kid, Empowered Woman. Learning means change and welcomeAn empire there isn't ے⁦نون⁩- . The only loss    ك̷و̷د̶⁩ ⁦̸خ̷ص̸م̴⁩  .   is the best part https://t.co/i9ZrDhW8o5\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.89 ms /    16 runs   (    0.56 ms per token,  1799.98 tokens per second)\n",
            "llama_print_timings: prompt eval time =     272.34 ms /    88 tokens (    3.09 ms per token,   323.13 tokens per second)\n",
            "llama_print_timings:        eval time =    1537.94 ms /    15 runs   (  102.53 ms per token,     9.75 tokens per second)\n",
            "llama_print_timings:       total time =    2056.76 ms /   103 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Black Woman Wall Art, Boho home decor, Feminist woman Art, Empowered woman print, Black girl print, black girl magic, female portrait print #Feminist #Portrait #wall #black #art #ArtEmpowered #magic #HomeDecor #print #GirlPrint #ArtbyDCMhttps://t.co/63ErPE6goF\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.23 ms /    16 runs   (    0.58 ms per token,  1733.67 tokens per second)\n",
            "llama_print_timings: prompt eval time =     250.16 ms /    45 tokens (    5.56 ms per token,   179.89 tokens per second)\n",
            "llama_print_timings:        eval time =    1534.29 ms /    15 runs   (  102.29 ms per token,     9.78 tokens per second)\n",
            "llama_print_timings:       total time =    1954.43 ms /    60 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Allyson Felix is the example of an empowered woman who gets ahead by her own means and talents, let's share her story to inspire more women.Alfredo Lorenzo Messina\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.19 ms /    16 runs   (    0.64 ms per token,  1570.32 tokens per second)\n",
            "llama_print_timings: prompt eval time =     284.16 ms /   111 tokens (    2.56 ms per token,   390.63 tokens per second)\n",
            "llama_print_timings:        eval time =    1603.17 ms /    15 runs   (  106.88 ms per token,     9.36 tokens per second)\n",
            "llama_print_timings:       total time =    2191.10 ms /   126 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Fragile Like A Bomb Shirt, Not Fragile Like A Flower RBG Shirt, Strong Woman Shirt, Feminist, Feminism, Girl Power, Empowered Woman 👋 #rbg #girl #shirt #Fragile #Feminist #Strong #woman #BombShirt #Feminism #Empowered #FirstAmendmentMerch #EtsyEmailhttps://t.co/dxPhwlnfLs\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.85 ms /    16 runs   (    0.68 ms per token,  1474.93 tokens per second)\n",
            "llama_print_timings: prompt eval time =     274.91 ms /    67 tokens (    4.10 ms per token,   243.72 tokens per second)\n",
            "llama_print_timings:        eval time =    1657.07 ms /    15 runs   (  110.47 ms per token,     9.05 tokens per second)\n",
            "llama_print_timings:       total time =    2292.57 ms /    82 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "The problem is that we men look for women who need exposure and empowering. Look for an already empowered woman who wants companionship. Wacheni madame wa kupewa kila kitu. Small privilege and she will terrorise you. You never know a person until they have money.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.61 ms /    16 runs   (    0.60 ms per token,  1664.59 tokens per second)\n",
            "llama_print_timings: prompt eval time =     270.34 ms /    78 tokens (    3.47 ms per token,   288.52 tokens per second)\n",
            "llama_print_timings:        eval time =    1675.99 ms /    15 runs   (  111.73 ms per token,     8.95 tokens per second)\n",
            "llama_print_timings:       total time =    2176.26 ms /    93 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Nichelle Nichols has died.  I'm devastated!  She was a hero to girls everywhere. Certainly for African American girls, but for all little girls.  She was groundbreaking, and just plain cool!  What an impressive, empowered woman!God Bless her family in their grief! RIP, Nichelle\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.60 ms /    16 runs   (    0.60 ms per token,  1667.54 tokens per second)\n",
            "llama_print_timings: prompt eval time =     253.73 ms /    46 tokens (    5.52 ms per token,   181.29 tokens per second)\n",
            "llama_print_timings:        eval time =    1538.74 ms /    15 runs   (  102.58 ms per token,     9.75 tokens per second)\n",
            "llama_print_timings:       total time =    1959.77 ms /    61 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@kirawontmiss Its nice that young women have a rapist to look up to! She really is an icon of empowerment. Women aren’t guilty of rape if they identify as innocent.\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.15 ms /    16 runs   (    0.57 ms per token,  1748.44 tokens per second)\n",
            "llama_print_timings: prompt eval time =     244.83 ms /    53 tokens (    4.62 ms per token,   216.48 tokens per second)\n",
            "llama_print_timings:        eval time =    1663.86 ms /    15 runs   (  110.92 ms per token,     9.02 tokens per second)\n",
            "llama_print_timings:       total time =    2094.57 ms /    68 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "went to a women empowerment circle today and it was the most healing experience ever 🧘🏻‍♀️🌱🧿 https://t.co/3go0wq7jCt\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      12.27 ms /    16 runs   (    0.77 ms per token,  1303.78 tokens per second)\n",
            "llama_print_timings: prompt eval time =     285.42 ms /    78 tokens (    3.66 ms per token,   273.28 tokens per second)\n",
            "llama_print_timings:        eval time =    1813.75 ms /    15 runs   (  120.92 ms per token,     8.27 tokens per second)\n",
            "llama_print_timings:       total time =    2491.33 ms /    93 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Andrew &amp; Shirley, our Mgmt Cttee lay members, bring a wealth of #LivedExperience to better inform our methodology &amp; keep us focused on benefitting everyone who is affected by any form of #dementia \"An often overlooked benefit of PPI is the empowerment it gives to lay people\"\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.88 ms /    16 runs   (    0.55 ms per token,  1802.21 tokens per second)\n",
            "llama_print_timings: prompt eval time =     260.13 ms /    44 tokens (    5.91 ms per token,   169.15 tokens per second)\n",
            "llama_print_timings:        eval time =    1606.42 ms /    15 runs   (  107.09 ms per token,     9.34 tokens per second)\n",
            "llama_print_timings:       total time =    2020.93 ms /    59 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Missy made multiple “I don’t need your shit because I got my own” anthems 😂😂😂 she was really on her self love and empowerment energy from day one\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.01 ms /    16 runs   (    0.63 ms per token,  1599.04 tokens per second)\n",
            "llama_print_timings: prompt eval time =     268.67 ms /    78 tokens (    3.44 ms per token,   290.32 tokens per second)\n",
            "llama_print_timings:        eval time =    1452.94 ms /    15 runs   (   96.86 ms per token,    10.32 tokens per second)\n",
            "llama_print_timings:       total time =    1968.79 ms /    93 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "9 In terms of empowerment, he’s empowered youths within and outside his constituency in tech, agriculture, education and several other spheres. He’s an alumna of LAUTECH which covers a bit if his district. Again, some Ajimobi core supporters won’t vote YUNUS for being a rebel in\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.30 ms /    16 runs   (    0.64 ms per token,  1554.00 tokens per second)\n",
            "llama_print_timings: prompt eval time =     248.40 ms /    55 tokens (    4.52 ms per token,   221.42 tokens per second)\n",
            "llama_print_timings:        eval time =    1660.17 ms /    15 runs   (  110.68 ms per token,     9.04 tokens per second)\n",
            "llama_print_timings:       total time =    2120.52 ms /    70 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@YahooSports @VinceGoodwill The owners may spin this narrative that they took control back from Durant, and players empowerment is dead, I think this situation is far from over. I think Nash is on the hot seat.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      12.35 ms /    16 runs   (    0.77 ms per token,  1296.07 tokens per second)\n",
            "llama_print_timings: prompt eval time =     272.26 ms /    69 tokens (    3.95 ms per token,   253.43 tokens per second)\n",
            "llama_print_timings:        eval time =    1766.21 ms /    15 runs   (  117.75 ms per token,     8.49 tokens per second)\n",
            "llama_print_timings:       total time =    2292.71 ms /    84 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Turgut65686619 @Lubnanix I know there is a difference brother. My point is that if there is not enough evidence, it is reasonable to say that the prophet did not say it.It depends on you epistemology and where you draw the line.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.38 ms /    16 runs   (    0.59 ms per token,  1706.67 tokens per second)\n",
            "llama_print_timings: prompt eval time =     257.86 ms /    39 tokens (    6.61 ms per token,   151.25 tokens per second)\n",
            "llama_print_timings:        eval time =    1538.42 ms /    15 runs   (  102.56 ms per token,     9.75 tokens per second)\n",
            "llama_print_timings:       total time =    2013.50 ms /    54 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@CountCagliostr1 @InspiringPhilos @DrDavidAFalk Nothing is wrong with IP epistemology if he went through all the study\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.87 ms /    16 runs   (    0.55 ms per token,  1803.63 tokens per second)\n",
            "llama_print_timings: prompt eval time =     269.16 ms /    78 tokens (    3.45 ms per token,   289.79 tokens per second)\n",
            "llama_print_timings:        eval time =    1619.45 ms /    15 runs   (  107.96 ms per token,     9.26 tokens per second)\n",
            "llama_print_timings:       total time =    2121.46 ms /    93 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Happening now: \"Gender, Authority, and Epistemology in Islamic Medical Ethics\" will begin in 1 day on:Date Time: Sep 30, 2022 04:30 PM Eastern Time (US and Canada) Cornell University https://t.co/WtePoD2VVF\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.57 ms /    16 runs   (    0.66 ms per token,  1513.29 tokens per second)\n",
            "llama_print_timings: prompt eval time =     248.19 ms /    60 tokens (    4.14 ms per token,   241.75 tokens per second)\n",
            "llama_print_timings:        eval time =    1570.85 ms /    15 runs   (  104.72 ms per token,     9.55 tokens per second)\n",
            "llama_print_timings:       total time =    2036.44 ms /    75 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@miniver The reference to Herbert Simon makes me smile and informs my own epistemology on what AI *is*.The real \"general AI\" isn't \"machine intelligence\"; it's the tight feedback loop between human behavior and highly advanced information processing.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.39 ms /    16 runs   (    0.59 ms per token,  1703.21 tokens per second)\n",
            "llama_print_timings: prompt eval time =     243.94 ms /    42 tokens (    5.81 ms per token,   172.17 tokens per second)\n",
            "llama_print_timings:        eval time =    1608.63 ms /    15 runs   (  107.24 ms per token,     9.32 tokens per second)\n",
            "llama_print_timings:       total time =    2025.48 ms /    57 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@samshep @JFletcherSaxon That's when I say epistemology or proxy in a sentence and lose the argument 🤷‍♀️.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.74 ms /    16 runs   (    0.73 ms per token,  1362.75 tokens per second)\n",
            "llama_print_timings: prompt eval time =     282.00 ms /    77 tokens (    3.66 ms per token,   273.04 tokens per second)\n",
            "llama_print_timings:        eval time =    1752.15 ms /    15 runs   (  116.81 ms per token,     8.56 tokens per second)\n",
            "llama_print_timings:       total time =    2430.61 ms /    92 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Esse_ad_Mortem @irumyuui I realized that Neoplatonism was wrong, which you and Kayak were instrumental in. I realized it was inconsistent with my epistemology (which was foundationalist but also direct realist - I've become radically more direct realist since then obviously).\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.41 ms /    16 runs   (    0.59 ms per token,  1699.78 tokens per second)\n",
            "llama_print_timings: prompt eval time =     278.89 ms /    80 tokens (    3.49 ms per token,   286.85 tokens per second)\n",
            "llama_print_timings:        eval time =    1585.00 ms /    15 runs   (  105.67 ms per token,     9.46 tokens per second)\n",
            "llama_print_timings:       total time =    2103.21 ms /    95 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@SueSuezep People in Netherlands are now advocating to get rid of the 40-hour week and introduce a 35-hour week for the same salary. This stimulates more equality between men and women.A similar thing happened last week over high energy bills, the people tell the Govt, Govt listens/acts.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.59 ms /    16 runs   (    0.60 ms per token,  1668.06 tokens per second)\n",
            "llama_print_timings: prompt eval time =     284.57 ms /    67 tokens (    4.25 ms per token,   235.44 tokens per second)\n",
            "llama_print_timings:        eval time =    1660.76 ms /    15 runs   (  110.72 ms per token,     9.03 tokens per second)\n",
            "llama_print_timings:       total time =    2152.74 ms /    82 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@sam_mcclure I really would like to see women have more self esteem and not strip down in public or sell their bodies, because while this is still going on, there can never be true equality between the sexes.  In saying that...this is grubby behaviour whenever it occurred.\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.67 ms /    16 runs   (    0.60 ms per token,  1655.12 tokens per second)\n",
            "llama_print_timings: prompt eval time =     249.12 ms /    56 tokens (    4.45 ms per token,   224.79 tokens per second)\n",
            "llama_print_timings:        eval time =    1561.75 ms /    15 runs   (  104.12 ms per token,     9.60 tokens per second)\n",
            "llama_print_timings:       total time =    2007.89 ms /    71 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "A liberal woman, who believes in equality between men and women, is required and works side by side in all fields to transport 1.5 tons of cement to the third floor. https://t.co/q40EspdSj2\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      12.38 ms /    16 runs   (    0.77 ms per token,  1292.93 tokens per second)\n",
            "llama_print_timings: prompt eval time =     247.63 ms /    45 tokens (    5.50 ms per token,   181.72 tokens per second)\n",
            "llama_print_timings:        eval time =    1875.90 ms /    15 runs   (  125.06 ms per token,     8.00 tokens per second)\n",
            "llama_print_timings:       total time =    2413.77 ms /    60 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Biblical equality between men and women is not grounded in sameness but in that they equally together reflect God's glory and rule. - @JeremyTreat5 @realityla\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.75 ms /    16 runs   (    0.61 ms per token,  1641.03 tokens per second)\n",
            "llama_print_timings: prompt eval time =     290.45 ms /    79 tokens (    3.68 ms per token,   271.99 tokens per second)\n",
            "llama_print_timings:        eval time =    1648.19 ms /    15 runs   (  109.88 ms per token,     9.10 tokens per second)\n",
            "llama_print_timings:       total time =    2181.22 ms /    94 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@TT4freedom @0liviajulianna Equality among sexes is a huge core of the issue here. You can’t have equality between sexes only in some states. Women will always have to face some more issues due to biology, but when it comes to laws - the rights to your own body should be consistent between states.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.94 ms /    16 runs   (    0.62 ms per token,  1609.17 tokens per second)\n",
            "llama_print_timings: prompt eval time =     259.27 ms /    67 tokens (    3.87 ms per token,   258.42 tokens per second)\n",
            "llama_print_timings:        eval time =    1502.59 ms /    15 runs   (  100.17 ms per token,     9.98 tokens per second)\n",
            "llama_print_timings:       total time =    1967.47 ms /    82 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@DrRJWebb There are massive inequalities in both directions, but as it stands they are significantly in favour of doctors. Advocating equality between professions is fantastic, but let’s aim for equal opportunities in training, pay, course fees, access to parking / mess / imaging etc\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.38 ms /    16 runs   (    0.59 ms per token,  1705.21 tokens per second)\n",
            "llama_print_timings: prompt eval time =     256.56 ms /    67 tokens (    3.83 ms per token,   261.14 tokens per second)\n",
            "llama_print_timings:        eval time =    1531.79 ms /    15 runs   (  102.12 ms per token,     9.79 tokens per second)\n",
            "llama_print_timings:       total time =    1999.87 ms /    82 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "The Western world’s near-total capitulation to infectious diseases is a clear sign of profound political-economic and sociocultural rot. The more undeniable that rot becomes, the more vehemently those who point it out will be accused of alarmism, essentialism, etc.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.17 ms /    16 runs   (    0.64 ms per token,  1573.25 tokens per second)\n",
            "llama_print_timings: prompt eval time =     700.91 ms /    26 tokens (   26.96 ms per token,    37.09 tokens per second)\n",
            "llama_print_timings:        eval time =    1803.64 ms /    15 runs   (  120.24 ms per token,     8.32 tokens per second)\n",
            "llama_print_timings:       total time =    2655.59 ms /    41 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@KatyMontgomerie When people have decided that bio essentialism is real they apply it to everything\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.90 ms /    16 runs   (    0.56 ms per token,  1797.35 tokens per second)\n",
            "llama_print_timings: prompt eval time =     796.70 ms /    30 tokens (   26.56 ms per token,    37.66 tokens per second)\n",
            "llama_print_timings:        eval time =    1701.14 ms /    15 runs   (  113.41 ms per token,     8.82 tokens per second)\n",
            "llama_print_timings:       total time =    2636.11 ms /    45 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "The right thing the right way at the right time. Nothing more. Eliminate all else. #Essentialism\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.05 ms /    16 runs   (    0.63 ms per token,  1592.67 tokens per second)\n",
            "llama_print_timings: prompt eval time =     267.90 ms /    81 tokens (    3.31 ms per token,   302.35 tokens per second)\n",
            "llama_print_timings:        eval time =    1523.56 ms /    15 runs   (  101.57 ms per token,     9.85 tokens per second)\n",
            "llama_print_timings:       total time =    2039.08 ms /    96 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@petercoffin the tweet is basically a moralizing of aesthetics, where the way you pronounce something MUST ALWAYS (essentialism) show some kind of unworthiness to speak.basically \"you sound parochial/uncultured\" by the standards of their wing of capital ideology (cosmo aesthetic morality)\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.84 ms /    16 runs   (    0.61 ms per token,  1626.02 tokens per second)\n",
            "llama_print_timings: prompt eval time =     241.75 ms /    49 tokens (    4.93 ms per token,   202.69 tokens per second)\n",
            "llama_print_timings:        eval time =    1529.13 ms /    15 runs   (  101.94 ms per token,     9.81 tokens per second)\n",
            "llama_print_timings:       total time =    1963.33 ms /    64 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@jameelajamil At some point, you will have to admit to yourself that nothing will be enough for the religion of Self Identity Essentialism. https://t.co/Nblms8RzHS\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.61 ms /    16 runs   (    0.60 ms per token,  1665.63 tokens per second)\n",
            "llama_print_timings: prompt eval time =     236.70 ms /    37 tokens (    6.40 ms per token,   156.32 tokens per second)\n",
            "llama_print_timings:        eval time =    1707.39 ms /    15 runs   (  113.83 ms per token,     8.79 tokens per second)\n",
            "llama_print_timings:       total time =    2116.55 ms /    52 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@PostingDoom @ProtonInspector it also tells me race essentialism is real and slavery is cool. also that magical kung fu is extremely fun\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       3.87 ms /     5 runs   (    0.77 ms per token,  1293.66 tokens per second)\n",
            "llama_print_timings: prompt eval time =     293.88 ms /    79 tokens (    3.72 ms per token,   268.82 tokens per second)\n",
            "llama_print_timings:        eval time =     479.38 ms /     4 runs   (  119.85 ms per token,     8.34 tokens per second)\n",
            "llama_print_timings:       total time =    1120.37 ms /    83 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Other half went on a shopping spree and everything just arrived.Delivery driver said I'd \"been busy with the other half's credit card\"Nope. All his.\"Oh but this one is for you\" while handing me a floor mopNope. Still not mine. The only thing for me is the everyday sexism 🙃\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.38 ms /    16 runs   (    0.59 ms per token,  1705.76 tokens per second)\n",
            "llama_print_timings: prompt eval time =     253.00 ms /    72 tokens (    3.51 ms per token,   284.59 tokens per second)\n",
            "llama_print_timings:        eval time =    1501.04 ms /    15 runs   (  100.07 ms per token,     9.99 tokens per second)\n",
            "llama_print_timings:       total time =    1977.35 ms /    87 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Work place sexism, overt &amp; covert it's everywhere. https://t.co/6NwcywDiBx recently shared the above in my workplace to start the conversation to Do Better. #sexism #change https://t.co/vG3Bt28CcI\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.90 ms /    16 runs   (    0.62 ms per token,  1615.35 tokens per second)\n",
            "llama_print_timings: prompt eval time =     263.26 ms /    82 tokens (    3.21 ms per token,   311.48 tokens per second)\n",
            "llama_print_timings:        eval time =    1715.93 ms /    15 runs   (  114.40 ms per token,     8.74 tokens per second)\n",
            "llama_print_timings:       total time =    2231.89 ms /    97 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "We have put together a list of the best books to read in your 20s to understand everything from panic attacks to financial literacy. Learn from psychologist Dr. Julie Smith, Dame Deborah James and Everyday Sexism creator Laura Bates 📚 #Twenties #Books https://t.co/taRCscpNwT\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.07 ms /    16 runs   (    0.63 ms per token,  1588.40 tokens per second)\n",
            "llama_print_timings: prompt eval time =     249.76 ms /    58 tokens (    4.31 ms per token,   232.22 tokens per second)\n",
            "llama_print_timings:        eval time =    1655.39 ms /    15 runs   (  110.36 ms per token,     9.06 tokens per second)\n",
            "llama_print_timings:       total time =    2113.45 ms /    73 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@hrconfes “He Thought I Was Just Doing The Admin. I’m The CEO”: Woman Starts A Viral Thread About Everyday Sexism At Work https://t.co/DRo71a9sQl #HR\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.92 ms /    16 runs   (    0.68 ms per token,  1465.87 tokens per second)\n",
            "llama_print_timings: prompt eval time =     266.14 ms /    70 tokens (    3.80 ms per token,   263.01 tokens per second)\n",
            "llama_print_timings:        eval time =    1686.30 ms /    15 runs   (  112.42 ms per token,     8.90 tokens per second)\n",
            "llama_print_timings:       total time =    2174.50 ms /    85 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@danielstorey85 I’ve struggled to explain why it’s so important. The everyday sexism I became accustomed to when I regularly attended matches is not something I’m willing to accept any more - for me or my daughters - but it has taken the lionesses success to empower this stance\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.47 ms /    16 runs   (    0.65 ms per token,  1528.61 tokens per second)\n",
            "llama_print_timings: prompt eval time =     291.20 ms /    67 tokens (    4.35 ms per token,   230.08 tokens per second)\n",
            "llama_print_timings:        eval time =    1547.76 ms /    15 runs   (  103.18 ms per token,     9.69 tokens per second)\n",
            "llama_print_timings:       total time =    2192.64 ms /    82 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Mamata Banerjee is a 3 term CM. Yet the everyday sexism that is India a Bjp Saumitra Khan makes an issue of her martial status. Would Khan have attacked Modi like this? https://t.co/ogwSNYLcf9\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.07 ms /    16 runs   (    0.63 ms per token,  1588.40 tokens per second)\n",
            "llama_print_timings: prompt eval time =     269.99 ms /    88 tokens (    3.07 ms per token,   325.94 tokens per second)\n",
            "llama_print_timings:        eval time =    1542.33 ms /    15 runs   (  102.82 ms per token,     9.73 tokens per second)\n",
            "llama_print_timings:       total time =    2063.46 ms /   103 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Rotten__Dan THIS ISNT WOKE AT ALL. ITS EXACTLY THE SAME. WHAT IS THIS THE EXOTICIZATION OF A FOREIGN LANGUAGE? IF YOU CALL SUN WUKONG JUST WUKONG YOU DEF DONT KNOW SHIT ABOUT THE LANGUAGE......... god its exactly the same word.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.53 ms /    16 runs   (    0.60 ms per token,  1678.38 tokens per second)\n",
            "llama_print_timings: prompt eval time =     259.32 ms /    66 tokens (    3.93 ms per token,   254.51 tokens per second)\n",
            "llama_print_timings:        eval time =    1656.74 ms /    15 runs   (  110.45 ms per token,     9.05 tokens per second)\n",
            "llama_print_timings:       total time =    2126.57 ms /    81 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "listen i'm not going to get into the whole \"racism\" debate w/ genshin, what I will say is that it is a Chinese game made for a Chinese audience, and china has problems w/ exoticization, non-Han groups and especially non-Chinese people\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.52 ms /    16 runs   (    0.59 ms per token,  1681.38 tokens per second)\n",
            "llama_print_timings: prompt eval time =     262.08 ms /    68 tokens (    3.85 ms per token,   259.46 tokens per second)\n",
            "llama_print_timings:        eval time =    1633.70 ms /    15 runs   (  108.91 ms per token,     9.18 tokens per second)\n",
            "llama_print_timings:       total time =    2112.49 ms /    83 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "A lot of mainstream stories from Northeast India stops at Assam. It moves beyond Assam, when there's a  \"breaking news\" situation, politics and insurgency, and the regular exoticization -- oh the living root bridges. I hope and wish there were more stories on governance,\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.14 ms /    16 runs   (    0.70 ms per token,  1435.88 tokens per second)\n",
            "llama_print_timings: prompt eval time =     282.10 ms /    95 tokens (    2.97 ms per token,   336.76 tokens per second)\n",
            "llama_print_timings:        eval time =    1732.44 ms /    15 runs   (  115.50 ms per token,     8.66 tokens per second)\n",
            "llama_print_timings:       total time =    2450.31 ms /   110 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "A key element of @JoiriMinaya’s practice is the reclaiming of agency through landscape 🌿On view now in \"#AnotherJustice: US is Them\" @Parrishart, these photographic collages draw attention to the exoticization of the female body: https://t.co/RZtfmpfBU3 https://t.co/gwAgw6zdk2\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.12 ms /    16 runs   (    0.57 ms per token,  1754.19 tokens per second)\n",
            "llama_print_timings: prompt eval time =     270.01 ms /    75 tokens (    3.60 ms per token,   277.76 tokens per second)\n",
            "llama_print_timings:        eval time =    1689.24 ms /    15 runs   (  112.62 ms per token,     8.88 tokens per second)\n",
            "llama_print_timings:       total time =    2176.35 ms /    90 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Since folk horror is on the rise, I have a question for all of you:whose folk?My folk is not your folk. My folk runs the risk of a) misunderstanding, b) appropriation, c) exoticization. My folk is not your folk.Writers, editors, think about this now rather than later.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.76 ms /    16 runs   (    0.61 ms per token,  1639.34 tokens per second)\n",
            "llama_print_timings: prompt eval time =     276.01 ms /    86 tokens (    3.21 ms per token,   311.58 tokens per second)\n",
            "llama_print_timings:        eval time =    1574.01 ms /    15 runs   (  104.93 ms per token,     9.53 tokens per second)\n",
            "llama_print_timings:       total time =    2095.29 ms /   101 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "This thread needs to spread. What's worse is that the movie even won two national awards. I was actually happy back then but didn't know that it was misrepresented this way. Will the blue ticked 'tribal leaders' of the state take up this issue of vested exoticization as well? https://t.co/GMYs7EUXNJ\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.82 ms /    16 runs   (    0.55 ms per token,  1814.47 tokens per second)\n",
            "llama_print_timings: prompt eval time =     234.53 ms /    36 tokens (    6.51 ms per token,   153.50 tokens per second)\n",
            "llama_print_timings:        eval time =    1533.44 ms /    15 runs   (  102.23 ms per token,     9.78 tokens per second)\n",
            "llama_print_timings:       total time =    1920.09 ms /    51 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@LRPow79 @MayoIsSpicyy Not even for a minute … Fat Donny is a puke 🤮\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      12.23 ms /    16 runs   (    0.76 ms per token,  1308.37 tokens per second)\n",
            "llama_print_timings: prompt eval time =     284.25 ms /    84 tokens (    3.38 ms per token,   295.51 tokens per second)\n",
            "llama_print_timings:        eval time =    1862.31 ms /    15 runs   (  124.15 ms per token,     8.05 tokens per second)\n",
            "llama_print_timings:       total time =    2558.42 ms /    99 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Man, fuck your PR, you're cancerous to the club, fuck off to Grimsby or wherever, make fat kids fatter over there, just get the fuck out already.#RashfordOut #MaguireOut#GlazersOut #ShawOut#McTominayOut https://t.co/aJEqnYlfOe\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.59 ms /    16 runs   (    0.54 ms per token,  1862.41 tokens per second)\n",
            "llama_print_timings: prompt eval time =     253.55 ms /    39 tokens (    6.50 ms per token,   153.82 tokens per second)\n",
            "llama_print_timings:        eval time =    1560.10 ms /    15 runs   (  104.01 ms per token,     9.61 tokens per second)\n",
            "llama_print_timings:       total time =    1961.95 ms /    54 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@lewdyjelly Well I'm definitely not saying no to that either ~ 😏 being stuck under your fat ass sounds so fun 😝\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.73 ms /    16 runs   (    0.55 ms per token,  1832.76 tokens per second)\n",
            "llama_print_timings: prompt eval time =     270.36 ms /    67 tokens (    4.04 ms per token,   247.82 tokens per second)\n",
            "llama_print_timings:        eval time =    1557.02 ms /    15 runs   (  103.80 ms per token,     9.63 tokens per second)\n",
            "llama_print_timings:       total time =    2046.81 ms /    82 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "01/09/2022 08:57 Weight:74.55kg Body Fat %:14.80% Muscle Mass:60.25Kg Metabolic Age:24Age  #tanita #healthplanet\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.91 ms /    16 runs   (    0.56 ms per token,  1796.54 tokens per second)\n",
            "llama_print_timings: prompt eval time =     246.22 ms /    36 tokens (    6.84 ms per token,   146.21 tokens per second)\n",
            "llama_print_timings:        eval time =    1593.41 ms /    15 runs   (  106.23 ms per token,     9.41 tokens per second)\n",
            "llama_print_timings:       total time =    1986.27 ms /    51 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@BorrachinhaMMA Did you bust a fat one Paulo? https://t.co/7DVbHFmm2K\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.20 ms /    16 runs   (    0.64 ms per token,  1568.94 tokens per second)\n",
            "llama_print_timings: prompt eval time =     252.55 ms /    48 tokens (    5.26 ms per token,   190.06 tokens per second)\n",
            "llama_print_timings:        eval time =    1740.00 ms /    15 runs   (  116.00 ms per token,     8.62 tokens per second)\n",
            "llama_print_timings:       total time =    2191.21 ms /    63 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "#Lean We will  display procedures to assist you cast off extra fat successfully https://t.co/yn42mFA84w https://t.co/9GDhTEnV5G\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.01 ms /    16 runs   (    0.56 ms per token,  1776.79 tokens per second)\n",
            "llama_print_timings: prompt eval time =     930.61 ms /    30 tokens (   31.02 ms per token,    32.24 tokens per second)\n",
            "llama_print_timings:        eval time =    1535.78 ms /    15 runs   (  102.39 ms per token,     9.77 tokens per second)\n",
            "llama_print_timings:       total time =    2619.71 ms /    45 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Outside of Moonbyul are there many other female k-pop rappers that write their own verses or…?\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.12 ms /    16 runs   (    0.57 ms per token,  1754.96 tokens per second)\n",
            "llama_print_timings: prompt eval time =     669.96 ms /    25 tokens (   26.80 ms per token,    37.32 tokens per second)\n",
            "llama_print_timings:        eval time =    1553.59 ms /    15 runs   (  103.57 ms per token,     9.66 tokens per second)\n",
            "llama_print_timings:       total time =    2338.91 ms /    40 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@dawnstaley will you cancel any games over the female duke players racist tweets\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.35 ms /    16 runs   (    0.65 ms per token,  1546.49 tokens per second)\n",
            "llama_print_timings: prompt eval time =     261.36 ms /    77 tokens (    3.39 ms per token,   294.61 tokens per second)\n",
            "llama_print_timings:        eval time =    1534.25 ms /    15 runs   (  102.28 ms per token,     9.78 tokens per second)\n",
            "llama_print_timings:       total time =    2038.91 ms /    92 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "My Fellow Actors #JenniferLawrence/#KarenGillan/#AliciaVikander/#FlorencePugh/#AnyaTaylorJoy sorry they're all Female Actors! I can't help it were just Friends!!! https://t.co/sXCeEwvmgt\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.34 ms /    16 runs   (    0.65 ms per token,  1546.94 tokens per second)\n",
            "llama_print_timings: prompt eval time =     251.87 ms /    60 tokens (    4.20 ms per token,   238.22 tokens per second)\n",
            "llama_print_timings:        eval time =    1626.86 ms /    15 runs   (  108.46 ms per token,     9.22 tokens per second)\n",
            "llama_print_timings:       total time =    2084.45 ms /    75 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Again, apparently every female journalist can get death threats with no police action, but they will absolutely jump to SWAT a trans-person who asked to be on a “No swatting” list. https://t.co/uJd1uk4NMK\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.29 ms /    16 runs   (    0.71 ms per token,  1417.06 tokens per second)\n",
            "llama_print_timings: prompt eval time =     275.70 ms /    60 tokens (    4.60 ms per token,   217.62 tokens per second)\n",
            "llama_print_timings:        eval time =    1702.22 ms /    15 runs   (  113.48 ms per token,     8.81 tokens per second)\n",
            "llama_print_timings:       total time =    2304.03 ms /    75 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@notcapnamerica Marketing this movie should be pretty easy. Just show women the trailer. Personally speaking, I'm absolutely craving to see a fierce female warrior protecting her people. Women are a pretty angry lot right now in case no one has noticed.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.56 ms /    16 runs   (    0.54 ms per token,  1868.94 tokens per second)\n",
            "llama_print_timings: prompt eval time =     715.07 ms /    28 tokens (   25.54 ms per token,    39.16 tokens per second)\n",
            "llama_print_timings:        eval time =    1491.91 ms /    15 runs   (   99.46 ms per token,    10.05 tokens per second)\n",
            "llama_print_timings:       total time =    2335.84 ms /    43 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Dajon hosted a great card 👏🏾🔥  that is one amazing female 🗣💯\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.31 ms /    16 runs   (    0.58 ms per token,  1719.32 tokens per second)\n",
            "llama_print_timings: prompt eval time =     239.09 ms /    47 tokens (    5.09 ms per token,   196.58 tokens per second)\n",
            "llama_print_timings:        eval time =    1571.47 ms /    15 runs   (  104.76 ms per token,     9.55 tokens per second)\n",
            "llama_print_timings:       total time =    1986.29 ms /    62 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Unironically saying “Feminazi” in 2022 https://t.co/FacSvZeorS https://t.co/ba8npfzYE9\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.21 ms /    16 runs   (    0.58 ms per token,  1738.19 tokens per second)\n",
            "llama_print_timings: prompt eval time =     244.40 ms /    49 tokens (    4.99 ms per token,   200.49 tokens per second)\n",
            "llama_print_timings:        eval time =    1536.55 ms /    15 runs   (  102.44 ms per token,     9.76 tokens per second)\n",
            "llama_print_timings:       total time =    1955.05 ms /    64 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Uuwuovo @ecce_bozo @j_arthur_bloom cool /v/ comic my fellow gamergater! Let’s take the fight to those feminazi sjws!\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.44 ms /    16 runs   (    0.65 ms per token,  1532.86 tokens per second)\n",
            "llama_print_timings: prompt eval time =     252.46 ms /    39 tokens (    6.47 ms per token,   154.48 tokens per second)\n",
            "llama_print_timings:        eval time =    1823.26 ms /    15 runs   (  121.55 ms per token,     8.23 tokens per second)\n",
            "llama_print_timings:       total time =    2329.43 ms /    54 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Shut up feminazi! https://t.co/xJ1pgxtWiF https://t.co/6i1ERfQWFA\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.78 ms /    16 runs   (    0.61 ms per token,  1636.16 tokens per second)\n",
            "llama_print_timings: prompt eval time =     271.70 ms /    75 tokens (    3.62 ms per token,   276.04 tokens per second)\n",
            "llama_print_timings:        eval time =    1507.35 ms /    15 runs   (  100.49 ms per token,     9.95 tokens per second)\n",
            "llama_print_timings:       total time =    1996.10 ms /    90 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Unwise_Trousers Oh yeah! + Feminazgul was birthed from the culture wars in metal fandom, to take this jokey version of the term 'feminazi' used by the knuckledraggers and own it. It helped that the ppl forming the band are musical genii!\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.42 ms /    16 runs   (    0.59 ms per token,  1698.15 tokens per second)\n",
            "llama_print_timings: prompt eval time =     275.25 ms /    70 tokens (    3.93 ms per token,   254.32 tokens per second)\n",
            "llama_print_timings:        eval time =    1585.12 ms /    15 runs   (  105.67 ms per token,     9.46 tokens per second)\n",
            "llama_print_timings:       total time =    2079.93 ms /    85 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@BaileyFinnley The only one who is pathetic here is you and im not a pick me and im not a feminazi im and im not trying to destroy masculinity and i will defantly not shut up tate minion lmao https://t.co/6ltCmyaLXa\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.61 ms /    16 runs   (    0.60 ms per token,  1664.59 tokens per second)\n",
            "llama_print_timings: prompt eval time =     248.26 ms /    62 tokens (    4.00 ms per token,   249.73 tokens per second)\n",
            "llama_print_timings:        eval time =    1475.21 ms /    15 runs   (   98.35 ms per token,    10.17 tokens per second)\n",
            "llama_print_timings:       total time =    1925.77 ms /    77 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@GraceRandolph You're just someone who pays Marvel to throw shit at other companies, in this case DC, you're supposed to be \"professional\" but you're a black dot in space, one more feminazi, you disgust me. fan boy\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.70 ms /    16 runs   (    0.67 ms per token,  1495.61 tokens per second)\n",
            "llama_print_timings: prompt eval time =     240.28 ms /    40 tokens (    6.01 ms per token,   166.47 tokens per second)\n",
            "llama_print_timings:        eval time =    1686.23 ms /    15 runs   (  112.42 ms per token,     8.90 tokens per second)\n",
            "llama_print_timings:       total time =    2100.82 ms /    55 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Catholic — News Report — Schlafly’s Feminine Mystique https://t.co/jRYAnPoGJz via @YouTube\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.54 ms /    16 runs   (    0.66 ms per token,  1518.75 tokens per second)\n",
            "llama_print_timings: prompt eval time =     271.85 ms /    60 tokens (    4.53 ms per token,   220.71 tokens per second)\n",
            "llama_print_timings:        eval time =    1616.55 ms /    15 runs   (  107.77 ms per token,     9.28 tokens per second)\n",
            "llama_print_timings:       total time =    2188.21 ms /    75 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Overheard later: Kate: 'Oh God, my knickers have gone up my arse.' Alan: 'Ah. Feminine mystique strikes again.' Sun went in and out all day so again we had to cover the scene in shine and cloud.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.39 ms /    16 runs   (    0.59 ms per token,  1704.30 tokens per second)\n",
            "llama_print_timings: prompt eval time =     265.63 ms /    76 tokens (    3.50 ms per token,   286.11 tokens per second)\n",
            "llama_print_timings:        eval time =    1638.73 ms /    15 runs   (  109.25 ms per token,     9.15 tokens per second)\n",
            "llama_print_timings:       total time =    2128.38 ms /    91 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@steadynappin @brningflames sorry no one passed alicent a copy of the feminine mystique. medieval society where she is the property of viserys , where’s she’s been taught that this is her duty and no complying will have consequences unlike rhaenyra. sorry the victim isn’t perfect\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.92 ms /    16 runs   (    0.56 ms per token,  1793.92 tokens per second)\n",
            "llama_print_timings: prompt eval time =     243.11 ms /    40 tokens (    6.08 ms per token,   164.53 tokens per second)\n",
            "llama_print_timings:        eval time =    1521.89 ms /    15 runs   (  101.46 ms per token,     9.86 tokens per second)\n",
            "llama_print_timings:       total time =    1921.66 ms /    55 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@TechGirlSteph_ I can recommend some nonfiction. The Feminine Mystique, The Body Keeps Score, and Inside Intel were pretty good.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.26 ms /    16 runs   (    0.58 ms per token,  1728.61 tokens per second)\n",
            "llama_print_timings: prompt eval time =     248.14 ms /    54 tokens (    4.60 ms per token,   217.62 tokens per second)\n",
            "llama_print_timings:        eval time =    1512.30 ms /    15 runs   (  100.82 ms per token,     9.92 tokens per second)\n",
            "llama_print_timings:       total time =    1938.38 ms /    69 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "\"Women who accepted the conditions which degraded them felt contempt for themselves and for all women. The feminists who fought those conditions freed themselves of that contempt.\"(Betty Friedan, \"The Feminine Mystique\")\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.71 ms /    16 runs   (    0.73 ms per token,  1366.70 tokens per second)\n",
            "llama_print_timings: prompt eval time =     263.20 ms /    77 tokens (    3.42 ms per token,   292.55 tokens per second)\n",
            "llama_print_timings:        eval time =    1914.64 ms /    15 runs   (  127.64 ms per token,     7.83 tokens per second)\n",
            "llama_print_timings:       total time =    2571.02 ms /    92 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Th3HippyTrip The system we perceive masculinity is false, only when one step into their personal space of power do we see this, we're all an alpha particle and the feminine mystique is the quark of creation.Objective reasoning in this mindset will bring about this truth.Fabric and thread.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.45 ms /    16 runs   (    0.59 ms per token,  1692.41 tokens per second)\n",
            "llama_print_timings: prompt eval time =     256.57 ms /    46 tokens (    5.58 ms per token,   179.29 tokens per second)\n",
            "llama_print_timings:        eval time =    1581.67 ms /    15 runs   (  105.44 ms per token,     9.48 tokens per second)\n",
            "llama_print_timings:       total time =    2033.68 ms /    61 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@DoreenNyanjura @kenneth_kizza That’s toxic feminism but u can be a none toxic feminist by not going off the bridge with the fundamental laws of nature\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.25 ms /    16 runs   (    0.64 ms per token,  1561.13 tokens per second)\n",
            "llama_print_timings: prompt eval time =     273.58 ms /    96 tokens (    2.85 ms per token,   350.90 tokens per second)\n",
            "llama_print_timings:        eval time =    1462.81 ms /    15 runs   (   97.52 ms per token,    10.25 tokens per second)\n",
            "llama_print_timings:       total time =    2000.60 ms /   111 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@ScentsyJules @adskol @WalshFreedom @RepLizCheney Wow, insulting a woman by her looks?  How utterly misogynistic of you.  Let me guess...you say you support feminism but will attack women's appearances when you don't like them.  You probably have tweeted about Trump being a misogynist for insulting a woman somewhere too huh?\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.98 ms /    16 runs   (    0.56 ms per token,  1782.33 tokens per second)\n",
            "llama_print_timings: prompt eval time =     234.85 ms /    35 tokens (    6.71 ms per token,   149.03 tokens per second)\n",
            "llama_print_timings:        eval time =    1531.76 ms /    15 runs   (  102.12 ms per token,     9.79 tokens per second)\n",
            "llama_print_timings:       total time =    1914.78 ms /    50 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "This perfectly describes not only feminism but how the left treats all its identity groups https://t.co/O02QvmUvli\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.11 ms /    16 runs   (    0.69 ms per token,  1440.01 tokens per second)\n",
            "llama_print_timings: prompt eval time =     280.91 ms /    82 tokens (    3.43 ms per token,   291.91 tokens per second)\n",
            "llama_print_timings:        eval time =    1667.01 ms /    15 runs   (  111.13 ms per token,     9.00 tokens per second)\n",
            "llama_print_timings:       total time =    2205.80 ms /    97 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@CDE2051 @tbatde That’s bc Doris is making up for abandoning her by providing free childcare.  She rails against the monarchy but insists on being referred to as Duchess. She proclaims feminism but is a stage 5 clinger worse than any teen with Haz.Hypocrite much?\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.71 ms /    16 runs   (    0.61 ms per token,  1648.13 tokens per second)\n",
            "llama_print_timings: prompt eval time =     307.75 ms /   103 tokens (    2.99 ms per token,   334.69 tokens per second)\n",
            "llama_print_timings:        eval time =    1501.56 ms /    15 runs   (  100.10 ms per token,     9.99 tokens per second)\n",
            "llama_print_timings:       total time =    2258.12 ms /   118 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "kpopies morals are so low they gave this d!sgvst!ng w€ird0 2k followers..... remember these r the gg stans who preach ab women &amp; feminism but in reality CHEER &amp; JUSTIFY SA &amp; v!0l€nc€ against women https://t.co/55giaF4QRD https://t.co/iPTMZAle2t\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.62 ms /    16 runs   (    0.60 ms per token,  1663.37 tokens per second)\n",
            "llama_print_timings: prompt eval time =     266.78 ms /    79 tokens (    3.38 ms per token,   296.12 tokens per second)\n",
            "llama_print_timings:        eval time =    1480.50 ms /    15 runs   (   98.70 ms per token,    10.13 tokens per second)\n",
            "llama_print_timings:       total time =    1993.42 ms /    94 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@ArtLeftist It's safe to say that LEFTISM is overall a good modifier for both the MRM and Feminism.But \"True Feminsim\" is iffy in a Capitalistic society because NOW gets all the funding and they're TERFs and they shape what theory is.No movement is without flaw.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       2.83 ms /     5 runs   (    0.57 ms per token,  1766.16 tokens per second)\n",
            "llama_print_timings: prompt eval time =     238.44 ms /    41 tokens (    5.82 ms per token,   171.95 tokens per second)\n",
            "llama_print_timings:        eval time =     396.28 ms /     4 runs   (   99.07 ms per token,    10.09 tokens per second)\n",
            "llama_print_timings:       total time =     762.14 ms /    45 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@ego_odion Feminism is of the pit of hell… just like the devil sought to be equal with God. Women were made to be help mates to men.\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.75 ms /    16 runs   (    0.55 ms per token,  1828.78 tokens per second)\n",
            "llama_print_timings: prompt eval time =     229.07 ms /    40 tokens (    5.73 ms per token,   174.62 tokens per second)\n",
            "llama_print_timings:        eval time =    1513.99 ms /    15 runs   (  100.93 ms per token,     9.91 tokens per second)\n",
            "llama_print_timings:       total time =    1908.83 ms /    55 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@your_uganda @Zuluelihlemchu1 @Matema_ @NginguSah Feminism is also starting to occur very fast in Africa\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.10 ms /    16 runs   (    0.69 ms per token,  1442.09 tokens per second)\n",
            "llama_print_timings: prompt eval time =     280.98 ms /   104 tokens (    2.70 ms per token,   370.14 tokens per second)\n",
            "llama_print_timings:        eval time =    1668.57 ms /    15 runs   (  111.24 ms per token,     8.99 tokens per second)\n",
            "llama_print_timings:       total time =    2255.42 ms /   119 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@BarbaraFrey15 Dasselbe Sujet wurde an der Demo von mehreren Personen hochgehalten, denn die Aussage ist wichtig:\"The biggest war for feminism is happening in Iran, right now. If you're living on earth &amp; you're being silent, you don't get to talk about women's rights anymore!\"S. auch hier: https://t.co/DEj7Ds1Iix\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.40 ms /    16 runs   (    0.65 ms per token,  1538.76 tokens per second)\n",
            "llama_print_timings: prompt eval time =     269.35 ms /    62 tokens (    4.34 ms per token,   230.18 tokens per second)\n",
            "llama_print_timings:        eval time =    1523.71 ms /    15 runs   (  101.58 ms per token,     9.84 tokens per second)\n",
            "llama_print_timings:       total time =    2094.41 ms /    77 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Women don't need an ideology that encourages them to become destructive, self-deluding feminist foot soldiers.The intense vitriol you get for fair critiques of pop feminism is a red flag on fire indicating how crucial those critiques actually are.\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.87 ms /    16 runs   (    0.55 ms per token,  1803.02 tokens per second)\n",
            "llama_print_timings: prompt eval time =     241.50 ms /    42 tokens (    5.75 ms per token,   173.91 tokens per second)\n",
            "llama_print_timings:        eval time =    1639.87 ms /    15 runs   (  109.32 ms per token,     9.15 tokens per second)\n",
            "llama_print_timings:       total time =    2044.51 ms /    57 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@SusanHutchins52 @FemCondition Yes! I cannot believe I never thought of this! Toxic feminism is exactly what she oozesz!\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.46 ms /    16 runs   (    0.59 ms per token,  1691.87 tokens per second)\n",
            "llama_print_timings: prompt eval time =     246.85 ms /    55 tokens (    4.49 ms per token,   222.80 tokens per second)\n",
            "llama_print_timings:        eval time =    1526.64 ms /    15 runs   (  101.78 ms per token,     9.83 tokens per second)\n",
            "llama_print_timings:       total time =    1962.64 ms /    70 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Mistreatment of women isn’t Islamic, they should start with that, bringing up feminism is a tool of deflection to avoid dealing with the issue. https://t.co/9lBvZuSXI5\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.05 ms /    16 runs   (    0.63 ms per token,  1592.52 tokens per second)\n",
            "llama_print_timings: prompt eval time =     246.35 ms /    61 tokens (    4.04 ms per token,   247.62 tokens per second)\n",
            "llama_print_timings:        eval time =    1488.95 ms /    15 runs   (   99.26 ms per token,    10.07 tokens per second)\n",
            "llama_print_timings:       total time =    1939.63 ms /    76 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Jeannie_Hartley Yes indeed! Where are they? Yalda Hakim posts every couple of days highlighting the closure of schools for older girls.. I’ve tagged many ‘feminists’... their silence is DEAFENING!\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.35 ms /    16 runs   (    0.71 ms per token,  1409.19 tokens per second)\n",
            "llama_print_timings: prompt eval time =     291.75 ms /    78 tokens (    3.74 ms per token,   267.36 tokens per second)\n",
            "llama_print_timings:        eval time =    1781.04 ms /    15 runs   (  118.74 ms per token,     8.42 tokens per second)\n",
            "llama_print_timings:       total time =    2467.69 ms /    93 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Aaron_Tadman @DannyDeVito So tired of blokes wanging on about how they are feminists and not all men are bad. It is not about ‘bad’ or ‘guilt’. It is the centuries old world system that has to be knocked on the head by those in power. We all know who is in power.\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.92 ms /    16 runs   (    0.56 ms per token,  1794.33 tokens per second)\n",
            "llama_print_timings: prompt eval time =     800.77 ms /    31 tokens (   25.83 ms per token,    38.71 tokens per second)\n",
            "llama_print_timings:        eval time =    1445.11 ms /    15 runs   (   96.34 ms per token,    10.38 tokens per second)\n",
            "llama_print_timings:       total time =    2373.99 ms /    46 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Comming from a bp stan... Understandable since y all like to play the feminists only when ur girls are involved\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.69 ms /    16 runs   (    0.61 ms per token,  1650.51 tokens per second)\n",
            "llama_print_timings: prompt eval time =     239.90 ms /    51 tokens (    4.70 ms per token,   212.59 tokens per second)\n",
            "llama_print_timings:        eval time =    1595.62 ms /    15 runs   (  106.37 ms per token,     9.40 tokens per second)\n",
            "llama_print_timings:       total time =    2015.18 ms /    66 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "white feminists love to focus on what muslim women choose to wear and call it oppression rather than the multitude of other things that are actually against women rights https://t.co/pw7Poqfjxx\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.78 ms /    16 runs   (    0.61 ms per token,  1635.49 tokens per second)\n",
            "llama_print_timings: prompt eval time =     263.81 ms /    68 tokens (    3.88 ms per token,   257.76 tokens per second)\n",
            "llama_print_timings:        eval time =    1557.19 ms /    15 runs   (  103.81 ms per token,     9.63 tokens per second)\n",
            "llama_print_timings:       total time =    2028.97 ms /    83 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@ShayanMusavi7 I don't understand why people act as if it is so ridiculous to ask this question. There are feminists who protest to \"free the nipple.\" Prohibiting women from going topless while allowing men to is literally a sexist distinction based on physical differences.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.80 ms /    16 runs   (    0.67 ms per token,  1482.03 tokens per second)\n",
            "llama_print_timings: prompt eval time =     241.29 ms /    41 tokens (    5.89 ms per token,   169.92 tokens per second)\n",
            "llama_print_timings:        eval time =    1877.68 ms /    15 runs   (  125.18 ms per token,     7.99 tokens per second)\n",
            "llama_print_timings:       total time =    2343.62 ms /    56 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Before we know it the #socialists will ban the names \"Manafort\" and \"Bill\". #feminists will punch anyone with those names. #CommonSense\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.66 ms /    16 runs   (    0.54 ms per token,  1848.22 tokens per second)\n",
            "llama_print_timings: prompt eval time =     717.04 ms /    27 tokens (   26.56 ms per token,    37.65 tokens per second)\n",
            "llama_print_timings:        eval time =    1547.61 ms /    15 runs   (  103.17 ms per token,     9.69 tokens per second)\n",
            "llama_print_timings:       total time =    2397.89 ms /    42 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@fellawhomstdve The forced feminization is worth it to watch Bluey with my kid.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.02 ms /    16 runs   (    0.56 ms per token,  1774.03 tokens per second)\n",
            "llama_print_timings: prompt eval time =     707.14 ms /    27 tokens (   26.19 ms per token,    38.18 tokens per second)\n",
            "llama_print_timings:        eval time =    1605.56 ms /    15 runs   (  107.04 ms per token,     9.34 tokens per second)\n",
            "llama_print_timings:       total time =    2441.01 ms /    42 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "I think id be into forced feminization, like done to me. Yeah i think so🫠\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.64 ms /    16 runs   (    0.54 ms per token,  1851.64 tokens per second)\n",
            "llama_print_timings: prompt eval time =     568.51 ms /    32 tokens (   17.77 ms per token,    56.29 tokens per second)\n",
            "llama_print_timings:        eval time =    1689.10 ms /    15 runs   (  112.61 ms per token,     8.88 tokens per second)\n",
            "llama_print_timings:       total time =    2392.30 ms /    47 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Forced feminization phone sex sissy fantasy https://t.co/ypbzrls5NQ\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       3.84 ms /     5 runs   (    0.77 ms per token,  1300.73 tokens per second)\n",
            "llama_print_timings: prompt eval time =     278.04 ms /    95 tokens (    2.93 ms per token,   341.67 tokens per second)\n",
            "llama_print_timings:        eval time =     483.10 ms /     4 runs   (  120.78 ms per token,     8.28 tokens per second)\n",
            "llama_print_timings:       total time =    1154.72 ms /    99 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Look at this fucking tiny dick sissy loser @SissyBrenda2 Such a pathetic excuse for a man. #sissy #sissymaid #feminization #sissypansy @Mistress_DJ Look at her pretty pink nails.  @TheBossySmurf @JennOTK https://t.co/WGeiOHoVo2\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.77 ms /    16 runs   (    0.61 ms per token,  1638.34 tokens per second)\n",
            "llama_print_timings: prompt eval time =     350.56 ms /   155 tokens (    2.26 ms per token,   442.15 tokens per second)\n",
            "llama_print_timings:        eval time =    1598.06 ms /    15 runs   (  106.54 ms per token,     9.39 tokens per second)\n",
            "llama_print_timings:       total time =    2692.88 ms /   170 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "#Chicago #Ohare Aug.29thAug.31st#DMV #EDGING #TANTRA #MISTRESS #NURU #PEGGING #BONDASSAGE #FINDOM #FETISH #CROSSDRESSING  #FANTASY #SISSYTRAINING #FEMINIZATION #CHICAGOBDSM #COMPANION #SPINNER #ARLINGTON #MILKING #TAMPA  #PHILLY #DOMINATION #BDSM #SPINNER #KINK #RUINEDORGASMS https://t.co/4eGlT4bhrS\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.18 ms /    16 runs   (    0.57 ms per token,  1743.68 tokens per second)\n",
            "llama_print_timings: prompt eval time =     750.35 ms /    30 tokens (   25.01 ms per token,    39.98 tokens per second)\n",
            "llama_print_timings:        eval time =    1560.39 ms /    15 runs   (  104.03 ms per token,     9.61 tokens per second)\n",
            "llama_print_timings:       total time =    2444.41 ms /    45 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "The forced feminization scene is actually unexpectedly discrete https://t.co/MEvxHfP9zr\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.31 ms /    16 runs   (    0.58 ms per token,  1718.95 tokens per second)\n",
            "llama_print_timings: prompt eval time =     239.46 ms /    46 tokens (    5.21 ms per token,   192.10 tokens per second)\n",
            "llama_print_timings:        eval time =    1673.51 ms /    15 runs   (  111.57 ms per token,     8.96 tokens per second)\n",
            "llama_print_timings:       total time =    2083.09 ms /    61 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@ara_hagopian For fun I even memorized a soliloquy (and a sonnet) for a girl who was taking a Shakespeare class and performed it in Starbucks.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.60 ms /    16 runs   (    0.60 ms per token,  1667.01 tokens per second)\n",
            "llama_print_timings: prompt eval time =     250.96 ms /    53 tokens (    4.74 ms per token,   211.19 tokens per second)\n",
            "llama_print_timings:        eval time =    1580.14 ms /    15 runs   (  105.34 ms per token,     9.49 tokens per second)\n",
            "llama_print_timings:       total time =    2016.28 ms /    68 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@reddit_lies My older son was often mistaken for a girl as a baby.  He had blond curls and big blue eyes.  He didn't know people were doing it because he was a baby, just like this kid\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.72 ms /    16 runs   (    0.67 ms per token,  1493.09 tokens per second)\n",
            "llama_print_timings: prompt eval time =     260.49 ms /    44 tokens (    5.92 ms per token,   168.91 tokens per second)\n",
            "llama_print_timings:        eval time =    1781.39 ms /    15 runs   (  118.76 ms per token,     8.42 tokens per second)\n",
            "llama_print_timings:       total time =    2309.34 ms /    59 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Looking cute for a girl who's gonna be killed by Goblins tonight (I'm in a play) https://t.co/gvBTbpwplr\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.80 ms /    16 runs   (    0.55 ms per token,  1819.01 tokens per second)\n",
            "llama_print_timings: prompt eval time =     641.19 ms /    24 tokens (   26.72 ms per token,    37.43 tokens per second)\n",
            "llama_print_timings:        eval time =    1553.32 ms /    15 runs   (  103.55 ms per token,     9.66 tokens per second)\n",
            "llama_print_timings:       total time =    2318.17 ms /    39 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Im a sucka for a girl with that curly Afro look 🤤\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.99 ms /    16 runs   (    0.56 ms per token,  1779.95 tokens per second)\n",
            "llama_print_timings: prompt eval time =     241.14 ms /    47 tokens (    5.13 ms per token,   194.91 tokens per second)\n",
            "llama_print_timings:        eval time =    1521.30 ms /    15 runs   (  101.42 ms per token,     9.86 tokens per second)\n",
            "llama_print_timings:       total time =    1941.99 ms /    62 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "someone woke up and thought \"Ah yes, C.LiTZ is a good name for a girl group.\" 💀💀 https://t.co/WuRULxWkUZ\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.56 ms /    16 runs   (    0.60 ms per token,  1672.94 tokens per second)\n",
            "llama_print_timings: prompt eval time =     289.75 ms /   103 tokens (    2.81 ms per token,   355.48 tokens per second)\n",
            "llama_print_timings:        eval time =    1610.97 ms /    15 runs   (  107.40 ms per token,     9.31 tokens per second)\n",
            "llama_print_timings:       total time =    2174.87 ms /   118 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@DelaneyKirk @Michelewrites3 She bonded to my older sister, born a premie, but I was born and isolated as the result of a nursery epidemic (I didn't get the bug), we didn't bond 11 days after my caesarean delivery &amp; I wasn't the boy she wanted, she didn't have a name in mind for a girl. Sister died at 7.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.50 ms /    16 runs   (    0.72 ms per token,  1390.82 tokens per second)\n",
            "llama_print_timings: prompt eval time =     361.65 ms /   136 tokens (    2.66 ms per token,   376.06 tokens per second)\n",
            "llama_print_timings:        eval time =    1846.46 ms /    15 runs   (  123.10 ms per token,     8.12 tokens per second)\n",
            "llama_print_timings:       total time =    2920.10 ms /   151 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Lota51716938 @RhiaClifton @MaestroZidane3 @DarkGentlewoman @MotherlodeMami @Villytineejims @Erikag0920 @Jasmineraine__ @NotHill_ different perspective: For a woman it can be empowering to take control of her income and do that in a way that also lets her have fun. Shes not giving up her body. Shes giving a service. Objectifying is a problem with ya'll because you can't seperate the person from the service.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.35 ms /    16 runs   (    0.58 ms per token,  1710.68 tokens per second)\n",
            "llama_print_timings: prompt eval time =     248.73 ms /    37 tokens (    6.72 ms per token,   148.76 tokens per second)\n",
            "llama_print_timings:        eval time =    1697.75 ms /    15 runs   (  113.18 ms per token,     8.84 tokens per second)\n",
            "llama_print_timings:       total time =    2102.29 ms /    52 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "for a woman who sang this song with every throat muscle she got? OF COURSEhttps://t.co/2L9FAY8ml7\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.74 ms /    16 runs   (    0.61 ms per token,  1642.71 tokens per second)\n",
            "llama_print_timings: prompt eval time =     262.68 ms /    47 tokens (    5.59 ms per token,   178.93 tokens per second)\n",
            "llama_print_timings:        eval time =    1583.48 ms /    15 runs   (  105.57 ms per token,     9.47 tokens per second)\n",
            "llama_print_timings:       total time =    2033.81 ms /    62 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "venice bitch,cinnamon girl e hope is a dangerous thing  for a woman like me to have – but i have it https://t.co/J6V3pK4NTa\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.02 ms /    16 runs   (    0.56 ms per token,  1774.03 tokens per second)\n",
            "llama_print_timings: prompt eval time =     238.83 ms /    35 tokens (    6.82 ms per token,   146.55 tokens per second)\n",
            "llama_print_timings:        eval time =    1619.12 ms /    15 runs   (  107.94 ms per token,     9.26 tokens per second)\n",
            "llama_print_timings:       total time =    2024.73 ms /    50 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@WildTig39125246 For the bathroom either. For a woman that's unheard of at events\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.90 ms /    16 runs   (    0.68 ms per token,  1467.62 tokens per second)\n",
            "llama_print_timings: prompt eval time =     283.38 ms /   112 tokens (    2.53 ms per token,   395.22 tokens per second)\n",
            "llama_print_timings:        eval time =    1761.37 ms /    15 runs   (  117.42 ms per token,     8.52 tokens per second)\n",
            "llama_print_timings:       total time =    2378.01 ms /   127 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@NeeclousL @ViralDetroit @FoxNews @GovRonDeSantis It is our duty to rebel against unjust laws. It is deeply American. It was once legal to own a human being.It was once illegal for a woman to vote.It was once legal to refuse service to someone based on their skin color.It was once illegal to marry the same gender. 🇺🇲👩🏿‍⚖️🌈\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.76 ms /    16 runs   (    0.55 ms per token,  1827.32 tokens per second)\n",
            "llama_print_timings: prompt eval time =     706.70 ms /    26 tokens (   27.18 ms per token,    36.79 tokens per second)\n",
            "llama_print_timings:        eval time =    1625.46 ms /    15 runs   (  108.36 ms per token,     9.23 tokens per second)\n",
            "llama_print_timings:       total time =    2460.60 ms /    41 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@itskokets0 Is it okay for a woman to take out her food and eat in public?\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.01 ms /    16 runs   (    0.63 ms per token,  1598.24 tokens per second)\n",
            "llama_print_timings: prompt eval time =     297.89 ms /   118 tokens (    2.52 ms per token,   396.12 tokens per second)\n",
            "llama_print_timings:        eval time =    1569.10 ms /    15 runs   (  104.61 ms per token,     9.56 tokens per second)\n",
            "llama_print_timings:       total time =    2189.36 ms /   133 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@gxxnar @PrizemArtNft @ZenNfties @nftcoinlaundry @HICeeCee @iKreate_ @iKCTeam1 @Vdk_Music @JenniKristen_ @MegaRetroNFT @cybervenus Job jobbed. What’s next? Am I actually a free woman. The sense of a life’s task completed was both overwhelming and underwhelming at the same time. As she was coming to terms with this…\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.06 ms /    16 runs   (    0.57 ms per token,  1766.00 tokens per second)\n",
            "llama_print_timings: prompt eval time =     659.60 ms /    25 tokens (   26.38 ms per token,    37.90 tokens per second)\n",
            "llama_print_timings:        eval time =    1648.88 ms /    15 runs   (  109.93 ms per token,     9.10 tokens per second)\n",
            "llama_print_timings:       total time =    2429.80 ms /    40 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@mmpadellan How is Ginni Thomas still living her best life as a free woman?\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.59 ms /    16 runs   (    0.72 ms per token,  1381.10 tokens per second)\n",
            "llama_print_timings: prompt eval time =     246.00 ms /    57 tokens (    4.32 ms per token,   231.71 tokens per second)\n",
            "llama_print_timings:        eval time =    1885.38 ms /    15 runs   (  125.69 ms per token,     7.96 tokens per second)\n",
            "llama_print_timings:       total time =    2350.21 ms /    72 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "How is a slave's Awrah being different to a free woman related to state-mandated laws? There are no slaves now. How is this ruling relevant to bring up? https://t.co/RhcSQbRaZk\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.91 ms /    16 runs   (    0.62 ms per token,  1614.86 tokens per second)\n",
            "llama_print_timings: prompt eval time =     286.09 ms /    67 tokens (    4.27 ms per token,   234.19 tokens per second)\n",
            "llama_print_timings:        eval time =    1491.63 ms /    15 runs   (   99.44 ms per token,    10.06 tokens per second)\n",
            "llama_print_timings:       total time =    1986.83 ms /    82 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Angry_Staffer Their Red Caps have squeezed out their brain cells. Hillary sat on live tv for over 9 hours and answered all questions and is A FREE woman. These A**hole* only repeat because they don’t read! The Orange Man is a Con PERIOD!\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.47 ms /    16 runs   (    0.59 ms per token,  1689.01 tokens per second)\n",
            "llama_print_timings: prompt eval time =     258.18 ms /    67 tokens (    3.85 ms per token,   259.51 tokens per second)\n",
            "llama_print_timings:        eval time =    1531.01 ms /    15 runs   (  102.07 ms per token,     9.80 tokens per second)\n",
            "llama_print_timings:       total time =    1995.60 ms /    82 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "•the entire Babylon choreo• Gaga walking in the middle of the crowd during free woman• singing born this way both acoustic and pop version• how she comes out as a little ant alien and just looks at the crowd before taking her helmet off• “AAAAaaAAH” in shallow\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.40 ms /    16 runs   (    0.59 ms per token,  1702.31 tokens per second)\n",
            "llama_print_timings: prompt eval time =     279.44 ms /    82 tokens (    3.41 ms per token,   293.44 tokens per second)\n",
            "llama_print_timings:        eval time =    1557.51 ms /    15 runs   (  103.83 ms per token,     9.63 tokens per second)\n",
            "llama_print_timings:       total time =    2076.29 ms /    97 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@davidmn316 @someofmyuncommo Neither gentile nor Jew, slangs nor free, woman nor man no more.Your claim about divorce tells me your theology is lazy. Your use of hate tells me you are no Christian. Your self-righteous attitude tells me you’re going to be mighty surprised on Judgement Day.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.34 ms /    16 runs   (    0.65 ms per token,  1547.99 tokens per second)\n",
            "llama_print_timings: prompt eval time =     282.24 ms /    71 tokens (    3.98 ms per token,   251.56 tokens per second)\n",
            "llama_print_timings:        eval time =    1653.74 ms /    15 runs   (  110.25 ms per token,     9.07 tokens per second)\n",
            "llama_print_timings:       total time =    2167.86 ms /    86 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "I'm so sick of the wife on sitcoms written as never wanting sex. Women are sexual beings. Look at the sales of romance books. These writers paint the wife as 'frigid' rather than the reality ... the husband doesn't prioritise her pleasure. Women want sex. Just good sex.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.46 ms /    16 runs   (    0.65 ms per token,  1529.49 tokens per second)\n",
            "llama_print_timings: prompt eval time =     292.05 ms /    66 tokens (    4.42 ms per token,   225.99 tokens per second)\n",
            "llama_print_timings:        eval time =    1682.71 ms /    15 runs   (  112.18 ms per token,     8.91 tokens per second)\n",
            "llama_print_timings:       total time =    2295.50 ms /    81 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Down his chin. Having cum twice over on the frigid fingers of his king. Still reeling with confusion on what's happening and why. So when mbj again grabs hold of him and positions himself close, sqh isn't paying enough attention to realize what he's doing\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.71 ms /    16 runs   (    0.54 ms per token,  1836.13 tokens per second)\n",
            "llama_print_timings: prompt eval time =     243.95 ms /    35 tokens (    6.97 ms per token,   143.47 tokens per second)\n",
            "llama_print_timings:        eval time =    1559.43 ms /    15 runs   (  103.96 ms per token,     9.62 tokens per second)\n",
            "llama_print_timings:       total time =    1944.66 ms /    50 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Best Tent Stoves To Go From Frigid To Cozy Camping https://t.co/F0w3wwce6s\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.84 ms /    16 runs   (    0.55 ms per token,  1810.36 tokens per second)\n",
            "llama_print_timings: prompt eval time =     801.45 ms /    31 tokens (   25.85 ms per token,    38.68 tokens per second)\n",
            "llama_print_timings:        eval time =    1610.85 ms /    15 runs   (  107.39 ms per token,     9.31 tokens per second)\n",
            "llama_print_timings:       total time =    2544.14 ms /    46 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Colteastwood Grab that nice warm coastal day!!!! BUT I know that water is still frigid 🤣😂.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.41 ms /    16 runs   (    0.59 ms per token,  1699.60 tokens per second)\n",
            "llama_print_timings: prompt eval time =     274.76 ms /    70 tokens (    3.93 ms per token,   254.77 tokens per second)\n",
            "llama_print_timings:        eval time =    1477.03 ms /    15 runs   (   98.47 ms per token,    10.16 tokens per second)\n",
            "llama_print_timings:       total time =    1963.84 ms /    85 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@BillfromBoynton No doubt. The bottom line is that football is a sport that requires you to face the elements. The Dolphins must learn to be successful in frigid temps late in the year. Teams coming to South Florida in September need to bring their pickle juice. Pretty straight forward.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.70 ms /    16 runs   (    0.67 ms per token,  1495.33 tokens per second)\n",
            "llama_print_timings: prompt eval time =     263.19 ms /    36 tokens (    7.31 ms per token,   136.78 tokens per second)\n",
            "llama_print_timings:        eval time =    1781.39 ms /    15 runs   (  118.76 ms per token,     8.42 tokens per second)\n",
            "llama_print_timings:       total time =    2290.63 ms /    51 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "no one is coming with me to check for the lost city of atlantis in the frigid black water beneath the ship i hate this family\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.77 ms /    16 runs   (    0.55 ms per token,  1823.57 tokens per second)\n",
            "llama_print_timings: prompt eval time =     251.95 ms /    39 tokens (    6.46 ms per token,   154.79 tokens per second)\n",
            "llama_print_timings:        eval time =    1497.27 ms /    15 runs   (   99.82 ms per token,    10.02 tokens per second)\n",
            "llama_print_timings:       total time =    1898.55 ms /    54 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@sourpatchlyds You're right but they're not wrong.  Fuck that cunt and her dear dead dad's dusty corpse.\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.95 ms /    16 runs   (    0.56 ms per token,  1788.31 tokens per second)\n",
            "llama_print_timings: prompt eval time =     241.35 ms /    43 tokens (    5.61 ms per token,   178.16 tokens per second)\n",
            "llama_print_timings:        eval time =    1479.24 ms /    15 runs   (   98.62 ms per token,    10.14 tokens per second)\n",
            "llama_print_timings:       total time =    1894.90 ms /    58 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@TeddyboyQPR @Spiegel_8 @PzRyan_ @CelticFC Fuck that cunt queen. She’s in a box where she belongs\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.73 ms /    16 runs   (    0.55 ms per token,  1831.71 tokens per second)\n",
            "llama_print_timings: prompt eval time =     652.01 ms /    25 tokens (   26.08 ms per token,    38.34 tokens per second)\n",
            "llama_print_timings:        eval time =    1579.89 ms /    15 runs   (  105.33 ms per token,     9.49 tokens per second)\n",
            "llama_print_timings:       total time =    2349.91 ms /    40 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@ask_aubry Made me so angry I couldn't finish watching. Fuck that cunt\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.38 ms /    16 runs   (    0.71 ms per token,  1405.73 tokens per second)\n",
            "llama_print_timings: prompt eval time =     248.16 ms /    52 tokens (    4.77 ms per token,   209.55 tokens per second)\n",
            "llama_print_timings:        eval time =    1781.50 ms /    15 runs   (  118.77 ms per token,     8.42 tokens per second)\n",
            "llama_print_timings:       total time =    2244.20 ms /    67 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@oneunderscore__ I don't often say things like this on twitter, but as far as Alex Jones is concerned, fuck that cunt.Humiliate him, bankrupt him, imprison him, then repeat.\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.18 ms /    16 runs   (    0.57 ms per token,  1742.73 tokens per second)\n",
            "llama_print_timings: prompt eval time =     697.33 ms /    27 tokens (   25.83 ms per token,    38.72 tokens per second)\n",
            "llama_print_timings:        eval time =    1506.49 ms /    15 runs   (  100.43 ms per token,     9.96 tokens per second)\n",
            "llama_print_timings:       total time =    2331.25 ms /    42 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@_pixlsugr @TwitchSupport Reported that shit frame 1. Fuck that cunt.\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.50 ms /    16 runs   (    0.59 ms per token,  1684.74 tokens per second)\n",
            "llama_print_timings: prompt eval time =     247.27 ms /    60 tokens (    4.12 ms per token,   242.65 tokens per second)\n",
            "llama_print_timings:        eval time =    1506.23 ms /    15 runs   (  100.42 ms per token,     9.96 tokens per second)\n",
            "llama_print_timings:       total time =    1948.39 ms /    75 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@DrJamesOlsson Karma is all i can say,after my uncle served and was killed in vietnam,she had to go and suck up to the north vietnamese,fuck that cunt is what my aunt's family says.\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.36 ms /    16 runs   (    0.59 ms per token,  1709.04 tokens per second)\n",
            "llama_print_timings: prompt eval time =     255.71 ms /    55 tokens (    4.65 ms per token,   215.09 tokens per second)\n",
            "llama_print_timings:        eval time =    1538.09 ms /    15 runs   (  102.54 ms per token,     9.75 tokens per second)\n",
            "llama_print_timings:       total time =    1973.52 ms /    70 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "I need to be gangbanged by multiple tall, curvy, hung futanari. One blonde, one redhead, one brunette, and one with black hair. Just using me for hours. That's the dream.\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.38 ms /    16 runs   (    0.59 ms per token,  1706.67 tokens per second)\n",
            "llama_print_timings: prompt eval time =     271.64 ms /    95 tokens (    2.86 ms per token,   349.73 tokens per second)\n",
            "llama_print_timings:        eval time =    1635.69 ms /    15 runs   (  109.05 ms per token,     9.17 tokens per second)\n",
            "llama_print_timings:       total time =    2178.94 ms /   110 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Bollywood whore wife Deepika Padukone loves to be gangbanged by BBC 💦💦💦💦💦💦💦💦💦💦💦💦💦💦 https://t.co/4OqEsbTQNd\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.72 ms /    16 runs   (    0.67 ms per token,  1492.40 tokens per second)\n",
            "llama_print_timings: prompt eval time =     264.57 ms /    52 tokens (    5.09 ms per token,   196.54 tokens per second)\n",
            "llama_print_timings:        eval time =    1715.66 ms /    15 runs   (  114.38 ms per token,     8.74 tokens per second)\n",
            "llama_print_timings:       total time =    2267.16 ms /    67 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@AnarchoNudity I only got gangbanged on Christmas by four fellow trans folks, it was nearly perfect ngl 😭❤Istg I've become tame with the pandemic, and not willfully\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.09 ms /    16 runs   (    0.57 ms per token,  1759.60 tokens per second)\n",
            "llama_print_timings: prompt eval time =     240.17 ms /    36 tokens (    6.67 ms per token,   149.89 tokens per second)\n",
            "llama_print_timings:        eval time =    1501.98 ms /    15 runs   (  100.13 ms per token,     9.99 tokens per second)\n",
            "llama_print_timings:       total time =    1894.08 ms /    51 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Like it or not you been gangbanged by this dude! #Hexicans https://t.co/gGTzZ1sMp5\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.88 ms /    16 runs   (    0.55 ms per token,  1802.82 tokens per second)\n",
            "llama_print_timings: prompt eval time =     636.72 ms /    25 tokens (   25.47 ms per token,    39.26 tokens per second)\n",
            "llama_print_timings:        eval time =    1586.24 ms /    15 runs   (  105.75 ms per token,     9.46 tokens per second)\n",
            "llama_print_timings:       total time =    2345.06 ms /    40 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "I’m a simple man. I just want to get gangbanged by the jackass crew\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.47 ms /    16 runs   (    0.53 ms per token,  1888.80 tokens per second)\n",
            "llama_print_timings: prompt eval time =     680.26 ms /    27 tokens (   25.19 ms per token,    39.69 tokens per second)\n",
            "llama_print_timings:        eval time =    1580.65 ms /    15 runs   (  105.38 ms per token,     9.49 tokens per second)\n",
            "llama_print_timings:       total time =    2384.04 ms /    42 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Woooooow I'm really getting gangbanged by all of these fucking symptoms 😭😭😭\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.53 ms /    16 runs   (    0.66 ms per token,  1520.19 tokens per second)\n",
            "llama_print_timings: prompt eval time =     276.12 ms /    73 tokens (    3.78 ms per token,   264.38 tokens per second)\n",
            "llama_print_timings:        eval time =    1800.95 ms /    15 runs   (  120.06 ms per token,     8.33 tokens per second)\n",
            "llama_print_timings:       total time =    2453.52 ms /    88 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "What a great advisor @TracyEverbach is for presenting for her advisee during her top paper session at @CSW_AEJMC. The paper on women and music journalists is insightful work in the area of gender harassment in the field. @AEJMC #AEJMC22 #phdlife\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.76 ms /    16 runs   (    0.55 ms per token,  1825.65 tokens per second)\n",
            "llama_print_timings: prompt eval time =     254.73 ms /    43 tokens (    5.92 ms per token,   168.80 tokens per second)\n",
            "llama_print_timings:        eval time =    1488.65 ms /    15 runs   (   99.24 ms per token,    10.08 tokens per second)\n",
            "llama_print_timings:       total time =    1901.33 ms /    58 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@centrist_phone @dracudads @dandandanon @LancsLGBT @Mermaids_Gender harassment even though it’s a protect belief\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.69 ms /    16 runs   (    0.61 ms per token,  1651.02 tokens per second)\n",
            "llama_print_timings: prompt eval time =     244.30 ms /    49 tokens (    4.99 ms per token,   200.58 tokens per second)\n",
            "llama_print_timings:        eval time =    1644.53 ms /    15 runs   (  109.64 ms per token,     9.12 tokens per second)\n",
            "llama_print_timings:       total time =    2072.54 ms /    64 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@takeitexsyyy literally likened my tweet to slavery and gender harassment like please be serious twitter support does not deal with idiots https://t.co/vPqwyDDDsF\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.84 ms /    16 runs   (    0.62 ms per token,  1625.36 tokens per second)\n",
            "llama_print_timings: prompt eval time =     290.58 ms /    87 tokens (    3.34 ms per token,   299.40 tokens per second)\n",
            "llama_print_timings:        eval time =    1507.60 ms /    15 runs   (  100.51 ms per token,     9.95 tokens per second)\n",
            "llama_print_timings:       total time =    2043.06 ms /   102 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "“GSA works to advance the field of genetics, but science can’t flourish while scientists are held back by sexual and gender harassment. We are pleased to team up with other societies in confronting this pervasive problem\" says @GeneticsGSA Executive Director @editor_traceyd #SDG5 https://t.co/GKA4x4u7a1\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.84 ms /    16 runs   (    0.74 ms per token,  1351.58 tokens per second)\n",
            "llama_print_timings: prompt eval time =     255.12 ms /    57 tokens (    4.48 ms per token,   223.42 tokens per second)\n",
            "llama_print_timings:        eval time =    1784.86 ms /    15 runs   (  118.99 ms per token,     8.40 tokens per second)\n",
            "llama_print_timings:       total time =    2264.63 ms /    72 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Is it wrong that I opted out of my university's Title IX class? I know my rights re: gender harassment and discrimination. The outline stated there were sensitive subjects such as SA. As a survivor, I need to respect my boundaries.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.44 ms /    16 runs   (    0.59 ms per token,  1695.09 tokens per second)\n",
            "llama_print_timings: prompt eval time =     269.45 ms /    64 tokens (    4.21 ms per token,   237.52 tokens per second)\n",
            "llama_print_timings:        eval time =    1531.88 ms /    15 runs   (  102.13 ms per token,     9.79 tokens per second)\n",
            "llama_print_timings:       total time =    1998.29 ms /    79 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "So does he search both sexes or none at all, due to risks of sexual harassment claims. Also why if sex and gender are so different, then why don't they call it gender harassment..🤔 https://t.co/2Ufvh8Mtaq\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.56 ms /    16 runs   (    0.60 ms per token,  1673.99 tokens per second)\n",
            "llama_print_timings: prompt eval time =     261.23 ms /    70 tokens (    3.73 ms per token,   267.96 tokens per second)\n",
            "llama_print_timings:        eval time =    1498.11 ms /    15 runs   (   99.87 ms per token,    10.01 tokens per second)\n",
            "llama_print_timings:       total time =    1989.90 ms /    85 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@EricG1247 We've invested huge sums of money in \"education\" over the years. The problem is the kids are being indoctrinated in cultural nonsense. Meanwhile, Chinese 8th graders are being taught calculus, while our kids are being taught about gender identity.\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.57 ms /    16 runs   (    0.60 ms per token,  1672.07 tokens per second)\n",
            "llama_print_timings: prompt eval time =     250.94 ms /    61 tokens (    4.11 ms per token,   243.09 tokens per second)\n",
            "llama_print_timings:        eval time =    1534.42 ms /    15 runs   (  102.29 ms per token,     9.78 tokens per second)\n",
            "llama_print_timings:       total time =    1999.71 ms /    76 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "honestly \"femboy\" wouldn't exist as an anime trope—much less a distinct gender identity—if anime weren't largely made &amp;/or localized by people with a shallow understanding &amp; deep mistrust of transness as a concept\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.98 ms /    16 runs   (    0.69 ms per token,  1457.73 tokens per second)\n",
            "llama_print_timings: prompt eval time =     413.80 ms /   216 tokens (    1.92 ms per token,   521.99 tokens per second)\n",
            "llama_print_timings:        eval time =    1744.11 ms /    15 runs   (  116.27 ms per token,     8.60 tokens per second)\n",
            "llama_print_timings:       total time =    2772.39 ms /   231 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Lionheart213072 @WoopsWoah @firewirenz @Karxy__ @RJDownard @alc_anthro @EeveeFaye1 @Zirnike @TBesserwisser @TakeThatDarwin @RandomNobody86 @deadelliotts @Rob70808509 @WestDockWharf @hungtran11 @ZaBong69 @donalynette @AtheistsRead @Xenomarc @NPSpock @Raymo72135972 @DanielJNickolas @Key3Skeleton @gpike_ @JerryMcPhers @LustfulLiberal @RichardDawkins ...because it doesn't matter?Why is it such a big deal to you what someone else's gender identity is? Is this why you stroke off to your own Tweets?\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.67 ms /    16 runs   (    0.60 ms per token,  1654.77 tokens per second)\n",
            "llama_print_timings: prompt eval time =     278.33 ms /    56 tokens (    4.97 ms per token,   201.20 tokens per second)\n",
            "llama_print_timings:        eval time =    1516.98 ms /    15 runs   (  101.13 ms per token,     9.89 tokens per second)\n",
            "llama_print_timings:       total time =    2072.14 ms /    71 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@merlinmacgyver @deanime_ I'd pretty much agree with this assessment. When I'm interested in men/women/NB people, it feels like a completely different thing depending on their gender identity for whatever reason.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.12 ms /    16 runs   (    0.57 ms per token,  1754.58 tokens per second)\n",
            "llama_print_timings: prompt eval time =     240.27 ms /    37 tokens (    6.49 ms per token,   153.99 tokens per second)\n",
            "llama_print_timings:        eval time =    1596.90 ms /    15 runs   (  106.46 ms per token,     9.39 tokens per second)\n",
            "llama_print_timings:       total time =    2000.33 ms /    52 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@nathaliejacoby1 Of course; as long as the person was qualified. For me, gender identity is irrelevant to qualifying for the job.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.68 ms /    16 runs   (    0.54 ms per token,  1844.38 tokens per second)\n",
            "llama_print_timings: prompt eval time =     241.63 ms /    40 tokens (    6.04 ms per token,   165.54 tokens per second)\n",
            "llama_print_timings:        eval time =    1513.50 ms /    15 runs   (  100.90 ms per token,     9.91 tokens per second)\n",
            "llama_print_timings:       total time =    1911.26 ms /    55 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Hate Crime: At the federal level, a crime motivated by bias against race, color, religion, national origin, sexual orientation, gender, gender identity, or disability.\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.95 ms /    16 runs   (    0.56 ms per token,  1787.31 tokens per second)\n",
            "llama_print_timings: prompt eval time =     232.02 ms /    39 tokens (    5.95 ms per token,   168.09 tokens per second)\n",
            "llama_print_timings:        eval time =    1530.18 ms /    15 runs   (  102.01 ms per token,     9.80 tokens per second)\n",
            "llama_print_timings:       total time =    1922.18 ms /    54 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@VgSenpai yknow for people that say theyre breaking down traditional gender rolesthey really do like conforming to traditional gender roles.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.73 ms /    16 runs   (    0.73 ms per token,  1364.26 tokens per second)\n",
            "llama_print_timings: prompt eval time =     285.32 ms /    64 tokens (    4.46 ms per token,   224.31 tokens per second)\n",
            "llama_print_timings:        eval time =    1815.64 ms /    15 runs   (  121.04 ms per token,     8.26 tokens per second)\n",
            "llama_print_timings:       total time =    2454.07 ms /    79 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Regarding sexism, lines of traditional gender roles are sharply drawn and women aren't admitted to the priesthood. Shortly before I left the church, the Ordain Women movement, led by Kate Kelly, was trying to change that. The response was crushing from the church.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.37 ms /    16 runs   (    0.59 ms per token,  1707.58 tokens per second)\n",
            "llama_print_timings: prompt eval time =     265.61 ms /    66 tokens (    4.02 ms per token,   248.49 tokens per second)\n",
            "llama_print_timings:        eval time =    1501.00 ms /    15 runs   (  100.07 ms per token,     9.99 tokens per second)\n",
            "llama_print_timings:       total time =    1970.26 ms /    81 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Getting more men into nursing means a rethink of gender roles, pay and recognition. But we need them urgently https://t.co/keEISGMrwQ #Nurse #healthcare #NursingShortage https://t.co/nrB9EriaIA\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.69 ms /    16 runs   (    0.54 ms per token,  1841.83 tokens per second)\n",
            "llama_print_timings: prompt eval time =     247.39 ms /    41 tokens (    6.03 ms per token,   165.73 tokens per second)\n",
            "llama_print_timings:        eval time =    1481.62 ms /    15 runs   (   98.77 ms per token,    10.12 tokens per second)\n",
            "llama_print_timings:       total time =    1889.77 ms /    56 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "he's in charge of important things and I'm in charge of things that will cost more money to do myself than if I simply just bought it ✨gender roles✨\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.70 ms /    16 runs   (    0.54 ms per token,  1839.50 tokens per second)\n",
            "llama_print_timings: prompt eval time =     647.73 ms /    26 tokens (   24.91 ms per token,    40.14 tokens per second)\n",
            "llama_print_timings:        eval time =    1506.73 ms /    15 runs   (  100.45 ms per token,     9.96 tokens per second)\n",
            "llama_print_timings:       total time =    2275.43 ms /    41 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@mari_vlopz gender roles 🌚💀 fax everyone simpin man\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.90 ms /    16 runs   (    0.68 ms per token,  1468.43 tokens per second)\n",
            "llama_print_timings: prompt eval time =     240.90 ms /    50 tokens (    4.82 ms per token,   207.56 tokens per second)\n",
            "llama_print_timings:        eval time =    1849.10 ms /    15 runs   (  123.27 ms per token,     8.11 tokens per second)\n",
            "llama_print_timings:       total time =    2305.64 ms /    65 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@charleybarley74 Yes. Yes they do. Because GC's are just misogynists who are simultaneously angry with their own misogyny and still believe everything they have been told about gender roles.\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.82 ms /    16 runs   (    0.55 ms per token,  1813.24 tokens per second)\n",
            "llama_print_timings: prompt eval time =     256.28 ms /    35 tokens (    7.32 ms per token,   136.57 tokens per second)\n",
            "llama_print_timings:        eval time =    1544.73 ms /    15 runs   (  102.98 ms per token,     9.71 tokens per second)\n",
            "llama_print_timings:       total time =    1943.46 ms /    50 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "JoJo printouts, the main reason WHY I went transgender was because I thought you were into noise more than sweet girl Natsuki.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.71 ms /    16 runs   (    0.54 ms per token,  1838.02 tokens per second)\n",
            "llama_print_timings: prompt eval time =     663.38 ms /    25 tokens (   26.54 ms per token,    37.69 tokens per second)\n",
            "llama_print_timings:        eval time =    1527.59 ms /    15 runs   (  101.84 ms per token,     9.82 tokens per second)\n",
            "llama_print_timings:       total time =    2308.92 ms /    40 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "‘omg you like harry styles ew’ girl stfu before i rock ur shit.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.06 ms /    16 runs   (    0.57 ms per token,  1765.81 tokens per second)\n",
            "llama_print_timings: prompt eval time =     242.34 ms /    43 tokens (    5.64 ms per token,   177.43 tokens per second)\n",
            "llama_print_timings:        eval time =    1648.52 ms /    15 runs   (  109.90 ms per token,     9.10 tokens per second)\n",
            "llama_print_timings:       total time =    2055.22 ms /    58 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "I want to get ready ready but samn yo girl needs to get these brows done. It's been like a month and half. Hopefully i can go this week for sure.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      12.49 ms /    16 runs   (    0.78 ms per token,  1280.61 tokens per second)\n",
            "llama_print_timings: prompt eval time =     685.57 ms /    26 tokens (   26.37 ms per token,    37.92 tokens per second)\n",
            "llama_print_timings:        eval time =    1628.09 ms /    15 runs   (  108.54 ms per token,     9.21 tokens per second)\n",
            "llama_print_timings:       total time =    2456.05 ms /    41 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "my mom will show me 87 videos back to back right off the walk in like damn girl?!\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.77 ms /    16 runs   (    0.55 ms per token,  1824.82 tokens per second)\n",
            "llama_print_timings: prompt eval time =     876.54 ms /    27 tokens (   32.46 ms per token,    30.80 tokens per second)\n",
            "llama_print_timings:        eval time =    1450.72 ms /    15 runs   (   96.71 ms per token,    10.34 tokens per second)\n",
            "llama_print_timings:       total time =    2497.53 ms /    42 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@pipkinpippa Oh mah gah, I wish I could be an anime girl!\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.39 ms /    16 runs   (    0.59 ms per token,  1704.30 tokens per second)\n",
            "llama_print_timings: prompt eval time =     263.30 ms /    71 tokens (    3.71 ms per token,   269.66 tokens per second)\n",
            "llama_print_timings:        eval time =    1612.06 ms /    15 runs   (  107.47 ms per token,     9.30 tokens per second)\n",
            "llama_print_timings:       total time =    2089.89 ms /    86 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@BBNaija  pls don’t play Ozo on my girl tomorrow party o🤣🤣🤣bcuz this girl can’t wait to see him tomorrow #BBNaija I don’t want to see tears on her face again https://t.co/p9voYv65Kq\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.38 ms /    16 runs   (    0.59 ms per token,  1704.85 tokens per second)\n",
            "llama_print_timings: prompt eval time =     238.21 ms /    40 tokens (    5.96 ms per token,   167.92 tokens per second)\n",
            "llama_print_timings:        eval time =    1540.71 ms /    15 runs   (  102.71 ms per token,     9.74 tokens per second)\n",
            "llama_print_timings:       total time =    1950.70 ms /    55 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Unproblematic and truly talented girls!!! Can’t wait for them to flourish more! https://t.co/lUU3P2q6cz\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.49 ms /    16 runs   (    0.59 ms per token,  1685.99 tokens per second)\n",
            "llama_print_timings: prompt eval time =     585.72 ms /    32 tokens (   18.30 ms per token,    54.63 tokens per second)\n",
            "llama_print_timings:        eval time =    1545.67 ms /    15 runs   (  103.04 ms per token,     9.70 tokens per second)\n",
            "llama_print_timings:       total time =    2279.27 ms /    47 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@kurtbardella Well girls can't wear spaghetti straps in school sooo we're already here\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.20 ms /    16 runs   (    0.70 ms per token,  1428.32 tokens per second)\n",
            "llama_print_timings: prompt eval time =     281.05 ms /    68 tokens (    4.13 ms per token,   241.95 tokens per second)\n",
            "llama_print_timings:        eval time =    1673.88 ms /    15 runs   (  111.59 ms per token,     8.96 tokens per second)\n",
            "llama_print_timings:       total time =    2309.10 ms /    83 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "My 4yo daughter told me that girls can’t marry girls and my heart breaks for all the bias and hate she’s enduring so young. I told her mommy is marrying Mama Michelle and she smiled at me really big. 🥹🥹🥹\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.56 ms /    16 runs   (    0.60 ms per token,  1672.77 tokens per second)\n",
            "llama_print_timings: prompt eval time =     237.94 ms /    40 tokens (    5.95 ms per token,   168.11 tokens per second)\n",
            "llama_print_timings:        eval time =    1683.53 ms /    15 runs   (  112.24 ms per token,     8.91 tokens per second)\n",
            "llama_print_timings:       total time =    2087.13 ms /    55 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@mancmcdonald74 My class if girls can't even want me let alone satisfy!🤭🥴🤭\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.91 ms /    16 runs   (    0.56 ms per token,  1796.54 tokens per second)\n",
            "llama_print_timings: prompt eval time =     259.17 ms /    48 tokens (    5.40 ms per token,   185.21 tokens per second)\n",
            "llama_print_timings:        eval time =    1475.88 ms /    15 runs   (   98.39 ms per token,    10.16 tokens per second)\n",
            "llama_print_timings:       total time =    1899.98 ms /    63 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "You just perfectly described your own fandom. But those girls can't even stop making music bc they never started in the first place. https://t.co/Rtj2XwRllb\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.93 ms /    16 runs   (    0.62 ms per token,  1610.95 tokens per second)\n",
            "llama_print_timings: prompt eval time =     259.40 ms /    65 tokens (    3.99 ms per token,   250.58 tokens per second)\n",
            "llama_print_timings:        eval time =    1449.35 ms /    15 runs   (   96.62 ms per token,    10.35 tokens per second)\n",
            "llama_print_timings:       total time =    1936.59 ms /    80 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@WAHS_swim_dive @hmblsrvnt Lookin Great Girls!!!! Can’t wait to see what the season brings …. SO EXCITED!!!GO LADY BLACKHAWKS!!🔴🔵👍🔴🔵😊\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.97 ms /    16 runs   (    0.69 ms per token,  1457.99 tokens per second)\n",
            "llama_print_timings: prompt eval time =     353.02 ms /   141 tokens (    2.50 ms per token,   399.41 tokens per second)\n",
            "llama_print_timings:        eval time =    1801.83 ms /    15 runs   (  120.12 ms per token,     8.32 tokens per second)\n",
            "llama_print_timings:       total time =    2748.18 ms /   156 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "pray 🙏🏻                      dirty house 🏚educated 📚             hoe 🚂a job 💰                     gold digger 🏗clean pussy 😌         stink pussy 🤢nice 🌈                       criminal ⛓loyal 💍                      5 kids 👨‍👩‍👧‍👦faithful 👼🏼                  cheater 🖇 https://t.co/nDaWhQZAg1\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.57 ms /    16 runs   (    0.60 ms per token,  1671.54 tokens per second)\n",
            "llama_print_timings: prompt eval time =     256.25 ms /    54 tokens (    4.75 ms per token,   210.73 tokens per second)\n",
            "llama_print_timings:        eval time =    1543.70 ms /    15 runs   (  102.91 ms per token,     9.72 tokens per second)\n",
            "llama_print_timings:       total time =    1978.95 ms /    69 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Now Playing : Kanye West ft Jamie Foxx - Gold Digger (Clean) -----&gt; Click link 2 listen @Beat947fm(https://t.co/nIVLSszVod)\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.28 ms /    16 runs   (    0.58 ms per token,  1723.58 tokens per second)\n",
            "llama_print_timings: prompt eval time =     256.68 ms /    54 tokens (    4.75 ms per token,   210.38 tokens per second)\n",
            "llama_print_timings:        eval time =    1541.53 ms /    15 runs   (  102.77 ms per token,     9.73 tokens per second)\n",
            "llama_print_timings:       total time =    1982.11 ms /    69 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@perfectus_est Once he and his gold digger get back home and see what they can get out of Netflix, there’ll be no thought given to his family and the book will follow. It’s all about 💰\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.38 ms /    16 runs   (    0.59 ms per token,  1706.30 tokens per second)\n",
            "llama_print_timings: prompt eval time =     238.83 ms /    38 tokens (    6.29 ms per token,   159.11 tokens per second)\n",
            "llama_print_timings:        eval time =    1515.40 ms /    15 runs   (  101.03 ms per token,     9.90 tokens per second)\n",
            "llama_print_timings:       total time =    1924.48 ms /    53 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Sumorsu1 Some brunette, some blondeSome truth seeker Some gold digger :)) #JustMarriedAbisiİdareEt\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.64 ms /    16 runs   (    0.60 ms per token,  1659.58 tokens per second)\n",
            "llama_print_timings: prompt eval time =     236.77 ms /    34 tokens (    6.96 ms per token,   143.60 tokens per second)\n",
            "llama_print_timings:        eval time =    1612.06 ms /    15 runs   (  107.47 ms per token,     9.30 tokens per second)\n",
            "llama_print_timings:       total time =    2013.61 ms /    49 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "i forgot this song was in my library omg the gleek jumped out  https://t.co/lgIa3PBRIi\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.28 ms /    16 runs   (    0.58 ms per token,  1724.51 tokens per second)\n",
            "llama_print_timings: prompt eval time =     270.41 ms /    63 tokens (    4.29 ms per token,   232.98 tokens per second)\n",
            "llama_print_timings:        eval time =    1738.98 ms /    15 runs   (  115.93 ms per token,     8.63 tokens per second)\n",
            "llama_print_timings:       total time =    2325.65 ms /    78 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@claudiaaoraha Social climbing/ambition. Gold digger/ambition. Manipulative/ambition. Find a rich husband/ambition. Become famous/ambition trash the royals/ambition. Yes she does have ambition.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.98 ms /    16 runs   (    0.56 ms per token,  1781.34 tokens per second)\n",
            "llama_print_timings: prompt eval time =     711.11 ms /    27 tokens (   26.34 ms per token,    37.97 tokens per second)\n",
            "llama_print_timings:        eval time =    1506.26 ms /    15 runs   (  100.42 ms per token,     9.96 tokens per second)\n",
            "llama_print_timings:       total time =    2345.23 ms /    42 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@overtime Yellow attempted to grab his dick first. He lucky he just got the ball bop to the head\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.82 ms /    16 runs   (    0.55 ms per token,  1814.47 tokens per second)\n",
            "llama_print_timings: prompt eval time =     243.26 ms /    44 tokens (    5.53 ms per token,   180.88 tokens per second)\n",
            "llama_print_timings:        eval time =    1585.83 ms /    15 runs   (  105.72 ms per token,     9.46 tokens per second)\n",
            "llama_print_timings:       total time =    1998.19 ms /    59 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@MZHemingway Whoops … a nobody just wasted my time.   Go grab a wubanub and look at pictures of the former guy praising neo nazis.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.20 ms /    16 runs   (    0.64 ms per token,  1568.32 tokens per second)\n",
            "llama_print_timings: prompt eval time =     271.40 ms /    84 tokens (    3.23 ms per token,   309.51 tokens per second)\n",
            "llama_print_timings:        eval time =    1489.68 ms /    15 runs   (   99.31 ms per token,    10.07 tokens per second)\n",
            "llama_print_timings:       total time =    2020.08 ms /    99 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "yet another instance (cant remember if earlier/later) but another first memory of mine was leaning out of my bedroom window to grab a live telephone line connecting our house to the telegraph polelike 4-year-old me leaning out of the window abt to fall bcs i was bored https://t.co/pOVHh7K8oI\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.15 ms /    16 runs   (    0.70 ms per token,  1435.24 tokens per second)\n",
            "llama_print_timings: prompt eval time =     238.56 ms /    33 tokens (    7.23 ms per token,   138.33 tokens per second)\n",
            "llama_print_timings:        eval time =    1794.77 ms /    15 runs   (  119.65 ms per token,     8.36 tokens per second)\n",
            "llama_print_timings:       total time =    2264.11 ms /    48 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@theeoliviap wait now let me grab a bottle on the way so we can drink it off afterwards 😝\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.88 ms /    16 runs   (    0.55 ms per token,  1802.61 tokens per second)\n",
            "llama_print_timings: prompt eval time =     788.11 ms /    31 tokens (   25.42 ms per token,    39.33 tokens per second)\n",
            "llama_print_timings:        eval time =    1477.88 ms /    15 runs   (   98.53 ms per token,    10.15 tokens per second)\n",
            "llama_print_timings:       total time =    2395.47 ms /    46 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Note only a dozen likes! How does that grab you? https://t.co/aqZJhy9sf4\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.18 ms /    16 runs   (    0.57 ms per token,  1742.35 tokens per second)\n",
            "llama_print_timings: prompt eval time =     239.22 ms /    46 tokens (    5.20 ms per token,   192.29 tokens per second)\n",
            "llama_print_timings:        eval time =    1596.46 ms /    15 runs   (  106.43 ms per token,     9.40 tokens per second)\n",
            "llama_print_timings:       total time =    2030.96 ms /    61 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@BarryBakerII @AerosolWatch Thanks Barry! The bucket does look like NRT. Yet my script, for some reason, doesn't always grab the latest... Hmmm\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.45 ms /    16 runs   (    0.59 ms per token,  1693.30 tokens per second)\n",
            "llama_print_timings: prompt eval time =     242.98 ms /    47 tokens (    5.17 ms per token,   193.43 tokens per second)\n",
            "llama_print_timings:        eval time =    1608.34 ms /    15 runs   (  107.22 ms per token,     9.33 tokens per second)\n",
            "llama_print_timings:       total time =    2031.16 ms /    62 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@BrittanyVenti C'mon nowWal-Mart employees don't have enough spine to harass people to donate, the fear of a manager getting away with targeted harassment broke them years ago\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      12.87 ms /    16 runs   (    0.80 ms per token,  1243.49 tokens per second)\n",
            "llama_print_timings: prompt eval time =     294.28 ms /   107 tokens (    2.75 ms per token,   363.60 tokens per second)\n",
            "llama_print_timings:        eval time =    1796.27 ms /    15 runs   (  119.75 ms per token,     8.35 tokens per second)\n",
            "llama_print_timings:       total time =    2521.44 ms /   122 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@lynnethjean @JohnFetterman \"so great to see you back, healthy and well!\" from his latest PA taxpayer-paid vacation to NEW JERSEY after \"almost dying\" &amp; then grifting for nickels from the poor &amp; middle class of PA, while spending mommy and daddy's money to buy shotgun ammunition to harass innocent Blacks. https://t.co/QhtbCQQdd5\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.07 ms /    16 runs   (    0.57 ms per token,  1764.64 tokens per second)\n",
            "llama_print_timings: prompt eval time =     294.22 ms /    87 tokens (    3.38 ms per token,   295.70 tokens per second)\n",
            "llama_print_timings:        eval time =    1657.41 ms /    15 runs   (  110.49 ms per token,     9.05 tokens per second)\n",
            "llama_print_timings:       total time =    2193.15 ms /   102 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@amfitryti she is so obsessed with u. crazy crazy crazy crazy chick. holy shit. not her sending her boyfriend to ur xbox dms to harass u even though she's been stalking u for 3 years and u have proof on proof on proof. Man is helen keller levels of blind and deaf to be ignoring these 🚩🚩\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       3.13 ms /     5 runs   (    0.63 ms per token,  1599.49 tokens per second)\n",
            "llama_print_timings: prompt eval time =     256.57 ms /    63 tokens (    4.07 ms per token,   245.55 tokens per second)\n",
            "llama_print_timings:        eval time =     404.22 ms /     4 runs   (  101.05 ms per token,     9.90 tokens per second)\n",
            "llama_print_timings:       total time =     819.64 ms /    67 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@laurenboebert Shouldn’t you be serving up some hoof and mouth burgers to your penis exposing husband?  Or, maybe you’d rather harass your neighbors today and threaten them?   Instead, you’re wasting your time here on Twitter.\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.97 ms /    16 runs   (    0.56 ms per token,  1783.33 tokens per second)\n",
            "llama_print_timings: prompt eval time =     232.25 ms /    42 tokens (    5.53 ms per token,   180.84 tokens per second)\n",
            "llama_print_timings:        eval time =    1491.10 ms /    15 runs   (   99.41 ms per token,    10.06 tokens per second)\n",
            "llama_print_timings:       total time =    1912.16 ms /    57 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@BrunoCa86996577 @NickDNapolitano Bruno you’re only allowed to harass me and Matt. No this is not Matt\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.54 ms /    16 runs   (    0.60 ms per token,  1676.97 tokens per second)\n",
            "llama_print_timings: prompt eval time =     241.28 ms /    50 tokens (    4.83 ms per token,   207.23 tokens per second)\n",
            "llama_print_timings:        eval time =    1506.51 ms /    15 runs   (  100.43 ms per token,     9.96 tokens per second)\n",
            "llama_print_timings:       total time =    1938.85 ms /    65 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@GOPChairwoman Sounds like voter harassment, brutality, bullying, threatening.Are you handing out guns to your election thugs?Come to NY-6 and try and harass me, Ronna\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.68 ms /    16 runs   (    0.73 ms per token,  1370.45 tokens per second)\n",
            "llama_print_timings: prompt eval time =     261.80 ms /    72 tokens (    3.64 ms per token,   275.01 tokens per second)\n",
            "llama_print_timings:        eval time =    1818.72 ms /    15 runs   (  121.25 ms per token,     8.25 tokens per second)\n",
            "llama_print_timings:       total time =    2458.58 ms /    87 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@chairmanmaostan To break this world order, we must break the US hegemony, to break the US hegemony, we must beat it at their own gameThis is the order of things, you can't jump the gun, because if communism cannot militarily/economically defeat the existing world order...\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.53 ms /    16 runs   (    0.60 ms per token,  1678.73 tokens per second)\n",
            "llama_print_timings: prompt eval time =     260.39 ms /    60 tokens (    4.34 ms per token,   230.43 tokens per second)\n",
            "llama_print_timings:        eval time =    1549.05 ms /    15 runs   (  103.27 ms per token,     9.68 tokens per second)\n",
            "llama_print_timings:       total time =    2004.64 ms /    75 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Yes, but after men's hegemony on the patriarchal system. They conform to be safe from all that imaginable consequence. Seperti ibunya RA Kartini. https://t.co/5yl1RRx1Ka\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.80 ms /    16 runs   (    0.61 ms per token,  1632.32 tokens per second)\n",
            "llama_print_timings: prompt eval time =     271.90 ms /    69 tokens (    3.94 ms per token,   253.77 tokens per second)\n",
            "llama_print_timings:        eval time =    1540.34 ms /    15 runs   (  102.69 ms per token,     9.74 tokens per second)\n",
            "llama_print_timings:       total time =    2021.60 ms /    84 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@IvyShoots @scrowder Then we are both good. Look how little we managed to accomplice other than metatalking about the talking itself. We could've discussed the specifics of hegemony but alas here we are, still divided and (not) pissed off.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.35 ms /    16 runs   (    0.58 ms per token,  1711.41 tokens per second)\n",
            "llama_print_timings: prompt eval time =     241.20 ms /    35 tokens (    6.89 ms per token,   145.11 tokens per second)\n",
            "llama_print_timings:        eval time =    1624.44 ms /    15 runs   (  108.30 ms per token,     9.23 tokens per second)\n",
            "llama_print_timings:       total time =    2023.14 ms /    50 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@ManagerTactical @jonmark93 Man City has won 4/5 and Barca/Madrid have a hegemony in Spain\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.62 ms /    16 runs   (    0.66 ms per token,  1507.16 tokens per second)\n",
            "llama_print_timings: prompt eval time =     275.25 ms /    94 tokens (    2.93 ms per token,   341.51 tokens per second)\n",
            "llama_print_timings:        eval time =    1632.00 ms /    15 runs   (  108.80 ms per token,     9.19 tokens per second)\n",
            "llama_print_timings:       total time =    2193.85 ms /   109 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Russia is the first modern country to break through the obsolete Right-Left Dialectic. It is for them not left and right but Anti-Anglo-American Establishment Hegemony or to be for it as Yeltsin did. More countries need to understand politics this way. Esp. In America. #MAGA2024 https://t.co/w5MYwSrrB3\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.90 ms /    16 runs   (    0.62 ms per token,  1616.32 tokens per second)\n",
            "llama_print_timings: prompt eval time =     261.43 ms /    45 tokens (    5.81 ms per token,   172.13 tokens per second)\n",
            "llama_print_timings:        eval time =    1647.25 ms /    15 runs   (  109.82 ms per token,     9.11 tokens per second)\n",
            "llama_print_timings:       total time =    2164.36 ms /    60 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Putin: \"The End of Western Hegemony is INEVITABLE\", by @KonstantinKisin https://t.co/7DJeU6NfuQ\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.00 ms /    16 runs   (    0.56 ms per token,  1778.57 tokens per second)\n",
            "llama_print_timings: prompt eval time =     247.64 ms /    47 tokens (    5.27 ms per token,   189.79 tokens per second)\n",
            "llama_print_timings:        eval time =    1540.10 ms /    15 runs   (  102.67 ms per token,     9.74 tokens per second)\n",
            "llama_print_timings:       total time =    1958.37 ms /    62 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Thanks to the incredible @iDiplomacy, #HerStory is back to grace your timeline this Wednesday at 3pm ET! https://t.co/Qvnm3Jufdi\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.27 ms /    16 runs   (    0.58 ms per token,  1725.44 tokens per second)\n",
            "llama_print_timings: prompt eval time =     236.94 ms /    42 tokens (    5.64 ms per token,   177.26 tokens per second)\n",
            "llama_print_timings:        eval time =    1507.19 ms /    15 runs   (  100.48 ms per token,     9.95 tokens per second)\n",
            "llama_print_timings:       total time =    1914.32 ms /    57 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Congratulations to the inductees into the inaugural @ACUMuseum Herstory Hall of Fame! https://t.co/pm3JDnUPOc\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.94 ms /    16 runs   (    0.56 ms per token,  1790.31 tokens per second)\n",
            "llama_print_timings: prompt eval time =     240.50 ms /    33 tokens (    7.29 ms per token,   137.22 tokens per second)\n",
            "llama_print_timings:        eval time =    1513.54 ms /    15 runs   (  100.90 ms per token,     9.91 tokens per second)\n",
            "llama_print_timings:       total time =    1907.40 ms /    48 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "this is herstory. the world’s first renaissance video https://t.co/nbn39415Qi\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.86 ms /    16 runs   (    0.74 ms per token,  1349.19 tokens per second)\n",
            "llama_print_timings: prompt eval time =     266.88 ms /    52 tokens (    5.13 ms per token,   194.84 tokens per second)\n",
            "llama_print_timings:        eval time =    1820.02 ms /    15 runs   (  121.33 ms per token,     8.24 tokens per second)\n",
            "llama_print_timings:       total time =    2405.48 ms /    67 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Congratulations @fsinations Vice-Chief @AlyBear2021 on making #HERstory 👏🏽👏🏽👏🏽https://t.co/M2SpxjIYAk\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.52 ms /    16 runs   (    0.59 ms per token,  1681.20 tokens per second)\n",
            "llama_print_timings: prompt eval time =     262.11 ms /    63 tokens (    4.16 ms per token,   240.35 tokens per second)\n",
            "llama_print_timings:        eval time =    1541.84 ms /    15 runs   (  102.79 ms per token,     9.73 tokens per second)\n",
            "llama_print_timings:       total time =    2006.16 ms /    78 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "🗞️ Herstory International Theatre Festival Opening Night In Soweto👉 https://t.co/TAkXD2PqUX📸 @Oujay_Bopape https://t.co/48VElPR23a\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.96 ms /    16 runs   (    0.56 ms per token,  1784.72 tokens per second)\n",
            "llama_print_timings: prompt eval time =     782.70 ms /    29 tokens (   26.99 ms per token,    37.05 tokens per second)\n",
            "llama_print_timings:        eval time =    1531.38 ms /    15 runs   (  102.09 ms per token,     9.80 tokens per second)\n",
            "llama_print_timings:       total time =    2445.22 ms /    44 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@LVAces @Usher @Bellagio @AriaLV @parkmgm Herstory*\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.59 ms /    16 runs   (    0.54 ms per token,  1863.50 tokens per second)\n",
            "llama_print_timings: prompt eval time =     236.02 ms /    33 tokens (    7.15 ms per token,   139.82 tokens per second)\n",
            "llama_print_timings:        eval time =    1470.36 ms /    15 runs   (   98.02 ms per token,    10.20 tokens per second)\n",
            "llama_print_timings:       total time =    1867.98 ms /    48 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Oh, looks like the Hips Didn’t Lie this time. https://t.co/Yej3QOQfSM\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.75 ms /    16 runs   (    0.67 ms per token,  1488.93 tokens per second)\n",
            "llama_print_timings: prompt eval time =     243.64 ms /    47 tokens (    5.18 ms per token,   192.91 tokens per second)\n",
            "llama_print_timings:        eval time =    1767.76 ms /    15 runs   (  117.85 ms per token,     8.49 tokens per second)\n",
            "llama_print_timings:       total time =    2209.07 ms /    62 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "that one run bts episode where yoongi said we just wanted to see hoseoks hips on bapsae and jimin said “my hips worked hard too😟”😭😭\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.61 ms /    16 runs   (    0.60 ms per token,  1665.45 tokens per second)\n",
            "llama_print_timings: prompt eval time =     266.42 ms /    44 tokens (    6.05 ms per token,   165.15 tokens per second)\n",
            "llama_print_timings:        eval time =    1499.66 ms /    15 runs   (   99.98 ms per token,    10.00 tokens per second)\n",
            "llama_print_timings:       total time =    2003.62 ms /    59 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "my hair was getting down to my thighs and i finally cut it back to my hips...before i realized i forgot to take a photo of me reaching my goal length ☹️\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.85 ms /    16 runs   (    0.62 ms per token,  1624.37 tokens per second)\n",
            "llama_print_timings: prompt eval time =     269.07 ms /    87 tokens (    3.09 ms per token,   323.33 tokens per second)\n",
            "llama_print_timings:        eval time =    1499.55 ms /    15 runs   (   99.97 ms per token,    10.00 tokens per second)\n",
            "llama_print_timings:       total time =    2024.43 ms /   102 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "People see the Child-Bearing Hips, but think it's just a Fat Old Man who loves Hamburgers &amp; Fast Foods💉😷😴\"We accept the reality of the world with which we are presented\" - Christof, 'The Truman Show' https://t.co/aJQN1kLd4s\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.73 ms /    16 runs   (    0.61 ms per token,  1644.91 tokens per second)\n",
            "llama_print_timings: prompt eval time =     276.53 ms /    94 tokens (    2.94 ms per token,   339.92 tokens per second)\n",
            "llama_print_timings:        eval time =    1543.84 ms /    15 runs   (  102.92 ms per token,     9.72 tokens per second)\n",
            "llama_print_timings:       total time =    2089.24 ms /   109 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "‘Oh. Guess I won’t kill ya fer that…’Juri turned around in full and placed her hands on her hips. He certainly looked better, but it just made her chuckle.‘Hell of a weight loss program ya got goin’ there. That shit permanent? Well, congrats, I guess, but ya better hope it - https://t.co/OiDI4ql8o4\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.94 ms /    16 runs   (    0.56 ms per token,  1790.11 tokens per second)\n",
            "llama_print_timings: prompt eval time =     241.42 ms /    36 tokens (    6.71 ms per token,   149.12 tokens per second)\n",
            "llama_print_timings:        eval time =    1473.24 ms /    15 runs   (   98.22 ms per token,    10.18 tokens per second)\n",
            "llama_print_timings:       total time =    1874.38 ms /    51 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "i love how they both have their hands on their hips and are staring judgingly https://t.co/zou0KCNu7B\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.97 ms /    16 runs   (    0.69 ms per token,  1458.92 tokens per second)\n",
            "llama_print_timings: prompt eval time =     261.89 ms /    48 tokens (    5.46 ms per token,   183.28 tokens per second)\n",
            "llama_print_timings:        eval time =    1732.19 ms /    15 runs   (  115.48 ms per token,     8.66 tokens per second)\n",
            "llama_print_timings:       total time =    2296.40 ms /    63 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "yall b sayin men shouldn’t hit women but like if i see a nigga knockin niggas out 1 by 1 y would i jump in like i could rock his ass?\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.29 ms /    16 runs   (    0.64 ms per token,  1554.61 tokens per second)\n",
            "llama_print_timings: prompt eval time =     263.81 ms /    74 tokens (    3.56 ms per token,   280.51 tokens per second)\n",
            "llama_print_timings:        eval time =    1582.62 ms /    15 runs   (  105.51 ms per token,     9.48 tokens per second)\n",
            "llama_print_timings:       total time =    2089.02 ms /    89 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@JustKaz1 @HamAndNutella The entire thing. While I strongly believe that men should not hit women; women must understand that an action can quickly cause a reaction. We’re seeing too many physical altercations between both parties, so at the end of the day, both should learn to keep hands to themselves\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.98 ms /    16 runs   (    0.56 ms per token,  1782.33 tokens per second)\n",
            "llama_print_timings: prompt eval time =     711.96 ms /    25 tokens (   28.48 ms per token,    35.11 tokens per second)\n",
            "llama_print_timings:        eval time =    1564.88 ms /    15 runs   (  104.33 ms per token,     9.59 tokens per second)\n",
            "llama_print_timings:       total time =    2399.53 ms /    40 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@slaz_is_here gigachad sigma male rule #1: hit women do drugs\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.32 ms /    16 runs   (    0.58 ms per token,  1716.37 tokens per second)\n",
            "llama_print_timings: prompt eval time =     241.66 ms /    49 tokens (    4.93 ms per token,   202.76 tokens per second)\n",
            "llama_print_timings:        eval time =    1621.76 ms /    15 runs   (  108.12 ms per token,     9.25 tokens per second)\n",
            "llama_print_timings:       total time =    2044.73 ms /    64 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@49COLLECTIONS @acloudystoryX If you like go dey do \"men shouldn't hit women\" and don't keep your hands to yourself. You go collect jagajaga.\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      12.19 ms /    16 runs   (    0.76 ms per token,  1312.87 tokens per second)\n",
            "llama_print_timings: prompt eval time =     267.06 ms /    74 tokens (    3.61 ms per token,   277.09 tokens per second)\n",
            "llama_print_timings:        eval time =    1965.73 ms /    15 runs   (  131.05 ms per token,     7.63 tokens per second)\n",
            "llama_print_timings:       total time =    2630.03 ms /    89 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Crises hit women &amp; girls especially hard. The COVID-19 pandemic pushed an estimated additional 47 million girls and women into extreme poverty, reversing decades of progress. To ease the world food crisis, resources need to focus on women and girls https://t.co/RHbhoX9bDG\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.50 ms /    16 runs   (    0.59 ms per token,  1685.10 tokens per second)\n",
            "llama_print_timings: prompt eval time =     276.58 ms /    66 tokens (    4.19 ms per token,   238.63 tokens per second)\n",
            "llama_print_timings:        eval time =    1638.57 ms /    15 runs   (  109.24 ms per token,     9.15 tokens per second)\n",
            "llama_print_timings:       total time =    2143.85 ms /    81 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Another hill I'm ready to die on, the moment a woman gets physical with I'm matching her energy. Nothing like \"don't hit women \" . Touch me first ,you'll collect woto woto. https://t.co/zJTJoLA3vs\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.84 ms /    16 runs   (    0.62 ms per token,  1625.69 tokens per second)\n",
            "llama_print_timings: prompt eval time =     288.01 ms /    70 tokens (    4.11 ms per token,   243.05 tokens per second)\n",
            "llama_print_timings:        eval time =    1513.37 ms /    15 runs   (  100.89 ms per token,     9.91 tokens per second)\n",
            "llama_print_timings:       total time =    2017.95 ms /    85 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Y’all! My husband is taking our daughter to her first concert - Lady Gaga!! I’m in awe of this special dad/daughter evening and I’m happy to be home and relax. #ladygagaconcert https://t.co/ojWZ8nKKfK\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.88 ms /    16 runs   (    0.56 ms per token,  1800.99 tokens per second)\n",
            "llama_print_timings: prompt eval time =     237.04 ms /    37 tokens (    6.41 ms per token,   156.09 tokens per second)\n",
            "llama_print_timings:        eval time =    1572.72 ms /    15 runs   (  104.85 ms per token,     9.54 tokens per second)\n",
            "llama_print_timings:       total time =    1973.64 ms /    52 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "This guy's crying again?  If my husband is crying over some chick we are bankrolled...??? Good grief. #seekingsisterwife\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.63 ms /    16 runs   (    0.60 ms per token,  1661.13 tokens per second)\n",
            "llama_print_timings: prompt eval time =     235.98 ms /    36 tokens (    6.55 ms per token,   152.56 tokens per second)\n",
            "llama_print_timings:        eval time =    1719.16 ms /    15 runs   (  114.61 ms per token,     8.73 tokens per second)\n",
            "llama_print_timings:       total time =    2132.08 ms /    51 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "lady on tiktok said yo husband could neva they in the comments tammat my husband bet not eva😂😂😂😂😂😂😂\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.08 ms /    16 runs   (    0.63 ms per token,  1586.83 tokens per second)\n",
            "llama_print_timings: prompt eval time =     255.45 ms /    34 tokens (    7.51 ms per token,   133.10 tokens per second)\n",
            "llama_print_timings:        eval time =    1550.16 ms /    15 runs   (  103.34 ms per token,     9.68 tokens per second)\n",
            "llama_print_timings:       total time =    2012.74 ms /    49 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@laurenboebert This is a periodic reminder that Lauren's husband was convicted of whipping his cock out in front of minor children\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.95 ms /    16 runs   (    0.62 ms per token,  1607.72 tokens per second)\n",
            "llama_print_timings: prompt eval time =     295.43 ms /   110 tokens (    2.69 ms per token,   372.33 tokens per second)\n",
            "llama_print_timings:        eval time =    1438.66 ms /    15 runs   (   95.91 ms per token,    10.43 tokens per second)\n",
            "llama_print_timings:       total time =    2038.68 ms /   125 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@deadgirlwendi @abbri2016 @yolon_gish2022 @DutchyPatrick Well I did learn about that one at my first dinner party w/my husband. I was the only American there…when I said “I fell on my fanny” (thinking how quaint that was instead of saying butt)…total silence.Then my husband said, “She’s American.”Everyone: Ahhhh ok carry on.🤷‍♀️\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.63 ms /    16 runs   (    0.60 ms per token,  1662.16 tokens per second)\n",
            "llama_print_timings: prompt eval time =     240.53 ms /    48 tokens (    5.01 ms per token,   199.56 tokens per second)\n",
            "llama_print_timings:        eval time =    1499.42 ms /    15 runs   (   99.96 ms per token,    10.00 tokens per second)\n",
            "llama_print_timings:       total time =    1923.19 ms /    63 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Heels_In_TheAir apparently he has two jobs. Part timers. But yet is up all night with MGL and he has twins that go to school. His husband works in DC all week\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.91 ms /    16 runs   (    0.56 ms per token,  1796.14 tokens per second)\n",
            "llama_print_timings: prompt eval time =     726.72 ms /    30 tokens (   24.22 ms per token,    41.28 tokens per second)\n",
            "llama_print_timings:        eval time =    1527.85 ms /    15 runs   (  101.86 ms per token,     9.82 tokens per second)\n",
            "llama_print_timings:       total time =    2390.14 ms /    45 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@YeriiBlossom @UltraThaGoat @mortysuperfan U said I hate women\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.06 ms /    16 runs   (    0.69 ms per token,  1446.00 tokens per second)\n",
            "llama_print_timings: prompt eval time =     395.55 ms /   154 tokens (    2.57 ms per token,   389.33 tokens per second)\n",
            "llama_print_timings:        eval time =    1665.82 ms /    15 runs   (  111.05 ms per token,     9.00 tokens per second)\n",
            "llama_print_timings:       total time =    2828.55 ms /   169 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Suit_2021 @SheHulkOfficial @HAWTToys @Nerdrotics @ReelShiftJoe Translation of this douche's rambling:\"GRRR, I HATE women! They no like me, no date me! WOKE BAD! WIMMENZ LIB BAD! TV ABT ANYTHING BESIDES WHITE STR8 MEN BAD!\"Also, \"PLZ WIMMENZ TOUCH MAH PEE-PEE JUST ONCE, I'M SO LONELY\" fapfapfapGet bent, incel. #SheHulk was amazing.\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.05 ms /    16 runs   (    0.57 ms per token,  1766.98 tokens per second)\n",
            "llama_print_timings: prompt eval time =     581.65 ms /    21 tokens (   27.70 ms per token,    36.10 tokens per second)\n",
            "llama_print_timings:        eval time =    1580.70 ms /    15 runs   (  105.38 ms per token,     9.49 tokens per second)\n",
            "llama_print_timings:       total time =    2277.68 ms /    36 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "I Hate Women Who Let Down Other Women Without A Solid Reason.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.65 ms /    16 runs   (    0.60 ms per token,  1658.03 tokens per second)\n",
            "llama_print_timings: prompt eval time =     242.21 ms /    51 tokens (    4.75 ms per token,   210.56 tokens per second)\n",
            "llama_print_timings:        eval time =    1479.34 ms /    15 runs   (   98.62 ms per token,    10.14 tokens per second)\n",
            "llama_print_timings:       total time =    1903.64 ms /    66 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "You can ask politely where it comes from and I’ll tell you. Plus, ‘how can I hate women, my bitch is a woman’ https://t.co/8SX0Zbw1LX\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.71 ms /    16 runs   (    0.54 ms per token,  1837.81 tokens per second)\n",
            "llama_print_timings: prompt eval time =     753.85 ms /    31 tokens (   24.32 ms per token,    41.12 tokens per second)\n",
            "llama_print_timings:        eval time =    1565.73 ms /    15 runs   (  104.38 ms per token,     9.58 tokens per second)\n",
            "llama_print_timings:       total time =    2453.17 ms /    46 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@EpicFunnyName I mean, I hate women, and I’d let Elizabeth Olsen sit on me.\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.66 ms /    16 runs   (    0.67 ms per token,  1500.94 tokens per second)\n",
            "llama_print_timings: prompt eval time =     249.66 ms /    37 tokens (    6.75 ms per token,   148.20 tokens per second)\n",
            "llama_print_timings:        eval time =    1758.84 ms /    15 runs   (  117.26 ms per token,     8.53 tokens per second)\n",
            "llama_print_timings:       total time =    2265.39 ms /    52 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "See, I could promote our stuff pretty good, but people would call me misogynistic and think I hate women... Not going through that shit again.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.04 ms /    16 runs   (    0.57 ms per token,  1769.72 tokens per second)\n",
            "llama_print_timings: prompt eval time =     602.39 ms /    22 tokens (   27.38 ms per token,    36.52 tokens per second)\n",
            "llama_print_timings:        eval time =    1454.78 ms /    15 runs   (   96.99 ms per token,    10.31 tokens per second)\n",
            "llama_print_timings:       total time =    2174.25 ms /    37 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@chylkara_ @vlovelyrose mother i would like to fuck\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.99 ms /    16 runs   (    0.56 ms per token,  1779.16 tokens per second)\n",
            "llama_print_timings: prompt eval time =     660.67 ms /    25 tokens (   26.43 ms per token,    37.84 tokens per second)\n",
            "llama_print_timings:        eval time =    1566.28 ms /    15 runs   (  104.42 ms per token,     9.58 tokens per second)\n",
            "llama_print_timings:       total time =    2349.21 ms /    40 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@dimababych @pan_sodom DilfDaddy I would Like to Fuck\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.59 ms /    16 runs   (    0.54 ms per token,  1861.76 tokens per second)\n",
            "llama_print_timings: prompt eval time =     594.49 ms /    24 tokens (   24.77 ms per token,    40.37 tokens per second)\n",
            "llama_print_timings:        eval time =    1576.54 ms /    15 runs   (  105.10 ms per token,     9.51 tokens per second)\n",
            "llama_print_timings:       total time =    2290.38 ms /    39 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@milia_eldritch I would like to fuck you mommy 🥺🥺🥺🥺\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.10 ms /    16 runs   (    0.69 ms per token,  1441.44 tokens per second)\n",
            "llama_print_timings: prompt eval time =     841.16 ms /    28 tokens (   30.04 ms per token,    33.29 tokens per second)\n",
            "llama_print_timings:        eval time =    1820.34 ms /    15 runs   (  121.36 ms per token,     8.24 tokens per second)\n",
            "llama_print_timings:       total time =    2873.24 ms /    43 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "i think i would like to fuck this man https://t.co/swuhMU43L8\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.17 ms /    16 runs   (    0.57 ms per token,  1744.25 tokens per second)\n",
            "llama_print_timings: prompt eval time =     249.27 ms /    48 tokens (    5.19 ms per token,   192.56 tokens per second)\n",
            "llama_print_timings:        eval time =    1581.77 ms /    15 runs   (  105.45 ms per token,     9.48 tokens per second)\n",
            "llama_print_timings:       total time =    2006.28 ms /    63 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "if i was his best friend i would like to fuck him while having lunch !😘🔥🥵🥵 https://t.co/WjTInXekHV\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.56 ms /    16 runs   (    0.60 ms per token,  1674.34 tokens per second)\n",
            "llama_print_timings: prompt eval time =     245.85 ms /    55 tokens (    4.47 ms per token,   223.71 tokens per second)\n",
            "llama_print_timings:        eval time =    1524.14 ms /    15 runs   (  101.61 ms per token,     9.84 tokens per second)\n",
            "llama_print_timings:       total time =    1963.83 ms /    70 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@ShadiestBabe dumbass loli defenders trying to claim that \"aaanybody can be a loli, loli DOESN'T inherently mean female child i would like to fuck\"ROLLS EYES\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.79 ms /    16 runs   (    0.61 ms per token,  1633.65 tokens per second)\n",
            "llama_print_timings: prompt eval time =     270.00 ms /    70 tokens (    3.86 ms per token,   259.26 tokens per second)\n",
            "llama_print_timings:        eval time =    1472.53 ms /    15 runs   (   98.17 ms per token,    10.19 tokens per second)\n",
            "llama_print_timings:       total time =    1959.98 ms /    85 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Florida is taking a huge step back today, and the regressive ideology that is being pushed by the GOP knows no limits. It is time to accept that the GOP is anti-science and will continue down a fascistic path. https://t.co/xQtCLiUsx2\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.21 ms /    16 runs   (    0.58 ms per token,  1738.00 tokens per second)\n",
            "llama_print_timings: prompt eval time =     256.77 ms /    71 tokens (    3.62 ms per token,   276.51 tokens per second)\n",
            "llama_print_timings:        eval time =    1735.51 ms /    15 runs   (  115.70 ms per token,     8.64 tokens per second)\n",
            "llama_print_timings:       total time =    2231.75 ms /    86 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "To any pro-statism individuals: heavily censored “public” media is 100% free of charge while uncensored media comes with a price tag, which consumers gladly pay (probably including yourself).This doesn’t cause you to question the inherent worthlessness of your ideology at all??\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.27 ms /    16 runs   (    0.58 ms per token,  1725.44 tokens per second)\n",
            "llama_print_timings: prompt eval time =     253.62 ms /    39 tokens (    6.50 ms per token,   153.77 tokens per second)\n",
            "llama_print_timings:        eval time =    1577.27 ms /    15 runs   (  105.15 ms per token,     9.51 tokens per second)\n",
            "llama_print_timings:       total time =    2073.70 ms /    54 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@joncoopertweets No the worst decision in t.v was for media in general to align themselves with any woke, liberal or socialist ideology.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.44 ms /    16 runs   (    0.59 ms per token,  1695.63 tokens per second)\n",
            "llama_print_timings: prompt eval time =     263.13 ms /    59 tokens (    4.46 ms per token,   224.22 tokens per second)\n",
            "llama_print_timings:        eval time =    1554.01 ms /    15 runs   (  103.60 ms per token,     9.65 tokens per second)\n",
            "llama_print_timings:       total time =    2001.66 ms /    74 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Money talks - Ideology walksPrinciples are easy! Ask any 2yr old or 🐒  Greed is a powerful thing.#ETH #BTC https://t.co/JUUfJVJG4g\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.75 ms /    16 runs   (    0.55 ms per token,  1827.94 tokens per second)\n",
            "llama_print_timings: prompt eval time =     275.26 ms /    90 tokens (    3.06 ms per token,   326.96 tokens per second)\n",
            "llama_print_timings:        eval time =    1564.33 ms /    15 runs   (  104.29 ms per token,     9.59 tokens per second)\n",
            "llama_print_timings:       total time =    2092.12 ms /   105 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Dan Bongino Conducts a “Fascism Check” on Democrats - https://t.co/ItGmuj51n3 Authoritarian charisma, cronyism, nationalize services, gov't/big business, media/teachers propagandize government, political ideology, no dissent, secret police, kangaroo courts, politicize police/art\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.91 ms /    16 runs   (    0.56 ms per token,  1795.13 tokens per second)\n",
            "llama_print_timings: prompt eval time =     270.35 ms /    86 tokens (    3.14 ms per token,   318.11 tokens per second)\n",
            "llama_print_timings:        eval time =    1588.68 ms /    15 runs   (  105.91 ms per token,     9.44 tokens per second)\n",
            "llama_print_timings:       total time =    2103.43 ms /   101 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@CaliforniaFirst Stop 👏🏻 speaking 👏🏻 over 👏🏻 trans 👏🏻 women 👏🏻Your comments are extremely harmful. Not to mention your far-right, white supremacist ideology prevents you from seeing that the US is the real aggressor here. As a progressive oppression-olympic athlete she had no other choice 💔😢\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.89 ms /    16 runs   (    0.74 ms per token,  1345.44 tokens per second)\n",
            "llama_print_timings: prompt eval time =     289.82 ms /    80 tokens (    3.62 ms per token,   276.03 tokens per second)\n",
            "llama_print_timings:        eval time =    1800.65 ms /    15 runs   (  120.04 ms per token,     8.33 tokens per second)\n",
            "llama_print_timings:       total time =    2496.65 ms /    95 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Leslieoo7 @RpsAgainstTrump “Not bad people” but they are vehemently pro forced birth(per your admission) meaning they are willing to kill women to get their way. And voting for gun-toting republicans that vote to keep guns in the hands of domestic terrorists. I wouldnt consider them “good people”.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.16 ms /    16 runs   (    0.64 ms per token,  1574.49 tokens per second)\n",
            "llama_print_timings: prompt eval time =     262.41 ms /    65 tokens (    4.04 ms per token,   247.70 tokens per second)\n",
            "llama_print_timings:        eval time =    1470.26 ms /    15 runs   (   98.02 ms per token,    10.20 tokens per second)\n",
            "llama_print_timings:       total time =    1943.48 ms /    80 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@jocelynhurndall I won't even mention Iranian protests (apparently another non-apartheid country but kill women for not covering their hair) or the 10 Kurds on Iraqi land that Iranian rockets killed today. what a disgrace.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.97 ms /    16 runs   (    0.56 ms per token,  1784.32 tokens per second)\n",
            "llama_print_timings: prompt eval time =     235.39 ms /    38 tokens (    6.19 ms per token,   161.43 tokens per second)\n",
            "llama_print_timings:        eval time =    1467.31 ms /    15 runs   (   97.82 ms per token,    10.22 tokens per second)\n",
            "llama_print_timings:       total time =    1872.97 ms /    53 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Some men kill women. Some make do with character assassination. Both crimes mostly emanating from patriarchy/sense of inferiority/ need to control.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.59 ms /    16 runs   (    0.60 ms per token,  1668.23 tokens per second)\n",
            "llama_print_timings: prompt eval time =     266.68 ms /    69 tokens (    3.86 ms per token,   258.74 tokens per second)\n",
            "llama_print_timings:        eval time =    1619.55 ms /    15 runs   (  107.97 ms per token,     9.26 tokens per second)\n",
            "llama_print_timings:       total time =    2097.76 ms /    84 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "#BoycottCVS for withholding lifesaving medications from women who aren't even pregnant!CVS would kill women who need treatment rather than follow doctors' prescriptions.#VoteWithYourWallet#BotcottCVS https://t.co/bODWze4gYr\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.41 ms /    16 runs   (    0.71 ms per token,  1402.52 tokens per second)\n",
            "llama_print_timings: prompt eval time =     282.90 ms /    98 tokens (    2.89 ms per token,   346.41 tokens per second)\n",
            "llama_print_timings:        eval time =    1819.88 ms /    15 runs   (  121.33 ms per token,     8.24 tokens per second)\n",
            "llama_print_timings:       total time =    2401.85 ms /   113 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Jonatha04031958 @AstorAaron @Mourning_Time @jamie_reinhold I think one could argue that if you do not view - and society agrees - that a fetus is a separate human, that you lack the intent to kill. Women in distress are sold abortions that have been legal. Someone in that situation may have difficulty appreciating that a life is ended.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.03 ms /    16 runs   (    0.56 ms per token,  1771.48 tokens per second)\n",
            "llama_print_timings: prompt eval time =     603.77 ms /    32 tokens (   18.87 ms per token,    53.00 tokens per second)\n",
            "llama_print_timings:        eval time =    1591.81 ms /    15 runs   (  106.12 ms per token,     9.42 tokens per second)\n",
            "llama_print_timings:       total time =    2328.81 ms /    47 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@NoLieWithBTC Well, R's are voting to kill women, so it makes sense there'd be blowback\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.65 ms /    16 runs   (    0.60 ms per token,  1657.17 tokens per second)\n",
            "llama_print_timings: prompt eval time =     272.95 ms /    92 tokens (    2.97 ms per token,   337.06 tokens per second)\n",
            "llama_print_timings:        eval time =    1621.97 ms /    15 runs   (  108.13 ms per token,     9.25 tokens per second)\n",
            "llama_print_timings:       total time =    2184.38 ms /   107 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@YourCPAcoach @BacicotBj @DisabledJess .... the language I used was precisely because it IS so stupid. \"Boys like blue and football and machines and guns and being laddish\" etc. is bollocks, it's based on what society has told them what makes them a boy. If a student came to me and said they wanted to be a midwife ...\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.89 ms /    16 runs   (    0.62 ms per token,  1617.31 tokens per second)\n",
            "llama_print_timings: prompt eval time =     260.59 ms /    72 tokens (    3.62 ms per token,   276.30 tokens per second)\n",
            "llama_print_timings:        eval time =    1482.59 ms /    15 runs   (   98.84 ms per token,    10.12 tokens per second)\n",
            "llama_print_timings:       total time =    1974.66 ms /    87 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "\"Laddish swagger\" - BBC, Ulster. The good people ⁦@DistroKid⁩ have added our track \"A Happy Heart\" to their Alternative - playlist by DistroKid | Spotify https://t.co/A941LUX5mD\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.40 ms /    16 runs   (    0.65 ms per token,  1538.91 tokens per second)\n",
            "llama_print_timings: prompt eval time =     264.21 ms /    83 tokens (    3.18 ms per token,   314.15 tokens per second)\n",
            "llama_print_timings:        eval time =    1801.82 ms /    15 runs   (  120.12 ms per token,     8.32 tokens per second)\n",
            "llama_print_timings:       total time =    2343.54 ms /    98 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@JeremyVineOn5 No to damehoods.Womens team have had overcome much greater adversity than male teams &amp; to achieve this win &amp; they are a credit to the nation &amp; inspiration to all girls but we really do need to be careful not to create a laddish cultureWith perspective they won a match not a war\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.96 ms /    16 runs   (    0.62 ms per token,  1606.75 tokens per second)\n",
            "llama_print_timings: prompt eval time =     295.04 ms /    77 tokens (    3.83 ms per token,   260.98 tokens per second)\n",
            "llama_print_timings:        eval time =    1557.79 ms /    15 runs   (  103.85 ms per token,     9.63 tokens per second)\n",
            "llama_print_timings:       total time =    2222.25 ms /    92 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "As I'm cycling away, the blond lad detaches his bicycle seat and is walking towards me, very clear threat of assault, him trying to reframe me cycling away as \"he cycled away because he was scared\". I really hate this laddish \"banter\" culture that exists in this city. (4/8)\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.66 ms /    16 runs   (    0.60 ms per token,  1656.49 tokens per second)\n",
            "llama_print_timings: prompt eval time =     248.09 ms /    61 tokens (    4.07 ms per token,   245.88 tokens per second)\n",
            "llama_print_timings:        eval time =    1558.70 ms /    15 runs   (  103.91 ms per token,     9.62 tokens per second)\n",
            "llama_print_timings:       total time =    2005.55 ms /    76 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@jonsopel @AngelaRayner “Waspish”? Misogynist?. Bully boy line?  Laddish line?  Any of those appropriate? Try following Truss and stay silent if that’s your best effort to demean .\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.64 ms /    16 runs   (    0.60 ms per token,  1659.58 tokens per second)\n",
            "llama_print_timings: prompt eval time =     263.72 ms /    75 tokens (    3.52 ms per token,   284.39 tokens per second)\n",
            "llama_print_timings:        eval time =    1529.18 ms /    15 runs   (  101.95 ms per token,     9.81 tokens per second)\n",
            "llama_print_timings:       total time =    2016.74 ms /    90 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@lavvheadinjail Fair enough. I just think that boorish, laddish bollocks stems from the way they've seen women treated in porn from a young age. I have two daughters and both told me of their boy friends watching stuff very young. Hopefully one day they'll grow up eh?\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.93 ms /    16 runs   (    0.56 ms per token,  1791.11 tokens per second)\n",
            "llama_print_timings: prompt eval time =     244.78 ms /    43 tokens (    5.69 ms per token,   175.67 tokens per second)\n",
            "llama_print_timings:        eval time =    1562.62 ms /    15 runs   (  104.17 ms per token,     9.60 tokens per second)\n",
            "llama_print_timings:       total time =    1972.10 ms /    58 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Ladies don't be shy,approach him and propose him.. we going through alot and aint noticing your green lights anymore 🙆‍♂️\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.75 ms /    16 runs   (    0.67 ms per token,  1488.23 tokens per second)\n",
            "llama_print_timings: prompt eval time =     252.16 ms /    40 tokens (    6.30 ms per token,   158.63 tokens per second)\n",
            "llama_print_timings:        eval time =    1748.08 ms /    15 runs   (  116.54 ms per token,     8.58 tokens per second)\n",
            "llama_print_timings:       total time =    2248.57 ms /    55 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Drakid7 How do people get into relationship and don’t have each other’s account number. Looks like most ladies don’t have the partners account details\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.07 ms /    16 runs   (    0.57 ms per token,  1763.86 tokens per second)\n",
            "llama_print_timings: prompt eval time =     249.30 ms /    39 tokens (    6.39 ms per token,   156.44 tokens per second)\n",
            "llama_print_timings:        eval time =    1565.38 ms /    15 runs   (  104.36 ms per token,     9.58 tokens per second)\n",
            "llama_print_timings:       total time =    1981.13 ms /    54 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "How to get a sugar daddy, ladies don’t say I did nothing for y’all https://t.co/H1tArbt500\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.84 ms /    16 runs   (    0.61 ms per token,  1626.18 tokens per second)\n",
            "llama_print_timings: prompt eval time =     274.69 ms /    73 tokens (    3.76 ms per token,   265.75 tokens per second)\n",
            "llama_print_timings:        eval time =    1480.57 ms /    15 runs   (   98.70 ms per token,    10.13 tokens per second)\n",
            "llama_print_timings:       total time =    1974.70 ms /    88 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Ladies don’t ever take any sugar cover lie men told you in the start of relationship, this very man of yours will turn his side after making you madly falling in love with him, “that yes men get irritated soon with over love” and that he don’t have feel for anything pls stop 😭\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.93 ms /    16 runs   (    0.56 ms per token,  1791.91 tokens per second)\n",
            "llama_print_timings: prompt eval time =     248.74 ms /    41 tokens (    6.07 ms per token,   164.83 tokens per second)\n",
            "llama_print_timings:        eval time =    1547.92 ms /    15 runs   (  103.19 ms per token,     9.69 tokens per second)\n",
            "llama_print_timings:       total time =    1954.33 ms /    56 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Yes, ladies!!! Don’t reject us at the onset! Reality is difficult to digest. https://t.co/q7TiYM5SmJ\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.02 ms /    16 runs   (    0.69 ms per token,  1451.64 tokens per second)\n",
            "llama_print_timings: prompt eval time =     736.51 ms /    30 tokens (   24.55 ms per token,    40.73 tokens per second)\n",
            "llama_print_timings:        eval time =    1766.05 ms /    15 runs   (  117.74 ms per token,     8.49 tokens per second)\n",
            "llama_print_timings:       total time =    2663.29 ms /    45 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Its #InternationalDogDay! Ladies, don't forget to take your man out for a walk.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.92 ms /    16 runs   (    0.56 ms per token,  1793.32 tokens per second)\n",
            "llama_print_timings: prompt eval time =     808.70 ms /    29 tokens (   27.89 ms per token,    35.86 tokens per second)\n",
            "llama_print_timings:        eval time =    1627.51 ms /    15 runs   (  108.50 ms per token,     9.22 tokens per second)\n",
            "llama_print_timings:       total time =    2572.73 ms /    44 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "feel like a lady and you my lady boy https://t.co/XfEX6oh3D9\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.20 ms /    16 runs   (    0.58 ms per token,  1739.13 tokens per second)\n",
            "llama_print_timings: prompt eval time =     244.00 ms /    54 tokens (    4.52 ms per token,   221.31 tokens per second)\n",
            "llama_print_timings:        eval time =    1601.38 ms /    15 runs   (  106.76 ms per token,     9.37 tokens per second)\n",
            "llama_print_timings:       total time =    2035.77 ms /    69 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@libsoftiktok Let the hazing begin ladies. I recommend a nice cinder block attached to a rope where the other end is attached to this dudes stick. Drop it off a building to make him really feel like a lady.\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.90 ms /    16 runs   (    0.56 ms per token,  1797.15 tokens per second)\n",
            "llama_print_timings: prompt eval time =     761.94 ms /    29 tokens (   26.27 ms per token,    38.06 tokens per second)\n",
            "llama_print_timings:        eval time =    1535.17 ms /    15 runs   (  102.34 ms per token,     9.77 tokens per second)\n",
            "llama_print_timings:       total time =    2424.16 ms /    44 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "That song Dude Looks Like a Lady but it’s Boy Looks Like an Eevee and that boy is me\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.66 ms /    16 runs   (    0.67 ms per token,  1501.22 tokens per second)\n",
            "llama_print_timings: prompt eval time =     233.61 ms /    35 tokens (    6.67 ms per token,   149.82 tokens per second)\n",
            "llama_print_timings:        eval time =    1846.84 ms /    15 runs   (  123.12 ms per token,     8.12 tokens per second)\n",
            "llama_print_timings:       total time =    2268.31 ms /    50 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Arsenal Nothing about Turner shows he’s a great keeper. This guy is shit lol, more like a lady in that goal post😂\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.83 ms /    16 runs   (    0.55 ms per token,  1811.39 tokens per second)\n",
            "llama_print_timings: prompt eval time =     261.44 ms /    43 tokens (    6.08 ms per token,   164.48 tokens per second)\n",
            "llama_print_timings:        eval time =    1487.83 ms /    15 runs   (   99.19 ms per token,    10.08 tokens per second)\n",
            "llama_print_timings:       total time =    1919.68 ms /    58 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "The adult beetle emerged from the pupa this week. Looks like a lady beetle but eats plants https://t.co/mwMSn0tu7G\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.86 ms /    16 runs   (    0.55 ms per token,  1806.68 tokens per second)\n",
            "llama_print_timings: prompt eval time =     264.21 ms /    66 tokens (    4.00 ms per token,   249.80 tokens per second)\n",
            "llama_print_timings:        eval time =    1499.37 ms /    15 runs   (   99.96 ms per token,    10.00 tokens per second)\n",
            "llama_print_timings:       total time =    1972.10 ms /    81 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@TailsChannel I just realized something very interesting, sonic has a regular looking koko in this posters, but tails has an ingenier looking koko, knuckles has a warrior koko and amy has what looks like a \"lady\" koko, it very cool\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.19 ms /    16 runs   (    0.57 ms per token,  1740.27 tokens per second)\n",
            "llama_print_timings: prompt eval time =     666.57 ms /    25 tokens (   26.66 ms per token,    37.51 tokens per second)\n",
            "llama_print_timings:        eval time =    1614.02 ms /    15 runs   (  107.60 ms per token,     9.29 tokens per second)\n",
            "llama_print_timings:       total time =    2402.59 ms /    40 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Jane5Daisy @Davidlaz There is nothing like a woman scorned !\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.75 ms /    16 runs   (    0.67 ms per token,  1488.37 tokens per second)\n",
            "llama_print_timings: prompt eval time =     260.38 ms /    71 tokens (    3.67 ms per token,   272.68 tokens per second)\n",
            "llama_print_timings:        eval time =    1618.10 ms /    15 runs   (  107.87 ms per token,     9.27 tokens per second)\n",
            "llama_print_timings:       total time =    2105.33 ms /    86 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "🎶Let me love you like a womanLet me hold you like a babyLet me shine like a diamondLet me be who I'm meant to be🎶- Lana Del Rey você é Pefeita ❤️ https://t.co/EQipfaMg8t\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.32 ms /    16 runs   (    0.65 ms per token,  1549.79 tokens per second)\n",
            "llama_print_timings: prompt eval time =     294.85 ms /    71 tokens (    4.15 ms per token,   240.80 tokens per second)\n",
            "llama_print_timings:        eval time =    1729.66 ms /    15 runs   (  115.31 ms per token,     8.67 tokens per second)\n",
            "llama_print_timings:       total time =    2383.23 ms /    86 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "one day, musa travelled back home to his village, and brought back someone he claimed was like his brother... i'd say good friends or so... but his brother, that is ibrahim, lol he's... they're the same acc, ibrahim just smiles like a woman lmao.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.43 ms /    16 runs   (    0.53 ms per token,  1897.31 tokens per second)\n",
            "llama_print_timings: prompt eval time =     237.42 ms /    40 tokens (    5.94 ms per token,   168.47 tokens per second)\n",
            "llama_print_timings:        eval time =    1579.17 ms /    15 runs   (  105.28 ms per token,     9.50 tokens per second)\n",
            "llama_print_timings:       total time =    1975.66 ms /    55 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "I definitely was forever fucked up since someone mentioned I walk like a woman and now I’m way too tuned into how I walk even though I ultimately don’t care\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.59 ms /    16 runs   (    0.60 ms per token,  1668.40 tokens per second)\n",
            "llama_print_timings: prompt eval time =     273.37 ms /    90 tokens (    3.04 ms per token,   329.23 tokens per second)\n",
            "llama_print_timings:        eval time =    1501.95 ms /    15 runs   (  100.13 ms per token,     9.99 tokens per second)\n",
            "llama_print_timings:       total time =    2034.71 ms /   105 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@biteback7 @RFU What’s creepy is cutting your d*ck off because you “feel” like a woman when in reality a man cannot know what being a woman feels like because he’s never been one (and vise versa). Also, 1000 yrs from now if scientists dug up a transwoman’s bones, they would classify him as male\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.08 ms /    16 runs   (    0.57 ms per token,  1761.34 tokens per second)\n",
            "llama_print_timings: prompt eval time =     634.35 ms /    25 tokens (   25.37 ms per token,    39.41 tokens per second)\n",
            "llama_print_timings:        eval time =    1519.06 ms /    15 runs   (  101.27 ms per token,     9.87 tokens per second)\n",
            "llama_print_timings:       total time =    2271.63 ms /    40 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@nvrbackdown11 would the exact words matter. they said he was treated like a woman\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      13.14 ms /    16 runs   (    0.82 ms per token,  1217.66 tokens per second)\n",
            "llama_print_timings: prompt eval time =     287.36 ms /    95 tokens (    3.02 ms per token,   330.59 tokens per second)\n",
            "llama_print_timings:        eval time =    1780.26 ms /    15 runs   (  118.68 ms per token,     8.43 tokens per second)\n",
            "llama_print_timings:       total time =    2521.43 ms /   110 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Bdanleaman @JonathanMirai @ARmastrangelo That’s all you’ve got? Mansplaining isn’t going to cut it. I’m merely pointing out how simple it is for you to check the sources of your disinformation.  And yes, I am at a doctoral level of education, which I highly suspect you are not.  BTW grades fr/the ignorant are nonsense!\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.22 ms /    16 runs   (    0.58 ms per token,  1734.61 tokens per second)\n",
            "llama_print_timings: prompt eval time =     250.61 ms /    45 tokens (    5.57 ms per token,   179.56 tokens per second)\n",
            "llama_print_timings:        eval time =    1532.87 ms /    15 runs   (  102.19 ms per token,     9.79 tokens per second)\n",
            "llama_print_timings:       total time =    1959.46 ms /    60 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Frances_Coppola That's my mansplaining, free for all, budget for today. Tomorrow I shall address tumble driers, via my substack premium account.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.34 ms /    16 runs   (    0.58 ms per token,  1712.33 tokens per second)\n",
            "llama_print_timings: prompt eval time =     277.19 ms /    90 tokens (    3.08 ms per token,   324.69 tokens per second)\n",
            "llama_print_timings:        eval time =    1591.49 ms /    15 runs   (  106.10 ms per token,     9.43 tokens per second)\n",
            "llama_print_timings:       total time =    2130.20 ms /   105 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@jablair1230 @StayAtHomeTrans @grace_scouten @ClevelandTom3 @marieprairiee You seem to think that because you found her argument poorly articulated, it's natural to offer her a critique of how she's expressing herself. Everything about that whole event is what women mean when we talk about mansplaining. /3\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.98 ms /    16 runs   (    0.62 ms per token,  1603.69 tokens per second)\n",
            "llama_print_timings: prompt eval time =     287.41 ms /    87 tokens (    3.30 ms per token,   302.70 tokens per second)\n",
            "llama_print_timings:        eval time =    1464.19 ms /    15 runs   (   97.61 ms per token,    10.24 tokens per second)\n",
            "llama_print_timings:       total time =    1998.35 ms /   102 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@unprodigal_sun @thehumanspiderx @athitrov @milkygoddess If you want to help ppl, cook some healthy food for your depressed friend and drop it off for them (without expecting them to interact with you). Or offer to clean their house so they can use their limited energy elsewhere. Etc. Mansplaining the obvious doesn’t help anyone.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.22 ms /    16 runs   (    0.70 ms per token,  1426.15 tokens per second)\n",
            "llama_print_timings: prompt eval time =     241.74 ms /    48 tokens (    5.04 ms per token,   198.56 tokens per second)\n",
            "llama_print_timings:        eval time =    1788.10 ms /    15 runs   (  119.21 ms per token,     8.39 tokens per second)\n",
            "llama_print_timings:       total time =    2236.65 ms /    63 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "outta the gate he complains about being blocked for mansplaining atwood, come onis this everyone’s first day online, or is being mad at imaginary people just too fun to pass up?\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.34 ms /    16 runs   (    0.58 ms per token,  1712.33 tokens per second)\n",
            "llama_print_timings: prompt eval time =     261.22 ms /    41 tokens (    6.37 ms per token,   156.95 tokens per second)\n",
            "llama_print_timings:        eval time =    1488.27 ms /    15 runs   (   99.22 ms per token,    10.08 tokens per second)\n",
            "llama_print_timings:       total time =    1984.51 ms /    56 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "says the man who tells women that actually they're the ones mansplaining him... https://t.co/Jn38b47iYd\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.19 ms /    16 runs   (    0.51 ms per token,  1954.32 tokens per second)\n",
            "llama_print_timings: prompt eval time =     664.60 ms /    26 tokens (   25.56 ms per token,    39.12 tokens per second)\n",
            "llama_print_timings:        eval time =    1499.50 ms /    15 runs   (   99.97 ms per token,    10.00 tokens per second)\n",
            "llama_print_timings:       total time =    2289.12 ms /    41 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "me n my cat manspreading n bed. this is life. this is happiness lmfao\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.94 ms /    16 runs   (    0.62 ms per token,  1609.66 tokens per second)\n",
            "llama_print_timings: prompt eval time =     251.82 ms /    56 tokens (    4.50 ms per token,   222.38 tokens per second)\n",
            "llama_print_timings:        eval time =    1535.44 ms /    15 runs   (  102.36 ms per token,     9.77 tokens per second)\n",
            "llama_print_timings:       total time =    1984.07 ms /    71 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@yujin_micah ...shit man I ACTUALLY BLUSHED UGHH HAHHA DAMN IT MICAH!! your manspreading babygirling omega-pheromoning has gone too far!!\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.60 ms /    16 runs   (    0.66 ms per token,  1509.72 tokens per second)\n",
            "llama_print_timings: prompt eval time =     272.41 ms /    60 tokens (    4.54 ms per token,   220.26 tokens per second)\n",
            "llama_print_timings:        eval time =    1642.75 ms /    15 runs   (  109.52 ms per token,     9.13 tokens per second)\n",
            "llama_print_timings:       total time =    2125.94 ms /    75 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "just thinking about Galadriel manspreading, actually it's very useful to protect those nasty hobbitses (that's their actual size) 🤔 #theringsofpower https://t.co/HqO3jOhDwr\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      13.48 ms /    16 runs   (    0.84 ms per token,  1186.94 tokens per second)\n",
            "llama_print_timings: prompt eval time =     275.13 ms /    74 tokens (    3.72 ms per token,   268.96 tokens per second)\n",
            "llama_print_timings:        eval time =    1709.09 ms /    15 runs   (  113.94 ms per token,     8.78 tokens per second)\n",
            "llama_print_timings:       total time =    2336.66 ms /    89 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@_elderstatesman @ToniHargis @AlchemicalDaddy The fact that you use the term toxic masculinity is why someone like Tate exists. Mansplaining, manspreading etc. Name one word associated with exclusively negative female behaviour. Being a man is seen as a bad thing in modern day society\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.85 ms /    16 runs   (    0.55 ms per token,  1808.73 tokens per second)\n",
            "llama_print_timings: prompt eval time =     799.74 ms /    30 tokens (   26.66 ms per token,    37.51 tokens per second)\n",
            "llama_print_timings:        eval time =    1556.47 ms /    15 runs   (  103.76 ms per token,     9.64 tokens per second)\n",
            "llama_print_timings:       total time =    2492.58 ms /    45 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "how does he make manspreading look hot https://t.co/ZeWiUtv6t1\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.11 ms /    16 runs   (    0.57 ms per token,  1756.50 tokens per second)\n",
            "llama_print_timings: prompt eval time =     246.03 ms /    48 tokens (    5.13 ms per token,   195.09 tokens per second)\n",
            "llama_print_timings:        eval time =    1465.92 ms /    15 runs   (   97.73 ms per token,    10.23 tokens per second)\n",
            "llama_print_timings:       total time =    1892.57 ms /    63 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Why is he manspreading like he has a 20 feet long anaconda between his legs??? 😭😭😭 https://t.co/pwG1yQJNzv\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       6.06 ms /    10 runs   (    0.61 ms per token,  1650.71 tokens per second)\n",
            "llama_print_timings: prompt eval time =     258.54 ms /    73 tokens (    3.54 ms per token,   282.36 tokens per second)\n",
            "llama_print_timings:        eval time =     928.77 ms /     9 runs   (  103.20 ms per token,     9.69 tokens per second)\n",
            "llama_print_timings:       total time =    1403.92 ms /    82 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@USCCB @usccbprolife The Catholic Church is not interested in love. It is interested in punishment, shaming of women who have sex outside of marriage, who have an unintended pregnancy, and with LGBTQ, whom they want to marginalize at best and jail for their \"sins\" at worst.\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.44 ms /    16 runs   (    0.72 ms per token,  1398.48 tokens per second)\n",
            "llama_print_timings: prompt eval time =     265.99 ms /    93 tokens (    2.86 ms per token,   349.64 tokens per second)\n",
            "llama_print_timings:        eval time =    1887.43 ms /    15 runs   (  125.83 ms per token,     7.95 tokens per second)\n",
            "llama_print_timings:       total time =    2454.94 ms /   108 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@PennyFu60625589 @GodsHelper101 @bennyjohnson No, of course I didn't say that, and this shows one more time that you clearly don't understand what I'm saying and not even what you are saying. You are literally saying they marginalize \"pretty much everyone\", that is enough justification for extremist to kill conservatives.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.45 ms /    16 runs   (    0.59 ms per token,  1693.66 tokens per second)\n",
            "llama_print_timings: prompt eval time =     271.19 ms /    55 tokens (    4.93 ms per token,   202.81 tokens per second)\n",
            "llama_print_timings:        eval time =    1542.02 ms /    15 runs   (  102.80 ms per token,     9.73 tokens per second)\n",
            "llama_print_timings:       total time =    1997.38 ms /    70 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Fwd_Party @tearoeprice Words hurt and can be harmful to marginalize groups. It’s not free speech if it’s use to harm people. I think at some point hateful individuals should be canceled.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.78 ms /    16 runs   (    0.61 ms per token,  1636.83 tokens per second)\n",
            "llama_print_timings: prompt eval time =     281.62 ms /    91 tokens (    3.09 ms per token,   323.14 tokens per second)\n",
            "llama_print_timings:        eval time =    1511.01 ms /    15 runs   (  100.73 ms per token,     9.93 tokens per second)\n",
            "llama_print_timings:       total time =    2048.56 ms /   106 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Veedway  you know its hurtful to see some one who waves our pastel flag go out of her way to Marginalize belittle and deadname me all for the sake to make me feel like shit and for you to feel better  ...now people will  get to see who you really are #TransRightsAreHumanRights https://t.co/eZXat7Jkdr\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.61 ms /    16 runs   (    0.60 ms per token,  1665.11 tokens per second)\n",
            "llama_print_timings: prompt eval time =     286.44 ms /   110 tokens (    2.60 ms per token,   384.02 tokens per second)\n",
            "llama_print_timings:        eval time =    1523.18 ms /    15 runs   (  101.55 ms per token,     9.85 tokens per second)\n",
            "llama_print_timings:       total time =    2115.10 ms /   125 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@pennypacker_29 @TracyGr14953023 @SherryW36619213 @sunlorrie @Chris_Bittle Funny how no conservatives seem to have their finger on the pulse of how conservatives generally responded to Cherry's comments.But you do know. They attacked immigrants, threatened to ostracize them, and marginalize them as not being Canadian enough.Disgusting hypocrisy.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.58 ms /    16 runs   (    0.66 ms per token,  1513.00 tokens per second)\n",
            "llama_print_timings: prompt eval time =     252.42 ms /    58 tokens (    4.35 ms per token,   229.78 tokens per second)\n",
            "llama_print_timings:        eval time =    1499.83 ms /    15 runs   (   99.99 ms per token,    10.00 tokens per second)\n",
            "llama_print_timings:       total time =    1966.74 ms /    73 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@borgposting capitalism already works to marginalize artists by taking cuts of their income wherever possible (look no further than music industries), it's stupid to think that those same forces won't jump at the chance to cut artists out entirely when given the opportunity.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.70 ms /    16 runs   (    0.61 ms per token,  1649.82 tokens per second)\n",
            "llama_print_timings: prompt eval time =     975.15 ms /    30 tokens (   32.51 ms per token,    30.76 tokens per second)\n",
            "llama_print_timings:        eval time =    1730.27 ms /    15 runs   (  115.35 ms per token,     8.67 tokens per second)\n",
            "llama_print_timings:       total time =    2897.29 ms /    45 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@micr0biz The album leaves you horny so you can masturbate after listening to it wbk…\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.90 ms /    16 runs   (    0.56 ms per token,  1797.75 tokens per second)\n",
            "llama_print_timings: prompt eval time =     676.21 ms /    28 tokens (   24.15 ms per token,    41.41 tokens per second)\n",
            "llama_print_timings:        eval time =    1555.52 ms /    15 runs   (  103.70 ms per token,     9.64 tokens per second)\n",
            "llama_print_timings:       total time =    2359.51 ms /    43 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "oh GROW UP older women masturbate too https://t.co/G4sl7pcrb2\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.79 ms /    16 runs   (    0.55 ms per token,  1819.22 tokens per second)\n",
            "llama_print_timings: prompt eval time =     235.81 ms /    34 tokens (    6.94 ms per token,   144.19 tokens per second)\n",
            "llama_print_timings:        eval time =    1564.32 ms /    15 runs   (  104.29 ms per token,     9.59 tokens per second)\n",
            "llama_print_timings:       total time =    1951.09 ms /    49 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@MiaLaney94 I did masturbate to you an hour ago , im 26 but I crave older women\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.99 ms /    16 runs   (    0.56 ms per token,  1779.56 tokens per second)\n",
            "llama_print_timings: prompt eval time =     233.90 ms /    36 tokens (    6.50 ms per token,   153.91 tokens per second)\n",
            "llama_print_timings:        eval time =    1583.49 ms /    15 runs   (  105.57 ms per token,     9.47 tokens per second)\n",
            "llama_print_timings:       total time =    1972.59 ms /    51 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@iam_dartoss Omo I de room with virgin. I just masturbate and cum in between her bum and rest my tin.\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.07 ms /    16 runs   (    0.69 ms per token,  1445.74 tokens per second)\n",
            "llama_print_timings: prompt eval time =     255.10 ms /    45 tokens (    5.67 ms per token,   176.40 tokens per second)\n",
            "llama_print_timings:        eval time =    1739.63 ms /    15 runs   (  115.98 ms per token,     8.62 tokens per second)\n",
            "llama_print_timings:       total time =    2276.50 ms /    60 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@ScuvyBob @magills_ @SeahawksMj @popcornsutton3 @RealPhillyP Yes, you masturbate yourself to sleep thinking that.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.49 ms /    16 runs   (    0.59 ms per token,  1685.63 tokens per second)\n",
            "llama_print_timings: prompt eval time =     281.75 ms /    85 tokens (    3.31 ms per token,   301.69 tokens per second)\n",
            "llama_print_timings:        eval time =    1509.61 ms /    15 runs   (  100.64 ms per token,     9.94 tokens per second)\n",
            "llama_print_timings:       total time =    2030.18 ms /   100 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@UsmanAyinde3 @DataDaddy2 @SavvyRinu As foolish as you can be na 😂 Another throw back. Don’t masturbate on them yet. I’m up for a challenge if you want bro. My TB life is what you’re living right now. https://t.co/v4LObjs0xM\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.00 ms /    16 runs   (    0.56 ms per token,  1777.19 tokens per second)\n",
            "llama_print_timings: prompt eval time =     243.29 ms /    42 tokens (    5.79 ms per token,   172.63 tokens per second)\n",
            "llama_print_timings:        eval time =    1587.51 ms /    15 runs   (  105.83 ms per token,     9.45 tokens per second)\n",
            "llama_print_timings:       total time =    2000.58 ms /    57 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@_MetaNarrative_ @Reflex_Finance How is the 8% going because I am not getting much, they add and subtract from the #RBUSD\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.70 ms /    16 runs   (    0.54 ms per token,  1839.08 tokens per second)\n",
            "llama_print_timings: prompt eval time =     282.91 ms /    84 tokens (    3.37 ms per token,   296.91 tokens per second)\n",
            "llama_print_timings:        eval time =    1578.88 ms /    15 runs   (  105.26 ms per token,     9.50 tokens per second)\n",
            "llama_print_timings:       total time =    2098.10 ms /    99 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "pathologic and mgs compliment each other so well btw. hence why so many people i know from one dabble in the other. it's the weight of a name. it's metanarrative. it's Bigger Than You. it's love in hopeless places. the technological mechanical, the organic anatomical. the snakes!\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.63 ms /    16 runs   (    0.73 ms per token,  1376.11 tokens per second)\n",
            "llama_print_timings: prompt eval time =     246.00 ms /    42 tokens (    5.86 ms per token,   170.73 tokens per second)\n",
            "llama_print_timings:        eval time =    1793.66 ms /    15 runs   (  119.58 ms per token,     8.36 tokens per second)\n",
            "llama_print_timings:       total time =    2239.05 ms /    57 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Vgtorious @kachiphilip @obi_Nwosu This metanarrative has changed. Don't be a relic from a corrupt generation.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.98 ms /    16 runs   (    0.56 ms per token,  1782.33 tokens per second)\n",
            "llama_print_timings: prompt eval time =     253.90 ms /    47 tokens (    5.40 ms per token,   185.11 tokens per second)\n",
            "llama_print_timings:        eval time =    1598.22 ms /    15 runs   (  106.55 ms per token,     9.39 tokens per second)\n",
            "llama_print_timings:       total time =    2019.81 ms /    62 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@WXWX34497605 On the metanarrative in EvangelionI dig this one toohttps://t.co/l4L0lEfUtm\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.20 ms /    16 runs   (    0.64 ms per token,  1568.94 tokens per second)\n",
            "llama_print_timings: prompt eval time =     259.24 ms /    57 tokens (    4.55 ms per token,   219.87 tokens per second)\n",
            "llama_print_timings:        eval time =    1488.95 ms /    15 runs   (   99.26 ms per token,    10.07 tokens per second)\n",
            "llama_print_timings:       total time =    1942.06 ms /    72 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@JosephGlass Oh I can’t remember the last one of these I completed but they’re fun for the 15 or so hours I put in and I always enjoy watching YouTubers summarise the garbage metanarrative!\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.22 ms /    16 runs   (    0.58 ms per token,  1735.92 tokens per second)\n",
            "llama_print_timings: prompt eval time =     250.44 ms /    49 tokens (    5.11 ms per token,   195.66 tokens per second)\n",
            "llama_print_timings:        eval time =    1657.53 ms /    15 runs   (  110.50 ms per token,     9.05 tokens per second)\n",
            "llama_print_timings:       total time =    2085.04 ms /    64 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@anyothersky it could semi-kinda-work as a serial television series but only if you've already played the game lmfaoor it'd have to do some funky metanarrative shit\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.71 ms /    16 runs   (    0.61 ms per token,  1647.62 tokens per second)\n",
            "llama_print_timings: prompt eval time =     274.40 ms /    81 tokens (    3.39 ms per token,   295.19 tokens per second)\n",
            "llama_print_timings:        eval time =    1569.78 ms /    15 runs   (  104.65 ms per token,     9.56 tokens per second)\n",
            "llama_print_timings:       total time =    2094.62 ms /    96 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "When you see how +234 women cannot have any discourse here about about their issues without their men galloping in to silence, insult them, or cry ‘misandry’, ‘stop generalising’, ‘stop hurting our feelings’ etc., this sad article begins to make sense. https://t.co/BICC6dYEeT\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.39 ms /    16 runs   (    0.71 ms per token,  1404.74 tokens per second)\n",
            "llama_print_timings: prompt eval time =     271.43 ms /    64 tokens (    4.24 ms per token,   235.79 tokens per second)\n",
            "llama_print_timings:        eval time =    1619.62 ms /    15 runs   (  107.97 ms per token,     9.26 tokens per second)\n",
            "llama_print_timings:       total time =    2214.33 ms /    79 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "🌸 hot take: misogyny and misandry are both just aspects of the same system (sexism) which also includes transphobia and transmysogygy draws on a combination of all three https://t.co/zehJPvOsxp\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.23 ms /    16 runs   (    0.58 ms per token,  1732.54 tokens per second)\n",
            "llama_print_timings: prompt eval time =     243.68 ms /    47 tokens (    5.18 ms per token,   192.87 tokens per second)\n",
            "llama_print_timings:        eval time =    1503.10 ms /    15 runs   (  100.21 ms per token,     9.98 tokens per second)\n",
            "llama_print_timings:       total time =    1928.94 ms /    62 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Theres no benefit whatsoever to get married as a man in the 21st century, in this climate of misandry, brokeshaming and cheat-and-blame\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.43 ms /    16 runs   (    0.59 ms per token,  1696.71 tokens per second)\n",
            "llama_print_timings: prompt eval time =     276.28 ms /    96 tokens (    2.88 ms per token,   347.47 tokens per second)\n",
            "llama_print_timings:        eval time =    1466.40 ms /    15 runs   (   97.76 ms per token,    10.23 tokens per second)\n",
            "llama_print_timings:       total time =    2022.34 ms /   111 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@ginmarrienne @alcoholicAK Let's deal with facts &amp; not your ignorance. I support a human who was falsely accused of dv/sa. I don't watch his movies. I watched the trial, read transcripts, viewed evidence. Feminazis depriving men of their rights isn't feminism, it's misandry. #AbuseHasNoGender #MenToo\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.13 ms /    16 runs   (    0.57 ms per token,  1751.70 tokens per second)\n",
            "llama_print_timings: prompt eval time =     242.81 ms /    45 tokens (    5.40 ms per token,   185.33 tokens per second)\n",
            "llama_print_timings:        eval time =    1524.97 ms /    15 runs   (  101.66 ms per token,     9.84 tokens per second)\n",
            "llama_print_timings:       total time =    1937.93 ms /    60 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@FemCondition There definitely are male equivalents. When did misandry become so popular? It really boggles my mind that anyone thinks putting down anyone else is the right answer to gaining equality.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.72 ms /    16 runs   (    0.67 ms per token,  1492.96 tokens per second)\n",
            "llama_print_timings: prompt eval time =     824.46 ms /    30 tokens (   27.48 ms per token,    36.39 tokens per second)\n",
            "llama_print_timings:        eval time =    1790.40 ms /    15 runs   (  119.36 ms per token,     8.38 tokens per second)\n",
            "llama_print_timings:       total time =    2822.81 ms /    45 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "daily experiences of harassment/catcalling/misogyny only further increasing my misandry tbh\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.80 ms /    16 runs   (    0.55 ms per token,  1817.56 tokens per second)\n",
            "llama_print_timings: prompt eval time =     248.34 ms /    47 tokens (    5.28 ms per token,   189.25 tokens per second)\n",
            "llama_print_timings:        eval time =    1479.38 ms /    15 runs   (   98.63 ms per token,    10.14 tokens per second)\n",
            "llama_print_timings:       total time =    1910.61 ms /    62 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Cardi B said she wasn’t wearing make up anymore and most women followed. Don’t tell me she don’t set the trends for the women in their 30’s or younger.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.22 ms /    16 runs   (    0.58 ms per token,  1734.42 tokens per second)\n",
            "llama_print_timings: prompt eval time =     256.82 ms /    55 tokens (    4.67 ms per token,   214.16 tokens per second)\n",
            "llama_print_timings:        eval time =    1551.32 ms /    15 runs   (  103.42 ms per token,     9.67 tokens per second)\n",
            "llama_print_timings:       total time =    2014.37 ms /    70 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@DigitalStefan @Berni_carpenter I’d like trans women to be comfortable being trans women and fight for their rights as trans women. Most women will happily support that. It is the delusion I struggle with.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.17 ms /    16 runs   (    0.70 ms per token,  1431.90 tokens per second)\n",
            "llama_print_timings: prompt eval time =     257.84 ms /    72 tokens (    3.58 ms per token,   279.25 tokens per second)\n",
            "llama_print_timings:        eval time =    1542.79 ms /    15 runs   (  102.85 ms per token,     9.72 tokens per second)\n",
            "llama_print_timings:       total time =    2030.66 ms /    87 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Most women, SWers included, have already had at least one pregnancy by the time they turn 40. Pregnancy means streched skin and hence stretch marks. I am mindblown how ppl do not embrace this perfectly narural beauty of a women and expect a flawless tight skin in the belly area?\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.77 ms /    16 runs   (    0.61 ms per token,  1638.00 tokens per second)\n",
            "llama_print_timings: prompt eval time =     237.60 ms /    34 tokens (    6.99 ms per token,   143.10 tokens per second)\n",
            "llama_print_timings:        eval time =    1629.02 ms /    15 runs   (  108.60 ms per token,     9.21 tokens per second)\n",
            "llama_print_timings:       total time =    2042.50 ms /    49 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "unpopular opinion: most women that go to the gym only do it to flex their ass and wear tight shortsAND IM HERE FOR IT\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.57 ms /    16 runs   (    0.72 ms per token,  1382.89 tokens per second)\n",
            "llama_print_timings: prompt eval time =     282.22 ms /    76 tokens (    3.71 ms per token,   269.29 tokens per second)\n",
            "llama_print_timings:        eval time =    1657.06 ms /    15 runs   (  110.47 ms per token,     9.05 tokens per second)\n",
            "llama_print_timings:       total time =    2302.59 ms /    91 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@redmirage2020 @undecyn @ElijahSchaffer There are a handful of women welders,it is just very hard physical work onsite that most women (and me ) don’t want to do. It is one factor in the wage gap that doesn’t really exist to the degree claimed.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       2.86 ms /     5 runs   (    0.57 ms per token,  1750.70 tokens per second)\n",
            "llama_print_timings: prompt eval time =     246.11 ms /    57 tokens (    4.32 ms per token,   231.60 tokens per second)\n",
            "llama_print_timings:        eval time =     450.98 ms /     4 runs   (  112.75 ms per token,     8.87 tokens per second)\n",
            "llama_print_timings:       total time =     872.83 ms /    61 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@PineCellar Well it’s just like what most women go through, you can’t get the real attention and money til you undress and shake your ass. I thinks she’s very talented and puts on a great show with high energy.\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.32 ms /    16 runs   (    0.58 ms per token,  1716.19 tokens per second)\n",
            "llama_print_timings: prompt eval time =     254.62 ms /    72 tokens (    3.54 ms per token,   282.78 tokens per second)\n",
            "llama_print_timings:        eval time =    1467.15 ms /    15 runs   (   97.81 ms per token,    10.22 tokens per second)\n",
            "llama_print_timings:       total time =    1944.41 ms /    87 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@TheNationNews The issue is that Nigeria need a man that is healthy or whose health is stable....I pray that money spent on unhealthy leaders will unveil someday so that we all will understand.Nigeria as a nation have passed to lead by such people.Please we have to say the truth...\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.32 ms /    16 runs   (    0.52 ms per token,  1923.08 tokens per second)\n",
            "llama_print_timings: prompt eval time =     238.44 ms /    40 tokens (    5.96 ms per token,   167.76 tokens per second)\n",
            "llama_print_timings:        eval time =    1541.80 ms /    15 runs   (  102.79 ms per token,     9.73 tokens per second)\n",
            "llama_print_timings:       total time =    1945.61 ms /    55 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@_shantelrena I told my mama this she told me i need a man 😹😹😹😹\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.77 ms /    16 runs   (    0.61 ms per token,  1637.83 tokens per second)\n",
            "llama_print_timings: prompt eval time =     668.07 ms /    28 tokens (   23.86 ms per token,    41.91 tokens per second)\n",
            "llama_print_timings:        eval time =    1664.97 ms /    15 runs   (  111.00 ms per token,     9.01 tokens per second)\n",
            "llama_print_timings:       total time =    2472.17 ms /    43 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Yeah honestly I don’t need a man bc I have more than enough hoodies in the closet for myself thanks\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.04 ms /    16 runs   (    0.63 ms per token,  1593.47 tokens per second)\n",
            "llama_print_timings: prompt eval time =     257.01 ms /    44 tokens (    5.84 ms per token,   171.20 tokens per second)\n",
            "llama_print_timings:        eval time =    1691.42 ms /    15 runs   (  112.76 ms per token,     8.87 tokens per second)\n",
            "llama_print_timings:       total time =    2211.35 ms /    59 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Amaka you’re strong on your own… you don’t need a man to valid you!! Learn to enjoy yourself on your own🫶❤️#BBNaija\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.89 ms /    16 runs   (    0.56 ms per token,  1800.59 tokens per second)\n",
            "llama_print_timings: prompt eval time =     601.07 ms /    24 tokens (   25.04 ms per token,    39.93 tokens per second)\n",
            "llama_print_timings:        eval time =    1457.07 ms /    15 runs   (   97.14 ms per token,    10.29 tokens per second)\n",
            "llama_print_timings:       total time =    2173.79 ms /    39 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "I need a man like Frenchie actually ... any guy from Marseille wanna hmu\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.65 ms /    16 runs   (    0.54 ms per token,  1848.64 tokens per second)\n",
            "llama_print_timings: prompt eval time =     575.09 ms /    23 tokens (   25.00 ms per token,    39.99 tokens per second)\n",
            "llama_print_timings:        eval time =    1511.13 ms /    15 runs   (  100.74 ms per token,     9.93 tokens per second)\n",
            "llama_print_timings:       total time =    2201.01 ms /    38 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "I don’t need “a man”. I need “several men on rotation”\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.84 ms /    16 runs   (    0.62 ms per token,  1625.52 tokens per second)\n",
            "llama_print_timings: prompt eval time =     248.01 ms /    60 tokens (    4.13 ms per token,   241.93 tokens per second)\n",
            "llama_print_timings:        eval time =    1479.10 ms /    15 runs   (   98.61 ms per token,    10.14 tokens per second)\n",
            "llama_print_timings:       total time =    1927.27 ms /    75 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "This thread is a beautiful reminder that not all men are scum and indeed there can be a happy home with both partners having careers. Congratulations on the presentation as well.  All the best. https://t.co/uMT3CfGnpu\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      12.01 ms /    16 runs   (    0.75 ms per token,  1331.89 tokens per second)\n",
            "llama_print_timings: prompt eval time =     276.22 ms /    75 tokens (    3.68 ms per token,   271.52 tokens per second)\n",
            "llama_print_timings:        eval time =    1723.34 ms /    15 runs   (  114.89 ms per token,     8.70 tokens per second)\n",
            "llama_print_timings:       total time =    2400.66 ms /    90 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@zyelexx are you slow? i’ve said a lot of christians are complicit. yeah that’s horrible, being complicit isnt good, but im not saying you’re all committing heinous acts. would be nice to see more self awareness rather than the equivalent of a “but not ALL men” response\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.03 ms /    16 runs   (    0.56 ms per token,  1771.28 tokens per second)\n",
            "llama_print_timings: prompt eval time =     241.74 ms /    38 tokens (    6.36 ms per token,   157.19 tokens per second)\n",
            "llama_print_timings:        eval time =    1587.38 ms /    15 runs   (  105.83 ms per token,     9.45 tokens per second)\n",
            "llama_print_timings:       total time =    1986.71 ms /    53 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Neemalations Don't wanna hear a moid cry \"not all men\" after saying shit like this.Keep those suicide stats up, boys 🙏\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.72 ms /    16 runs   (    0.55 ms per token,  1834.02 tokens per second)\n",
            "llama_print_timings: prompt eval time =     248.60 ms /    40 tokens (    6.21 ms per token,   160.90 tokens per second)\n",
            "llama_print_timings:        eval time =    1565.95 ms /    15 runs   (  104.40 ms per token,     9.58 tokens per second)\n",
            "llama_print_timings:       total time =    1973.90 ms /    55 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@BadMedicalTakes Why do they cry about “not all men” if they’re just gonna double down and make these “actually all men do this” takes\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.42 ms /    16 runs   (    0.59 ms per token,  1699.24 tokens per second)\n",
            "llama_print_timings: prompt eval time =     268.41 ms /    76 tokens (    3.53 ms per token,   283.15 tokens per second)\n",
            "llama_print_timings:        eval time =    1585.23 ms /    15 runs   (  105.68 ms per token,     9.46 tokens per second)\n",
            "llama_print_timings:       total time =    2084.63 ms /    91 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@thegirdlengr When you read this kind of thing you realise very quickly that men are the driving force still for the longevity of this cruel cut (not all men) but still the majority &amp; that the fear of stigmatisation &amp; rejection force women to keep cutting their daughters this mix is harming us\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.54 ms /    16 runs   (    0.66 ms per token,  1518.75 tokens per second)\n",
            "llama_print_timings: prompt eval time =     240.25 ms /    41 tokens (    5.86 ms per token,   170.66 tokens per second)\n",
            "llama_print_timings:        eval time =    1782.36 ms /    15 runs   (  118.82 ms per token,     8.42 tokens per second)\n",
            "llama_print_timings:       total time =    2212.68 ms /    56 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@RasheedAdefemi @me_lanin_pie It is buh not all men, some can b lucky and some that are very sensitive might not be lucky\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.49 ms /    16 runs   (    0.59 ms per token,  1686.16 tokens per second)\n",
            "llama_print_timings: prompt eval time =     263.78 ms /    57 tokens (    4.63 ms per token,   216.09 tokens per second)\n",
            "llama_print_timings:        eval time =    1553.98 ms /    15 runs   (  103.60 ms per token,     9.65 tokens per second)\n",
            "llama_print_timings:       total time =    2018.85 ms /    72 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Hey @JustinTrudeau, if your wife or children were sick and needed to be rushed to the hospital, would you rather have no nurse or an unvaccinated nurse? https://t.co/AGrLrNVkHI\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.61 ms /    16 runs   (    0.60 ms per token,  1665.45 tokens per second)\n",
            "llama_print_timings: prompt eval time =     252.21 ms /    58 tokens (    4.35 ms per token,   229.96 tokens per second)\n",
            "llama_print_timings:        eval time =    1572.17 ms /    15 runs   (  104.81 ms per token,     9.54 tokens per second)\n",
            "llama_print_timings:       total time =    2020.75 ms /    73 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@tknts720 @GriffinCary @doehlerd85 No he settled down with a nice lady,who was a nurse,then he got deathly il,she took care of him,and alive because of it.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.14 ms /    16 runs   (    0.57 ms per token,  1750.74 tokens per second)\n",
            "llama_print_timings: prompt eval time =     244.82 ms /    49 tokens (    5.00 ms per token,   200.15 tokens per second)\n",
            "llama_print_timings:        eval time =    1535.86 ms /    15 runs   (  102.39 ms per token,     9.77 tokens per second)\n",
            "llama_print_timings:       total time =    1971.94 ms /    64 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@teonawrites “I would suggest talking to a social worker at the hospital if the person goes back to the er.  If you get static ask or demand to speak with a charge nurse or chaplin.”\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.39 ms /    16 runs   (    0.65 ms per token,  1540.24 tokens per second)\n",
            "llama_print_timings: prompt eval time =     258.99 ms /    65 tokens (    3.98 ms per token,   250.97 tokens per second)\n",
            "llama_print_timings:        eval time =    1645.03 ms /    15 runs   (  109.67 ms per token,     9.12 tokens per second)\n",
            "llama_print_timings:       total time =    2139.76 ms /    80 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@POTUS She’s been paying for student debt 44 years! That’s a bunch of BS! You expect people to believe a NURSE working 44 years can’t pay off a student loan? COME ON MAN! #studentloanforgiveness\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.78 ms /    16 runs   (    0.67 ms per token,  1483.95 tokens per second)\n",
            "llama_print_timings: prompt eval time =     292.68 ms /    77 tokens (    3.80 ms per token,   263.09 tokens per second)\n",
            "llama_print_timings:        eval time =    1753.75 ms /    15 runs   (  116.92 ms per token,     8.55 tokens per second)\n",
            "llama_print_timings:       total time =    2422.39 ms /    92 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Let's listen to @FostKim  Resilient Nurse - how mental health nurse can build resilience in their roles in a climate of change #ACMHN2022 #mentalhealthnursing #NUMentalHealthNurse https://t.co/awQm6wO1iI\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.50 ms /    16 runs   (    0.59 ms per token,  1685.10 tokens per second)\n",
            "llama_print_timings: prompt eval time =     289.73 ms /    85 tokens (    3.41 ms per token,   293.38 tokens per second)\n",
            "llama_print_timings:        eval time =    1603.42 ms /    15 runs   (  106.89 ms per token,     9.35 tokens per second)\n",
            "llama_print_timings:       total time =    2144.58 ms /   100 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@VenetiaSpencer @WeHearPodcast I was canvassing a few years ago.  A woman told me she was a strongly pro-life Catholic.  Then she told me she’s also an ER nurse who had recently watched a 15 y/o girl die from an abortion she did on herself.  She’s pro choice for others.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.99 ms /    16 runs   (    0.56 ms per token,  1778.96 tokens per second)\n",
            "llama_print_timings: prompt eval time =     256.43 ms /    65 tokens (    3.95 ms per token,   253.48 tokens per second)\n",
            "llama_print_timings:        eval time =    1591.92 ms /    15 runs   (  106.13 ms per token,     9.42 tokens per second)\n",
            "llama_print_timings:       total time =    2050.22 ms /    80 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Available 24/7#pay essay#pay homework#pay assignment#pay Hw#pay Math#pay Chem#biology#pay online class#aleks#mymathlab #nursing#history#dissertation#researchHmu @Homework_Saver\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.86 ms /    16 runs   (    0.62 ms per token,  1622.06 tokens per second)\n",
            "llama_print_timings: prompt eval time =     278.82 ms /   102 tokens (    2.73 ms per token,   365.83 tokens per second)\n",
            "llama_print_timings:        eval time =    1530.47 ms /    15 runs   (  102.03 ms per token,     9.80 tokens per second)\n",
            "llama_print_timings:       total time =    2101.88 ms /   117 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Welcome back, @annbrencoop and Alison Hao-Smith, from the 1st EVER item writer workshop for the Certified Burn Registered Nurse certification!! #proud of the @nyphospital @Burn_CenterICU representation for this historical moment in Burn #nursing! #weillcornellnursingproud #CBRN https://t.co/Nrfmf2h1Sx\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      13.54 ms /    16 runs   (    0.85 ms per token,  1182.03 tokens per second)\n",
            "llama_print_timings: prompt eval time =     270.74 ms /    73 tokens (    3.71 ms per token,   269.63 tokens per second)\n",
            "llama_print_timings:        eval time =    1862.26 ms /    15 runs   (  124.15 ms per token,     8.05 tokens per second)\n",
            "llama_print_timings:       total time =    2516.07 ms /    88 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@francis_alana @DrEricLevi True. But you also need enough health $$$ to employ everyone. For-profit aged care without adequate nursing staff ratios doesn’t help. Neither does underfunding primary care. “Just send them to hospital” is the default because there is no reasonable alternative\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.08 ms /    16 runs   (    0.57 ms per token,  1761.73 tokens per second)\n",
            "llama_print_timings: prompt eval time =     246.25 ms /    42 tokens (    5.86 ms per token,   170.56 tokens per second)\n",
            "llama_print_timings:        eval time =    1572.64 ms /    15 runs   (  104.84 ms per token,     9.54 tokens per second)\n",
            "llama_print_timings:       total time =    1997.67 ms /    57 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@4Yourinformati3 Then he's too old to run his companies or be involved in politics.And it wouldn't be prison, just a maximum security nursing home.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.90 ms /    16 runs   (    0.56 ms per token,  1797.15 tokens per second)\n",
            "llama_print_timings: prompt eval time =     577.38 ms /    32 tokens (   18.04 ms per token,    55.42 tokens per second)\n",
            "llama_print_timings:        eval time =    1482.24 ms /    15 runs   (   98.82 ms per token,    10.12 tokens per second)\n",
            "llama_print_timings:       total time =    2206.58 ms /    47 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Bro the cooperation these nursing babes have is untouchable. Effortlessly made me fall in love with their fyb thing\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.66 ms /    16 runs   (    0.54 ms per token,  1847.36 tokens per second)\n",
            "llama_print_timings: prompt eval time =     235.19 ms /    33 tokens (    7.13 ms per token,   140.31 tokens per second)\n",
            "llama_print_timings:        eval time =    1576.80 ms /    15 runs   (  105.12 ms per token,     9.51 tokens per second)\n",
            "llama_print_timings:       total time =    1967.91 ms /    48 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "#HunterBellevueSON BEST in Nursing Education https://t.co/94MhpPWHqx\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.65 ms /    16 runs   (    0.73 ms per token,  1372.92 tokens per second)\n",
            "llama_print_timings: prompt eval time =     271.52 ms /    90 tokens (    3.02 ms per token,   331.47 tokens per second)\n",
            "llama_print_timings:        eval time =    1777.98 ms /    15 runs   (  118.53 ms per token,     8.44 tokens per second)\n",
            "llama_print_timings:       total time =    2336.91 ms /   105 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Lylebell0 @Michaelkman1 @DharmaJanitor @WallStreetSilv If you're gonna correct someone at least get it right bruh0 dimensions = a single point with no length, width, or height1D = a straight line that only has length2D = shape with length and width (like a square)3D = object with length, width and height\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.53 ms /    16 runs   (    0.60 ms per token,  1678.56 tokens per second)\n",
            "llama_print_timings: prompt eval time =     305.00 ms /    84 tokens (    3.63 ms per token,   275.41 tokens per second)\n",
            "llama_print_timings:        eval time =    1573.08 ms /    15 runs   (  104.87 ms per token,     9.54 tokens per second)\n",
            "llama_print_timings:       total time =    2176.46 ms /    99 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@jessieontheedge @Strandjunker Odd, but reports of depression, mental health issues and thoughts of suicide showed massive leaps, upwards of 60+% starting in 2005/2007.  How about you look at that cause and effect as opposed to an inanimate object that never harmed anyone by itself?\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.07 ms /    16 runs   (    0.57 ms per token,  1764.45 tokens per second)\n",
            "llama_print_timings: prompt eval time =     248.64 ms /    63 tokens (    3.95 ms per token,   253.38 tokens per second)\n",
            "llama_print_timings:        eval time =    1650.20 ms /    15 runs   (  110.01 ms per token,     9.09 tokens per second)\n",
            "llama_print_timings:       total time =    2110.59 ms /    78 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@sullydish Would you object to this?“I also don't forget Iraq had nothing to do with it, yet the US government invaded them.Nor do I forget the Taliban offered to give up Bin Laden, yet the US government invaded Afghanistan.”\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.03 ms /    16 runs   (    0.56 ms per token,  1772.07 tokens per second)\n",
            "llama_print_timings: prompt eval time =     270.59 ms /    71 tokens (    3.81 ms per token,   262.39 tokens per second)\n",
            "llama_print_timings:        eval time =    1555.17 ms /    15 runs   (  103.68 ms per token,     9.65 tokens per second)\n",
            "llama_print_timings:       total time =    2041.41 ms /    86 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@ChristopherJM @amnesty @OPokalchuk No donations to @amnesty.  Object your organizations, colleges, corporations donating to @amnesty.  Do not volunteer with Amnesty. Make it non-grata till Agnès Callamard and her ilk resign.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.24 ms /    16 runs   (    0.58 ms per token,  1732.35 tokens per second)\n",
            "llama_print_timings: prompt eval time =     268.70 ms /    87 tokens (    3.09 ms per token,   323.79 tokens per second)\n",
            "llama_print_timings:        eval time =    1548.37 ms /    15 runs   (  103.22 ms per token,     9.69 tokens per second)\n",
            "llama_print_timings:       total time =    2071.45 ms /   102 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@varavigil Not the only acceptable way.It is also acceptable--even encouraged--when exiting a helicopter at height sans parachute. Oh sure, most people might yell \"Geronimo!' when jumping from an identified flying object, but Frank here knows what I'm talking about. 👇 https://t.co/80H7NLVPOx\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.03 ms /    16 runs   (    0.69 ms per token,  1450.59 tokens per second)\n",
            "llama_print_timings: prompt eval time =     272.02 ms /    41 tokens (    6.63 ms per token,   150.72 tokens per second)\n",
            "llama_print_timings:        eval time =    1685.59 ms /    15 runs   (  112.37 ms per token,     8.90 tokens per second)\n",
            "llama_print_timings:       total time =    2206.23 ms /    56 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Did Kip Sabian mistreat a job guy? If not, why is he pulling a Perry Saturn and talking to an inanimate object? #AEWAllOut\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.72 ms /    16 runs   (    0.61 ms per token,  1645.41 tokens per second)\n",
            "llama_print_timings: prompt eval time =     260.19 ms /    70 tokens (    3.72 ms per token,   269.03 tokens per second)\n",
            "llama_print_timings:        eval time =    1449.23 ms /    15 runs   (   96.62 ms per token,    10.35 tokens per second)\n",
            "llama_print_timings:       total time =    1927.83 ms /    85 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Unfortunately in the early days of this modern femme empowerment \"girl power\" movement sexual harassment and objectification of men was deemed acceptable.Just because women had been the target of this for, well, centuries, two wrongs never make a right https://t.co/adDZsRilKj\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.96 ms /    16 runs   (    0.62 ms per token,  1606.10 tokens per second)\n",
            "llama_print_timings: prompt eval time =     270.60 ms /    85 tokens (    3.18 ms per token,   314.12 tokens per second)\n",
            "llama_print_timings:        eval time =    1648.87 ms /    15 runs   (  109.92 ms per token,     9.10 tokens per second)\n",
            "llama_print_timings:       total time =    2173.50 ms /   100 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@hector_9595 @Waspy69 @lp_gibby @ChoooCole @TanksAlotBrad Exactly! We feel sexualized. Just because one man thinks he hides his porn consumption so well doesn't mean a thing for how girls wish we could skip the sexual objectification we feel/dread thanks to porn culture.\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.25 ms /    16 runs   (    0.58 ms per token,  1730.48 tokens per second)\n",
            "llama_print_timings: prompt eval time =     275.83 ms /    71 tokens (    3.88 ms per token,   257.40 tokens per second)\n",
            "llama_print_timings:        eval time =    1566.86 ms /    15 runs   (  104.46 ms per token,     9.57 tokens per second)\n",
            "llama_print_timings:       total time =    2060.68 ms /    86 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@VERONASFILMS Some people, facing age, fetishize youth. Other people, facing insecurity, fetishize stability. Mostly, what seems gross about age gaps is the objectification, same in relationships built around money. But they happen every day. And they sometimes work out. And life goes on.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.99 ms /    16 runs   (    0.75 ms per token,  1334.56 tokens per second)\n",
            "llama_print_timings: prompt eval time =     266.63 ms /    77 tokens (    3.46 ms per token,   288.79 tokens per second)\n",
            "llama_print_timings:        eval time =    1812.22 ms /    15 runs   (  120.81 ms per token,     8.28 tokens per second)\n",
            "llama_print_timings:       total time =    2462.04 ms /    92 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Secretruin1 @crw555 @LibyaLiberty If you read any Islamic missionary literature, you'd know that even the burka is empowering to women of faith. By covering the body, it frees the woman from objectification and allows others to judge her not by her appearance but by her character.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.96 ms /    16 runs   (    0.56 ms per token,  1786.11 tokens per second)\n",
            "llama_print_timings: prompt eval time =     250.53 ms /    44 tokens (    5.69 ms per token,   175.63 tokens per second)\n",
            "llama_print_timings:        eval time =    1645.16 ms /    15 runs   (  109.68 ms per token,     9.12 tokens per second)\n",
            "llama_print_timings:       total time =    2065.48 ms /    59 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "like on the other hand this does fully read like a klk fan saying the fanservice is meaningful at face value but its Really Fucking Blatant about its role reversal of objectification\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.01 ms /    16 runs   (    0.56 ms per token,  1776.79 tokens per second)\n",
            "llama_print_timings: prompt eval time =     711.19 ms /    26 tokens (   27.35 ms per token,    36.56 tokens per second)\n",
            "llama_print_timings:        eval time =    1645.26 ms /    15 runs   (  109.68 ms per token,     9.12 tokens per second)\n",
            "llama_print_timings:       total time =    2487.67 ms /    41 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@HonestYPTweets Evangelizing is objectification. Respect other people beliefs.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.53 ms /    16 runs   (    0.60 ms per token,  1678.56 tokens per second)\n",
            "llama_print_timings: prompt eval time =     246.28 ms /    51 tokens (    4.83 ms per token,   207.08 tokens per second)\n",
            "llama_print_timings:        eval time =    1553.65 ms /    15 runs   (  103.58 ms per token,     9.65 tokens per second)\n",
            "llama_print_timings:       total time =    1984.57 ms /    66 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "😳Again I ask, how and why are we as a society upholding and defending end-stage capitalism and its interconnected systems of oppression? https://t.co/t3kcmoos2q\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.99 ms /    16 runs   (    0.69 ms per token,  1456.00 tokens per second)\n",
            "llama_print_timings: prompt eval time =     539.45 ms /    32 tokens (   16.86 ms per token,    59.32 tokens per second)\n",
            "llama_print_timings:        eval time =    1726.89 ms /    15 runs   (  115.13 ms per token,     8.69 tokens per second)\n",
            "llama_print_timings:       total time =    2425.78 ms /    47 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@kylegriffin1 Natural hierarchy of oppression, and subordination of individual interests is the Dems platform lmao\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.63 ms /    16 runs   (    0.60 ms per token,  1660.78 tokens per second)\n",
            "llama_print_timings: prompt eval time =     294.07 ms /    83 tokens (    3.54 ms per token,   282.24 tokens per second)\n",
            "llama_print_timings:        eval time =    1619.61 ms /    15 runs   (  107.97 ms per token,     9.26 tokens per second)\n",
            "llama_print_timings:       total time =    2160.33 ms /    98 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@tankie_think @capitalismkiIIs You guys have no idea wtf u are talking about. Castro was a monster that has caused incalculable damage to the lives of many. There is a reason people jump into shark infested waters in hopes of escaping that disgusting regime. You obviously don't know what REAL oppression is.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.88 ms /    16 runs   (    0.62 ms per token,  1619.60 tokens per second)\n",
            "llama_print_timings: prompt eval time =     245.03 ms /    55 tokens (    4.46 ms per token,   224.46 tokens per second)\n",
            "llama_print_timings:        eval time =    1514.37 ms /    15 runs   (  100.96 ms per token,     9.91 tokens per second)\n",
            "llama_print_timings:       total time =    1962.57 ms /    70 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Honestly, yeah, this. These are people seeking freedom from the oppression they face in Russia. They are absolutely refugees and we should welcome them with open arms. https://t.co/j4XJU2b5la\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.87 ms /    16 runs   (    0.62 ms per token,  1620.58 tokens per second)\n",
            "llama_print_timings: prompt eval time =     274.22 ms /    67 tokens (    4.09 ms per token,   244.33 tokens per second)\n",
            "llama_print_timings:        eval time =    1614.27 ms /    15 runs   (  107.62 ms per token,     9.29 tokens per second)\n",
            "llama_print_timings:       total time =    2101.69 ms /    82 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Seeming almost interchangeable on the outside. I see tons of comments about people being other POC (Hispanic, Asian, Middle Eastern, etc) weighing in, but even OUR actual life experiences with our own forms of oppression and harm bear no weight on the experiences of others,\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.49 ms /    16 runs   (    0.66 ms per token,  1525.41 tokens per second)\n",
            "llama_print_timings: prompt eval time =     270.17 ms /    87 tokens (    3.11 ms per token,   322.02 tokens per second)\n",
            "llama_print_timings:        eval time =    1583.89 ms /    15 runs   (  105.59 ms per token,     9.47 tokens per second)\n",
            "llama_print_timings:       total time =    2119.44 ms /   102 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@The1JohnComedy @DroidLiberator @muke10101 ‘Inherently oppressive’ sounds like a pretty religious mindset. Reminds me of ‘tax is theft’, to which the answer is ‘yeah kinda, but..’. Truth is done form of sovereign democratic polity is necessary to actually minimise the level of oppression in society overall\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.71 ms /    16 runs   (    0.67 ms per token,  1493.51 tokens per second)\n",
            "llama_print_timings: prompt eval time =     276.47 ms /    49 tokens (    5.64 ms per token,   177.24 tokens per second)\n",
            "llama_print_timings:        eval time =    1598.27 ms /    15 runs   (  106.55 ms per token,     9.39 tokens per second)\n",
            "llama_print_timings:       total time =    2145.30 ms /    64 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@karencruzen1 @FruitKace @AlyceLMiller What the actual f*ck is this dismissive, sanctimonious nonsense upholding some white patriarchal bs?\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.55 ms /    16 runs   (    0.60 ms per token,  1675.04 tokens per second)\n",
            "llama_print_timings: prompt eval time =     261.19 ms /    75 tokens (    3.48 ms per token,   287.15 tokens per second)\n",
            "llama_print_timings:        eval time =    1504.92 ms /    15 runs   (  100.33 ms per token,     9.97 tokens per second)\n",
            "llama_print_timings:       total time =    1992.07 ms /    90 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Making hay till the Sun shines.Nepalese are poor students of history. Don't they see what's happening around in SEAsia and Africa. China wants to wreck and dominate. India is a big brother, a patriarchal one. https://t.co/o0hXxawER4\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.93 ms /    16 runs   (    0.56 ms per token,  1791.51 tokens per second)\n",
            "llama_print_timings: prompt eval time =     236.19 ms /    39 tokens (    6.06 ms per token,   165.12 tokens per second)\n",
            "llama_print_timings:        eval time =    1503.49 ms /    15 runs   (  100.23 ms per token,     9.98 tokens per second)\n",
            "llama_print_timings:       total time =    1909.30 ms /    54 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@ireshii_ 👌🏼Excellent reply. Otherwise these patriarchal narrow minds will take woman as granted and they know everything better than the women.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.79 ms /    16 runs   (    0.55 ms per token,  1820.46 tokens per second)\n",
            "llama_print_timings: prompt eval time =     234.36 ms /    36 tokens (    6.51 ms per token,   153.61 tokens per second)\n",
            "llama_print_timings:        eval time =    1642.78 ms /    15 runs   (  109.52 ms per token,     9.13 tokens per second)\n",
            "llama_print_timings:       total time =    2040.58 ms /    51 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@LarryQobooks @CalltoActivism If you’re a patriarchal partisan, yes. Enlightened male, no.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      12.01 ms /    16 runs   (    0.75 ms per token,  1332.11 tokens per second)\n",
            "llama_print_timings: prompt eval time =     304.03 ms /   104 tokens (    2.92 ms per token,   342.08 tokens per second)\n",
            "llama_print_timings:        eval time =    1862.50 ms /    15 runs   (  124.17 ms per token,     8.05 tokens per second)\n",
            "llama_print_timings:       total time =    2646.72 ms /   119 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@bri_saunders @badash_birdie @mystalkersadick @xPlantZaddy @DrewAfualo Did you miss the part where Drew upholds patriarchal standards by doing exactly what those people are doing: bodyshaming? I guess your parents never taught you not to stoop down to someone’s level. Figures. Body shaming will always exist so long as Drew’s content does. Bye!\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.39 ms /    16 runs   (    0.59 ms per token,  1703.40 tokens per second)\n",
            "llama_print_timings: prompt eval time =     251.61 ms /    47 tokens (    5.35 ms per token,   186.80 tokens per second)\n",
            "llama_print_timings:        eval time =    1577.23 ms /    15 runs   (  105.15 ms per token,     9.51 tokens per second)\n",
            "llama_print_timings:       total time =    2003.94 ms /    62 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@AwokeRoseArisen This screengrab was written by a woman, but you are so right - she was definitely brainwashed by her patriarchal religion and the men in her life.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.60 ms /    16 runs   (    0.60 ms per token,  1667.36 tokens per second)\n",
            "llama_print_timings: prompt eval time =     274.19 ms /    78 tokens (    3.52 ms per token,   284.48 tokens per second)\n",
            "llama_print_timings:        eval time =    1548.32 ms /    15 runs   (  103.22 ms per token,     9.69 tokens per second)\n",
            "llama_print_timings:       total time =    2044.68 ms /    93 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "I had a dream last night where I had 4 new Pretty Princess Formal Dresses. Woke up to a grey and oppressive reality in which I only have the same 5 dresses and no new ones. This is what life under patriarchy looks like. Join the fight against sexism today. 💋✊\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.41 ms /    16 runs   (    0.53 ms per token,  1903.18 tokens per second)\n",
            "llama_print_timings: prompt eval time =     243.55 ms /    38 tokens (    6.41 ms per token,   156.03 tokens per second)\n",
            "llama_print_timings:        eval time =    1663.99 ms /    15 runs   (  110.93 ms per token,     9.01 tokens per second)\n",
            "llama_print_timings:       total time =    2070.48 ms /    53 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "I don’t hate men, I hate patriarchy and if you can’t discern between the two then I do in fact hate you 🤗\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.60 ms /    16 runs   (    0.66 ms per token,  1508.86 tokens per second)\n",
            "llama_print_timings: prompt eval time =     256.13 ms /    57 tokens (    4.49 ms per token,   222.54 tokens per second)\n",
            "llama_print_timings:        eval time =    1817.26 ms /    15 runs   (  121.15 ms per token,     8.25 tokens per second)\n",
            "llama_print_timings:       total time =    2287.50 ms /    72 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@legionesumus @samplante03 you are annoying and gross lol. stay stuck with the sheep by thinking this way, see what that does for ya. the patriarchy is for the top 1% and clearly its not getting you anywhere\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.01 ms /    16 runs   (    0.63 ms per token,  1598.56 tokens per second)\n",
            "llama_print_timings: prompt eval time =     277.47 ms /    68 tokens (    4.08 ms per token,   245.08 tokens per second)\n",
            "llama_print_timings:        eval time =    1566.23 ms /    15 runs   (  104.42 ms per token,     9.58 tokens per second)\n",
            "llama_print_timings:       total time =    2168.89 ms /    83 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Typhoid_Kaitlyn Yeah it is. I’m 6’1” (185cm) and I love it. ❤️ I am an amazonian warrior goddess and once I get some high heels I will crush the patriarchy beneath them. 💃\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.31 ms /    16 runs   (    0.64 ms per token,  1552.49 tokens per second)\n",
            "llama_print_timings: prompt eval time =     276.13 ms /    86 tokens (    3.21 ms per token,   311.44 tokens per second)\n",
            "llama_print_timings:        eval time =    1627.81 ms /    15 runs   (  108.52 ms per token,     9.21 tokens per second)\n",
            "llama_print_timings:       total time =    2152.18 ms /   101 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Joseph621960 @tomaroundworld @magisternihil you are drifting away a little. or should i say you are too specific? it is a broad issue. just, small things lead to bigger ones. that is why patriarchy still exists. statistics can say otherwise sometimes. of course. but it is visible in peoples mindset you don't+\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.77 ms /    16 runs   (    0.61 ms per token,  1637.00 tokens per second)\n",
            "llama_print_timings: prompt eval time =     276.15 ms /    99 tokens (    2.79 ms per token,   358.50 tokens per second)\n",
            "llama_print_timings:        eval time =    1523.10 ms /    15 runs   (  101.54 ms per token,     9.85 tokens per second)\n",
            "llama_print_timings:       total time =    2078.04 ms /   114 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@blessed_3ssence @ManibaGiovanni @Lekki27004154 @EmmanuelUguru6 Yea why are you telling me this? Do you think I agree with this? That's what patriarchy does like all other systems it instills beliefs in people but we don't do any good by attacking the wrong issues we need to properly attack ideas the patriarchy instills not say lol secret gay\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.45 ms /    16 runs   (    0.53 ms per token,  1893.27 tokens per second)\n",
            "llama_print_timings: prompt eval time =     249.75 ms /    58 tokens (    4.31 ms per token,   232.23 tokens per second)\n",
            "llama_print_timings:        eval time =    1444.54 ms /    15 runs   (   96.30 ms per token,    10.38 tokens per second)\n",
            "llama_print_timings:       total time =    1891.73 ms /    73 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@nezih_seven “patrilineal descendants” of the Yamnaya which suggests a direction migration from the steppes correlating with point (1). As for if there was any gene flow from Central Asia, this could still be possible.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.70 ms /    16 runs   (    0.73 ms per token,  1367.99 tokens per second)\n",
            "llama_print_timings: prompt eval time =     258.20 ms /    54 tokens (    4.78 ms per token,   209.14 tokens per second)\n",
            "llama_print_timings:        eval time =    1761.76 ms /    15 runs   (  117.45 ms per token,     8.51 tokens per second)\n",
            "llama_print_timings:       total time =    2329.79 ms /    69 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "You have your terms in reverse. Most BW still have their kids take the father's last name. That's patrilineal. We are mostly matriarchal https://t.co/DeYefpulZw\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.09 ms /    16 runs   (    0.57 ms per token,  1761.14 tokens per second)\n",
            "llama_print_timings: prompt eval time =     260.60 ms /    69 tokens (    3.78 ms per token,   264.78 tokens per second)\n",
            "llama_print_timings:        eval time =    1549.20 ms /    15 runs   (  103.28 ms per token,     9.68 tokens per second)\n",
            "llama_print_timings:       total time =    2020.56 ms /    84 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@YChalt You can't have two sets of Jews, those Jewish from a religious perspective and those who are Jewish from another.The innovative of patrilineal descent for Jewish identity is an official American Reform platform. Being anti-Israel is not an official platform of Orthodox Judaism.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.34 ms /    16 runs   (    0.58 ms per token,  1712.51 tokens per second)\n",
            "llama_print_timings: prompt eval time =     282.98 ms /    98 tokens (    2.89 ms per token,   346.32 tokens per second)\n",
            "llama_print_timings:        eval time =    1480.34 ms /    15 runs   (   98.69 ms per token,    10.13 tokens per second)\n",
            "llama_print_timings:       total time =    2031.72 ms /   113 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "FYI, this is misleading. Genetic diversity plummeted in the bottleneck, but that means the diversity of men reproducing was cratering, not male populations in general. Y lineages were being wiped out, but suggestion 94% of men were as well is a reach.https://t.co/L7axo6T7mx https://t.co/58DeP5pvLw\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.88 ms /    16 runs   (    0.55 ms per token,  1802.21 tokens per second)\n",
            "llama_print_timings: prompt eval time =     242.35 ms /    41 tokens (    5.91 ms per token,   169.17 tokens per second)\n",
            "llama_print_timings:        eval time =    1575.39 ms /    15 runs   (  105.03 ms per token,     9.52 tokens per second)\n",
            "llama_print_timings:       total time =    1984.17 ms /    56 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@lancerubinparty Aw yay, thank you so much, Lance!! (This book and this author are fully on the side of patrilineal Jews.)\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      12.10 ms /    16 runs   (    0.76 ms per token,  1321.99 tokens per second)\n",
            "llama_print_timings: prompt eval time =     275.44 ms /    79 tokens (    3.49 ms per token,   286.81 tokens per second)\n",
            "llama_print_timings:        eval time =    1815.72 ms /    15 runs   (  121.05 ms per token,     8.26 tokens per second)\n",
            "llama_print_timings:       total time =    2381.29 ms /    94 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@ParmSingh82 @RadRoopa We see the custom of automatic patrilineal surnames in Canada having an impact on names of minority cultures. Eg. You’ll meet women with Polish ethnic backgrounds (like myself) with “ski” rather than the traditional “ska”. Why? Because that’s my father’s last name.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.31 ms /    16 runs   (    0.58 ms per token,  1718.21 tokens per second)\n",
            "llama_print_timings: prompt eval time =     259.80 ms /    39 tokens (    6.66 ms per token,   150.12 tokens per second)\n",
            "llama_print_timings:        eval time =    1569.97 ms /    15 runs   (  104.66 ms per token,     9.55 tokens per second)\n",
            "llama_print_timings:       total time =    1983.13 ms /    54 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@DrProudman Apparently bonobos are patrilocal but the females dominate and rule because they cooperate, form alliances and treat each other like sisters.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.89 ms /    16 runs   (    0.62 ms per token,  1616.98 tokens per second)\n",
            "llama_print_timings: prompt eval time =     272.16 ms /    95 tokens (    2.86 ms per token,   349.06 tokens per second)\n",
            "llama_print_timings:        eval time =    1546.80 ms /    15 runs   (  103.12 ms per token,     9.70 tokens per second)\n",
            "llama_print_timings:       total time =    2095.42 ms /   110 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@AdamBode4 @SimianSeminar @CostelloWilliam Just rt that 1 earlier today. Haven't got past the abstr bt didn't want to lose it in my stack. For a quick skim, it seems like it might challenge the recent paper by Singh&amp;Glowacki Re present convo, seems to indicate kin supp might not be present, esplly if mostly patrilocal\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.72 ms /    16 runs   (    0.61 ms per token,  1645.24 tokens per second)\n",
            "llama_print_timings: prompt eval time =     267.44 ms /    83 tokens (    3.22 ms per token,   310.35 tokens per second)\n",
            "llama_print_timings:        eval time =    1469.44 ms /    15 runs   (   97.96 ms per token,    10.21 tokens per second)\n",
            "llama_print_timings:       total time =    1974.12 ms /    98 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Many women in patrilocal societies face constraints in their reproductive decision-making. A new blog summarizes the latest research by @MVKarra + colleagues into how social networks can help women better access family planning services: https://t.co/453IimPxY5 https://t.co/q5qXIAmYHQ\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.77 ms /    16 runs   (    0.61 ms per token,  1638.17 tokens per second)\n",
            "llama_print_timings: prompt eval time =     236.72 ms /    36 tokens (    6.58 ms per token,   152.08 tokens per second)\n",
            "llama_print_timings:        eval time =    1638.98 ms /    15 runs   (  109.27 ms per token,     9.15 tokens per second)\n",
            "llama_print_timings:       total time =    2038.77 ms /    51 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "I want to work with Margaret Qualley again. Think they'd like to be Patrilocal Saturdays Debtman in my next game?\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.50 ms /    16 runs   (    0.66 ms per token,  1523.81 tokens per second)\n",
            "llama_print_timings: prompt eval time =     299.72 ms /    86 tokens (    3.49 ms per token,   286.93 tokens per second)\n",
            "llama_print_timings:        eval time =    1626.30 ms /    15 runs   (  108.42 ms per token,     9.22 tokens per second)\n",
            "llama_print_timings:       total time =    2326.00 ms /   101 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Evolving_Moloch https://t.co/M8cLZmW8wdEuropean Neolithic society, at one extreme (but hardly peripheral) edge of its distribution, may have been patrilineal, patrilocal, and hierarchical long before the arrival of the Beaker complex and (most likely) Indo-European speech\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.70 ms /    16 runs   (    0.61 ms per token,  1648.97 tokens per second)\n",
            "llama_print_timings: prompt eval time =     277.40 ms /    95 tokens (    2.92 ms per token,   342.46 tokens per second)\n",
            "llama_print_timings:        eval time =    1601.57 ms /    15 runs   (  106.77 ms per token,     9.37 tokens per second)\n",
            "llama_print_timings:       total time =    2138.79 ms /   110 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Greco-Roman marriage rites seem exactly like Vedic Hindu rites. Father giving away his daughter (kanyadaan), Agni (sacred fire) as witness, patrilocal residence, the groom' party coming to take her away (baraat), rarity of divorce/polygamy, arranged marriages, dowry, color red https://t.co/KaAZ3IOCIm\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.55 ms /    16 runs   (    0.60 ms per token,  1675.74 tokens per second)\n",
            "llama_print_timings: prompt eval time =     258.81 ms /    70 tokens (    3.70 ms per token,   270.47 tokens per second)\n",
            "llama_print_timings:        eval time =    1578.20 ms /    15 runs   (  105.21 ms per token,     9.50 tokens per second)\n",
            "llama_print_timings:       total time =    2065.05 ms /    85 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Are Penis Envy mushrooms actually 2-3x more potent than other strains? https://t.co/M7WDxereZ9 - #Mmemberville #StonerFam #CannabisCommunity https://t.co/YaQeenHdoE\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.71 ms /    16 runs   (    0.54 ms per token,  1835.92 tokens per second)\n",
            "llama_print_timings: prompt eval time =     237.37 ms /    36 tokens (    6.59 ms per token,   151.66 tokens per second)\n",
            "llama_print_timings:        eval time =    1701.73 ms /    15 runs   (  113.45 ms per token,     8.81 tokens per second)\n",
            "llama_print_timings:       total time =    2093.09 ms /    51 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Another cuck with #Trump penis envy. 👇 https://t.co/cVxIKHfnEQ\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.91 ms /    16 runs   (    0.74 ms per token,  1343.07 tokens per second)\n",
            "llama_print_timings: prompt eval time =     267.47 ms /    58 tokens (    4.61 ms per token,   216.85 tokens per second)\n",
            "llama_print_timings:        eval time =    1844.89 ms /    15 runs   (  122.99 ms per token,     8.13 tokens per second)\n",
            "llama_print_timings:       total time =    2438.88 ms /    73 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@PamelaKellar3 @JohnFugelsang China had a lot of cash on hand and announced a moon&gt;Mars project some years back, and we got penis envy. So far, we’ve got Space Force!\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.60 ms /    16 runs   (    0.60 ms per token,  1665.97 tokens per second)\n",
            "llama_print_timings: prompt eval time =     558.04 ms /    20 tokens (   27.90 ms per token,    35.84 tokens per second)\n",
            "llama_print_timings:        eval time =    1579.27 ms /    15 runs   (  105.28 ms per token,     9.50 tokens per second)\n",
            "llama_print_timings:       total time =    2251.92 ms /    35 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@RadioFreeTom Does Ben Shapiro suffer from penis envy??!\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.82 ms /    16 runs   (    0.55 ms per token,  1814.88 tokens per second)\n",
            "llama_print_timings: prompt eval time =     747.53 ms /    30 tokens (   24.92 ms per token,    40.13 tokens per second)\n",
            "llama_print_timings:        eval time =    1467.29 ms /    15 runs   (   97.82 ms per token,    10.22 tokens per second)\n",
            "llama_print_timings:       total time =    2346.39 ms /    45 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Imagine having penis envy, couldn’t be me…. Actually it is me. Unblessed FeelsBadMan\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.78 ms /    16 runs   (    0.55 ms per token,  1823.15 tokens per second)\n",
            "llama_print_timings: prompt eval time =     669.70 ms /    27 tokens (   24.80 ms per token,    40.32 tokens per second)\n",
            "llama_print_timings:        eval time =    1456.51 ms /    15 runs   (   97.10 ms per token,    10.30 tokens per second)\n",
            "llama_print_timings:       total time =    2253.08 ms /    42 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@susi815 @robreiner Because Lil .@robreiner has penis envy\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      12.08 ms /    16 runs   (    0.76 ms per token,  1324.17 tokens per second)\n",
            "llama_print_timings: prompt eval time =     247.43 ms /    56 tokens (    4.42 ms per token,   226.33 tokens per second)\n",
            "llama_print_timings:        eval time =    1896.23 ms /    15 runs   (  126.42 ms per token,     7.91 tokens per second)\n",
            "llama_print_timings:       total time =    2378.54 ms /    71 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@GeoffWarburton @SophieRunning Interesting how bothered you are by women standing for children, girls and womens rights, safety and dignity.You would do well to reflect deeply on your misogyny and phallocentrism.\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.81 ms /    16 runs   (    0.55 ms per token,  1815.50 tokens per second)\n",
            "llama_print_timings: prompt eval time =     610.09 ms /    23 tokens (   26.53 ms per token,    37.70 tokens per second)\n",
            "llama_print_timings:        eval time =    1550.48 ms /    15 runs   (  103.37 ms per token,     9.67 tokens per second)\n",
            "llama_print_timings:       total time =    2274.55 ms /    38 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@amerix I prefer Amerix sticking to phallocentrism politics is for the uncouth\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.09 ms /    16 runs   (    0.63 ms per token,  1585.41 tokens per second)\n",
            "llama_print_timings: prompt eval time =     263.04 ms /    71 tokens (    3.70 ms per token,   269.92 tokens per second)\n",
            "llama_print_timings:        eval time =    1579.63 ms /    15 runs   (  105.31 ms per token,     9.50 tokens per second)\n",
            "llama_print_timings:       total time =    2076.79 ms /    86 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Marshall Neilan's \"Stella Maris\" (1918) is a powerful testament to Mary Pickford's remarkable versatility. Her delicate vulnerability is counteracted by a rugged strength of character in a dual role that simultaneously questions social phallocentrism and feminine agency.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.90 ms /    16 runs   (    0.62 ms per token,  1616.32 tokens per second)\n",
            "llama_print_timings: prompt eval time =     262.69 ms /    75 tokens (    3.50 ms per token,   285.50 tokens per second)\n",
            "llama_print_timings:        eval time =    1549.81 ms /    15 runs   (  103.32 ms per token,     9.68 tokens per second)\n",
            "llama_print_timings:       total time =    2039.55 ms /    90 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@mercy4marcy @karwansewe @CoolRiderr @Grindr If they didn't see like that, he wouldn't be specific about \"biological male\". I think they see trans men as men, but not enough since they have p*ssy. It's just phallocentrism\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.71 ms /    16 runs   (    0.67 ms per token,  1494.21 tokens per second)\n",
            "llama_print_timings: prompt eval time =     243.81 ms /    46 tokens (    5.30 ms per token,   188.67 tokens per second)\n",
            "llama_print_timings:        eval time =    1770.08 ms /    15 runs   (  118.01 ms per token,     8.47 tokens per second)\n",
            "llama_print_timings:       total time =    2208.33 ms /    61 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Modern London skyline exemplifies architectural phallocentrism at its worst. An ego driven tumescence contest of glass and steel that cannot seem to decide whose is uglier than whose.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.93 ms /    16 runs   (    0.56 ms per token,  1791.51 tokens per second)\n",
            "llama_print_timings: prompt eval time =     575.78 ms /    32 tokens (   17.99 ms per token,    55.58 tokens per second)\n",
            "llama_print_timings:        eval time =    1519.61 ms /    15 runs   (  101.31 ms per token,     9.87 tokens per second)\n",
            "llama_print_timings:       total time =    2281.24 ms /    47 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@catholicpat Ableism and phallocentrism are my new political opinions now that I’m over 30\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.42 ms /    16 runs   (    0.59 ms per token,  1698.15 tokens per second)\n",
            "llama_print_timings: prompt eval time =     260.03 ms /    70 tokens (    3.71 ms per token,   269.20 tokens per second)\n",
            "llama_print_timings:        eval time =    1559.53 ms /    15 runs   (  103.97 ms per token,     9.62 tokens per second)\n",
            "llama_print_timings:       total time =    2046.83 ms /    85 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Subjectivity and Sexual Difference: Analyzes of Phallogocentrism in Psychoanalysis and Poststructuralist FeminismLee el artículo en: https://t.co/PenMs0TR63 https://t.co/XUf441yHYJ\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.03 ms /    16 runs   (    0.63 ms per token,  1595.85 tokens per second)\n",
            "llama_print_timings: prompt eval time =     278.52 ms /    75 tokens (    3.71 ms per token,   269.28 tokens per second)\n",
            "llama_print_timings:        eval time =    1617.34 ms /    15 runs   (  107.82 ms per token,     9.27 tokens per second)\n",
            "llama_print_timings:       total time =    2128.07 ms /    90 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@v_zahtila @ContraPoints i don't know a lot here but i'm pretty sure they [some people] claim the reverse is true [that definite conclusions are \"masculine\" and endless discourse is \"feminine\"]https://t.co/vFvFyhGMJt\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.97 ms /    16 runs   (    0.62 ms per token,  1605.30 tokens per second)\n",
            "llama_print_timings: prompt eval time =     273.67 ms /    78 tokens (    3.51 ms per token,   285.02 tokens per second)\n",
            "llama_print_timings:        eval time =    1583.68 ms /    15 runs   (  105.58 ms per token,     9.47 tokens per second)\n",
            "llama_print_timings:       total time =    2088.13 ms /    93 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "via @NYTimes. Of course #Derrida makes an appearance. Of course NYT embarrasses itself. D did not “coin” the term “deconstruction”. He did however write about carno-phallogocentrism, a concept that seems relevant here.  https://t.co/6unqWbYRc7\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.68 ms /    16 runs   (    0.73 ms per token,  1369.39 tokens per second)\n",
            "llama_print_timings: prompt eval time =     255.09 ms /    55 tokens (    4.64 ms per token,   215.61 tokens per second)\n",
            "llama_print_timings:        eval time =    1782.00 ms /    15 runs   (  118.80 ms per token,     8.42 tokens per second)\n",
            "llama_print_timings:       total time =    2340.91 ms /    70 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@feelsdesperate Heterocispatriarchy. Phallogocentrism. Harm. Violence. Canceled. (I left out the words that would coherently connect these terms, as those are irrelevant.)\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.72 ms /    16 runs   (    0.61 ms per token,  1645.24 tokens per second)\n",
            "llama_print_timings: prompt eval time =     268.31 ms /    57 tokens (    4.71 ms per token,   212.44 tokens per second)\n",
            "llama_print_timings:        eval time =    1519.40 ms /    15 runs   (  101.29 ms per token,     9.87 tokens per second)\n",
            "llama_print_timings:       total time =    1969.08 ms /    72 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "in general would call myself a pluralist in most aspects. \"the struggle for language and the struggle against perfect communication, against the one code that translates all meaning perfectly, the central dogma of phallogocentrism\" as haraway puts it\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.88 ms /    16 runs   (    0.62 ms per token,  1620.25 tokens per second)\n",
            "llama_print_timings: prompt eval time =     242.83 ms /    52 tokens (    4.67 ms per token,   214.14 tokens per second)\n",
            "llama_print_timings:        eval time =    1526.94 ms /    15 runs   (  101.80 ms per token,     9.82 tokens per second)\n",
            "llama_print_timings:       total time =    1970.06 ms /    67 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "I recall learning about Derrida's term phallogocentrism in a college critical theory seminar. It always seemed a bit obtuse for everyday political discourse but nope, MAGA proves me wrong.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.70 ms /    16 runs   (    0.54 ms per token,  1840.14 tokens per second)\n",
            "llama_print_timings: prompt eval time =     252.88 ms /    49 tokens (    5.16 ms per token,   193.77 tokens per second)\n",
            "llama_print_timings:        eval time =    1528.11 ms /    15 runs   (  101.87 ms per token,     9.82 tokens per second)\n",
            "llama_print_timings:       total time =    1959.93 ms /    64 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "⠀ Like what ?Does Cassandra have some people she can fight ! ?⠀ https://t.co/nTxHhpdyI6 https://t.co/g8F4vDqHmr\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.45 ms /    16 runs   (    0.72 ms per token,  1397.01 tokens per second)\n",
            "llama_print_timings: prompt eval time =     255.40 ms /    57 tokens (    4.48 ms per token,   223.18 tokens per second)\n",
            "llama_print_timings:        eval time =    1752.49 ms /    15 runs   (  116.83 ms per token,     8.56 tokens per second)\n",
            "llama_print_timings:       total time =    2233.04 ms /    72 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "aren't we going to talk about how freaking hot this photo is?? this is just a glimpse but holy moly i cannot breathe #SarahGisBack fr fr https://t.co/Rd2Z4p92oo\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.78 ms /    16 runs   (    0.61 ms per token,  1635.82 tokens per second)\n",
            "llama_print_timings: prompt eval time =     294.79 ms /    91 tokens (    3.24 ms per token,   308.70 tokens per second)\n",
            "llama_print_timings:        eval time =    1520.37 ms /    15 runs   (  101.36 ms per token,     9.87 tokens per second)\n",
            "llama_print_timings:       total time =    2069.15 ms /   106 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "SO THE ALIEN’S NAME IS ACTUALLY KIWI BUT THEY CALL HER THE LIZZERD KWEEN WHICH WAS A NICKNAME THE ARTIST GOT IN HS BUT SHE’S BEEN DRAWING KIWI SINCE CHILDHOOD https://t.co/mNoYWVWYnG\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.99 ms /    16 runs   (    0.56 ms per token,  1779.36 tokens per second)\n",
            "llama_print_timings: prompt eval time =     241.49 ms /    41 tokens (    5.89 ms per token,   169.78 tokens per second)\n",
            "llama_print_timings:        eval time =    1554.30 ms /    15 runs   (  103.62 ms per token,     9.65 tokens per second)\n",
            "llama_print_timings:       total time =    1961.18 ms /    56 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "They always do! Hypocrisy of the mainstream media!#GazaUnderAttack https://t.co/Ryq5gxH0xu\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.69 ms /    16 runs   (    0.54 ms per token,  1840.56 tokens per second)\n",
            "llama_print_timings: prompt eval time =     242.80 ms /    37 tokens (    6.56 ms per token,   152.39 tokens per second)\n",
            "llama_print_timings:        eval time =    1555.81 ms /    15 runs   (  103.72 ms per token,     9.64 tokens per second)\n",
            "llama_print_timings:       total time =    1958.76 ms /    52 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Zendaya for Versace #FashionIcons #Zendaya #Versace https://t.co/mEXh70WiBu\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.42 ms /    16 runs   (    0.59 ms per token,  1698.51 tokens per second)\n",
            "llama_print_timings: prompt eval time =     240.84 ms /    48 tokens (    5.02 ms per token,   199.30 tokens per second)\n",
            "llama_print_timings:        eval time =    1529.32 ms /    15 runs   (  101.95 ms per token,     9.81 tokens per second)\n",
            "llama_print_timings:       total time =    1955.27 ms /    63 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Not on my watch!#TeamSprunk#GTAOnline #Snapmatic #VirtualPhotography @RockstarGames https://t.co/AlcoRJgepQ\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.11 ms /    16 runs   (    0.63 ms per token,  1581.97 tokens per second)\n",
            "llama_print_timings: prompt eval time =     247.33 ms /    34 tokens (    7.27 ms per token,   137.47 tokens per second)\n",
            "llama_print_timings:        eval time =    1654.35 ms /    15 runs   (  110.29 ms per token,     9.07 tokens per second)\n",
            "llama_print_timings:       total time =    2121.15 ms /    49 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@_DesigNNN @Courbevoie_PND @Pandore_esport Tes le boss ❤️\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.07 ms /    16 runs   (    0.57 ms per token,  1764.84 tokens per second)\n",
            "llama_print_timings: prompt eval time =     242.27 ms /    44 tokens (    5.51 ms per token,   181.62 tokens per second)\n",
            "llama_print_timings:        eval time =    1537.73 ms /    15 runs   (  102.52 ms per token,     9.75 tokens per second)\n",
            "llama_print_timings:       total time =    1956.67 ms /    59 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@ECtheArtist On top of people saying PND instead of PNBrock 🙄 the spread of false information. I had to literally search to see what happened and to WHO.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.88 ms /    16 runs   (    0.56 ms per token,  1801.80 tokens per second)\n",
            "llama_print_timings: prompt eval time =     695.34 ms /    27 tokens (   25.75 ms per token,    38.83 tokens per second)\n",
            "llama_print_timings:        eval time =    1516.75 ms /    15 runs   (  101.12 ms per token,     9.89 tokens per second)\n",
            "llama_print_timings:       total time =    2344.28 ms /    42 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "i just want to thank PND, Kanye and anime instrumentals for getting me to my full potential\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.21 ms /    16 runs   (    0.58 ms per token,  1738.00 tokens per second)\n",
            "llama_print_timings: prompt eval time =     789.91 ms /    30 tokens (   26.33 ms per token,    37.98 tokens per second)\n",
            "llama_print_timings:        eval time =    1628.87 ms /    15 runs   (  108.59 ms per token,     9.21 tokens per second)\n",
            "llama_print_timings:       total time =    2558.30 ms /    45 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Soros mini-me, God help us:https://t.co/VbEO5KgaB8\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.01 ms /    16 runs   (    0.63 ms per token,  1598.56 tokens per second)\n",
            "llama_print_timings: prompt eval time =     812.51 ms /    25 tokens (   32.50 ms per token,    30.77 tokens per second)\n",
            "llama_print_timings:        eval time =    1800.62 ms /    15 runs   (  120.04 ms per token,     8.33 tokens per second)\n",
            "llama_print_timings:       total time =    2797.85 ms /    40 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Mad overcast today. I’ll be listening to all PND. A fucking vibe.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      13.40 ms /    16 runs   (    0.84 ms per token,  1194.21 tokens per second)\n",
            "llama_print_timings: prompt eval time =     254.23 ms /    64 tokens (    3.97 ms per token,   251.74 tokens per second)\n",
            "llama_print_timings:        eval time =    1540.99 ms /    15 runs   (  102.73 ms per token,     9.73 tokens per second)\n",
            "llama_print_timings:       total time =    2007.69 ms /    79 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@JasperPeachSays Just a bunch of incredibly kind, earnest young dudes. One still says hi to me if he sees me at the coffee shop. One brought his fresh baby to school for a month while his wife was recovering from PND. They were awesome.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.23 ms /    16 runs   (    0.58 ms per token,  1734.04 tokens per second)\n",
            "llama_print_timings: prompt eval time =     266.02 ms /    73 tokens (    3.64 ms per token,   274.42 tokens per second)\n",
            "llama_print_timings:        eval time =    1540.48 ms /    15 runs   (  102.70 ms per token,     9.74 tokens per second)\n",
            "llama_print_timings:       total time =    2025.61 ms /    88 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Top story: Pound sinks below $1.16 as UK ‘faces deepest living standards squeeze in a century’ – business live  | Business | The Guardian https://t.co/c8m7v8xodY, see more https://t.co/qJ85ODwrSo\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.61 ms /    16 runs   (    0.60 ms per token,  1665.11 tokens per second)\n",
            "llama_print_timings: prompt eval time =     250.36 ms /    54 tokens (    4.64 ms per token,   215.69 tokens per second)\n",
            "llama_print_timings:        eval time =    1455.72 ms /    15 runs   (   97.05 ms per token,    10.30 tokens per second)\n",
            "llama_print_timings:       total time =    1906.30 ms /    69 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Nascar twitter mad a black man won a nascar race. Dude has talent. More talent than you dumb hick fucks at home with your 450 pound wife and section 8. Fuck outta here\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      12.31 ms /    16 runs   (    0.77 ms per token,  1299.97 tokens per second)\n",
            "llama_print_timings: prompt eval time =     241.40 ms /    58 tokens (    4.16 ms per token,   240.27 tokens per second)\n",
            "llama_print_timings:        eval time =    1880.34 ms /    15 runs   (  125.36 ms per token,     7.98 tokens per second)\n",
            "llama_print_timings:       total time =    2417.38 ms /    73 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Day 1 basically: “the problem here is that things were far too stable under my predecessor and continue to be today, let’s make the pound and the market go boom, that will help” ~ @trussliz or something…just now\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.12 ms /    16 runs   (    0.57 ms per token,  1753.42 tokens per second)\n",
            "llama_print_timings: prompt eval time =     254.91 ms /    33 tokens (    7.72 ms per token,   129.46 tokens per second)\n",
            "llama_print_timings:        eval time =    1439.40 ms /    15 runs   (   95.96 ms per token,    10.42 tokens per second)\n",
            "llama_print_timings:       total time =    1859.26 ms /    48 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "\"i'm going to pound you into the dirt later\" https://t.co/OnXVsOQBhA\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.00 ms /    16 runs   (    0.56 ms per token,  1777.98 tokens per second)\n",
            "llama_print_timings: prompt eval time =     241.31 ms /    43 tokens (    5.61 ms per token,   178.20 tokens per second)\n",
            "llama_print_timings:        eval time =    1580.54 ms /    15 runs   (  105.37 ms per token,     9.49 tokens per second)\n",
            "llama_print_timings:       total time =    1990.28 ms /    58 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@HoneynLola @Staffy_Pooch You guys looks bigger than a pound to me... https://t.co/ZrrL2zElZd\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.33 ms /    16 runs   (    0.52 ms per token,  1921.69 tokens per second)\n",
            "llama_print_timings: prompt eval time =     581.29 ms /    24 tokens (   24.22 ms per token,    41.29 tokens per second)\n",
            "llama_print_timings:        eval time =    1558.35 ms /    15 runs   (  103.89 ms per token,     9.63 tokens per second)\n",
            "llama_print_timings:       total time =    2256.91 ms /    39 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "I unintentionally lost a pound in one week. I hate unhealthy weight loss\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.85 ms /    16 runs   (    0.62 ms per token,  1625.03 tokens per second)\n",
            "llama_print_timings: prompt eval time =     242.06 ms /    43 tokens (    5.63 ms per token,   177.64 tokens per second)\n",
            "llama_print_timings:        eval time =    1502.06 ms /    15 runs   (  100.14 ms per token,     9.99 tokens per second)\n",
            "llama_print_timings:       total time =    1925.66 ms /    58 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@_mika60_ @sushib0mb or five and a half with Yor pregnant /again/ as she holds a bundle of joy in her arms 🥺😭\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.73 ms /    16 runs   (    0.61 ms per token,  1645.08 tokens per second)\n",
            "llama_print_timings: prompt eval time =     927.19 ms /    31 tokens (   29.91 ms per token,    33.43 tokens per second)\n",
            "llama_print_timings:        eval time =    1582.39 ms /    15 runs   (  105.49 ms per token,     9.48 tokens per second)\n",
            "llama_print_timings:       total time =    2716.36 ms /    46 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@FoxNews Pregnant elite schoolgirls. Yeah, that'll happen. Don't send your daughters there.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       3.00 ms /     5 runs   (    0.60 ms per token,  1666.67 tokens per second)\n",
            "llama_print_timings: prompt eval time =     265.05 ms /    72 tokens (    3.68 ms per token,   271.65 tokens per second)\n",
            "llama_print_timings:        eval time =     410.04 ms /     4 runs   (  102.51 ms per token,     9.76 tokens per second)\n",
            "llama_print_timings:       total time =     851.37 ms /    76 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Family speaks out after pregnant woman handcuffed at gunpoint during traffic stop in Florida https://t.co/WqSaMv22Pv via @Yahoo That figures,another black person with an attorney.Cant just except the apology and get on with life.Looking for that easy cash.\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.99 ms /    16 runs   (    0.56 ms per token,  1779.95 tokens per second)\n",
            "llama_print_timings: prompt eval time =     521.43 ms /    32 tokens (   16.29 ms per token,    61.37 tokens per second)\n",
            "llama_print_timings:        eval time =    1560.54 ms /    15 runs   (  104.04 ms per token,     9.61 tokens per second)\n",
            "llama_print_timings:       total time =    2215.34 ms /    47 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@hellonecole @JazzmineFleur But also be careful! I took this for a few months and ended up pregnant\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.21 ms /    16 runs   (    0.64 ms per token,  1566.48 tokens per second)\n",
            "llama_print_timings: prompt eval time =     249.62 ms /    62 tokens (    4.03 ms per token,   248.38 tokens per second)\n",
            "llama_print_timings:        eval time =    1534.30 ms /    15 runs   (  102.29 ms per token,     9.78 tokens per second)\n",
            "llama_print_timings:       total time =    1995.80 ms /    77 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@sarahmhawkinson Ugh the Hatchet series is so fun, but if you decide to watch Hatchet 2, just know a certain sequence in the film might be upsetting to you given the fact that you’re pregnant. Just a heads up!\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.77 ms /    16 runs   (    0.67 ms per token,  1485.88 tokens per second)\n",
            "llama_print_timings: prompt eval time =     273.81 ms /    94 tokens (    2.91 ms per token,   343.30 tokens per second)\n",
            "llama_print_timings:        eval time =    1796.45 ms /    15 runs   (  119.76 ms per token,     8.35 tokens per second)\n",
            "llama_print_timings:       total time =    2351.60 ms /   109 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@MickyMango1 Edinburgh girl calls 999. Operator: ‘What’s your emergency?’ Girl: ‘I’m pregnant.’ Operator: ‘Pregnancy is not an emergency!’ Girl: ‘My waters have broken!’ Operator: ‘Ok. Ok. That's different. Where are you ringing from?'Girl: ‘From ma fanny tae ma feet!’\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.60 ms /    16 runs   (    0.54 ms per token,  1860.68 tokens per second)\n",
            "llama_print_timings: prompt eval time =     300.72 ms /    73 tokens (    4.12 ms per token,   242.75 tokens per second)\n",
            "llama_print_timings:        eval time =    1523.43 ms /    15 runs   (  101.56 ms per token,     9.85 tokens per second)\n",
            "llama_print_timings:       total time =    2064.30 ms /    88 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Ruben_Angeles There are many reasons they might want to remain married that aren’t puritan or conservative. It’s not up for you or me to decide for them whether they remain married or not. They’re going to do what’s best for them, not what randos on Twitter tell them to do\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.58 ms /    16 runs   (    0.60 ms per token,  1669.62 tokens per second)\n",
            "llama_print_timings: prompt eval time =     246.58 ms /    54 tokens (    4.57 ms per token,   219.00 tokens per second)\n",
            "llama_print_timings:        eval time =    1543.90 ms /    15 runs   (  102.93 ms per token,     9.72 tokens per second)\n",
            "llama_print_timings:       total time =    1987.80 ms /    69 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "millennials don’t lack work ethic. I will break through concrete to get a job done the right way. but you will never catch me glorifying work for its own sake. puritan work ethic is a scam\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.35 ms /    16 runs   (    0.58 ms per token,  1710.86 tokens per second)\n",
            "llama_print_timings: prompt eval time =     241.23 ms /    42 tokens (    5.74 ms per token,   174.10 tokens per second)\n",
            "llama_print_timings:        eval time =    1473.31 ms /    15 runs   (   98.22 ms per token,    10.18 tokens per second)\n",
            "llama_print_timings:       total time =    1896.48 ms /    57 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@JWNairn I know it well. The Whalley family had an interesting trajectory as Puritan gentry who placed Puritan clergy in Notts parishes.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.12 ms /    16 runs   (    0.63 ms per token,  1580.72 tokens per second)\n",
            "llama_print_timings: prompt eval time =     274.51 ms /    99 tokens (    2.77 ms per token,   360.64 tokens per second)\n",
            "llama_print_timings:        eval time =    1570.39 ms /    15 runs   (  104.69 ms per token,     9.55 tokens per second)\n",
            "llama_print_timings:       total time =    2126.63 ms /   114 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Gamers should absolutely be put on blast for being boring ass vanilla cishet puritan dudebros\"I play fantasy games to escape reality\" my ass. Buncha squares I stg. \"Daring today, aren't we?\" when a Gamer makes their eye color yellow instead of brown. 🥱🥱🥱 https://t.co/fY3UmkTjL7\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.19 ms /    16 runs   (    0.70 ms per token,  1430.36 tokens per second)\n",
            "llama_print_timings: prompt eval time =     261.22 ms /    61 tokens (    4.28 ms per token,   233.52 tokens per second)\n",
            "llama_print_timings:        eval time =    1804.92 ms /    15 runs   (  120.33 ms per token,     8.31 tokens per second)\n",
            "llama_print_timings:       total time =    2382.33 ms /    76 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@1689JE @Sachinettiyil @JeremyTate41 @GiorgiaMeloni Typical puritan bullshit bingo. Being a saint isn't a prerequisite to being a righteous politician.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.24 ms /    16 runs   (    0.58 ms per token,  1731.60 tokens per second)\n",
            "llama_print_timings: prompt eval time =     253.02 ms /    44 tokens (    5.75 ms per token,   173.90 tokens per second)\n",
            "llama_print_timings:        eval time =    1579.03 ms /    15 runs   (  105.27 ms per token,     9.50 tokens per second)\n",
            "llama_print_timings:       total time =    2009.39 ms /    59 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "I'm no puritan saying nobody should drink but to say you have a problem if you DONT drink is flat out wrong https://t.co/AUrgpQbPfu\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.36 ms /    16 runs   (    0.65 ms per token,  1544.40 tokens per second)\n",
            "llama_print_timings: prompt eval time =     255.39 ms /    52 tokens (    4.91 ms per token,   203.61 tokens per second)\n",
            "llama_print_timings:        eval time =    1426.70 ms /    15 runs   (   95.11 ms per token,    10.51 tokens per second)\n",
            "llama_print_timings:       total time =    1868.07 ms /    67 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@DanPriceSeattle So if a woman goes to the hospital after you rape her does she have to have insurance for that or do you cover it?https://t.co/cXZJVsYMgw\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.60 ms /    16 runs   (    0.54 ms per token,  1859.60 tokens per second)\n",
            "llama_print_timings: prompt eval time =     241.47 ms /    45 tokens (    5.37 ms per token,   186.36 tokens per second)\n",
            "llama_print_timings:        eval time =    1593.40 ms /    15 runs   (  106.23 ms per token,     9.41 tokens per second)\n",
            "llama_print_timings:       total time =    2014.64 ms /    60 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@XCoastie73 @viequesdynamo @FoxNews You said 100000 dead by the way. I hadn’t gotten to rape yet.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.86 ms /    16 runs   (    0.68 ms per token,  1473.98 tokens per second)\n",
            "llama_print_timings: prompt eval time =     280.88 ms /   110 tokens (    2.55 ms per token,   391.63 tokens per second)\n",
            "llama_print_timings:        eval time =    1901.05 ms /    15 runs   (  126.74 ms per token,     7.89 tokens per second)\n",
            "llama_print_timings:       total time =    2687.32 ms /   125 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@thalia25123534 @_nikolakii_ @CTenaciousd @NototyrannyNOW Your mind said evidence doesn't count because, in a 30 year war, the locals managed to kill 80 invaders.Sure, the first attack was a massacre of 60 locals, and 6,500 were ultimately lost, but ANY violence from locals erases the words \"massacre\" and \"rape\" from existence.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.98 ms /    16 runs   (    0.62 ms per token,  1603.37 tokens per second)\n",
            "llama_print_timings: prompt eval time =     265.32 ms /    54 tokens (    4.91 ms per token,   203.52 tokens per second)\n",
            "llama_print_timings:        eval time =    1504.94 ms /    15 runs   (  100.33 ms per token,     9.97 tokens per second)\n",
            "llama_print_timings:       total time =    1976.84 ms /    69 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Do these ppl know that this law negatively affects male rape victims? Men go to report the crime and police run dem and threaten to charge them with buggery... https://t.co/oaDJMOFgj2\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.83 ms /    16 runs   (    0.55 ms per token,  1812.83 tokens per second)\n",
            "llama_print_timings: prompt eval time =     241.09 ms /    51 tokens (    4.73 ms per token,   211.54 tokens per second)\n",
            "llama_print_timings:        eval time =    1497.25 ms /    15 runs   (   99.82 ms per token,    10.02 tokens per second)\n",
            "llama_print_timings:       total time =    1917.96 ms /    66 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@SillEbot Facts man, tho I wouldn’t mind if it’s a hot woman but if I don’t mind is it still rape? Idk, If I don’t consent it is\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.37 ms /    16 runs   (    0.59 ms per token,  1707.76 tokens per second)\n",
            "llama_print_timings: prompt eval time =     269.32 ms /    81 tokens (    3.32 ms per token,   300.76 tokens per second)\n",
            "llama_print_timings:        eval time =    1485.19 ms /    15 runs   (   99.01 ms per token,    10.10 tokens per second)\n",
            "llama_print_timings:       total time =    1992.74 ms /    96 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@SturgeonRocket @eigenrobot ...to steady it in WAY too many modelsyou hit the screw with an impact gun (while your head is still inside the grill, because you have to) and now it reverberates, fucking your earsthere are ways to make this process easier, they largely don't save you the trouble of ear rape\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      12.16 ms /    16 runs   (    0.76 ms per token,  1316.22 tokens per second)\n",
            "llama_print_timings: prompt eval time =     769.18 ms /    30 tokens (   25.64 ms per token,    39.00 tokens per second)\n",
            "llama_print_timings:        eval time =    1733.08 ms /    15 runs   (  115.54 ms per token,     8.66 tokens per second)\n",
            "llama_print_timings:       total time =    2654.78 ms /    45 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "thanks for unlocking that repressed memory https://t.co/EuN8K0S9mC\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.61 ms /    16 runs   (    0.54 ms per token,  1858.52 tokens per second)\n",
            "llama_print_timings: prompt eval time =     623.00 ms /    18 tokens (   34.61 ms per token,    28.89 tokens per second)\n",
            "llama_print_timings:        eval time =    1478.64 ms /    15 runs   (   98.58 ms per token,    10.14 tokens per second)\n",
            "llama_print_timings:       total time =    2217.48 ms /    33 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "When feeling  repressed Miranda goes to Darley Dale.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.13 ms /    16 runs   (    0.63 ms per token,  1578.84 tokens per second)\n",
            "llama_print_timings: prompt eval time =     259.45 ms /    73 tokens (    3.55 ms per token,   281.36 tokens per second)\n",
            "llama_print_timings:        eval time =    1568.56 ms /    15 runs   (  104.57 ms per token,     9.56 tokens per second)\n",
            "llama_print_timings:       total time =    2047.20 ms /    88 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@JenSookfongLee it kind of explains my unabashed midlife crisis/psychosis in my 30s. As a repressed Catholic, I did every phase late. Now approaching 40 the weirdness and grump have set in. But I'm quite comfy with it?\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.91 ms /    16 runs   (    0.56 ms per token,  1794.93 tokens per second)\n",
            "llama_print_timings: prompt eval time =     233.31 ms /    33 tokens (    7.07 ms per token,   141.44 tokens per second)\n",
            "llama_print_timings:        eval time =    1497.59 ms /    15 runs   (   99.84 ms per token,    10.02 tokens per second)\n",
            "llama_print_timings:       total time =    1887.88 ms /    48 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@ReviewofDeath William Hartnell was a repressed homosexual who sometimes had sex with a man who played a Zarbi.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.55 ms /    16 runs   (    0.60 ms per token,  1675.22 tokens per second)\n",
            "llama_print_timings: prompt eval time =     266.32 ms /    72 tokens (    3.70 ms per token,   270.35 tokens per second)\n",
            "llama_print_timings:        eval time =    1565.90 ms /    15 runs   (  104.39 ms per token,     9.58 tokens per second)\n",
            "llama_print_timings:       total time =    2066.80 ms /    87 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "For the most part, I can't stand how I am because it causes me to suffer, but on occasion, I think the very same thing is beautiful bc it allows me to feel life on a level that's really raw and deep andSame thing makes me suffer a lot, but as someone who used to be repressed\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.36 ms /    16 runs   (    0.71 ms per token,  1408.57 tokens per second)\n",
            "llama_print_timings: prompt eval time =     289.84 ms /    88 tokens (    3.29 ms per token,   303.62 tokens per second)\n",
            "llama_print_timings:        eval time =    1668.40 ms /    15 runs   (  111.23 ms per token,     8.99 tokens per second)\n",
            "llama_print_timings:       total time =    2371.24 ms /   103 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "late is better than never: my lovers from DEATH FLIRTS BACK🩸for #themday wilma, an anger-repressed insomniac and elaine, the ghost girl haunting her home &amp; her heart new artwork by my beloved @writtenbyvic 💌 https://t.co/f4kqHSjAzk\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.02 ms /    16 runs   (    0.56 ms per token,  1774.82 tokens per second)\n",
            "llama_print_timings: prompt eval time =     242.97 ms /    44 tokens (    5.52 ms per token,   181.09 tokens per second)\n",
            "llama_print_timings:        eval time =    1610.65 ms /    15 runs   (  107.38 ms per token,     9.31 tokens per second)\n",
            "llama_print_timings:       total time =    2027.72 ms /    59 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@jacksonhinklle Oh no, these brutal Germans, storing fuel in fuel tanks and getting phones! Unprecedented levels of repression really. Lol. You clown.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.69 ms /    16 runs   (    0.61 ms per token,  1650.68 tokens per second)\n",
            "llama_print_timings: prompt eval time =     260.20 ms /    66 tokens (    3.94 ms per token,   253.65 tokens per second)\n",
            "llama_print_timings:        eval time =    1610.29 ms /    15 runs   (  107.35 ms per token,     9.32 tokens per second)\n",
            "llama_print_timings:       total time =    2086.05 ms /    81 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "okay so whenever I’m sad or anxious, I will scour the internet to find content that resonates with/explains what I’m feeling and then immediately decide I am done feeling that way…processing my emotions or repression, who knows 🤪🤪\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.21 ms /    16 runs   (    0.58 ms per token,  1737.62 tokens per second)\n",
            "llama_print_timings: prompt eval time =     269.88 ms /    84 tokens (    3.21 ms per token,   311.24 tokens per second)\n",
            "llama_print_timings:        eval time =    1547.60 ms /    15 runs   (  103.17 ms per token,     9.69 tokens per second)\n",
            "llama_print_timings:       total time =    2052.82 ms /    99 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@i24NEWS_EN @memarsadeghi Thanks for covering #Mahsa_Amini's teragedy.This has been Iranian normal life for 43 years. Let us talk about that and get the world known about the darkness and repression imposed by Islamic regime. Let us tell you how Islamic Laws have caused million lives destroyed.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      12.42 ms /    16 runs   (    0.78 ms per token,  1288.76 tokens per second)\n",
            "llama_print_timings: prompt eval time =     286.89 ms /    67 tokens (    4.28 ms per token,   233.54 tokens per second)\n",
            "llama_print_timings:        eval time =    1788.71 ms /    15 runs   (  119.25 ms per token,     8.39 tokens per second)\n",
            "llama_print_timings:       total time =    2428.70 ms /    82 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@CN_jhy @BernardGyorgy @SpokespersonCHN yes, you admit China and Russia are using exploitation and repression now- you are right. This is a very unwise, downward, destructive, failing path for 2 very large nations to take.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.71 ms /    16 runs   (    0.61 ms per token,  1647.62 tokens per second)\n",
            "llama_print_timings: prompt eval time =     266.70 ms /    62 tokens (    4.30 ms per token,   232.47 tokens per second)\n",
            "llama_print_timings:        eval time =    1550.94 ms /    15 runs   (  103.40 ms per token,     9.67 tokens per second)\n",
            "llama_print_timings:       total time =    2016.53 ms /    77 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "FUCK YEAH “19th century Tsarist traits that can equally describe the Russia of Vladimir Putin, to include domestic repression, institutional incompetence and a culture of lies” https://t.co/Ufew80eCSg\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.97 ms /    16 runs   (    0.56 ms per token,  1784.12 tokens per second)\n",
            "llama_print_timings: prompt eval time =     244.68 ms /    39 tokens (    6.27 ms per token,   159.39 tokens per second)\n",
            "llama_print_timings:        eval time =    1465.80 ms /    15 runs   (   97.72 ms per token,    10.23 tokens per second)\n",
            "llama_print_timings:       total time =    1877.05 ms /    54 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "this surprising indie gem paints an uncomfortable portrait of repression and eating disorders https://t.co/PwSsO8RrO7\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.73 ms /    16 runs   (    0.61 ms per token,  1644.40 tokens per second)\n",
            "llama_print_timings: prompt eval time =     242.88 ms /    48 tokens (    5.06 ms per token,   197.63 tokens per second)\n",
            "llama_print_timings:        eval time =    1570.18 ms /    15 runs   (  104.68 ms per token,     9.55 tokens per second)\n",
            "llama_print_timings:       total time =    2006.01 ms /    63 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@weedcatholic Have you ever seen one of those posts where people say the oversexualization or twinks is problematic or something, as if twinkhood isn't literally a sex role\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.70 ms /    16 runs   (    0.67 ms per token,  1496.03 tokens per second)\n",
            "llama_print_timings: prompt eval time =     277.02 ms /    92 tokens (    3.01 ms per token,   332.11 tokens per second)\n",
            "llama_print_timings:        eval time =    1564.17 ms /    15 runs   (  104.28 ms per token,     9.59 tokens per second)\n",
            "llama_print_timings:       total time =    2115.10 ms /   107 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@VideoGameCowOTD @All_I_CannotSay @DuncanHenry78 @OffOfMyLanai You’re welcome. Glad you acknowledge it. Doesn’t take much to debunk a shitty regressive concept that doesn’t comport with reality like ‘gender identity’ &amp; the ridiculous sexism of slavish adherence to sex role stereotypes.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.90 ms /    16 runs   (    0.68 ms per token,  1468.16 tokens per second)\n",
            "llama_print_timings: prompt eval time =     261.41 ms /    60 tokens (    4.36 ms per token,   229.53 tokens per second)\n",
            "llama_print_timings:        eval time =    1660.59 ms /    15 runs   (  110.71 ms per token,     9.03 tokens per second)\n",
            "llama_print_timings:       total time =    2229.62 ms /    75 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@MidseaXXX @JackThe09712525 @slimreezygoddy @Sunshir0 @mattxiv Is this the same girl that have told twice in her videos that it was sex role play and nothing else?\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.07 ms /    16 runs   (    0.63 ms per token,  1588.72 tokens per second)\n",
            "llama_print_timings: prompt eval time =     248.64 ms /    41 tokens (    6.06 ms per token,   164.90 tokens per second)\n",
            "llama_print_timings:        eval time =    1595.55 ms /    15 runs   (  106.37 ms per token,     9.40 tokens per second)\n",
            "llama_print_timings:       total time =    2014.43 ms /    56 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Victoria Daniel’s Sex Role In ‘Money Miss Road’ Sets Tongues Wagging https://t.co/M2QoozttYx\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.51 ms /    16 runs   (    0.59 ms per token,  1681.73 tokens per second)\n",
            "llama_print_timings: prompt eval time =     258.63 ms /    64 tokens (    4.04 ms per token,   247.46 tokens per second)\n",
            "llama_print_timings:        eval time =    1504.12 ms /    15 runs   (  100.27 ms per token,     9.97 tokens per second)\n",
            "llama_print_timings:       total time =    1975.65 ms /    79 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "New Yorkers don't know how to sex, and she is the role model of at least kissing right, learning from the ad placement all around the city to have Japanese the sex role model in the end of the day. And Ms.Kamela Harris.#impeach\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.82 ms /    16 runs   (    0.55 ms per token,  1814.47 tokens per second)\n",
            "llama_print_timings: prompt eval time =     237.91 ms /    33 tokens (    7.21 ms per token,   138.71 tokens per second)\n",
            "llama_print_timings:        eval time =    1538.44 ms /    15 runs   (  102.56 ms per token,     9.75 tokens per second)\n",
            "llama_print_timings:       total time =    1927.61 ms /    48 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@UZlAK69 Bro I saw someone sex role-playing as a kid yesterday in that chat 😧\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      12.78 ms /    16 runs   (    0.80 ms per token,  1251.56 tokens per second)\n",
            "llama_print_timings: prompt eval time =     284.55 ms /    71 tokens (    4.01 ms per token,   249.51 tokens per second)\n",
            "llama_print_timings:        eval time =    1799.82 ms /    15 runs   (  119.99 ms per token,     8.33 tokens per second)\n",
            "llama_print_timings:       total time =    2461.15 ms /    86 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Eddie_Piss So seeing men get upset, angry, bristle, say the scene isn’t necessary for Jen to point out she’s better at managing anger than Bruce is frustrating. Because not only do we have to deal with little shitty sexist or racist comments daily and keep a smile on…\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.55 ms /    16 runs   (    0.60 ms per token,  1675.92 tokens per second)\n",
            "llama_print_timings: prompt eval time =     275.84 ms /    71 tokens (    3.89 ms per token,   257.40 tokens per second)\n",
            "llama_print_timings:        eval time =    1668.77 ms /    15 runs   (  111.25 ms per token,     8.99 tokens per second)\n",
            "llama_print_timings:       total time =    2158.95 ms /    86 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "For goodness' sake, I've seen MEN write better female characters than this alleged feminist! Ian Irvine, Robert Jordan and Brandon Sanderson have much more feminist female characters than Rowling.Even the late (and sexist) Terry Goodkind was MORE of a feminist than Rowling.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.95 ms /    16 runs   (    0.56 ms per token,  1788.11 tokens per second)\n",
            "llama_print_timings: prompt eval time =     259.63 ms /    43 tokens (    6.04 ms per token,   165.62 tokens per second)\n",
            "llama_print_timings:        eval time =    1525.39 ms /    15 runs   (  101.69 ms per token,     9.83 tokens per second)\n",
            "llama_print_timings:       total time =    1969.51 ms /    58 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@WrestlePurists Gotta love the “not mad at the sexist, rapist elite POS because he made a lot a people a lot of money” statement.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.02 ms /    16 runs   (    0.56 ms per token,  1773.05 tokens per second)\n",
            "llama_print_timings: prompt eval time =     241.47 ms /    40 tokens (    6.04 ms per token,   165.65 tokens per second)\n",
            "llama_print_timings:        eval time =    1540.02 ms /    15 runs   (  102.67 ms per token,     9.74 tokens per second)\n",
            "llama_print_timings:       total time =    1951.85 ms /    55 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "So being racist and sexist is okay but you draw the line at shaming someone in fast food 💀 https://t.co/glETPFEPd2\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.78 ms /    16 runs   (    0.67 ms per token,  1483.95 tokens per second)\n",
            "llama_print_timings: prompt eval time =     261.53 ms /    74 tokens (    3.53 ms per token,   282.95 tokens per second)\n",
            "llama_print_timings:        eval time =    1789.11 ms /    15 runs   (  119.27 ms per token,     8.38 tokens per second)\n",
            "llama_print_timings:       total time =    2296.27 ms /    89 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@OverZeeIous The reason women get the “limelight” or are trending all of the time is because we are always suffering because of the fact we are women. International Women’s day is to celebrate us being women because of sexism looking down on us. I understand you do not think you are sexist +\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.54 ms /    16 runs   (    0.60 ms per token,  1677.50 tokens per second)\n",
            "llama_print_timings: prompt eval time =     287.61 ms /    68 tokens (    4.23 ms per token,   236.43 tokens per second)\n",
            "llama_print_timings:        eval time =    1530.91 ms /    15 runs   (  102.06 ms per token,     9.80 tokens per second)\n",
            "llama_print_timings:       total time =    2152.21 ms /    83 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@BMcKev XX or XYAnyone can be anyone they wish to be, but chromosomes will always stay the same.BTW, women can choose to be men too, yes? Or does the 'human right' only apply to men, 'cos that would be sexist. 🤔\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.93 ms /    16 runs   (    0.56 ms per token,  1791.91 tokens per second)\n",
            "llama_print_timings: prompt eval time =     644.05 ms /    26 tokens (   24.77 ms per token,    40.37 tokens per second)\n",
            "llama_print_timings:        eval time =    1462.37 ms /    15 runs   (   97.49 ms per token,    10.26 tokens per second)\n",
            "llama_print_timings:       total time =    2227.80 ms /    41 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Only sexual harassment, drinking, and flashing racist hand-signs is real work, evidently\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.70 ms /    16 runs   (    0.61 ms per token,  1649.48 tokens per second)\n",
            "llama_print_timings: prompt eval time =     243.36 ms /    56 tokens (    4.35 ms per token,   230.11 tokens per second)\n",
            "llama_print_timings:        eval time =    1585.65 ms /    15 runs   (  105.71 ms per token,     9.46 tokens per second)\n",
            "llama_print_timings:       total time =    2031.79 ms /    71 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@lmresists @alfranken Franken wan’t having any of her https://t.co/f7VKCZijfL him and unlike Trump who was slso charged with sexual harassment, Franken resigned\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.95 ms /    16 runs   (    0.62 ms per token,  1608.20 tokens per second)\n",
            "llama_print_timings: prompt eval time =     251.29 ms /    42 tokens (    5.98 ms per token,   167.14 tokens per second)\n",
            "llama_print_timings:        eval time =    1606.36 ms /    15 runs   (  107.09 ms per token,     9.34 tokens per second)\n",
            "llama_print_timings:       total time =    2030.38 ms /    57 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@TheDarklord76 @ClownWorld_ Is this appropriate? Isn't this sexual harassment? https://t.co/DhEGAvuPgQ\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.12 ms /    16 runs   (    0.69 ms per token,  1439.37 tokens per second)\n",
            "llama_print_timings: prompt eval time =     264.67 ms /    51 tokens (    5.19 ms per token,   192.70 tokens per second)\n",
            "llama_print_timings:        eval time =    1746.20 ms /    15 runs   (  116.41 ms per token,     8.59 tokens per second)\n",
            "llama_print_timings:       total time =    2300.49 ms /    66 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "that hashtag makes her seem like an evil fucking villain when all she did was date their fave? it’s actually fucking disgusting to compare a movement against sexual harassment to what olivia has “done”\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.22 ms /    16 runs   (    0.58 ms per token,  1735.36 tokens per second)\n",
            "llama_print_timings: prompt eval time =     241.48 ms /    39 tokens (    6.19 ms per token,   161.50 tokens per second)\n",
            "llama_print_timings:        eval time =    1512.19 ms /    15 runs   (  100.81 ms per token,     9.92 tokens per second)\n",
            "llama_print_timings:       total time =    1920.36 ms /    54 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@BillOReilly Was it because of sexual harrassement like in your case? https://t.co/NzFNB90dE3\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.32 ms /    16 runs   (    0.58 ms per token,  1717.29 tokens per second)\n",
            "llama_print_timings: prompt eval time =     236.73 ms /    43 tokens (    5.51 ms per token,   181.64 tokens per second)\n",
            "llama_print_timings:        eval time =    1555.53 ms /    15 runs   (  103.70 ms per token,     9.64 tokens per second)\n",
            "llama_print_timings:       total time =    1975.15 ms /    58 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Suraiya_B_Pullo You don't know what you are saying ? Did you know how many sexual harassment happening in southern of this country each and every month ?\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.76 ms /    16 runs   (    0.61 ms per token,  1640.02 tokens per second)\n",
            "llama_print_timings: prompt eval time =     278.92 ms /    75 tokens (    3.72 ms per token,   268.90 tokens per second)\n",
            "llama_print_timings:        eval time =    1602.95 ms /    15 runs   (  106.86 ms per token,     9.36 tokens per second)\n",
            "llama_print_timings:       total time =    2109.56 ms /    90 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@littlemousechu Isn't a bad thing? They gullible n innocent...we need to teach respect, honesty, hard work, team work...but unfortunately people like u feel lets plant doubts in there minds about sexual identity...it's kids! May Allah help the kids u come in contact with PPL like u\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.76 ms /    16 runs   (    0.73 ms per token,  1360.78 tokens per second)\n",
            "llama_print_timings: prompt eval time =     248.09 ms /    55 tokens (    4.51 ms per token,   221.69 tokens per second)\n",
            "llama_print_timings:        eval time =    1856.35 ms /    15 runs   (  123.76 ms per token,     8.08 tokens per second)\n",
            "llama_print_timings:       total time =    2325.26 ms /    70 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Sharinberg As long as I agreed with their platform. Gender and sexual identity doesn’t automatically pull or drop my support. Neither does race, religion, etc. Quality of character, experience, honesty and integrity are much more important.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.76 ms /    16 runs   (    0.61 ms per token,  1640.18 tokens per second)\n",
            "llama_print_timings: prompt eval time =     266.82 ms /    55 tokens (    4.85 ms per token,   206.13 tokens per second)\n",
            "llama_print_timings:        eval time =    1477.03 ms /    15 runs   (   98.47 ms per token,    10.16 tokens per second)\n",
            "llama_print_timings:       total time =    1937.04 ms /    70 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@444AngelaD Their whole account is racist &amp; filled with lies about pedophilia that “Dems” are pushing on kids and calling gay people names.  Report the whole account for racist &amp; sexual identity slurs\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.88 ms /    16 runs   (    0.62 ms per token,  1619.60 tokens per second)\n",
            "llama_print_timings: prompt eval time =     258.82 ms /    69 tokens (    3.75 ms per token,   266.60 tokens per second)\n",
            "llama_print_timings:        eval time =    1604.49 ms /    15 runs   (  106.97 ms per token,     9.35 tokens per second)\n",
            "llama_print_timings:       total time =    2088.92 ms /    84 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@JasonSCampbell @mmfa These people don’t care to understand anyone that thinks differently then they do. Her argument makes perfect sense coming from someone that has zero understanding of sexual identity or sexual preferences. “If you are not like me, something must be wrong with you”.  It’s gross.\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.14 ms /    16 runs   (    0.57 ms per token,  1750.55 tokens per second)\n",
            "llama_print_timings: prompt eval time =     245.05 ms /    50 tokens (    4.90 ms per token,   204.04 tokens per second)\n",
            "llama_print_timings:        eval time =    1486.38 ms /    15 runs   (   99.09 ms per token,    10.09 tokens per second)\n",
            "llama_print_timings:       total time =    1920.31 ms /    65 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Seems Transgender mutilation is a barbaric practice being pushed upon children to validate sick adults struggling with their own sexual identity being Transgender. https://t.co/qU55tHSVys\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.90 ms /    16 runs   (    0.62 ms per token,  1616.81 tokens per second)\n",
            "llama_print_timings: prompt eval time =     260.62 ms /    61 tokens (    4.27 ms per token,   234.06 tokens per second)\n",
            "llama_print_timings:        eval time =    1554.58 ms /    15 runs   (  103.64 ms per token,     9.65 tokens per second)\n",
            "llama_print_timings:       total time =    2024.74 ms /    76 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Boomieleaks I said it before, and I'll say it again: Progressives are a few years away from pushing pedophilia as an oppressed sexual identity and trying to include it in the LGBTQ community, to the LGBTQ folks' dismay.\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.34 ms /    16 runs   (    0.65 ms per token,  1546.94 tokens per second)\n",
            "llama_print_timings: prompt eval time =     293.43 ms /    78 tokens (    3.76 ms per token,   265.82 tokens per second)\n",
            "llama_print_timings:        eval time =    1663.00 ms /    15 runs   (  110.87 ms per token,     9.02 tokens per second)\n",
            "llama_print_timings:       total time =    2343.24 ms /    93 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "I don't care about their sexual orientation, because as long as people are not blind, they can see the love between them. This is not defined by sexual orientation, but the purest love that transcends all constraints. https://t.co/PvcgEVj8Us https://t.co/z5xerokB0S\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.19 ms /    16 runs   (    0.51 ms per token,  1954.56 tokens per second)\n",
            "llama_print_timings: prompt eval time =     253.74 ms /    39 tokens (    6.51 ms per token,   153.70 tokens per second)\n",
            "llama_print_timings:        eval time =    1593.07 ms /    15 runs   (  106.20 ms per token,     9.42 tokens per second)\n",
            "llama_print_timings:       total time =    2007.94 ms /    54 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "everyone reacting shocked to my bereal like?? is everyone surprised i have friends or is everyone thinking i have changed my sexual orientation 😭😭😭😭😭😭\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.16 ms /    16 runs   (    0.57 ms per token,  1746.72 tokens per second)\n",
            "llama_print_timings: prompt eval time =     552.85 ms /    32 tokens (   17.28 ms per token,    57.88 tokens per second)\n",
            "llama_print_timings:        eval time =    1541.82 ms /    15 runs   (  102.79 ms per token,     9.73 tokens per second)\n",
            "llama_print_timings:       total time =    2228.17 ms /    47 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Just as sexual orientation exists, the same is true for dating. Some people are polyamorous, while some are monogamous.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.87 ms /    16 runs   (    0.62 ms per token,  1621.90 tokens per second)\n",
            "llama_print_timings: prompt eval time =     265.55 ms /    82 tokens (    3.24 ms per token,   308.80 tokens per second)\n",
            "llama_print_timings:        eval time =    1570.19 ms /    15 runs   (  104.68 ms per token,     9.55 tokens per second)\n",
            "llama_print_timings:       total time =    2081.41 ms /    97 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "This immorality must be ended. This is a disgrace to everyone.  This group of sexual orientation assholes must be destroyed snd never allowed near a child under the age of 18!  What is the reason they have to continue this nonsense. Parents keep your children out of their sphere. https://t.co/AlabvLfBsk\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.99 ms /    16 runs   (    0.75 ms per token,  1334.56 tokens per second)\n",
            "llama_print_timings: prompt eval time =     262.85 ms /    43 tokens (    6.11 ms per token,   163.59 tokens per second)\n",
            "llama_print_timings:        eval time =    1841.92 ms /    15 runs   (  122.79 ms per token,     8.14 tokens per second)\n",
            "llama_print_timings:       total time =    2397.22 ms /    58 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@SteveScalise Which school services are \"related to sexual orientation or gender identity\"? What might schools be \"doing with their kids\"? You makes schools and teachers sound iffy.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.47 ms /    16 runs   (    0.59 ms per token,  1689.90 tokens per second)\n",
            "llama_print_timings: prompt eval time =     253.30 ms /    61 tokens (    4.15 ms per token,   240.82 tokens per second)\n",
            "llama_print_timings:        eval time =    1574.92 ms /    15 runs   (  104.99 ms per token,     9.52 tokens per second)\n",
            "llama_print_timings:       total time =    2030.49 ms /    76 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@sadmonsters Sounds a lot like the talking points of the right whenever anyone supports basic human rights for non-cis people. The term \"groomer\" being tossed about for anyone not conforming to conventional gender/sexual orientation standards seems like a Hamilton move.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.78 ms /    16 runs   (    0.61 ms per token,  1636.16 tokens per second)\n",
            "llama_print_timings: prompt eval time =     261.46 ms /    66 tokens (    3.96 ms per token,   252.43 tokens per second)\n",
            "llama_print_timings:        eval time =    1452.16 ms /    15 runs   (   96.81 ms per token,    10.33 tokens per second)\n",
            "llama_print_timings:       total time =    1929.48 ms /    81 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Hayzelet @Moqueta17 @PlayOverwatch @skiesti_ You think that because of stereotypes. How else could you tell somebody's sexuality simply by looking at them? You aren't just a clown, you're the entire circus.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.93 ms /    16 runs   (    0.62 ms per token,  1611.28 tokens per second)\n",
            "llama_print_timings: prompt eval time =     275.21 ms /    98 tokens (    2.81 ms per token,   356.10 tokens per second)\n",
            "llama_print_timings:        eval time =    1587.47 ms /    15 runs   (  105.83 ms per token,     9.45 tokens per second)\n",
            "llama_print_timings:       total time =    2159.10 ms /   113 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@stygian_john @JeffOrstad @davidsfeldman @FoxNews Imagine being personally offended by someone else's sexuality. \"MoRaLlY 🤓\" dude.... Nothing is morally wrong with it. By our existence we are offensive ☠️ Like hun..... Your Bible had dudes with 100 wives and fuckin them all. You think that's okay?\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      14.60 ms /    16 runs   (    0.91 ms per token,  1095.89 tokens per second)\n",
            "llama_print_timings: prompt eval time =     384.50 ms /   138 tokens (    2.79 ms per token,   358.91 tokens per second)\n",
            "llama_print_timings:        eval time =    1839.73 ms /    15 runs   (  122.65 ms per token,     8.15 tokens per second)\n",
            "llama_print_timings:       total time =    2663.74 ms /   153 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Star guardian Xayah🌟Female🌟Height: 5’4 - 165 CM🌟Weight: 110 lbs - 49.9 KG🌟Cup: C🌟Eye color: Violet🌟Skin: Paleish🌟Hair: Pink with purple strands🌟Sexuality: Bisexual🌟Stance: Switch🌟50/50 - Dom/Sub-🌟--⬇️-\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.60 ms /    16 runs   (    0.66 ms per token,  1510.15 tokens per second)\n",
            "llama_print_timings: prompt eval time =     297.22 ms /    96 tokens (    3.10 ms per token,   322.99 tokens per second)\n",
            "llama_print_timings:        eval time =    1576.15 ms /    15 runs   (  105.08 ms per token,     9.52 tokens per second)\n",
            "llama_print_timings:       total time =    2140.24 ms /   111 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@allanas__ @_Alicewe @leftistlawyer @Chester66Red @IndieWire well, the only difference is that harry doesn't want to talk about his dating life at all. but how does that make him less queer than omar? like, do we need to know someone's dating life to allow them the agency of their identity/sexuality? i surely do hope not...\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.21 ms /    16 runs   (    0.64 ms per token,  1567.86 tokens per second)\n",
            "llama_print_timings: prompt eval time =     261.47 ms /    73 tokens (    3.58 ms per token,   279.19 tokens per second)\n",
            "llama_print_timings:        eval time =    1531.33 ms /    15 runs   (  102.09 ms per token,     9.80 tokens per second)\n",
            "llama_print_timings:       total time =    2024.28 ms /    88 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Excited to share that I was invited to write an entry for the latest Palgrave Encyclopedia of Sexuality Education.My exploratory entry considers the literature on what frameworks for ethical sexual communication might look like 'Beyond Consent'. https://t.co/qt5g6JEona\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.70 ms /    16 runs   (    0.61 ms per token,  1650.17 tokens per second)\n",
            "llama_print_timings: prompt eval time =     275.84 ms /    92 tokens (    3.00 ms per token,   333.53 tokens per second)\n",
            "llama_print_timings:        eval time =    1611.54 ms /    15 runs   (  107.44 ms per token,     9.31 tokens per second)\n",
            "llama_print_timings:       total time =    2164.22 ms /   107 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Age: 19Country: USHeight: 185cmSign: AriesSexuality: HeteroReligion: Atheist/Agnostic, depends on how you define itIdeology: Optimistic nihilismSkin color: PaleShort or long hair: Long and fluffy https://t.co/fP3swsJ4Rq\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.19 ms /    16 runs   (    0.70 ms per token,  1430.23 tokens per second)\n",
            "llama_print_timings: prompt eval time =     265.33 ms /    71 tokens (    3.74 ms per token,   267.59 tokens per second)\n",
            "llama_print_timings:        eval time =    1637.91 ms /    15 runs   (  109.19 ms per token,     9.16 tokens per second)\n",
            "llama_print_timings:       total time =    2139.14 ms /    86 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Here is the rookie coming at you with a update, looks like famous Bootleg marketeer Smaht Goblin made a Abysshead shirt. The Roadie just letting folks know. @StarfinderFacts @mersiamnot https://t.co/2RfXbn3Wyk\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.83 ms /    16 runs   (    0.61 ms per token,  1628.50 tokens per second)\n",
            "llama_print_timings: prompt eval time =     313.16 ms /   122 tokens (    2.57 ms per token,   389.58 tokens per second)\n",
            "llama_print_timings:        eval time =    1617.27 ms /    15 runs   (  107.82 ms per token,     9.27 tokens per second)\n",
            "llama_print_timings:       total time =    2477.68 ms /   137 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Unicorn Tie Dyed T-Shirt, Purple Shirt, Painted Unicorn Shirt, Blue Shirt, Children's Clothing, Girl's Tops, Boy's Shirts, Tie Dyed Clothes ✋ #shirt #tops #Tshirt #Shirts #Unicorn #tie #ClothingGirl #dyed #Purple #Painted #MountainMajik #EtsyEmailhttps://t.co/P0eI0N1Lm0\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.49 ms /    16 runs   (    0.59 ms per token,  1686.34 tokens per second)\n",
            "llama_print_timings: prompt eval time =     240.29 ms /    45 tokens (    5.34 ms per token,   187.27 tokens per second)\n",
            "llama_print_timings:        eval time =    1638.88 ms /    15 runs   (  109.26 ms per token,     9.15 tokens per second)\n",
            "llama_print_timings:       total time =    2059.42 ms /    60 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "imagine making a shirt of a game u lost 😂😭 i love bengals fans, keep us in ur head https://t.co/9r7xehA1FY\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.88 ms /    16 runs   (    0.56 ms per token,  1800.79 tokens per second)\n",
            "llama_print_timings: prompt eval time =     779.83 ms /    30 tokens (   25.99 ms per token,    38.47 tokens per second)\n",
            "llama_print_timings:        eval time =    1447.83 ms /    15 runs   (   96.52 ms per token,    10.36 tokens per second)\n",
            "llama_print_timings:       total time =    2357.83 ms /    45 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@AndTartary a slave with a collar shirt slacks and a hat...😂 no boule negro traitor\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.94 ms /    16 runs   (    0.62 ms per token,  1609.01 tokens per second)\n",
            "llama_print_timings: prompt eval time =     272.49 ms /    91 tokens (    2.99 ms per token,   333.95 tokens per second)\n",
            "llama_print_timings:        eval time =    1604.02 ms /    15 runs   (  106.93 ms per token,     9.35 tokens per second)\n",
            "llama_print_timings:       total time =    2144.94 ms /   106 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "If rugby was easy it would be called football, Rugby shirt, football shirt wales,Unisex Softstyle T-Shirt,rugby gift uk #Football #SoftstyleTshirtrugby #shirt #rugby #Walesunisex #GiftUk #GiftswithStyleCo #EtsySellerhttps://t.co/xxeg3wuM9g\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.97 ms /    16 runs   (    0.69 ms per token,  1458.39 tokens per second)\n",
            "llama_print_timings: prompt eval time =     286.89 ms /    68 tokens (    4.22 ms per token,   237.03 tokens per second)\n",
            "llama_print_timings:        eval time =    1664.47 ms /    15 runs   (  110.96 ms per token,     9.01 tokens per second)\n",
            "llama_print_timings:       total time =    2296.65 ms /    83 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@MaleficVirtuoso God, he's addicted to those kisses. Fingers tug the other man closer by his shirt, smiling against his lips.\"Take me anywhere you want, then. We can save the suite for after the show if you'd like.\" Winks.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.69 ms /    16 runs   (    0.54 ms per token,  1841.83 tokens per second)\n",
            "llama_print_timings: prompt eval time =     246.44 ms /    40 tokens (    6.16 ms per token,   162.31 tokens per second)\n",
            "llama_print_timings:        eval time =    1443.62 ms /    15 runs   (   96.24 ms per token,    10.39 tokens per second)\n",
            "llama_print_timings:       total time =    1859.60 ms /    55 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@slutforyourmom5 Bruh all I here is beep, beep, beep, every two seconds GO OUTSIDE YOU GOOFY SKANK\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.13 ms /    16 runs   (    0.57 ms per token,  1753.04 tokens per second)\n",
            "llama_print_timings: prompt eval time =     237.30 ms /    42 tokens (    5.65 ms per token,   176.99 tokens per second)\n",
            "llama_print_timings:        eval time =    1553.35 ms /    15 runs   (  103.56 ms per token,     9.66 tokens per second)\n",
            "llama_print_timings:       total time =    1977.00 ms /    57 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@ToiletRoePaper @JEPR9750 @skank_a_licious I don't want to go further north I am good 😂\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.90 ms /    16 runs   (    0.56 ms per token,  1798.16 tokens per second)\n",
            "llama_print_timings: prompt eval time =     595.35 ms /    24 tokens (   24.81 ms per token,    40.31 tokens per second)\n",
            "llama_print_timings:        eval time =    1478.50 ms /    15 runs   (   98.57 ms per token,    10.15 tokens per second)\n",
            "llama_print_timings:       total time =    2191.66 ms /    39 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@chakery Biden is a sicko and so is his wife and kamala the skank\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.08 ms /    16 runs   (    0.69 ms per token,  1444.56 tokens per second)\n",
            "llama_print_timings: prompt eval time =     241.17 ms /    39 tokens (    6.18 ms per token,   161.71 tokens per second)\n",
            "llama_print_timings:        eval time =    1956.05 ms /    15 runs   (  130.40 ms per token,     7.67 tokens per second)\n",
            "llama_print_timings:       total time =    2453.04 ms /    54 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@giantgashole Tomi Lahren found out the hard way! 😜 https://t.co/MeBCLJTgvk\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.39 ms /    16 runs   (    0.52 ms per token,  1906.35 tokens per second)\n",
            "llama_print_timings: prompt eval time =     527.50 ms /    18 tokens (   29.31 ms per token,    34.12 tokens per second)\n",
            "llama_print_timings:        eval time =    1556.02 ms /    15 runs   (  103.73 ms per token,     9.64 tokens per second)\n",
            "llama_print_timings:       total time =    2186.96 ms /    33 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Hermioneblon Good grief. Go away skank.\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.17 ms /    16 runs   (    0.57 ms per token,  1744.06 tokens per second)\n",
            "llama_print_timings: prompt eval time =     752.83 ms /    31 tokens (   24.28 ms per token,    41.18 tokens per second)\n",
            "llama_print_timings:        eval time =    1593.31 ms /    15 runs   (  106.22 ms per token,     9.41 tokens per second)\n",
            "llama_print_timings:       total time =    2482.69 ms /    46 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@LionelMedia One could give Matt Gaetz the same advice as well. Look up the word skank in the dictionary.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.76 ms /    16 runs   (    0.61 ms per token,  1640.02 tokens per second)\n",
            "llama_print_timings: prompt eval time =     272.57 ms /    88 tokens (    3.10 ms per token,   322.85 tokens per second)\n",
            "llama_print_timings:        eval time =    1662.38 ms /    15 runs   (  110.83 ms per token,     9.02 tokens per second)\n",
            "llama_print_timings:       total time =    2182.65 ms /   103 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@theroyaleditor 2/2 2 Where was C+C's loyalty, calling Camillas friend AL's BS out? Meghans dad paid by British outlets to slag her off on national tv. The royal family authorised KP staff to break NDA and give out Meghans email to support Daily mail not Meghan in court. Loyalty plays both ways.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.35 ms /    16 runs   (    0.71 ms per token,  1409.82 tokens per second)\n",
            "llama_print_timings: prompt eval time =     281.27 ms /   103 tokens (    2.73 ms per token,   366.19 tokens per second)\n",
            "llama_print_timings:        eval time =    1928.49 ms /    15 runs   (  128.57 ms per token,     7.78 tokens per second)\n",
            "llama_print_timings:       total time =    2535.32 ms /   118 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@brandonJLchambs @NottsCounty1991 @TheNottsHub I'm what you call a happy clapper, I always clap the players off wouldn't dream of booing but yes we all get frustrated at times.. taking to twitter to slag them off isn't the answer though.. Build them, get behind them and let's get back in the efl  🖤🤍\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.95 ms /    16 runs   (    0.56 ms per token,  1787.91 tokens per second)\n",
            "llama_print_timings: prompt eval time =     256.22 ms /    46 tokens (    5.57 ms per token,   179.53 tokens per second)\n",
            "llama_print_timings:        eval time =    1520.76 ms /    15 runs   (  101.38 ms per token,     9.86 tokens per second)\n",
            "llama_print_timings:       total time =    1963.89 ms /    61 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@EmmaKennedy You’re very boring aren’t you….. how would you solve anything….. it’s one thing to slag someone off but what would you do…???\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.04 ms /    16 runs   (    0.63 ms per token,  1593.47 tokens per second)\n",
            "llama_print_timings: prompt eval time =     272.07 ms /    66 tokens (    4.12 ms per token,   242.58 tokens per second)\n",
            "llama_print_timings:        eval time =    1548.62 ms /    15 runs   (  103.24 ms per token,     9.69 tokens per second)\n",
            "llama_print_timings:       total time =    2028.13 ms /    81 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@krazyjoe @KilIerQ @sapphixy @brielarson Lmfao, no I heard male tears being used at a slag term for cum, back in highschool. That was like 15 years ago. Damn y'all are dumb.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.24 ms /    16 runs   (    0.58 ms per token,  1731.41 tokens per second)\n",
            "llama_print_timings: prompt eval time =     250.11 ms /    37 tokens (    6.76 ms per token,   147.93 tokens per second)\n",
            "llama_print_timings:        eval time =    1470.09 ms /    15 runs   (   98.01 ms per token,    10.20 tokens per second)\n",
            "llama_print_timings:       total time =    1880.10 ms /    52 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "We take the plunge; under water our limbsThe leaden slag of the worldRivals her whetted look, divining what conceit\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.26 ms /    16 runs   (    0.58 ms per token,  1727.30 tokens per second)\n",
            "llama_print_timings: prompt eval time =     238.91 ms /    41 tokens (    5.83 ms per token,   171.62 tokens per second)\n",
            "llama_print_timings:        eval time =    1584.00 ms /    15 runs   (  105.60 ms per token,     9.47 tokens per second)\n",
            "llama_print_timings:       total time =    2011.88 ms /    56 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Alexa play under the influence.. here under the influence by Chris brown....nah fuck face .. under the influence by Eminem biaaaatch... Fuckin slag bag\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.72 ms /    16 runs   (    0.61 ms per token,  1646.77 tokens per second)\n",
            "llama_print_timings: prompt eval time =     271.91 ms /    39 tokens (    6.97 ms per token,   143.43 tokens per second)\n",
            "llama_print_timings:        eval time =    1738.93 ms /    15 runs   (  115.93 ms per token,     8.63 tokens per second)\n",
            "llama_print_timings:       total time =    2255.10 ms /    54 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Thank you Kayode.We will slap 100m sense into Phyna’s head at the end of the show.  #BBNaija\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.14 ms /    16 runs   (    0.57 ms per token,  1750.36 tokens per second)\n",
            "llama_print_timings: prompt eval time =     269.04 ms /    58 tokens (    4.64 ms per token,   215.59 tokens per second)\n",
            "llama_print_timings:        eval time =    1565.85 ms /    15 runs   (  104.39 ms per token,     9.58 tokens per second)\n",
            "llama_print_timings:       total time =    2057.72 ms /    73 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Monte and Taylor’s POV is why it’s slap to the face for turner and Terrance floating keep Kyle…LIKE BITCH DONT DISCOUNT WHAT I WENT THRU IN MY LIFE #BB24\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.04 ms /    16 runs   (    0.57 ms per token,  1769.91 tokens per second)\n",
            "llama_print_timings: prompt eval time =     256.81 ms /    68 tokens (    3.78 ms per token,   264.78 tokens per second)\n",
            "llama_print_timings:        eval time =    1535.98 ms /    15 runs   (  102.40 ms per token,     9.77 tokens per second)\n",
            "llama_print_timings:       total time =    2014.60 ms /    83 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@DhammaRoots @notjoobs If roots man doesn't think we got plenty of cow punk this summer run, then 100% dude don't know cow phunk. Finally some cow phunk is back. Blossom 2001 cow phunk slap\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.38 ms /    16 runs   (    0.59 ms per token,  1706.67 tokens per second)\n",
            "llama_print_timings: prompt eval time =     237.66 ms /    39 tokens (    6.09 ms per token,   164.10 tokens per second)\n",
            "llama_print_timings:        eval time =    1621.68 ms /    15 runs   (  108.11 ms per token,     9.25 tokens per second)\n",
            "llama_print_timings:       total time =    2027.96 ms /    54 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "finna go to Wyoming and slap tf outta reed OMM !!! cause if you don’t gaf about me you can just say that!\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      14.62 ms /    16 runs   (    0.91 ms per token,  1094.09 tokens per second)\n",
            "llama_print_timings: prompt eval time =     235.33 ms /    36 tokens (    6.54 ms per token,   152.97 tokens per second)\n",
            "llama_print_timings:        eval time =    1867.25 ms /    15 runs   (  124.48 ms per token,     8.03 tokens per second)\n",
            "llama_print_timings:       total time =    2358.76 ms /    51 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "am I mad that etid will always slap? yeah kinda bc it hurts a lil differently now but whatever gutter phenomenon is just next level\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.27 ms /    16 runs   (    0.58 ms per token,  1726.56 tokens per second)\n",
            "llama_print_timings: prompt eval time =     279.37 ms /    69 tokens (    4.05 ms per token,   246.98 tokens per second)\n",
            "llama_print_timings:        eval time =    1556.64 ms /    15 runs   (  103.78 ms per token,     9.64 tokens per second)\n",
            "llama_print_timings:       total time =    2054.03 ms /    84 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "\"What happens if 10 seconds into the fight he slap you?\"\"It's a fight you can get slapped. I don't know brother maybe I break slap record. Take him down slap him 100 times in one minute\"  Chimaev is hilarious.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.13 ms /    16 runs   (    0.57 ms per token,  1751.51 tokens per second)\n",
            "llama_print_timings: prompt eval time =     524.78 ms /    20 tokens (   26.24 ms per token,    38.11 tokens per second)\n",
            "llama_print_timings:        eval time =    1550.57 ms /    15 runs   (  103.37 ms per token,     9.67 tokens per second)\n",
            "llama_print_timings:       total time =    2187.74 ms /    35 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Would you watch a horror movie called \"The Nard Slapper\"?\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.35 ms /    16 runs   (    0.52 ms per token,  1916.63 tokens per second)\n",
            "llama_print_timings: prompt eval time =     560.28 ms /    21 tokens (   26.68 ms per token,    37.48 tokens per second)\n",
            "llama_print_timings:        eval time =    1511.70 ms /    15 runs   (  100.78 ms per token,     9.92 tokens per second)\n",
            "llama_print_timings:       total time =    2181.28 ms /    36 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "fucking hell. and i actually need to use bass slapper.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.53 ms /    16 runs   (    0.66 ms per token,  1520.19 tokens per second)\n",
            "llama_print_timings: prompt eval time =     270.00 ms /    86 tokens (    3.14 ms per token,   318.52 tokens per second)\n",
            "llama_print_timings:        eval time =    1831.20 ms /    15 runs   (  122.08 ms per token,     8.19 tokens per second)\n",
            "llama_print_timings:       total time =    2389.67 ms /   101 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@lawreigncium tsumugi would not slap you, but i think he would if you asked!! eichi would slap you sorry :( (unless thats a good thing..?) shu is not a slapper unless he’s very upset but he would slap if you asked! sora would never ever slap! he would get sad if he did\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.92 ms /    16 runs   (    0.56 ms per token,  1793.32 tokens per second)\n",
            "llama_print_timings: prompt eval time =     265.22 ms /    40 tokens (    6.63 ms per token,   150.82 tokens per second)\n",
            "llama_print_timings:        eval time =    1562.46 ms /    15 runs   (  104.16 ms per token,     9.60 tokens per second)\n",
            "llama_print_timings:       total time =    2016.35 ms /    55 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "The Joke of the Week this week is a knee slapper! #LombardVeterinaryHospital https://t.co/MYfixlli0v\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.76 ms /    16 runs   (    0.55 ms per token,  1826.48 tokens per second)\n",
            "llama_print_timings: prompt eval time =     775.24 ms /    30 tokens (   25.84 ms per token,    38.70 tokens per second)\n",
            "llama_print_timings:        eval time =    1481.77 ms /    15 runs   (   98.78 ms per token,    10.12 tokens per second)\n",
            "llama_print_timings:       total time =    2387.28 ms /    45 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Bro that tank slapper shook me hard. I am not crossing 130 till I get new tyres.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.65 ms /    16 runs   (    0.60 ms per token,  1657.17 tokens per second)\n",
            "llama_print_timings: prompt eval time =     258.66 ms /    66 tokens (    3.92 ms per token,   255.16 tokens per second)\n",
            "llama_print_timings:        eval time =    1449.15 ms /    15 runs   (   96.61 ms per token,    10.35 tokens per second)\n",
            "llama_print_timings:       total time =    1935.32 ms /    81 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@FifeRED83 @ron_mould given the tories have managed to totally fuck the 4 nations' economies. I'm a dude buying cheap biccies at Asda. does harrods deliver all her biscuits? pig-ignorant slapper\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.70 ms /    16 runs   (    0.61 ms per token,  1650.34 tokens per second)\n",
            "llama_print_timings: prompt eval time =     242.98 ms /    54 tokens (    4.50 ms per token,   222.24 tokens per second)\n",
            "llama_print_timings:        eval time =    1555.51 ms /    15 runs   (  103.70 ms per token,     9.64 tokens per second)\n",
            "llama_print_timings:       total time =    2008.13 ms /    69 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "i love my silly gc cos half the chat is calling one person a slut while i’m frantically asking everyone how likely it is that there’s still drain cleaner in the tub and that i’m poisoning myself\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.75 ms /    16 runs   (    0.61 ms per token,  1640.35 tokens per second)\n",
            "llama_print_timings: prompt eval time =     901.58 ms /    30 tokens (   30.05 ms per token,    33.27 tokens per second)\n",
            "llama_print_timings:        eval time =    1683.56 ms /    15 runs   (  112.24 ms per token,     8.91 tokens per second)\n",
            "llama_print_timings:       total time =    2779.63 ms /    45 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Idk why, but being barefoot makes me feel like a slut 🤭🙈😂\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.83 ms /    16 runs   (    0.61 ms per token,  1628.50 tokens per second)\n",
            "llama_print_timings: prompt eval time =     246.04 ms /    49 tokens (    5.02 ms per token,   199.15 tokens per second)\n",
            "llama_print_timings:        eval time =    1535.72 ms /    15 runs   (  102.38 ms per token,     9.77 tokens per second)\n",
            "llama_print_timings:       total time =    1977.33 ms /    64 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@littleapostate Soooooo all you people talking about slut shaming. Do you hold the same standard for men? Are they also sluts and now low quality men? I sure hope so.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.09 ms /    16 runs   (    0.57 ms per token,  1759.40 tokens per second)\n",
            "llama_print_timings: prompt eval time =     258.20 ms /    56 tokens (    4.61 ms per token,   216.89 tokens per second)\n",
            "llama_print_timings:        eval time =    1568.74 ms /    15 runs   (  104.58 ms per token,     9.56 tokens per second)\n",
            "llama_print_timings:       total time =    2024.78 ms /    71 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Of course you can still use the graphic to make your own shirts, if Redbubble aint your thing. I dont give a SHIT. The same applies to everything prior that I made, im a bit of a slut that way.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.92 ms /    16 runs   (    0.56 ms per token,  1794.53 tokens per second)\n",
            "llama_print_timings: prompt eval time =     755.49 ms /    29 tokens (   26.05 ms per token,    38.39 tokens per second)\n",
            "llama_print_timings:        eval time =    1521.54 ms /    15 runs   (  101.44 ms per token,     9.86 tokens per second)\n",
            "llama_print_timings:       total time =    2409.14 ms /    44 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Me: so John Locke only thought men with property should be able to be representatives-Student: what a SLUT\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.91 ms /    16 runs   (    0.68 ms per token,  1466.68 tokens per second)\n",
            "llama_print_timings: prompt eval time =     250.64 ms /    45 tokens (    5.57 ms per token,   179.54 tokens per second)\n",
            "llama_print_timings:        eval time =    1880.41 ms /    15 runs   (  125.36 ms per token,     7.98 tokens per second)\n",
            "llama_print_timings:       total time =    2404.44 ms /    60 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Hells_Slut \"No teasing, huh? Well then... Come at me. I dare ya, sexy.\" https://t.co/gVM2eUabFI\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.09 ms /    16 runs   (    0.63 ms per token,  1586.20 tokens per second)\n",
            "llama_print_timings: prompt eval time =     289.28 ms /    84 tokens (    3.44 ms per token,   290.38 tokens per second)\n",
            "llama_print_timings:        eval time =    1610.94 ms /    15 runs   (  107.40 ms per token,     9.31 tokens per second)\n",
            "llama_print_timings:       total time =    2143.78 ms /    99 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "I just lost my last of my tweets.It’s 4 years of Straightup Hana Kim. Now…dissolving meaning of slutbag metoo movement.Stacia…like..grow teeth better than Aleczandrea Schelmzle.Now I can go back to Tinder and Twitter as if Design Major means Edith Young even smarter than cle\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.43 ms /    16 runs   (    0.59 ms per token,  1696.53 tokens per second)\n",
            "llama_print_timings: prompt eval time =     257.75 ms /    51 tokens (    5.05 ms per token,   197.87 tokens per second)\n",
            "llama_print_timings:        eval time =    1481.99 ms /    15 runs   (   98.80 ms per token,    10.12 tokens per second)\n",
            "llama_print_timings:       total time =    1927.18 ms /    66 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Just sold! Get yours! Maria Drains Her Slutbag https://t.co/IB478hiCK1 #MVSales https://t.co/hJxXNnG02N\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.12 ms /    16 runs   (    0.57 ms per token,  1754.19 tokens per second)\n",
            "llama_print_timings: prompt eval time =     285.49 ms /    98 tokens (    2.91 ms per token,   343.28 tokens per second)\n",
            "llama_print_timings:        eval time =    1628.28 ms /    15 runs   (  108.55 ms per token,     9.21 tokens per second)\n",
            "llama_print_timings:       total time =    2175.81 ms /   113 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "So yeah. This album is AMAZING. Crazy to think we made this 14-15 YEARS ago!! 😮‍💨😳 s/o @DenmarkVes @marvwon @lreneeofficial @xdannyxbrownx @DOPEHEAD313 @Bboy1987https://t.co/DP3GWWwL5G\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      15.17 ms /    16 runs   (    0.95 ms per token,  1054.99 tokens per second)\n",
            "llama_print_timings: prompt eval time =     272.94 ms /    68 tokens (    4.01 ms per token,   249.14 tokens per second)\n",
            "llama_print_timings:        eval time =    1827.48 ms /    15 runs   (  121.83 ms per token,     8.21 tokens per second)\n",
            "llama_print_timings:       total time =    2419.93 ms /    83 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@kathygriffin @THEMOCOLLINS She said it slutbag hag. She told Sterling it was a prank gone wrong. She admitted to it. Go drink some tea grandma then put the tea bags on ur eyes and hope it helps with your cataracts!!\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.95 ms /    16 runs   (    0.56 ms per token,  1787.51 tokens per second)\n",
            "llama_print_timings: prompt eval time =     691.06 ms /    27 tokens (   25.59 ms per token,    39.07 tokens per second)\n",
            "llama_print_timings:        eval time =    1550.44 ms /    15 runs   (  103.36 ms per token,     9.67 tokens per second)\n",
            "llama_print_timings:       total time =    2370.91 ms /    42 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@bettywoody183 Listen i don't need a fat ass slutbag following me.\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.38 ms /    16 runs   (    0.59 ms per token,  1705.21 tokens per second)\n",
            "llama_print_timings: prompt eval time =     271.80 ms /    77 tokens (    3.53 ms per token,   283.30 tokens per second)\n",
            "llama_print_timings:        eval time =    1494.28 ms /    15 runs   (   99.62 ms per token,    10.04 tokens per second)\n",
            "llama_print_timings:       total time =    2011.85 ms /    92 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "drift into a midwest town, hole up in a motel, take a guitar to the bar and play Mary Jane’s Last Dance but stay on the A minor for the whole song, get lucky with the biggest slutbag in town, have the coolest answers when she traces my tattoos with her red nails in the smoky dawn\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.16 ms /    16 runs   (    0.57 ms per token,  1746.92 tokens per second)\n",
            "llama_print_timings: prompt eval time =     233.18 ms /    34 tokens (    6.86 ms per token,   145.81 tokens per second)\n",
            "llama_print_timings:        eval time =    1484.59 ms /    15 runs   (   98.97 ms per token,    10.10 tokens per second)\n",
            "llama_print_timings:       total time =    1878.78 ms /    49 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@txbigrig56 @DefiyantlyFree If he WAS abused as a kid, then society DID fail him.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.46 ms /    16 runs   (    0.65 ms per token,  1528.91 tokens per second)\n",
            "llama_print_timings: prompt eval time =     247.79 ms /    61 tokens (    4.06 ms per token,   246.18 tokens per second)\n",
            "llama_print_timings:        eval time =    1647.09 ms /    15 runs   (  109.81 ms per token,     9.11 tokens per second)\n",
            "llama_print_timings:       total time =    2129.37 ms /    76 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@ggreenwald It's bizarre. She's basically saying we need mass censorship to combat internet trolls who really only effect the perpetually online. The majority of society doesn't give a shit but somehow need to be protected from internet trolls?\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.87 ms /    16 runs   (    0.68 ms per token,  1472.21 tokens per second)\n",
            "llama_print_timings: prompt eval time =     288.09 ms /    74 tokens (    3.89 ms per token,   256.87 tokens per second)\n",
            "llama_print_timings:        eval time =    1638.22 ms /    15 runs   (  109.21 ms per token,     9.16 tokens per second)\n",
            "llama_print_timings:       total time =    2291.60 ms /    89 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@dieselboy77 @CullipherGaye @RepMTG Of course we live in a society where that’s acceptable but it’s not a good thing imagine you and your boyfriend have casual sex the condom breaks your boyfriend doesn’t wanna take care of you or the baby awfully selfish and irresponsible.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.54 ms /    16 runs   (    0.60 ms per token,  1677.32 tokens per second)\n",
            "llama_print_timings: prompt eval time =     249.28 ms /    59 tokens (    4.23 ms per token,   236.68 tokens per second)\n",
            "llama_print_timings:        eval time =    1491.35 ms /    15 runs   (   99.42 ms per token,    10.06 tokens per second)\n",
            "llama_print_timings:       total time =    1940.81 ms /    74 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@ChrisPinnock1 I know you know Chris, what are the answers here? How does the JDF/JCF turn the tables &amp; become the intimidators to the gunmen.When do our people especially the vulnerable in society become less afraid?\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.43 ms /    16 runs   (    0.59 ms per token,  1697.61 tokens per second)\n",
            "llama_print_timings: prompt eval time =     287.07 ms /   113 tokens (    2.54 ms per token,   393.63 tokens per second)\n",
            "llama_print_timings:        eval time =    1476.71 ms /    15 runs   (   98.45 ms per token,    10.16 tokens per second)\n",
            "llama_print_timings:       total time =    2066.55 ms /   128 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Horrific. Unbelievable cruelty! This us what happens when you take God and morality out of a society! This terrible terrible crime against this woman! @FoxNews @SkyNews @RT_com @BBCWorld @seanhannity @TuckerCarlson @IngrahamAngle @BlazeTV @LevinTV @newsmax @OANN @EWTN @700club https://t.co/iT4DzRr2Ki\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.60 ms /    16 runs   (    0.60 ms per token,  1665.97 tokens per second)\n",
            "llama_print_timings: prompt eval time =     247.47 ms /    58 tokens (    4.27 ms per token,   234.37 tokens per second)\n",
            "llama_print_timings:        eval time =    1570.06 ms /    15 runs   (  104.67 ms per token,     9.55 tokens per second)\n",
            "llama_print_timings:       total time =    2018.33 ms /    73 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Common FE MS Paint L. People would be crazy to think Lilina Gaming isn't the future of high society https://t.co/GBGtlHsTjc https://t.co/WYRHNBrDBU\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.53 ms /    16 runs   (    0.66 ms per token,  1519.76 tokens per second)\n",
            "llama_print_timings: prompt eval time =     911.77 ms /    29 tokens (   31.44 ms per token,    31.81 tokens per second)\n",
            "llama_print_timings:        eval time =    1737.76 ms /    15 runs   (  115.85 ms per token,     8.63 tokens per second)\n",
            "llama_print_timings:       total time =    2861.10 ms /    44 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@OlatunjiOlagok5 Obi should sodomize your useless father next. Omo ale.\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.81 ms /    16 runs   (    0.61 ms per token,  1631.49 tokens per second)\n",
            "llama_print_timings: prompt eval time =     260.28 ms /    72 tokens (    3.62 ms per token,   276.62 tokens per second)\n",
            "llama_print_timings:        eval time =    1419.98 ms /    15 runs   (   94.67 ms per token,    10.56 tokens per second)\n",
            "llama_print_timings:       total time =    1902.88 ms /    87 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@DirtyDigDug I guess Knight, technically? I don't get off to my own work much, but Knight's my fursona and everyone commissions him getting his balls worshipped or having him sodomize sphinx girls, which is all *very* self-indulgent &lt;3\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.54 ms /    16 runs   (    0.53 ms per token,  1872.44 tokens per second)\n",
            "llama_print_timings: prompt eval time =     596.76 ms /    23 tokens (   25.95 ms per token,    38.54 tokens per second)\n",
            "llama_print_timings:        eval time =    1574.47 ms /    15 runs   (  104.96 ms per token,     9.53 tokens per second)\n",
            "llama_print_timings:       total time =    2288.93 ms /    38 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@TehBasco Sodomize m- i mean... super cool change-!\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.12 ms /    16 runs   (    0.57 ms per token,  1754.58 tokens per second)\n",
            "llama_print_timings: prompt eval time =     237.12 ms /    37 tokens (    6.41 ms per token,   156.04 tokens per second)\n",
            "llama_print_timings:        eval time =    1559.13 ms /    15 runs   (  103.94 ms per token,     9.62 tokens per second)\n",
            "llama_print_timings:       total time =    1974.87 ms /    52 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@StephenM Haven’t the feds raided your crypt yet? Please, keep motivating young people to sodomize your party this November, creep\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      12.13 ms /    16 runs   (    0.76 ms per token,  1318.50 tokens per second)\n",
            "llama_print_timings: prompt eval time =     240.62 ms /    37 tokens (    6.50 ms per token,   153.77 tokens per second)\n",
            "llama_print_timings:        eval time =    1852.34 ms /    15 runs   (  123.49 ms per token,     8.10 tokens per second)\n",
            "llama_print_timings:       total time =    2295.39 ms /    52 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@TryCatchHCF @AlyssaM_InfoSec That dude needs to sodomize himself with his own lacerated penis sideways.\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.65 ms /    16 runs   (    0.60 ms per token,  1658.03 tokens per second)\n",
            "llama_print_timings: prompt eval time =     286.61 ms /    92 tokens (    3.12 ms per token,   321.00 tokens per second)\n",
            "llama_print_timings:        eval time =    1465.15 ms /    15 runs   (   97.68 ms per token,    10.24 tokens per second)\n",
            "llama_print_timings:       total time =    2014.88 ms /   107 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@RealPatMcDougal @CNNOpinion @JAEnda1 The phrase “Giuliani time” originated with Louima’s story, whether it was true or not.  I challenge anyone to find a positive use of the phrase.  It is in the Urban Dictionary as “to sodomize with a plunger,” and was the title of a movie explicitly taken from the incident.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.00 ms /    16 runs   (    0.56 ms per token,  1778.57 tokens per second)\n",
            "llama_print_timings: prompt eval time =     244.22 ms /    52 tokens (    4.70 ms per token,   212.92 tokens per second)\n",
            "llama_print_timings:        eval time =    1643.47 ms /    15 runs   (  109.56 ms per token,     9.13 tokens per second)\n",
            "llama_print_timings:       total time =    2075.58 ms /    67 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@SelfMadeMastery You mean if I spank women they'll give me money 💰 or give money 💵 to me .. right 🤔🤔🤔 because if so I'm all for this new plan\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.28 ms /    16 runs   (    0.64 ms per token,  1555.81 tokens per second)\n",
            "llama_print_timings: prompt eval time =     274.86 ms /    74 tokens (    3.71 ms per token,   269.23 tokens per second)\n",
            "llama_print_timings:        eval time =    1523.00 ms /    15 runs   (  101.53 ms per token,     9.85 tokens per second)\n",
            "llama_print_timings:       total time =    2039.10 ms /    89 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Omg how insufferable will white dudes who wanna be doms in open relationships be if they get to be classed as lgtbq? \"I'm an oppressed sexual minority bc i like to spank women and cheat on my wife\" https://t.co/hvN2RhGUeq\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.40 ms /    16 runs   (    0.65 ms per token,  1539.05 tokens per second)\n",
            "llama_print_timings: prompt eval time =     246.32 ms /    57 tokens (    4.32 ms per token,   231.40 tokens per second)\n",
            "llama_print_timings:        eval time =    1579.14 ms /    15 runs   (  105.28 ms per token,     9.50 tokens per second)\n",
            "llama_print_timings:       total time =    2038.05 ms /    72 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Justjay2021 @0ddeyesvon @DorVSutherland @JusticeForGame1 @HannaBarberaCap Just as a heads up, don't randomly spank women. It will not work\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.98 ms /    16 runs   (    0.62 ms per token,  1603.37 tokens per second)\n",
            "llama_print_timings: prompt eval time =     282.17 ms /    81 tokens (    3.48 ms per token,   287.06 tokens per second)\n",
            "llama_print_timings:        eval time =    1639.10 ms /    15 runs   (  109.27 ms per token,     9.15 tokens per second)\n",
            "llama_print_timings:       total time =    2311.77 ms /    96 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@VicktoriaTacos sniff instead of spanking I don't spank women I never have never will do that I can't never do that because I likes and loves women including you also vicktoria tacos and I am not going to spank you instead I will sniff instead if I could just sniff I would be happy and proud .\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.85 ms /    16 runs   (    0.55 ms per token,  1807.30 tokens per second)\n",
            "llama_print_timings: prompt eval time =     578.58 ms /    32 tokens (   18.08 ms per token,    55.31 tokens per second)\n",
            "llama_print_timings:        eval time =    1454.29 ms /    15 runs   (   96.95 ms per token,    10.31 tokens per second)\n",
            "llama_print_timings:       total time =    2164.90 ms /    47 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Yo president said it criminal offence to spank women https://t.co/kfwXxo72bZ\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.69 ms /    16 runs   (    0.61 ms per token,  1650.51 tokens per second)\n",
            "llama_print_timings: prompt eval time =     248.67 ms /    63 tokens (    3.95 ms per token,   253.35 tokens per second)\n",
            "llama_print_timings:        eval time =    1578.36 ms /    15 runs   (  105.22 ms per token,     9.50 tokens per second)\n",
            "llama_print_timings:       total time =    2079.40 ms /    78 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@JaviereChevali1 @KyivIndependent Thank you for the explanation. It does have a certain logic now. Only i wonder why the man is not in Ukraine 🤔 he could really defend his country, not just spank women 😞\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.26 ms /    16 runs   (    0.58 ms per token,  1727.49 tokens per second)\n",
            "llama_print_timings: prompt eval time =     254.38 ms /    50 tokens (    5.09 ms per token,   196.55 tokens per second)\n",
            "llama_print_timings:        eval time =    1717.13 ms /    15 runs   (  114.48 ms per token,     8.74 tokens per second)\n",
            "llama_print_timings:       total time =    2147.45 ms /    65 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@notprettygood @ThisNiggaFr @democracytaylor @ghostopal_ @sherwood_fores_ ur truly stereotyping at the moment friend. begone.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.80 ms /    16 runs   (    0.74 ms per token,  1355.70 tokens per second)\n",
            "llama_print_timings: prompt eval time =     283.09 ms /    80 tokens (    3.54 ms per token,   282.60 tokens per second)\n",
            "llama_print_timings:        eval time =    1871.28 ms /    15 runs   (  124.75 ms per token,     8.02 tokens per second)\n",
            "llama_print_timings:       total time =    2566.50 ms /    95 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@benhurleykarman @StormblessedGil Either you're stereotyping or logic is the closest you've ever gotten to listening to rap because no rapper is swinging on someone for asking them something during an interview. Most would either dodge the question like he did or walk out if they got upset like kodak did.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.38 ms /    16 runs   (    0.59 ms per token,  1705.76 tokens per second)\n",
            "llama_print_timings: prompt eval time =     293.01 ms /    83 tokens (    3.53 ms per token,   283.26 tokens per second)\n",
            "llama_print_timings:        eval time =    1582.47 ms /    15 runs   (  105.50 ms per token,     9.48 tokens per second)\n",
            "llama_print_timings:       total time =    2122.83 ms /    98 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@GunnelsWarren @jashead I’m a boomer and have never felt that way, ever!  My student loans were hell to pay off for me too- so please stop stereotyping.  I made $3.50 an hour at my first job after graduation- I would have LOVED some forgiveness and happy it’s finally happening!!\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.63 ms /    16 runs   (    0.60 ms per token,  1660.78 tokens per second)\n",
            "llama_print_timings: prompt eval time =     246.35 ms /    58 tokens (    4.25 ms per token,   235.44 tokens per second)\n",
            "llama_print_timings:        eval time =    1656.19 ms /    15 runs   (  110.41 ms per token,     9.06 tokens per second)\n",
            "llama_print_timings:       total time =    2109.20 ms /    73 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "If you think of this from the idea that laughter originated as a primal signal that everything was OK, plus some hunter/gatherer stereotyping, this kinda makes sense. https://t.co/kRGf2FblSz\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.54 ms /    16 runs   (    0.53 ms per token,  1873.10 tokens per second)\n",
            "llama_print_timings: prompt eval time =     777.72 ms /    29 tokens (   26.82 ms per token,    37.29 tokens per second)\n",
            "llama_print_timings:        eval time =    1555.48 ms /    15 runs   (  103.70 ms per token,     9.64 tokens per second)\n",
            "llama_print_timings:       total time =    2459.10 ms /    44 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@socmediaisdumb @WGNNews Let me guess you know nothing about animals and are stereotyping\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      12.11 ms /    16 runs   (    0.76 ms per token,  1321.66 tokens per second)\n",
            "llama_print_timings: prompt eval time =     280.34 ms /    83 tokens (    3.38 ms per token,   296.07 tokens per second)\n",
            "llama_print_timings:        eval time =    1936.40 ms /    15 runs   (  129.09 ms per token,     7.75 tokens per second)\n",
            "llama_print_timings:       total time =    2647.80 ms /    98 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Budgie49004312 @BelTel @FeileBelfast @AllisonMorris1 We've a right to call out our local media for contributing to a festival as obscene as the Feile.When have I ever banged a drum or lit a bonfire? Sounds like sectarian stereotyping on your part.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.38 ms /    16 runs   (    0.52 ms per token,  1908.62 tokens per second)\n",
            "llama_print_timings: prompt eval time =     606.24 ms /    32 tokens (   18.95 ms per token,    52.78 tokens per second)\n",
            "llama_print_timings:        eval time =    1489.99 ms /    15 runs   (   99.33 ms per token,    10.07 tokens per second)\n",
            "llama_print_timings:       total time =    2228.67 ms /    47 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "to see if you still stupid 🤷🏾‍♂️ https://t.co/qK0Xj5Jde5\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.78 ms /    16 runs   (    0.55 ms per token,  1822.95 tokens per second)\n",
            "llama_print_timings: prompt eval time =     648.91 ms /    25 tokens (   25.96 ms per token,    38.53 tokens per second)\n",
            "llama_print_timings:        eval time =    1548.53 ms /    15 runs   (  103.24 ms per token,     9.69 tokens per second)\n",
            "llama_print_timings:       total time =    2318.33 ms /    40 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@deserteiga until something interesting happens to me i will be stuck with this stupid ass game\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.56 ms /    16 runs   (    0.53 ms per token,  1870.03 tokens per second)\n",
            "llama_print_timings: prompt eval time =     637.42 ms /    25 tokens (   25.50 ms per token,    39.22 tokens per second)\n",
            "llama_print_timings:        eval time =    1607.93 ms /    15 runs   (  107.20 ms per token,     9.33 tokens per second)\n",
            "llama_print_timings:       total time =    2365.54 ms /    40 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "By humans encroaching on their habitat for their homes and corporations doing the same for stupid projects.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.93 ms /    16 runs   (    0.75 ms per token,  1340.93 tokens per second)\n",
            "llama_print_timings: prompt eval time =     247.05 ms /    52 tokens (    4.75 ms per token,   210.48 tokens per second)\n",
            "llama_print_timings:        eval time =    1843.48 ms /    15 runs   (  122.90 ms per token,     8.14 tokens per second)\n",
            "llama_print_timings:       total time =    2340.70 ms /    67 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@DanAlbas It's startling that you even have to point out to another adult that the travel requirements for a world leader aren't supposed to be measured against the average person. Shockingly stupid tweet Dan.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.94 ms /    16 runs   (    0.56 ms per token,  1789.51 tokens per second)\n",
            "llama_print_timings: prompt eval time =     734.14 ms /    27 tokens (   27.19 ms per token,    36.78 tokens per second)\n",
            "llama_print_timings:        eval time =    1419.60 ms /    15 runs   (   94.64 ms per token,    10.57 tokens per second)\n",
            "llama_print_timings:       total time =    2282.04 ms /    42 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "I need someone like Namjoon to talk me through on how to fix this stupid water heater 😤\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.39 ms /    16 runs   (    0.59 ms per token,  1704.48 tokens per second)\n",
            "llama_print_timings: prompt eval time =     256.48 ms /    70 tokens (    3.66 ms per token,   272.93 tokens per second)\n",
            "llama_print_timings:        eval time =    1534.76 ms /    15 runs   (  102.32 ms per token,     9.77 tokens per second)\n",
            "llama_print_timings:       total time =    2015.73 ms /    85 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@theyloveechiiii @leodoesntcare you sound stupid af. nobodu post they location ESPECIALLY in california. be tryna defend shit that dont even make sense. the last thing you should do is post yo location when yo pay grade that high. wtf r u dumb\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.33 ms /    16 runs   (    0.65 ms per token,  1548.44 tokens per second)\n",
            "llama_print_timings: prompt eval time =     288.94 ms /   120 tokens (    2.41 ms per token,   415.31 tokens per second)\n",
            "llama_print_timings:        eval time =    1587.84 ms /    15 runs   (  105.86 ms per token,     9.45 tokens per second)\n",
            "llama_print_timings:       total time =    2203.13 ms /   135 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Spoilers:We are 1st introduced to Kim Yuri. Our feisty &amp; brave queen who stands for what's right &amp; is quite stubborn about it. In KJH's words she has quite a 'superwoman syndrome' &amp; rightly so, she's our super heroin in law without the costume🦸‍♀️#TheLawCafe #LeeSeYoung #이세영 https://t.co/rhGtO047G6\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.98 ms /    16 runs   (    0.69 ms per token,  1456.80 tokens per second)\n",
            "llama_print_timings: prompt eval time =     247.63 ms /    56 tokens (    4.42 ms per token,   226.14 tokens per second)\n",
            "llama_print_timings:        eval time =    1762.23 ms /    15 runs   (  117.48 ms per token,     8.51 tokens per second)\n",
            "llama_print_timings:       total time =    2236.49 ms /    71 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "I’m taking the Superwoman Syndrome Quiz with @lkmonroe00 Results are loading…..@ClassLink #LinkingWomenInTech https://t.co/u2sxi3wvHF\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.06 ms /    16 runs   (    0.57 ms per token,  1765.03 tokens per second)\n",
            "llama_print_timings: prompt eval time =     858.85 ms /    30 tokens (   28.63 ms per token,    34.93 tokens per second)\n",
            "llama_print_timings:        eval time =    1461.03 ms /    15 runs   (   97.40 ms per token,    10.27 tokens per second)\n",
            "llama_print_timings:       total time =    2455.74 ms /    45 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Women in India experiencing the superwoman syndrome– a crisis creating overwhelming expectations for women, giving rise to a new malady\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.49 ms /    16 runs   (    0.59 ms per token,  1686.52 tokens per second)\n",
            "llama_print_timings: prompt eval time =     281.18 ms /   112 tokens (    2.51 ms per token,   398.33 tokens per second)\n",
            "llama_print_timings:        eval time =    1597.97 ms /    15 runs   (  106.53 ms per token,     9.39 tokens per second)\n",
            "llama_print_timings:       total time =    2183.14 ms /   127 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "It's time to find out self-care strategies in case you are a SUPERWOMAN. Join the Masterclass: Debunk the SuperWoman Syndrome today at 4:00 pm by 👉 Meenal Sawhney.Register here: https://t.co/pPNkh9UAzQHurry! Only a few hours left!#NextBigYou #Masterclass #notasuperwoman https://t.co/lNepr12tIT\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.29 ms /    16 runs   (    0.58 ms per token,  1723.02 tokens per second)\n",
            "llama_print_timings: prompt eval time =     236.24 ms /    38 tokens (    6.22 ms per token,   160.86 tokens per second)\n",
            "llama_print_timings:        eval time =    1504.74 ms /    15 runs   (  100.32 ms per token,     9.97 tokens per second)\n",
            "llama_print_timings:       total time =    1907.26 ms /    53 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Put Down Your Cape: Solving the Black Superwoman Syndrome https://t.co/I3auXd0OKY via @ebonymag\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.87 ms /    16 runs   (    0.62 ms per token,  1620.58 tokens per second)\n",
            "llama_print_timings: prompt eval time =     274.16 ms /    98 tokens (    2.80 ms per token,   357.45 tokens per second)\n",
            "llama_print_timings:        eval time =    1576.92 ms /    15 runs   (  105.13 ms per token,     9.51 tokens per second)\n",
            "llama_print_timings:       total time =    2137.10 ms /   113 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "TOMORROW at 1 on @PortiaTVShow, Tamika Johnson, work-life balance strategist, talks about wearing many hats &amp; how she balances life’s pressure. Viewer Kimberly Biggs struggles w/ “superwoman syndrome” and is ready to take the cape off and create a work-life balance. #PortiaTVShow https://t.co/GcToZd0ssq\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.12 ms /    16 runs   (    0.57 ms per token,  1754.00 tokens per second)\n",
            "llama_print_timings: prompt eval time =     298.67 ms /    93 tokens (    3.21 ms per token,   311.39 tokens per second)\n",
            "llama_print_timings:        eval time =    1659.86 ms /    15 runs   (  110.66 ms per token,     9.04 tokens per second)\n",
            "llama_print_timings:       total time =    2389.51 ms /   108 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@PessoaBrain @NeuroPolarbear @patchurchland I was thinking about this: https://t.co/KRTIC6rdpW). But I agree with you. Indeed there studies showing attention also involves some nonlinearities like a centre-surround suppression (Mexican hat kind of tuning): https://t.co/k7vfut3Q2L). I was\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.65 ms /    16 runs   (    0.60 ms per token,  1657.34 tokens per second)\n",
            "llama_print_timings: prompt eval time =     250.55 ms /    63 tokens (    3.98 ms per token,   251.45 tokens per second)\n",
            "llama_print_timings:        eval time =    1558.73 ms /    15 runs   (  103.92 ms per token,     9.62 tokens per second)\n",
            "llama_print_timings:       total time =    2012.10 ms /    78 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@TheLastWord @nick_rathod @BetoORourke @Lawrence Let's vote in numbers that voter suppression can't touch!#BetoForABetterTexas https://t.co/veMQkKWqqJ\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.58 ms /    16 runs   (    0.60 ms per token,  1670.67 tokens per second)\n",
            "llama_print_timings: prompt eval time =     247.58 ms /    62 tokens (    3.99 ms per token,   250.43 tokens per second)\n",
            "llama_print_timings:        eval time =    1569.57 ms /    15 runs   (  104.64 ms per token,     9.56 tokens per second)\n",
            "llama_print_timings:       total time =    2024.33 ms /    77 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@GOP Thanks for that tweet from Opposite Land. The truth: The trump party cannot win a free and fair election, hence all the gerrymandering, voter suppression and conspiracy theory nods. It's what happens when you value power over democracy.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.97 ms /    16 runs   (    0.56 ms per token,  1782.73 tokens per second)\n",
            "llama_print_timings: prompt eval time =     279.06 ms /    99 tokens (    2.82 ms per token,   354.76 tokens per second)\n",
            "llama_print_timings:        eval time =    1512.18 ms /    15 runs   (  100.81 ms per token,     9.92 tokens per second)\n",
            "llama_print_timings:       total time =    2054.00 ms /   114 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@bambihelen @Lazerthecat1 @Pulptor @snakelady647 @BudrykZack @MaraWilson oh my god, have you never heard of voter suppression!? PEOPLE are trying to do things, every day. the inhuman creatures in power are the ones who choose to do nothing. What do you think normal people can do? Magically destroy every gun?\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      12.01 ms /    16 runs   (    0.75 ms per token,  1332.00 tokens per second)\n",
            "llama_print_timings: prompt eval time =     274.57 ms /    87 tokens (    3.16 ms per token,   316.86 tokens per second)\n",
            "llama_print_timings:        eval time =    1906.35 ms /    15 runs   (  127.09 ms per token,     7.87 tokens per second)\n",
            "llama_print_timings:       total time =    2614.54 ms /   102 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Mark451994 @AmockingbirdP @WoodrowForCO Partly correct because a lot of that thought is criminal/coup-y or so cruel that it is something one would expect from a dictatorship. The reverse is also true, with book bans, suppression of the teaching of history, censorship of teachers/monitoring of their ideology...\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.00 ms /    16 runs   (    0.63 ms per token,  1599.84 tokens per second)\n",
            "llama_print_timings: prompt eval time =     287.81 ms /    89 tokens (    3.23 ms per token,   309.23 tokens per second)\n",
            "llama_print_timings:        eval time =    1428.82 ms /    15 runs   (   95.25 ms per token,    10.50 tokens per second)\n",
            "llama_print_timings:       total time =    1971.82 ms /   104 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@RainBl0wunicorn @xCptMorgann @GPrime85 @tomaskenn “characterized by a dictatorial leader, centralized autocracy, militarism, forcible suppression of opposition”, you don’t think this is what lockdowns and mandates were, deplatforming of anyone speaking out on Covid, masks? Doctors were silenced.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.59 ms /    16 runs   (    0.60 ms per token,  1668.93 tokens per second)\n",
            "llama_print_timings: prompt eval time =     277.22 ms /    88 tokens (    3.15 ms per token,   317.44 tokens per second)\n",
            "llama_print_timings:        eval time =    1474.08 ms /    15 runs   (   98.27 ms per token,    10.18 tokens per second)\n",
            "llama_print_timings:       total time =    2008.40 ms /   103 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@EmmaH1123 Because all the blokes in the media are in the “boys club” kenty, matty etc that will only promote “tough” rock 🤣 Macklemore sings his big hit the other year &amp; they sooked about not being tough enough. Meanwhile the Super Bowl puts out all types of halftime shows &amp; rakes in 💰\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.66 ms /    16 runs   (    0.60 ms per token,  1656.83 tokens per second)\n",
            "llama_print_timings: prompt eval time =     246.06 ms /    58 tokens (    4.24 ms per token,   235.71 tokens per second)\n",
            "llama_print_timings:        eval time =    1570.29 ms /    15 runs   (  104.69 ms per token,     9.55 tokens per second)\n",
            "llama_print_timings:       total time =    2019.49 ms /    73 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@kimsjailcell @WolfEnt So agree! Apparently Dick isn’t paying attention to what’s going on in the country right now. Women are not second class citizens. And we’re pissed! End the “Boys Club”!\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.55 ms /    16 runs   (    0.60 ms per token,  1674.52 tokens per second)\n",
            "llama_print_timings: prompt eval time =     235.58 ms /    37 tokens (    6.37 ms per token,   157.06 tokens per second)\n",
            "llama_print_timings:        eval time =    1658.81 ms /    15 runs   (  110.59 ms per token,     9.04 tokens per second)\n",
            "llama_print_timings:       total time =    2078.69 ms /    52 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "I need to do an episode on the Boys Club that is Films in SK and how big name actors can get away with playing the same role over and over again\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.77 ms /    16 runs   (    0.67 ms per token,  1485.19 tokens per second)\n",
            "llama_print_timings: prompt eval time =     297.67 ms /    80 tokens (    3.72 ms per token,   268.76 tokens per second)\n",
            "llama_print_timings:        eval time =    1593.29 ms /    15 runs   (  106.22 ms per token,     9.41 tokens per second)\n",
            "llama_print_timings:       total time =    2282.70 ms /    95 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@a_b_phillips It's symbolic to show the club is serious about turning corner &amp; putting the chapter at rest. Roo has had many faux par in the media and outside of it, him being in the position still makes it easy to question the clubs sincerity and extends the boys club label. Needs to go.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.25 ms /    16 runs   (    0.58 ms per token,  1730.48 tokens per second)\n",
            "llama_print_timings: prompt eval time =     242.72 ms /    46 tokens (    5.28 ms per token,   189.52 tokens per second)\n",
            "llama_print_timings:        eval time =    1460.04 ms /    15 runs   (   97.34 ms per token,    10.27 tokens per second)\n",
            "llama_print_timings:       total time =    1882.75 ms /    61 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@mjammer31 @DarrenDreger John Ferguson Jr has a job still people need to stop complaining about diversity and maybe complain about the boys club NHL management is\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.73 ms /    16 runs   (    0.55 ms per token,  1832.97 tokens per second)\n",
            "llama_print_timings: prompt eval time =     236.53 ms /    35 tokens (    6.76 ms per token,   147.97 tokens per second)\n",
            "llama_print_timings:        eval time =    1649.25 ms /    15 runs   (  109.95 ms per token,     9.10 tokens per second)\n",
            "llama_print_timings:       total time =    2043.11 ms /    50 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Milliganreports @AlboMP @PatsKarvelas @ScottMorrisonMP It's called the boys club.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.97 ms /    16 runs   (    0.62 ms per token,  1604.17 tokens per second)\n",
            "llama_print_timings: prompt eval time =     263.31 ms /    70 tokens (    3.76 ms per token,   265.84 tokens per second)\n",
            "llama_print_timings:        eval time =    1445.85 ms /    15 runs   (   96.39 ms per token,    10.37 tokens per second)\n",
            "llama_print_timings:       total time =    1929.22 ms /    85 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Daddy sets the new diaper next to you as he digs out some wipes and powder. As daddy was getting supplies ready, you couldn't help but fuss as you'd catch the gaze of other patrons entering and leaving the restroom, often holding their noses as they walk by.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      12.04 ms /    16 runs   (    0.75 ms per token,  1329.46 tokens per second)\n",
            "llama_print_timings: prompt eval time =     271.85 ms /    92 tokens (    2.95 ms per token,   338.43 tokens per second)\n",
            "llama_print_timings:        eval time =    1839.36 ms /    15 runs   (  122.62 ms per token,     8.16 tokens per second)\n",
            "llama_print_timings:       total time =    2561.92 ms /   107 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "⠀⠀⠀⠀⠀ surrounded by it and have no room to escape. The gaze of the nobles would be in utter horrified as they witness the lady in the middle. \"A little fire show for everyone ~! Please enjoy as we burn this woman to ashes!\"#HOUSEAGRICHEGRANDBALL ⠀⠀⠀ https://t.co/TJT3Zit6qN\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.42 ms /    16 runs   (    0.59 ms per token,  1698.33 tokens per second)\n",
            "llama_print_timings: prompt eval time =     301.51 ms /   107 tokens (    2.82 ms per token,   354.88 tokens per second)\n",
            "llama_print_timings:        eval time =    1640.45 ms /    15 runs   (  109.36 ms per token,     9.14 tokens per second)\n",
            "llama_print_timings:       total time =    2246.20 ms /   122 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "The remission granted to men convicted of gangrape and mass murder is our defeat. The time has come to shift the gaze inwards to find the value of justice @LadyVelvet_HFQ#NYTimes @washingtonpost@observer @gulf_news@straits_times @BBCWorld@HHShkMohdhttps://t.co/QTxQOVQTp7 https://t.co/KK8ENTGiXW\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.05 ms /    16 runs   (    0.57 ms per token,  1768.74 tokens per second)\n",
            "llama_print_timings: prompt eval time =     262.42 ms /    68 tokens (    3.86 ms per token,   259.13 tokens per second)\n",
            "llama_print_timings:        eval time =    1479.25 ms /    15 runs   (   98.62 ms per token,    10.14 tokens per second)\n",
            "llama_print_timings:       total time =    1969.12 ms /    83 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "They later changed the partial title in article #1 to \"Jin, a real statue\" from the ' gaze of a statue '#Yours_Jin #SuperTuna_Jin #JIN #Moon_BTS #방탄소년단진 @bts_twt\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.84 ms /    16 runs   (    0.55 ms per token,  1809.75 tokens per second)\n",
            "llama_print_timings: prompt eval time =     234.54 ms /    35 tokens (    6.70 ms per token,   149.23 tokens per second)\n",
            "llama_print_timings:        eval time =    1484.79 ms /    15 runs   (   98.99 ms per token,    10.10 tokens per second)\n",
            "llama_print_timings:       total time =    1883.69 ms /    50 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@alphaINTEL remember the pink demon cyborg wattson?? or the gaze eternal rev skin?? bring back whoever made those those are worth money\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.13 ms /    16 runs   (    0.63 ms per token,  1579.31 tokens per second)\n",
            "llama_print_timings: prompt eval time =     249.62 ms /    46 tokens (    5.43 ms per token,   184.28 tokens per second)\n",
            "llama_print_timings:        eval time =    1692.88 ms /    15 runs   (  112.86 ms per token,     8.86 tokens per second)\n",
            "llama_print_timings:       total time =    2134.88 ms /    61 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@notgwendalupe at the end of the Call Me Maybe mv Carly said \"oh i know what the gaze want\" https://t.co/JwzbPHnqyf\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.45 ms /    16 runs   (    0.59 ms per token,  1692.76 tokens per second)\n",
            "llama_print_timings: prompt eval time =     261.08 ms /    54 tokens (    4.83 ms per token,   206.83 tokens per second)\n",
            "llama_print_timings:        eval time =    1718.00 ms /    15 runs   (  114.53 ms per token,     8.73 tokens per second)\n",
            "llama_print_timings:       total time =    2261.27 ms /    69 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@CoryGraves ‼️ also saw the man in front of me send the following 3 texts in rapid succession: “the pitcher is from the A’s” “the trade” “😑”\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.56 ms /    16 runs   (    0.60 ms per token,  1672.94 tokens per second)\n",
            "llama_print_timings: prompt eval time =     279.06 ms /    80 tokens (    3.49 ms per token,   286.68 tokens per second)\n",
            "llama_print_timings:        eval time =    1555.94 ms /    15 runs   (  103.73 ms per token,     9.64 tokens per second)\n",
            "llama_print_timings:       total time =    2072.68 ms /    95 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Thanks for your reply. What I am witnessing within the Body of Christ among spiritual fathers and spiritual sons is a tribe of greedy and prideful men as well as spiritual daughters. This is due to seeking man instead of pursuing the Man Jesus Christ. We need Jesus Christ's DNA! https://t.co/WFoW0Cudyw\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.56 ms /    16 runs   (    0.60 ms per token,  1673.29 tokens per second)\n",
            "llama_print_timings: prompt eval time =     257.40 ms /    66 tokens (    3.90 ms per token,   256.41 tokens per second)\n",
            "llama_print_timings:        eval time =    1542.64 ms /    15 runs   (  102.84 ms per token,     9.72 tokens per second)\n",
            "llama_print_timings:       total time =    2013.82 ms /    81 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@spanishkitten76 @Ali_TeslaMY @wanda_hudson I have read not of those things. I just looked at the man, looked into his past and I don't trust him. Not talking about his affairs or all that tabloid stuff.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.60 ms /    16 runs   (    0.60 ms per token,  1666.67 tokens per second)\n",
            "llama_print_timings: prompt eval time =     250.49 ms /    59 tokens (    4.25 ms per token,   235.53 tokens per second)\n",
            "llama_print_timings:        eval time =    1550.29 ms /    15 runs   (  103.35 ms per token,     9.68 tokens per second)\n",
            "llama_print_timings:       total time =    1992.45 ms /    74 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Dsage_BigHeart The man stand for Nigeria and all Nigerians, what did Buhari do for Lagos state during his staying in Aso Rock?Tinubu made all Yoruba to vote Buhari. Life became a mess\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.74 ms /    16 runs   (    0.67 ms per token,  1489.34 tokens per second)\n",
            "llama_print_timings: prompt eval time =     257.72 ms /    43 tokens (    5.99 ms per token,   166.85 tokens per second)\n",
            "llama_print_timings:        eval time =    1772.09 ms /    15 runs   (  118.14 ms per token,     8.46 tokens per second)\n",
            "llama_print_timings:       total time =    2284.39 ms /    58 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Why in audiobooks the man’s voice is so funny??? It’s always so deep idk why. I can’t keep a straight face while listening.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.38 ms /    16 runs   (    0.59 ms per token,  1705.76 tokens per second)\n",
            "llama_print_timings: prompt eval time =     248.98 ms /    56 tokens (    4.45 ms per token,   224.92 tokens per second)\n",
            "llama_print_timings:        eval time =    1689.88 ms /    15 runs   (  112.66 ms per token,     8.88 tokens per second)\n",
            "llama_print_timings:       total time =    2132.86 ms /    71 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@lincolnduff @NoLayingUp @TronCarterNLU what did HE have to say about it?  Golf Digest took him to task for being over the top, but no quotes from the man explaining what happened.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.92 ms /    16 runs   (    0.56 ms per token,  1792.92 tokens per second)\n",
            "llama_print_timings: prompt eval time =     680.22 ms /    25 tokens (   27.21 ms per token,    36.75 tokens per second)\n",
            "llama_print_timings:        eval time =    1437.03 ms /    15 runs   (   95.80 ms per token,    10.44 tokens per second)\n",
            "llama_print_timings:       total time =    2236.92 ms /    40 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@brezzyiana @ilovesunshine_ Tits longer than Crenshaw blvd\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.46 ms /    16 runs   (    0.59 ms per token,  1690.97 tokens per second)\n",
            "llama_print_timings: prompt eval time =     235.49 ms /    38 tokens (    6.20 ms per token,   161.37 tokens per second)\n",
            "llama_print_timings:        eval time =    1491.37 ms /    15 runs   (   99.42 ms per token,    10.06 tokens per second)\n",
            "llama_print_timings:       total time =    1889.06 ms /    53 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Tenderloche Maybe!! Idk! Might need someone to make a 3D model though https://t.co/lih1SomqFv\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      13.12 ms /    16 runs   (    0.82 ms per token,  1219.42 tokens per second)\n",
            "llama_print_timings: prompt eval time =     277.43 ms /    99 tokens (    2.80 ms per token,   356.85 tokens per second)\n",
            "llama_print_timings:        eval time =    1829.63 ms /    15 runs   (  121.98 ms per token,     8.20 tokens per second)\n",
            "llama_print_timings:       total time =    2444.45 ms /   114 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Masked brunette with bouncing tits... She delights in sucking two big cocks while a third slams her hard.... She screams a little!!!#Masked #Brunette #Fucked #Hard #Slammed #Deep #Banged #Rough #Sucking #Big #Dicks #Good #Blowjob #Loud #Pleasure https://t.co/f3NCu7mmVE\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.49 ms /    16 runs   (    0.59 ms per token,  1685.63 tokens per second)\n",
            "llama_print_timings: prompt eval time =     270.51 ms /    61 tokens (    4.43 ms per token,   225.50 tokens per second)\n",
            "llama_print_timings:        eval time =    1559.46 ms /    15 runs   (  103.96 ms per token,     9.62 tokens per second)\n",
            "llama_print_timings:       total time =    2035.77 ms /    76 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "#NSFWStoriesI flip you around again and throw your legs over my shoulders and start squeezing your tits as I thrust deeper inside you with every pump. You cum for me, your pussy squeezing my cock as the waves of orgasm passed over you.\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.74 ms /    16 runs   (    0.55 ms per token,  1831.08 tokens per second)\n",
            "llama_print_timings: prompt eval time =     237.54 ms /    33 tokens (    7.20 ms per token,   138.93 tokens per second)\n",
            "llama_print_timings:        eval time =    1559.71 ms /    15 runs   (  103.98 ms per token,     9.62 tokens per second)\n",
            "llama_print_timings:       total time =    1954.42 ms /    48 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Lightning_Tits @clkluvsux3 HEHEHEHE SHES GONNA BE HERE SOON\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.91 ms /    16 runs   (    0.56 ms per token,  1796.14 tokens per second)\n",
            "llama_print_timings: prompt eval time =     240.25 ms /    41 tokens (    5.86 ms per token,   170.66 tokens per second)\n",
            "llama_print_timings:        eval time =    1559.89 ms /    15 runs   (  103.99 ms per token,     9.62 tokens per second)\n",
            "llama_print_timings:       total time =    1972.97 ms /    56 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@StockCats @taylor_d_duran Any relation to Tits Magee? https://t.co/JB2giPEGdK\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       2.75 ms /     5 runs   (    0.55 ms per token,  1819.51 tokens per second)\n",
            "llama_print_timings: prompt eval time =     274.02 ms /    77 tokens (    3.56 ms per token,   281.00 tokens per second)\n",
            "llama_print_timings:        eval time =     444.20 ms /     4 runs   (  111.05 ms per token,     9.01 tokens per second)\n",
            "llama_print_timings:       total time =     906.44 ms /    81 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Here's the thing.Complaining about lots of today's women being whores accomplishes nothing.Exploit the situation to your advantage.Use the whores for fun, and marry a proper woman (preferably virgin) when you're ready for marriage.Don't marry the whores and you'll do fine\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.39 ms /    16 runs   (    0.71 ms per token,  1405.23 tokens per second)\n",
            "llama_print_timings: prompt eval time =     235.57 ms /    48 tokens (    4.91 ms per token,   203.76 tokens per second)\n",
            "llama_print_timings:        eval time =    1899.66 ms /    15 runs   (  126.64 ms per token,     7.90 tokens per second)\n",
            "llama_print_timings:       total time =    2428.49 ms /    63 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@BROWNCHILLIE @Iam_Imanuel @naijaeikn @tech_contractor Which ones? 😂 😂 😂 Not today's women that am certain about\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.67 ms /    16 runs   (    0.54 ms per token,  1846.51 tokens per second)\n",
            "llama_print_timings: prompt eval time =     299.95 ms /    97 tokens (    3.09 ms per token,   323.38 tokens per second)\n",
            "llama_print_timings:        eval time =    1522.80 ms /    15 runs   (  101.52 ms per token,     9.85 tokens per second)\n",
            "llama_print_timings:       total time =    2097.16 ms /   112 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Today’s Find: USA Today’s “Women of the Century” list published 14 Aug 2020 included several with #Alabama ties https://t.co/jTCf5VEpvt One is #Birmingham #Alabama native  Angela Davis #bham https://t.co/eoyd2RD28S https://t.co/SiLp3OdGhP\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       3.08 ms /     5 runs   (    0.62 ms per token,  1622.85 tokens per second)\n",
            "llama_print_timings: prompt eval time =     273.32 ms /    89 tokens (    3.07 ms per token,   325.63 tokens per second)\n",
            "llama_print_timings:        eval time =     446.43 ms /     4 runs   (  111.61 ms per token,     8.96 tokens per second)\n",
            "llama_print_timings:       total time =     934.58 ms /    93 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "https://t.co/mFeR7DUclE It happens only in #India @KirenRijiju One can reverse #gender to just imagine what torture #Men would go through had it been a lady Forget #celebrity who only consume #drugs ruin future generation including #SSR Today's #women R pathetic #FeminismIsCancer\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.08 ms /    16 runs   (    0.63 ms per token,  1587.30 tokens per second)\n",
            "llama_print_timings: prompt eval time =     258.93 ms /    81 tokens (    3.20 ms per token,   312.83 tokens per second)\n",
            "llama_print_timings:        eval time =    1558.76 ms /    15 runs   (  103.92 ms per token,     9.62 tokens per second)\n",
            "llama_print_timings:       total time =    2067.97 ms /    96 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "All due respect to women from 50s but today's women are so much cooler They're on average, significantly more educated, more intelligent and care more about their looksAlso nothing hotter than knowing your girl *wants* to be with you, instead of just being an arranged marriage https://t.co/NSVeAWjffx\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.93 ms /    16 runs   (    0.62 ms per token,  1611.12 tokens per second)\n",
            "llama_print_timings: prompt eval time =     245.04 ms /    51 tokens (    4.80 ms per token,   208.13 tokens per second)\n",
            "llama_print_timings:        eval time =    1634.49 ms /    15 runs   (  108.97 ms per token,     9.18 tokens per second)\n",
            "llama_print_timings:       total time =    2071.57 ms /    66 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "We’re honoring a deserving Iowa woman as one of USA Today’s Women of the Year. Tell us who we should recognize.  https://t.co/H9OJCUrPQ1\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      12.03 ms /    16 runs   (    0.75 ms per token,  1329.68 tokens per second)\n",
            "llama_print_timings: prompt eval time =     279.95 ms /   101 tokens (    2.77 ms per token,   360.78 tokens per second)\n",
            "llama_print_timings:        eval time =    1888.73 ms /    15 runs   (  125.92 ms per token,     7.94 tokens per second)\n",
            "llama_print_timings:       total time =    2653.47 ms /   116 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "True love talks with you even through the screen of your phone, it will touch your heart .True love is as simple as you see but so deep. You will understand \"I love you\" isn't a sentence but an action. God made them for each other ❤#หยิ่นวอร์ #warwanarat #yinyin_anw #YINWAR https://t.co/bp8bnTq8m8\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.65 ms /    16 runs   (    0.60 ms per token,  1657.69 tokens per second)\n",
            "llama_print_timings: prompt eval time =     259.45 ms /    61 tokens (    4.25 ms per token,   235.11 tokens per second)\n",
            "llama_print_timings:        eval time =    1576.31 ms /    15 runs   (  105.09 ms per token,     9.52 tokens per second)\n",
            "llama_print_timings:       total time =    2052.08 ms /    76 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "also it’s common knowledge in drag bars to NEVER get near, touch, or on the same stage as the performer. STOP USING DRAG QUEENS AS YOUR GATEWAY FOR HOMOPHOBIA AND TRANSPHOBIA.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.44 ms /    16 runs   (    0.59 ms per token,  1695.63 tokens per second)\n",
            "llama_print_timings: prompt eval time =     259.84 ms /    66 tokens (    3.94 ms per token,   254.00 tokens per second)\n",
            "llama_print_timings:        eval time =    1514.19 ms /    15 runs   (  100.95 ms per token,     9.91 tokens per second)\n",
            "llama_print_timings:       total time =    1987.96 ms /    81 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "RT DHSPress: RT @TitanAthletics2: Order now on my life https://t.co/VwJmCNZCfc using your Picture Day ID : EVTFZJ84B https://t.co/bCRPV8VOuh\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.19 ms /    16 runs   (    0.57 ms per token,  1740.27 tokens per second)\n",
            "llama_print_timings: prompt eval time =     261.87 ms /    68 tokens (    3.85 ms per token,   259.67 tokens per second)\n",
            "llama_print_timings:        eval time =    1546.68 ms /    15 runs   (  103.11 ms per token,     9.70 tokens per second)\n",
            "llama_print_timings:       total time =    2017.06 ms /    83 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "I honestly don't want to make friends anymore because I'm that person who can't keep relationships and I will feel bad for putting the pressure on the other people to keep trying to stay in touch with me.I'm just better with the few who understand we're still great no matter what\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.13 ms /    16 runs   (    0.63 ms per token,  1578.84 tokens per second)\n",
            "llama_print_timings: prompt eval time =     246.25 ms /    55 tokens (    4.48 ms per token,   223.35 tokens per second)\n",
            "llama_print_timings:        eval time =    1761.62 ms /    15 runs   (  117.44 ms per token,     8.51 tokens per second)\n",
            "llama_print_timings:       total time =    2228.17 ms /    70 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "28-09-2022 01:00:01 https://t.co/QSSPnxvGl1 #BlastFMRock 🔊 Touch The Buffalo - Heart Is For\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.70 ms /    16 runs   (    0.61 ms per token,  1649.65 tokens per second)\n",
            "llama_print_timings: prompt eval time =     291.25 ms /    82 tokens (    3.55 ms per token,   281.55 tokens per second)\n",
            "llama_print_timings:        eval time =    1546.46 ms /    15 runs   (  103.10 ms per token,     9.70 tokens per second)\n",
            "llama_print_timings:       total time =    2209.02 ms /    97 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@TonyHWindsor I think the absurdly high salaries of many of these media \"celebs\" conservatises them. They become happy servants of their new-found affluence &amp; employers. Out of touch, incapable of fearless, objective journalism, &amp; very taken with themselves. (I include ABC here, these days.)\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.99 ms /    16 runs   (    0.56 ms per token,  1779.95 tokens per second)\n",
            "llama_print_timings: prompt eval time =     246.11 ms /    50 tokens (    4.92 ms per token,   203.16 tokens per second)\n",
            "llama_print_timings:        eval time =    1552.11 ms /    15 runs   (  103.47 ms per token,     9.66 tokens per second)\n",
            "llama_print_timings:       total time =    1985.67 ms /    65 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Living the trophy wife life as you see from the outfit. Wait for it on September 21. 🤪💗 https://t.co/JjZVSdmvcO\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.16 ms /    16 runs   (    0.57 ms per token,  1746.72 tokens per second)\n",
            "llama_print_timings: prompt eval time =     758.32 ms /    31 tokens (   24.46 ms per token,    40.88 tokens per second)\n",
            "llama_print_timings:        eval time =    1540.66 ms /    15 runs   (  102.71 ms per token,     9.74 tokens per second)\n",
            "llama_print_timings:       total time =    2433.45 ms /    46 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "now that I actually enjoy hoovering my apartment with my new vacuum cleaner I actually feel ready to be a trophy wife\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.47 ms /    16 runs   (    0.59 ms per token,  1688.65 tokens per second)\n",
            "llama_print_timings: prompt eval time =     463.42 ms /    17 tokens (   27.26 ms per token,    36.68 tokens per second)\n",
            "llama_print_timings:        eval time =    1554.29 ms /    15 runs   (  103.62 ms per token,     9.65 tokens per second)\n",
            "llama_print_timings:       total time =    2129.84 ms /    32 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "wait i think trophy wife would be a more accurate word\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.85 ms /    16 runs   (    0.62 ms per token,  1624.53 tokens per second)\n",
            "llama_print_timings: prompt eval time =     240.58 ms /    34 tokens (    7.08 ms per token,   141.33 tokens per second)\n",
            "llama_print_timings:        eval time =    1830.76 ms /    15 runs   (  122.05 ms per token,     8.19 tokens per second)\n",
            "llama_print_timings:       total time =    2290.33 ms /    49 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "why is he giving trophy wife vibes 🥺❤️ https://t.co/sHnmf5Gf2H\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.61 ms /    16 runs   (    0.54 ms per token,  1858.52 tokens per second)\n",
            "llama_print_timings: prompt eval time =     254.14 ms /    34 tokens (    7.47 ms per token,   133.79 tokens per second)\n",
            "llama_print_timings:        eval time =    1514.57 ms /    15 runs   (  100.97 ms per token,     9.90 tokens per second)\n",
            "llama_print_timings:       total time =    1922.38 ms /    49 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Why is 2m!n look like Rich CEO and His trophy wife https://t.co/6IwnVMvTYk\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.34 ms /    16 runs   (    0.58 ms per token,  1713.43 tokens per second)\n",
            "llama_print_timings: prompt eval time =     375.96 ms /   167 tokens (    2.25 ms per token,   444.20 tokens per second)\n",
            "llama_print_timings:        eval time =    1586.47 ms /    15 runs   (  105.76 ms per token,     9.45 tokens per second)\n",
            "llama_print_timings:       total time =    2441.54 ms /   182 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "LOOK FOR PHIPPS-BRED YEARLINGS AT #KEESEPT:🐴418 c. War Front - Sabbatical https://t.co/5sU1H3Lz0M🐴1252 c. More Than Ready - Trophy Wife https://t.co/nnEVL9uNkq🐴2008 f. Runhappy - Side of Sass https://t.co/lDCuaiN3iK🐴2240 c. Frosted - Guilty Verdict https://t.co/iKmJTmUaDr https://t.co/ZelATWvucx\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.80 ms /    16 runs   (    0.55 ms per token,  1818.18 tokens per second)\n",
            "llama_print_timings: prompt eval time =     238.09 ms /    38 tokens (    6.27 ms per token,   159.60 tokens per second)\n",
            "llama_print_timings:        eval time =    1506.04 ms /    15 runs   (  100.40 ms per token,     9.96 tokens per second)\n",
            "llama_print_timings:       total time =    1906.01 ms /    53 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@ArtSimone This is the movie I put on if I ever want a big ugly cry https://t.co/rHFFal7JRU\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.44 ms /    16 runs   (    0.71 ms per token,  1398.85 tokens per second)\n",
            "llama_print_timings: prompt eval time =     755.28 ms /    24 tokens (   31.47 ms per token,    31.78 tokens per second)\n",
            "llama_print_timings:        eval time =    1888.99 ms /    15 runs   (  125.93 ms per token,     7.94 tokens per second)\n",
            "llama_print_timings:       total time =    2853.74 ms /    39 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "the deadliest fighters in the Imperium. The Count, a dapper and ugly little\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.77 ms /    16 runs   (    0.61 ms per token,  1637.33 tokens per second)\n",
            "llama_print_timings: prompt eval time =     271.52 ms /    63 tokens (    4.31 ms per token,   232.02 tokens per second)\n",
            "llama_print_timings:        eval time =    1455.17 ms /    15 runs   (   97.01 ms per token,    10.31 tokens per second)\n",
            "llama_print_timings:       total time =    1937.19 ms /    78 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@cutelitlemango6 @koocwtch @1989Iore @chartdata @BTS_twt LmaoAnd the twink in question: fadlisa flat ugly ass https://t.co/ZH4nsM1Xuw\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.85 ms /    16 runs   (    0.55 ms per token,  1807.50 tokens per second)\n",
            "llama_print_timings: prompt eval time =     495.96 ms /    20 tokens (   24.80 ms per token,    40.33 tokens per second)\n",
            "llama_print_timings:        eval time =    1507.24 ms /    15 runs   (  100.48 ms per token,     9.95 tokens per second)\n",
            "llama_print_timings:       total time =    2116.42 ms /    35 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "I love seeing girls breaking up with their ugly boyfriends &lt;3\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.43 ms /    16 runs   (    0.53 ms per token,  1898.66 tokens per second)\n",
            "llama_print_timings: prompt eval time =     233.38 ms /    33 tokens (    7.07 ms per token,   141.40 tokens per second)\n",
            "llama_print_timings:        eval time =    1580.29 ms /    15 runs   (  105.35 ms per token,     9.49 tokens per second)\n",
            "llama_print_timings:       total time =    1967.48 ms /    48 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Noses are periwinkle, bluebells are lightsalmon, Elliot from Mr. Robot is ugly and so on.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.26 ms /    16 runs   (    0.70 ms per token,  1421.46 tokens per second)\n",
            "llama_print_timings: prompt eval time =     248.01 ms /    56 tokens (    4.43 ms per token,   225.80 tokens per second)\n",
            "llama_print_timings:        eval time =    1650.24 ms /    15 runs   (  110.02 ms per token,     9.09 tokens per second)\n",
            "llama_print_timings:       total time =    2116.13 ms /    71 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "apple’s iOS 16 update is UGLY and a INCONVENIENCE LIKE WHY THE FUCK WOULD YOU DO THIS TO US APPLEi’m not updating my phone🫡\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.06 ms /    16 runs   (    0.69 ms per token,  1447.18 tokens per second)\n",
            "llama_print_timings: prompt eval time =     580.74 ms /    32 tokens (   18.15 ms per token,    55.10 tokens per second)\n",
            "llama_print_timings:        eval time =    1510.15 ms /    15 runs   (  100.68 ms per token,     9.93 tokens per second)\n",
            "llama_print_timings:       total time =    2293.44 ms /    47 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "sat on a banana at lunch and now have banana smears on both the ass of my jeans and in my underpants\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.51 ms /    16 runs   (    0.59 ms per token,  1681.73 tokens per second)\n",
            "llama_print_timings: prompt eval time =     233.55 ms /    34 tokens (    6.87 ms per token,   145.58 tokens per second)\n",
            "llama_print_timings:        eval time =    1679.73 ms /    15 runs   (  111.98 ms per token,     8.93 tokens per second)\n",
            "llama_print_timings:       total time =    2072.23 ms /    49 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@flamencolambada Ok but wheres his underpants https://t.co/WVOXxDBqNQ\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.07 ms /    16 runs   (    0.57 ms per token,  1764.25 tokens per second)\n",
            "llama_print_timings: prompt eval time =     252.99 ms /    47 tokens (    5.38 ms per token,   185.78 tokens per second)\n",
            "llama_print_timings:        eval time =    1532.86 ms /    15 runs   (  102.19 ms per token,     9.79 tokens per second)\n",
            "llama_print_timings:       total time =    1965.38 ms /    62 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@delthelemon I feel this so deeply. “I’ve not had an underpants crisis in probably more than 20 years but this trip I could encounter at least 3 per day.”\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.87 ms /    16 runs   (    0.55 ms per token,  1803.22 tokens per second)\n",
            "llama_print_timings: prompt eval time =     247.53 ms /    39 tokens (    6.35 ms per token,   157.56 tokens per second)\n",
            "llama_print_timings:        eval time =    1582.84 ms /    15 runs   (  105.52 ms per token,     9.48 tokens per second)\n",
            "llama_print_timings:       total time =    1991.12 ms /    54 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@M40345 @Donytaste @IAmSteveHarvey Accidents like these were caused by the lack of underpants! 🤣\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.52 ms /    16 runs   (    0.72 ms per token,  1389.49 tokens per second)\n",
            "llama_print_timings: prompt eval time =     270.87 ms /    54 tokens (    5.02 ms per token,   199.36 tokens per second)\n",
            "llama_print_timings:        eval time =    1690.13 ms /    15 runs   (  112.68 ms per token,     8.88 tokens per second)\n",
            "llama_print_timings:       total time =    2276.66 ms /    69 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@maria_avdv Russian barrier troops won't let the running away Russian fighters return to their mothers and wives. Now that is embarrassing when the barriers began giving the retreating soldiers fresh underpants in exchange for soiled ones.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.20 ms /    16 runs   (    0.58 ms per token,  1738.94 tokens per second)\n",
            "llama_print_timings: prompt eval time =     244.34 ms /    44 tokens (    5.55 ms per token,   180.08 tokens per second)\n",
            "llama_print_timings:        eval time =    1583.80 ms /    15 runs   (  105.59 ms per token,     9.47 tokens per second)\n",
            "llama_print_timings:       total time =    2001.04 ms /    59 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "I daydreamed, while at Blarney Castle, about the time I set fire to my underpants in Annamoe with an angelic Uruguayan scene painter.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.30 ms /    16 runs   (    0.58 ms per token,  1720.25 tokens per second)\n",
            "llama_print_timings: prompt eval time =     265.48 ms /    76 tokens (    3.49 ms per token,   286.27 tokens per second)\n",
            "llama_print_timings:        eval time =    1486.69 ms /    15 runs   (   99.11 ms per token,    10.09 tokens per second)\n",
            "llama_print_timings:       total time =    1981.02 ms /    91 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@AdvoBarryRoux I honestly get this, our society is some how rotten but to expect men to do anything but I guess it experts men to provide but...Some men are mistonistigic and dont understand women will provide if they are treated softly or are dominantly treated right! Fuck I hate our societ💔\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.94 ms /    16 runs   (    0.56 ms per token,  1789.71 tokens per second)\n",
            "llama_print_timings: prompt eval time =     233.43 ms /    36 tokens (    6.48 ms per token,   154.22 tokens per second)\n",
            "llama_print_timings:        eval time =    1566.97 ms /    15 runs   (  104.46 ms per token,     9.57 tokens per second)\n",
            "llama_print_timings:       total time =    1966.87 ms /    51 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@eddyfontaine @TheGrandVezir You don't like this 4 months heads up or what? I don't understand women\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      12.87 ms /    16 runs   (    0.80 ms per token,  1243.68 tokens per second)\n",
            "llama_print_timings: prompt eval time =     822.50 ms /    31 tokens (   26.53 ms per token,    37.69 tokens per second)\n",
            "llama_print_timings:        eval time =    1900.08 ms /    15 runs   (  126.67 ms per token,     7.89 tokens per second)\n",
            "llama_print_timings:       total time =    2941.29 ms /    46 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@MollyJongFast This is what happens when someone without a uterus thinks they understand women and child birth. SMH\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.80 ms /    16 runs   (    0.55 ms per token,  1817.15 tokens per second)\n",
            "llama_print_timings: prompt eval time =     697.63 ms /    26 tokens (   26.83 ms per token,    37.27 tokens per second)\n",
            "llama_print_timings:        eval time =    1546.46 ms /    15 runs   (  103.10 ms per token,     9.70 tokens per second)\n",
            "llama_print_timings:       total time =    2373.68 ms /    41 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Sassyemmalove What's wrong with men ?? Besides we don't understand women sometimes lol\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.79 ms /    16 runs   (    0.55 ms per token,  1820.46 tokens per second)\n",
            "llama_print_timings: prompt eval time =     256.93 ms /    63 tokens (    4.08 ms per token,   245.20 tokens per second)\n",
            "llama_print_timings:        eval time =    1605.90 ms /    15 runs   (  107.06 ms per token,     9.34 tokens per second)\n",
            "llama_print_timings:       total time =    2066.94 ms /    78 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@mbadalet So often facilitate rational engagement with others and normalise reading widely about reproductive health.I was shocked 3 ladies instantly blocked me after my first post as if what I said is not part of human life. Allowing men to participate also help them understand women too\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.75 ms /    16 runs   (    0.55 ms per token,  1829.62 tokens per second)\n",
            "llama_print_timings: prompt eval time =     240.45 ms /    36 tokens (    6.68 ms per token,   149.72 tokens per second)\n",
            "llama_print_timings:        eval time =    1589.32 ms /    15 runs   (  105.95 ms per token,     9.44 tokens per second)\n",
            "llama_print_timings:       total time =    1990.56 ms /    51 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Not only men but also women can't understand women ... 🙆🤦 https://t.co/PFpd4MXH6E\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.85 ms /    16 runs   (    0.68 ms per token,  1474.52 tokens per second)\n",
            "llama_print_timings: prompt eval time =     263.44 ms /    76 tokens (    3.47 ms per token,   288.50 tokens per second)\n",
            "llama_print_timings:        eval time =    1707.37 ms /    15 runs   (  113.82 ms per token,     8.79 tokens per second)\n",
            "llama_print_timings:       total time =    2216.46 ms /    91 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@freemonotheist @AJEnglish True though.Nowadays, we girls need to wear the hijab and full-cloth uniform to school. While my mom when she was a student she must wear a very short skirt and the teacher will cut it short if its below knee. She said those were Jahiliah times.😂\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.32 ms /    16 runs   (    0.65 ms per token,  1550.39 tokens per second)\n",
            "llama_print_timings: prompt eval time =     288.44 ms /    86 tokens (    3.35 ms per token,   298.15 tokens per second)\n",
            "llama_print_timings:        eval time =    1533.00 ms /    15 runs   (  102.20 ms per token,     9.78 tokens per second)\n",
            "llama_print_timings:       total time =    2211.32 ms /   101 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Hi @amnesty,Nobody is in harm's way if they aren't being targeted by Russian forces. But thanks for the lesson in victim blaming. 🙄You should Google \"the victim wore a very short skirt\". You'll find loads of stuff to fit your bizarre viewpoint there. https://t.co/xY6vPvi4kX\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.55 ms /    16 runs   (    0.53 ms per token,  1872.22 tokens per second)\n",
            "llama_print_timings: prompt eval time =     249.16 ms /    41 tokens (    6.08 ms per token,   164.55 tokens per second)\n",
            "llama_print_timings:        eval time =    1564.15 ms /    15 runs   (  104.28 ms per token,     9.59 tokens per second)\n",
            "llama_print_timings:       total time =    1980.88 ms /    56 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@VanessaPur Very short skirt and long nylon legs are a perfect combination I have to say 🥵😍😈💦\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.73 ms /    16 runs   (    0.55 ms per token,  1833.39 tokens per second)\n",
            "llama_print_timings: prompt eval time =     240.40 ms /    46 tokens (    5.23 ms per token,   191.35 tokens per second)\n",
            "llama_print_timings:        eval time =    1523.82 ms /    15 runs   (  101.59 ms per token,     9.84 tokens per second)\n",
            "llama_print_timings:       total time =    1947.51 ms /    61 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "When i see girls wear short skirts i get so jealous 😭 , i have a very short skirt and i want to wear it 😭😭😭but what if my bumbum show 😭\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.47 ms /    16 runs   (    0.59 ms per token,  1688.83 tokens per second)\n",
            "llama_print_timings: prompt eval time =     250.32 ms /    62 tokens (    4.04 ms per token,   247.69 tokens per second)\n",
            "llama_print_timings:        eval time =    1642.35 ms /    15 runs   (  109.49 ms per token,     9.13 tokens per second)\n",
            "llama_print_timings:       total time =    2101.30 ms /    77 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "As a teenager a tried on a short skirt in a trendy shop. The look the shop assistant gave me put me off for a very long time. But today I'm wearing a very short skirt. And tights. And fuck it if I'm wobbly.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.09 ms /    16 runs   (    0.69 ms per token,  1442.61 tokens per second)\n",
            "llama_print_timings: prompt eval time =     285.78 ms /    91 tokens (    3.14 ms per token,   318.43 tokens per second)\n",
            "llama_print_timings:        eval time =    1705.02 ms /    15 runs   (  113.67 ms per token,     8.80 tokens per second)\n",
            "llama_print_timings:       total time =    2423.91 ms /   106 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "photorealistic painting of two beautiful and stunning house wives kissing each other passionately in the kitchen, very short skirt, epic scenery, highly detailed, sensuality, lush blonde hair, bare legs, bare thighs, art by greg rutkowski, milo manara and Rebecca Guay, trendi... https://t.co/n6Yatqffiw\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.37 ms /    16 runs   (    0.59 ms per token,  1707.21 tokens per second)\n",
            "llama_print_timings: prompt eval time =     253.11 ms /    62 tokens (    4.08 ms per token,   244.96 tokens per second)\n",
            "llama_print_timings:        eval time =    1487.34 ms /    15 runs   (   99.16 ms per token,    10.09 tokens per second)\n",
            "llama_print_timings:       total time =    1947.81 ms /    77 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Real_mkkk @NnaEnibe @seunosewa Right about what?You mean someone can come on twitter and tweet shit and after being called out for the bigot he is he start playing the victim card and here you are typing shit all over again\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.74 ms /    16 runs   (    0.61 ms per token,  1642.04 tokens per second)\n",
            "llama_print_timings: prompt eval time =     277.61 ms /    79 tokens (    3.51 ms per token,   284.58 tokens per second)\n",
            "llama_print_timings:        eval time =    1509.46 ms /    15 runs   (  100.63 ms per token,     9.94 tokens per second)\n",
            "llama_print_timings:       total time =    2019.82 ms /    94 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@ppbajpai Assuming misuse of CBI/ED/IT is true in todays Modi govt period and todays media is taking an issue along with the opposition playing victim card, why was the media not standing with Modi then, when he complained of same agencies misuse. Isn’t that hypocrisy of media now.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.98 ms /    16 runs   (    0.56 ms per token,  1782.53 tokens per second)\n",
            "llama_print_timings: prompt eval time =     245.02 ms /    49 tokens (    5.00 ms per token,   199.98 tokens per second)\n",
            "llama_print_timings:        eval time =    1502.80 ms /    15 runs   (  100.19 ms per token,     9.98 tokens per second)\n",
            "llama_print_timings:       total time =    1943.94 ms /    64 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Bella can play the victim card all she wants, she won’t still win the show. Why didn’t she walk out from the toilet? did sheggz tie her legs there? #BBnaija\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.31 ms /    16 runs   (    0.71 ms per token,  1415.05 tokens per second)\n",
            "llama_print_timings: prompt eval time =     261.41 ms /    75 tokens (    3.49 ms per token,   286.90 tokens per second)\n",
            "llama_print_timings:        eval time =    1800.45 ms /    15 runs   (  120.03 ms per token,     8.33 tokens per second)\n",
            "llama_print_timings:       total time =    2324.52 ms /    90 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Woke_Chicken Missed the point. It is not ok, Gun  said it was not ok and was problematic.Gunn admitted he had made a mistake and that he had grown as a person. Gunn actually took responsibility. BLP has not and seems like he will not. Instead he continues with the victim card.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.98 ms /    16 runs   (    0.62 ms per token,  1603.37 tokens per second)\n",
            "llama_print_timings: prompt eval time =     272.78 ms /    64 tokens (    4.26 ms per token,   234.62 tokens per second)\n",
            "llama_print_timings:        eval time =    1541.61 ms /    15 runs   (  102.77 ms per token,     9.73 tokens per second)\n",
            "llama_print_timings:       total time =    2022.06 ms /    79 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "They get back the same energy that they threw at 875 for 2 years and suddenly now we made alliances and they take out the victim card because they are literally dragging them all over the place. https://t.co/BvdLd1qHKB\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.85 ms /    16 runs   (    0.55 ms per token,  1808.73 tokens per second)\n",
            "llama_print_timings: prompt eval time =     263.12 ms /    69 tokens (    3.81 ms per token,   262.24 tokens per second)\n",
            "llama_print_timings:        eval time =    1479.95 ms /    15 runs   (   98.66 ms per token,    10.14 tokens per second)\n",
            "llama_print_timings:       total time =    1966.07 ms /    84 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@gladyce_b @spacelagace I'm not playing the victim card over ONE job posting.You asked for ONE. So I gave it.What I am saying is we are creating a culture of racial discrimination to tackle a culture of racial discrimination. It's idiotic and toxic.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.50 ms /    16 runs   (    0.59 ms per token,  1684.39 tokens per second)\n",
            "llama_print_timings: prompt eval time =     271.89 ms /    90 tokens (    3.02 ms per token,   331.01 tokens per second)\n",
            "llama_print_timings:        eval time =    1502.51 ms /    15 runs   (  100.17 ms per token,     9.98 tokens per second)\n",
            "llama_print_timings:       total time =    2034.92 ms /   105 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@JdubAndrew @ForSureNotRobot @llb325 @Biscuitman13 @joncoopertweets These things are not related. This dude got unauthorized access to the data and the software, after, and he gave that access to more people. No, the system wasn't vulnerable. He filed his \"evidence\" in a court and it got dismissed.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.74 ms /    16 runs   (    0.61 ms per token,  1642.20 tokens per second)\n",
            "llama_print_timings: prompt eval time =     239.19 ms /    38 tokens (    6.29 ms per token,   158.87 tokens per second)\n",
            "llama_print_timings:        eval time =    1633.08 ms /    15 runs   (  108.87 ms per token,     9.19 tokens per second)\n",
            "llama_print_timings:       total time =    2048.34 ms /    53 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@seanzjay @TomMostlyZen Nuclear plants aren’t as vulnerable as many think. A grenade toss won’t do it!\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.47 ms /    16 runs   (    0.65 ms per token,  1527.59 tokens per second)\n",
            "llama_print_timings: prompt eval time =     286.54 ms /    69 tokens (    4.15 ms per token,   240.80 tokens per second)\n",
            "llama_print_timings:        eval time =    1626.52 ms /    15 runs   (  108.43 ms per token,     9.22 tokens per second)\n",
            "llama_print_timings:       total time =    2259.26 ms /    84 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@herstardom How does one deny temptation when it breaks all barriers, leaving him bare, entirely naked and vulnerable.He missed her warmth and taste dearly, and it's evident in the urgency of his kisses, touches slow but wanting and passionate as he holds her waist, pressing her against -\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.58 ms /    16 runs   (    0.60 ms per token,  1670.32 tokens per second)\n",
            "llama_print_timings: prompt eval time =     265.62 ms /    78 tokens (    3.41 ms per token,   293.65 tokens per second)\n",
            "llama_print_timings:        eval time =    1542.93 ms /    15 runs   (  102.86 ms per token,     9.72 tokens per second)\n",
            "llama_print_timings:       total time =    2043.89 ms /    93 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "We applaud state legislators for their overwhelming, bipartisan vote to change how we address mental health with CARE Courts – an innovative way to ensure vulnerable Californians get the help they need. Thank you @SenSusanEggman @SenatorUmberg &amp; @GavinNewsom for your leadership!\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.59 ms /    16 runs   (    0.60 ms per token,  1668.58 tokens per second)\n",
            "llama_print_timings: prompt eval time =     244.80 ms /    50 tokens (    4.90 ms per token,   204.25 tokens per second)\n",
            "llama_print_timings:        eval time =    1417.52 ms /    15 runs   (   94.50 ms per token,    10.58 tokens per second)\n",
            "llama_print_timings:       total time =    1871.89 ms /    65 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@jamesdavidmagee @bennyjohnson @Timcast Enough already. If you’re that vulnerable stay home or go to an open field. We should all be past this arbitrary garbage.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.38 ms /    16 runs   (    0.59 ms per token,  1705.58 tokens per second)\n",
            "llama_print_timings: prompt eval time =     281.50 ms /   112 tokens (    2.51 ms per token,   397.87 tokens per second)\n",
            "llama_print_timings:        eval time =    1561.08 ms /    15 runs   (  104.07 ms per token,     9.61 tokens per second)\n",
            "llama_print_timings:       total time =    2137.18 ms /   127 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@SimcoeGreyGPC @Women___Exist @erewhon4ever @stuartlosaltos @esme_saysno @jonkay @CBCDavid @aballinga @Gray_Mackenzie Words like girl, woman, trans man, she, her etc are used to describe females, the most vulnerable and least powerful demographic who historically have been and still are discriminated against by males. Women say NO to males taking away our ability to describe ourselves.\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.98 ms /    16 runs   (    0.69 ms per token,  1456.80 tokens per second)\n",
            "llama_print_timings: prompt eval time =     248.16 ms /    34 tokens (    7.30 ms per token,   137.01 tokens per second)\n",
            "llama_print_timings:        eval time =    1855.25 ms /    15 runs   (  123.68 ms per token,     8.09 tokens per second)\n",
            "llama_print_timings:       total time =    2330.61 ms /    49 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@rog2dawgs @LindaBrink7 @Marcus4Georgia She id the poster child for attention whore.\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.70 ms /    16 runs   (    0.54 ms per token,  1839.93 tokens per second)\n",
            "llama_print_timings: prompt eval time =     646.18 ms /    23 tokens (   28.09 ms per token,    35.59 tokens per second)\n",
            "llama_print_timings:        eval time =    1525.22 ms /    15 runs   (  101.68 ms per token,     9.83 tokens per second)\n",
            "llama_print_timings:       total time =    2283.59 ms /    38 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@GIRLYMAGNE Fat assed whore is looking to get knocked up ~ !\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.22 ms /    16 runs   (    0.58 ms per token,  1735.36 tokens per second)\n",
            "llama_print_timings: prompt eval time =     248.05 ms /    55 tokens (    4.51 ms per token,   221.73 tokens per second)\n",
            "llama_print_timings:        eval time =    1578.98 ms /    15 runs   (  105.27 ms per token,     9.50 tokens per second)\n",
            "llama_print_timings:       total time =    2031.50 ms /    70 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Iiltwink Just protect your physical and mental health no matter whatTttt whether you’re an ice cream whore or another type 🌹👄👄🤩🤩\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.44 ms /    16 runs   (    0.53 ms per token,  1895.73 tokens per second)\n",
            "llama_print_timings: prompt eval time =     756.91 ms /    31 tokens (   24.42 ms per token,    40.96 tokens per second)\n",
            "llama_print_timings:        eval time =    1575.67 ms /    15 runs   (  105.04 ms per token,     9.52 tokens per second)\n",
            "llama_print_timings:       total time =    2460.68 ms /    46 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "fuuchan looks like hes wearing the whore gloves https://t.co/92b5yEpjtt\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.62 ms /    16 runs   (    0.66 ms per token,  1506.45 tokens per second)\n",
            "llama_print_timings: prompt eval time =     244.20 ms /    33 tokens (    7.40 ms per token,   135.14 tokens per second)\n",
            "llama_print_timings:        eval time =    1800.16 ms /    15 runs   (  120.01 ms per token,     8.33 tokens per second)\n",
            "llama_print_timings:       total time =    2221.04 ms /    48 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "why are you talking shit abt my driving? like we’re in MY car?? next time take yours, raggedy whore\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.24 ms /    16 runs   (    0.58 ms per token,  1732.35 tokens per second)\n",
            "llama_print_timings: prompt eval time =     264.54 ms /    40 tokens (    6.61 ms per token,   151.21 tokens per second)\n",
            "llama_print_timings:        eval time =    1469.70 ms /    15 runs   (   97.98 ms per token,    10.21 tokens per second)\n",
            "llama_print_timings:       total time =    1976.47 ms /    55 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Talk to me like the filthy whore u are 🥵🤪 https://t.co/zz2Wqk4iIF\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.31 ms /    16 runs   (    0.58 ms per token,  1718.77 tokens per second)\n",
            "llama_print_timings: prompt eval time =     569.02 ms /    24 tokens (   23.71 ms per token,    42.18 tokens per second)\n",
            "llama_print_timings:        eval time =    1473.62 ms /    15 runs   (   98.24 ms per token,    10.18 tokens per second)\n",
            "llama_print_timings:       total time =    2161.28 ms /    39 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@redsteeze Was actually just a 40 year old woman driving the Tesla\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.46 ms /    16 runs   (    0.53 ms per token,  1890.81 tokens per second)\n",
            "llama_print_timings: prompt eval time =     486.04 ms /    19 tokens (   25.58 ms per token,    39.09 tokens per second)\n",
            "llama_print_timings:        eval time =    1495.89 ms /    15 runs   (   99.73 ms per token,    10.03 tokens per second)\n",
            "llama_print_timings:       total time =    2085.83 ms /    34 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "This woman driving my shit like a hellcat rn my god😂\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.63 ms /    16 runs   (    0.60 ms per token,  1660.78 tokens per second)\n",
            "llama_print_timings: prompt eval time =     243.47 ms /    52 tokens (    4.68 ms per token,   213.58 tokens per second)\n",
            "llama_print_timings:        eval time =    1620.20 ms /    15 runs   (  108.01 ms per token,     9.26 tokens per second)\n",
            "llama_print_timings:       total time =    2063.86 ms /    67 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "An 80-year-old woman driving a moped was killed in a crash involving an SUV in Falmouth, Massachusetts, according to police. https://t.co/4NS3qbJz4J\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.25 ms /    16 runs   (    0.70 ms per token,  1421.84 tokens per second)\n",
            "llama_print_timings: prompt eval time =     259.43 ms /    61 tokens (    4.25 ms per token,   235.13 tokens per second)\n",
            "llama_print_timings:        eval time =    1720.61 ms /    15 runs   (  114.71 ms per token,     8.72 tokens per second)\n",
            "llama_print_timings:       total time =    2298.38 ms /    76 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@debboamerik @TheGoddessDoor @JortsTheCat She once drove the leader of Saudi Arabia around in the royal Land Rover and scared the stuffing out of him because a)woman driving and b) she drove like a formula one driver.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.01 ms /    16 runs   (    0.56 ms per token,  1775.21 tokens per second)\n",
            "llama_print_timings: prompt eval time =     610.24 ms /    22 tokens (   27.74 ms per token,    36.05 tokens per second)\n",
            "llama_print_timings:        eval time =    1546.17 ms /    15 runs   (  103.08 ms per token,     9.70 tokens per second)\n",
            "llama_print_timings:       total time =    2269.67 ms /    37 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Just witnessed a woman driving on the highway while flossing her teeth with both hands\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.39 ms /    16 runs   (    0.59 ms per token,  1704.30 tokens per second)\n",
            "llama_print_timings: prompt eval time =     239.07 ms /    37 tokens (    6.46 ms per token,   154.77 tokens per second)\n",
            "llama_print_timings:        eval time =    1501.35 ms /    15 runs   (  100.09 ms per token,     9.99 tokens per second)\n",
            "llama_print_timings:       total time =    1919.31 ms /    52 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Woman driving rental car finds dead body in boot after pulling over to investigate strange smell https://t.co/PkmdCP9Urp\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.42 ms /    16 runs   (    0.59 ms per token,  1699.42 tokens per second)\n",
            "llama_print_timings: prompt eval time =     274.37 ms /    91 tokens (    3.02 ms per token,   331.67 tokens per second)\n",
            "llama_print_timings:        eval time =    1623.25 ms /    15 runs   (  108.22 ms per token,     9.24 tokens per second)\n",
            "llama_print_timings:       total time =    2167.06 ms /   106 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@AlHxymon @divneptune @jacklarsonok @Dunstglocke @DrewAfualo buying into that value/traditional bs... you are. that makes you a misogynist. somehow men's \"value\" increases but a woman's \"decreases\" for the same thing? really sit on that and think on it. genuinely.\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      12.75 ms /    16 runs   (    0.80 ms per token,  1254.51 tokens per second)\n",
            "llama_print_timings: prompt eval time =     298.39 ms /    94 tokens (    3.17 ms per token,   315.03 tokens per second)\n",
            "llama_print_timings:        eval time =    1812.87 ms /    15 runs   (  120.86 ms per token,     8.27 tokens per second)\n",
            "llama_print_timings:       total time =    2571.83 ms /   109 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Helen Reddy - I Am Woman (1971) https://t.co/AgoN9U47l1 via @YouTubeI think we need to get this classic song out again and SCREAM it in the faces of those who believe a woman is a second class citizen/incubator. WE ARE WOMEN, HEAR US ROAR!!!  Please share! We GOT THIS!\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.41 ms /    16 runs   (    0.59 ms per token,  1700.14 tokens per second)\n",
            "llama_print_timings: prompt eval time =     242.12 ms /    34 tokens (    7.12 ms per token,   140.43 tokens per second)\n",
            "llama_print_timings:        eval time =    1565.50 ms /    15 runs   (  104.37 ms per token,     9.58 tokens per second)\n",
            "llama_print_timings:       total time =    1975.95 ms /    49 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Woman Waste No Time Gettin Back In The Field Soon As I Pree The Single Vibes Cant Play With It 😂\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.05 ms /    16 runs   (    0.57 ms per token,  1768.15 tokens per second)\n",
            "llama_print_timings: prompt eval time =     249.38 ms /    33 tokens (    7.56 ms per token,   132.33 tokens per second)\n",
            "llama_print_timings:        eval time =    1560.51 ms /    15 runs   (  104.03 ms per token,     9.61 tokens per second)\n",
            "llama_print_timings:       total time =    1961.47 ms /    48 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@DunlapBrian5 @benshapiro Then what is a woman since you’re clearly a human biologist🤔\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.14 ms /    16 runs   (    0.57 ms per token,  1750.93 tokens per second)\n",
            "llama_print_timings: prompt eval time =     267.17 ms /    63 tokens (    4.24 ms per token,   235.80 tokens per second)\n",
            "llama_print_timings:        eval time =    1634.37 ms /    15 runs   (  108.96 ms per token,     9.18 tokens per second)\n",
            "llama_print_timings:       total time =    2105.79 ms /    78 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Have temporarily traded the teeny movie posters for a glitch stitch, and boy, it’s a young woman’s style; my eyes are killing me and I can’t count higher than four https://t.co/zA2eAes8c1\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.65 ms /    16 runs   (    0.60 ms per token,  1657.69 tokens per second)\n",
            "llama_print_timings: prompt eval time =     239.71 ms /    35 tokens (    6.85 ms per token,   146.01 tokens per second)\n",
            "llama_print_timings:        eval time =    1658.26 ms /    15 runs   (  110.55 ms per token,     9.05 tokens per second)\n",
            "llama_print_timings:       total time =    2070.75 ms /    50 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@GOP Not if you are a woman.   Then controlling the woman’s uterus is paramount.  Screw her freedom.\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.08 ms /    16 runs   (    0.63 ms per token,  1586.67 tokens per second)\n",
            "llama_print_timings: prompt eval time =     300.88 ms /    92 tokens (    3.27 ms per token,   305.77 tokens per second)\n",
            "llama_print_timings:        eval time =    1629.63 ms /    15 runs   (  108.64 ms per token,     9.20 tokens per second)\n",
            "llama_print_timings:       total time =    2345.08 ms /   107 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Zion McThomas is a grad student at Auburn University studying History, &amp; her research interests include Black femininity/masculinity, Black Queer Studies, womanism, &amp; womanist theology. She is also a rapper, poet, filmmaker, &amp; small business owner of Made You Think Clothing. https://t.co/7Hrlg9c7Zg\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.97 ms /    16 runs   (    0.56 ms per token,  1784.12 tokens per second)\n",
            "llama_print_timings: prompt eval time =     260.32 ms /    47 tokens (    5.54 ms per token,   180.55 tokens per second)\n",
            "llama_print_timings:        eval time =    1477.00 ms /    15 runs   (   98.47 ms per token,    10.16 tokens per second)\n",
            "llama_print_timings:       total time =    1910.96 ms /    62 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@emmafinlay78 @CarreAndi @womensmarch Cause it’s “feminism” not “trans womanism” the spoiler is in the name.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.31 ms /    16 runs   (    0.52 ms per token,  1924.93 tokens per second)\n",
            "llama_print_timings: prompt eval time =     638.04 ms /    26 tokens (   24.54 ms per token,    40.75 tokens per second)\n",
            "llama_print_timings:        eval time =    1501.81 ms /    15 runs   (  100.12 ms per token,     9.99 tokens per second)\n",
            "llama_print_timings:       total time =    2261.41 ms /    41 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "I've never seen a woman reject feminism/womanism that actually understood what it was about.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.83 ms /    16 runs   (    0.55 ms per token,  1813.03 tokens per second)\n",
            "llama_print_timings: prompt eval time =     234.82 ms /    33 tokens (    7.12 ms per token,   140.53 tokens per second)\n",
            "llama_print_timings:        eval time =    1574.63 ms /    15 runs   (  104.98 ms per token,     9.53 tokens per second)\n",
            "llama_print_timings:       total time =    1969.20 ms /    48 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "I never thought I’d be the one explaining womanism in a class filled with a bunch of woman, but hey first time for everything.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.88 ms /    16 runs   (    0.68 ms per token,  1470.45 tokens per second)\n",
            "llama_print_timings: prompt eval time =     267.91 ms /    61 tokens (    4.39 ms per token,   227.69 tokens per second)\n",
            "llama_print_timings:        eval time =    1703.09 ms /    15 runs   (  113.54 ms per token,     8.81 tokens per second)\n",
            "llama_print_timings:       total time =    2312.19 ms /    76 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Bl1v3smatt3r__ 💖💖💖💖💖💖💖☮️☮️🕊💔🦉have you found womanism it’s fascinating. I am sorry this is still happening.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.82 ms /    16 runs   (    0.55 ms per token,  1814.47 tokens per second)\n",
            "llama_print_timings: prompt eval time =     238.15 ms /    45 tokens (    5.29 ms per token,   188.96 tokens per second)\n",
            "llama_print_timings:        eval time =    1608.93 ms /    15 runs   (  107.26 ms per token,     9.32 tokens per second)\n",
            "llama_print_timings:       total time =    2024.14 ms /    60 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "I suggest you read Alice Walker among others and why the term womanism came into being and why it separated from feminism. https://t.co/4f83H8RnlX\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.13 ms /    16 runs   (    0.57 ms per token,  1751.89 tokens per second)\n",
            "llama_print_timings: prompt eval time =     246.55 ms /    45 tokens (    5.48 ms per token,   182.52 tokens per second)\n",
            "llama_print_timings:        eval time =    1570.30 ms /    15 runs   (  104.69 ms per token,     9.55 tokens per second)\n",
            "llama_print_timings:       total time =    1991.25 ms /    60 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@joncoopertweets Florida you can do this!! Florida Women are definitely going to give a shit this November: https://t.co/BhxWvpN8mJ\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.47 ms /    16 runs   (    0.59 ms per token,  1690.08 tokens per second)\n",
            "llama_print_timings: prompt eval time =     256.98 ms /    48 tokens (    5.35 ms per token,   186.78 tokens per second)\n",
            "llama_print_timings:        eval time =    1656.19 ms /    15 runs   (  110.41 ms per token,     9.06 tokens per second)\n",
            "llama_print_timings:       total time =    2096.60 ms /    63 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "We all dance now and then. Women are redefining what it is to be in government .Keep dancing @MarinSanna. https://t.co/4yD5atPw9s\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      12.61 ms /    16 runs   (    0.79 ms per token,  1269.24 tokens per second)\n",
            "llama_print_timings: prompt eval time =     265.95 ms /    72 tokens (    3.69 ms per token,   270.73 tokens per second)\n",
            "llama_print_timings:        eval time =    1800.52 ms /    15 runs   (  120.03 ms per token,     8.33 tokens per second)\n",
            "llama_print_timings:       total time =    2324.12 ms /    87 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@AlexPromiskuita 100%!! For any human ❤️ Others can be used to having a higher sex drive or more sexual energy during times of stress so reminding that we all fluctuate and women are especially known for coming off not interested in sex and men not understanding why but the stress is the why\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.36 ms /    16 runs   (    0.58 ms per token,  1709.40 tokens per second)\n",
            "llama_print_timings: prompt eval time =     289.26 ms /    70 tokens (    4.13 ms per token,   242.00 tokens per second)\n",
            "llama_print_timings:        eval time =    1654.33 ms /    15 runs   (  110.29 ms per token,     9.07 tokens per second)\n",
            "llama_print_timings:       total time =    2150.57 ms /    85 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@KeepBlazing85 You don't represent the Black community. You represent Black \"alpha males\" who believe Black women are tools. If your ego isn't sufficiently stroked, you'll gladly side with the GQP to help keep Black women \"in their place.\" Kindly kick rocks.\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.07 ms /    16 runs   (    0.57 ms per token,  1763.28 tokens per second)\n",
            "llama_print_timings: prompt eval time =     275.53 ms /    98 tokens (    2.81 ms per token,   355.68 tokens per second)\n",
            "llama_print_timings:        eval time =    1554.69 ms /    15 runs   (  103.65 ms per token,     9.65 tokens per second)\n",
            "llama_print_timings:       total time =    2100.49 ms /   113 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@miosugita @AlboMP @SenatorWong @dfat @abcnews @australian @dailytelegraph @newscomauHQ @9NewsAUS @SBSNewsKishida's Parliamentary Vice-Minister for Internal Affairs and Communications publicly denied gender equality and reportedly accused rape victims claiming that women are liars.#Resign https://t.co/bt4vfYFJeZ\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.00 ms /    16 runs   (    0.62 ms per token,  1600.16 tokens per second)\n",
            "llama_print_timings: prompt eval time =     267.87 ms /    69 tokens (    3.88 ms per token,   257.59 tokens per second)\n",
            "llama_print_timings:        eval time =    1483.05 ms /    15 runs   (   98.87 ms per token,    10.11 tokens per second)\n",
            "llama_print_timings:       total time =    1992.87 ms /    84 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@OofT74480205 @opinionated66 @CritFacts You want changes? What kind?Also interesting you say this considering how I pointed out that strength in men and women are primarily determined by hormones, and even that differences is small... Just saying.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.34 ms /    16 runs   (    0.65 ms per token,  1546.94 tokens per second)\n",
            "llama_print_timings: prompt eval time =     250.76 ms /    63 tokens (    3.98 ms per token,   251.23 tokens per second)\n",
            "llama_print_timings:        eval time =    1609.40 ms /    15 runs   (  107.29 ms per token,     9.32 tokens per second)\n",
            "llama_print_timings:       total time =    2078.70 ms /    78 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "They can have him in my book!! His false FREE Statements !! Free that women can't choose what happens to their own bodies!!! Teachers are NOT Free to even talk about their own spouses if they are ofthe same sex that is and Free to NOT learn Black History!\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      12.33 ms /    16 runs   (    0.77 ms per token,  1297.86 tokens per second)\n",
            "llama_print_timings: prompt eval time =     251.31 ms /    38 tokens (    6.61 ms per token,   151.21 tokens per second)\n",
            "llama_print_timings:        eval time =    1769.77 ms /    15 runs   (  117.98 ms per token,     8.48 tokens per second)\n",
            "llama_print_timings:       total time =    2261.24 ms /    53 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@CAKitchener @SusanSvrluga We can hit an asteroid 7 million miles away but women can’t have freedom at home.\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.60 ms /    16 runs   (    0.60 ms per token,  1666.67 tokens per second)\n",
            "llama_print_timings: prompt eval time =     271.41 ms /    68 tokens (    3.99 ms per token,   250.54 tokens per second)\n",
            "llama_print_timings:        eval time =    1476.25 ms /    15 runs   (   98.42 ms per token,    10.16 tokens per second)\n",
            "llama_print_timings:       total time =    1962.57 ms /    83 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@_wallfl0w4r @MrsWangLang They claim they don’t watch the show, but they’re active on social media so how come they’ve not seen the videos?? But someone was bold enough to sew thread that career women can’t be good wives and mothers!\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       2.93 ms /     5 runs   (    0.59 ms per token,  1709.40 tokens per second)\n",
            "llama_print_timings: prompt eval time =     278.31 ms /    87 tokens (    3.20 ms per token,   312.60 tokens per second)\n",
            "llama_print_timings:        eval time =     430.56 ms /     4 runs   (  107.64 ms per token,     9.29 tokens per second)\n",
            "llama_print_timings:       total time =     939.88 ms /    91 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@janeclarejones He's a disgust. Cruel, heartless, awww poor trans pretending to be women. Can't get their fetishes fed. They are NOT women @OwenJones84. They aren't lesbians, nor straight women. They are biological men. Yeah, let them erase women. Save their little feelings. Not happening.\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       2.02 ms /     3 runs   (    0.67 ms per token,  1486.62 tokens per second)\n",
            "llama_print_timings: prompt eval time =     269.46 ms /    96 tokens (    2.81 ms per token,   356.27 tokens per second)\n",
            "llama_print_timings:        eval time =     222.24 ms /     2 runs   (  111.12 ms per token,     9.00 tokens per second)\n",
            "llama_print_timings:       total time =     705.12 ms /    98 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Orcs2Elves @54greek @mofotrouble @NancyMAGAmonkey @gretchenwhitmer Care to tell me what horrible epidemic do we have today where that many women can't continue a pregnancy?  You can't. It's not about health. It's about not being responsible. You made an oopsie so you want to eliminate a baby. Sad.\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.57 ms /    16 runs   (    0.60 ms per token,  1671.54 tokens per second)\n",
            "llama_print_timings: prompt eval time =     258.02 ms /    79 tokens (    3.27 ms per token,   306.18 tokens per second)\n",
            "llama_print_timings:        eval time =    1676.19 ms /    15 runs   (  111.75 ms per token,     8.95 tokens per second)\n",
            "llama_print_timings:       total time =    2174.66 ms /    94 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "It's the whole \"If you have *any* skin in the game, you are biased and therefore untrustworthy\"Basically the same argument misogynistic men make about why women can't properly debate things like misogyny, bodily autonomy, etc. https://t.co/2djkhRLscC\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      13.71 ms /    16 runs   (    0.86 ms per token,  1167.12 tokens per second)\n",
            "llama_print_timings: prompt eval time =     267.03 ms /    76 tokens (    3.51 ms per token,   284.61 tokens per second)\n",
            "llama_print_timings:        eval time =    1800.71 ms /    15 runs   (  120.05 ms per token,     8.33 tokens per second)\n",
            "llama_print_timings:       total time =    2402.27 ms /    91 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "You don’t seem to get this. Women don’t have to get married. YOU made that choice &amp; apparently made a great choice with this 5th hubby. YOU can’t do better than Dud &amp; you know it. #losers https://t.co/eSCmY9AS6m\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.26 ms /    16 runs   (    0.58 ms per token,  1727.30 tokens per second)\n",
            "llama_print_timings: prompt eval time =     278.31 ms /    75 tokens (    3.71 ms per token,   269.49 tokens per second)\n",
            "llama_print_timings:        eval time =    1536.93 ms /    15 runs   (  102.46 ms per token,     9.76 tokens per second)\n",
            "llama_print_timings:       total time =    2036.79 ms /    90 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "These 2.5 miles are for Eliza, and for every woman who has been attacked or killed while daring to exist in her body in this world. God, give us a day where women don’t have to run with a weapon tucked discretely in their bra https://t.co/Jh1ujVWhxU\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.78 ms /    16 runs   (    0.61 ms per token,  1636.49 tokens per second)\n",
            "llama_print_timings: prompt eval time =     290.25 ms /   113 tokens (    2.57 ms per token,   389.32 tokens per second)\n",
            "llama_print_timings:        eval time =    1550.21 ms /    15 runs   (  103.35 ms per token,     9.68 tokens per second)\n",
            "llama_print_timings:       total time =    2139.26 ms /   128 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@aripari18 @WNYOpenSchools @SaintStNick @brocklyboy @Agent4Change75 @freyas_house Yes. “Feminine” has meaning &amp; there’s not a single definition that includes aggression. Is there a specific way to be a woman?  No. Women don’t have to conform to stereotypes to be women b/c the designation is predicated on material reality (which, by definition, excludes men.)\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.54 ms /    16 runs   (    0.53 ms per token,  1874.63 tokens per second)\n",
            "llama_print_timings: prompt eval time =     239.71 ms /    41 tokens (    5.85 ms per token,   171.04 tokens per second)\n",
            "llama_print_timings:        eval time =    1527.84 ms /    15 runs   (  101.86 ms per token,     9.82 tokens per second)\n",
            "llama_print_timings:       total time =    1933.95 ms /    56 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Wholesome women don’t have to proclaim how wholesome they are. They just are. https://t.co/sZ8OMiOJaT\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.23 ms /    16 runs   (    0.64 ms per token,  1563.26 tokens per second)\n",
            "llama_print_timings: prompt eval time =     258.21 ms /    74 tokens (    3.49 ms per token,   286.59 tokens per second)\n",
            "llama_print_timings:        eval time =    1672.85 ms /    15 runs   (  111.52 ms per token,     8.97 tokens per second)\n",
            "llama_print_timings:       total time =    2166.30 ms /    89 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@winnie4prez @DanimalDanial Well I do agree that it is a character flaw on their side but working is a solution in the sense that at least women don't have to constantly put themselves at their mercy for their basic needs which doesn't solve the problem but does sort of rescue women from in a way\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.99 ms /    16 runs   (    0.75 ms per token,  1334.11 tokens per second)\n",
            "llama_print_timings: prompt eval time =     302.13 ms /    84 tokens (    3.60 ms per token,   278.02 tokens per second)\n",
            "llama_print_timings:        eval time =    1583.77 ms /    15 runs   (  105.58 ms per token,     9.47 tokens per second)\n",
            "llama_print_timings:       total time =    2277.57 ms /    99 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@girlseesred @Scottish_Fella @ProblematicF3m @EffyMourning @SLXTH666 she literally is chemically a woman. estrogen. isn’t that hard of a concept. mind you, trans women don’t have to do shit to prove to ignorant assholes like you that they’re a woman.\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.86 ms /    16 runs   (    0.62 ms per token,  1622.39 tokens per second)\n",
            "llama_print_timings: prompt eval time =     254.20 ms /    65 tokens (    3.91 ms per token,   255.70 tokens per second)\n",
            "llama_print_timings:        eval time =    1432.78 ms /    15 runs   (   95.52 ms per token,    10.47 tokens per second)\n",
            "llama_print_timings:       total time =    1897.93 ms /    80 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Vox6111 @PranavvjIN @smyltr Well, there's is an always room for improvement. But here I can speak for women (don't know about men tho), wearing anything which you like isn't asking for \"it\"\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.40 ms /    16 runs   (    0.59 ms per token,  1702.49 tokens per second)\n",
            "llama_print_timings: prompt eval time =     264.23 ms /    77 tokens (    3.43 ms per token,   291.41 tokens per second)\n",
            "llama_print_timings:        eval time =    1459.12 ms /    15 runs   (   97.27 ms per token,    10.28 tokens per second)\n",
            "llama_print_timings:       total time =    1972.54 ms /    92 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@SenLummis Seditionist Lemming;“Proud”Women are equal how?Most young women don’t know or care how hard women have had to fight for what you call equal rights Do your homework, think before you tweet. You Dolt. https://t.co/9B8XKoWzvo\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.10 ms /    16 runs   (    0.57 ms per token,  1757.86 tokens per second)\n",
            "llama_print_timings: prompt eval time =     552.13 ms /    23 tokens (   24.01 ms per token,    41.66 tokens per second)\n",
            "llama_print_timings:        eval time =    1653.84 ms /    15 runs   (  110.26 ms per token,     9.07 tokens per second)\n",
            "llama_print_timings:       total time =    2322.06 ms /    38 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "What would we do in a world without powerful, hot women? Don’t know.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.85 ms /    16 runs   (    0.74 ms per token,  1350.10 tokens per second)\n",
            "llama_print_timings: prompt eval time =     271.03 ms /    73 tokens (    3.71 ms per token,   269.34 tokens per second)\n",
            "llama_print_timings:        eval time =    1801.04 ms /    15 runs   (  120.07 ms per token,     8.33 tokens per second)\n",
            "llama_print_timings:       total time =    2477.67 ms /    88 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@cisgenderhaver I would much rather have lived half my life without pockets, than live with dysphoria.Such a bizarre thing to get mad about. “Trans women don’t know the pain of dresses without pockets!” But like… they know lots of other pain that you didn’t have, so…\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.46 ms /    16 runs   (    0.59 ms per token,  1691.87 tokens per second)\n",
            "llama_print_timings: prompt eval time =     255.30 ms /    51 tokens (    5.01 ms per token,   199.76 tokens per second)\n",
            "llama_print_timings:        eval time =    1483.44 ms /    15 runs   (   98.90 ms per token,    10.11 tokens per second)\n",
            "llama_print_timings:       total time =    1931.55 ms /    66 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@FreeAgencyTV007 Alot of women don't know how to please themselves or their man... I think it's cool to hv a class to learn so they can be more confident in the bedroom...\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.86 ms /    16 runs   (    0.62 ms per token,  1622.88 tokens per second)\n",
            "llama_print_timings: prompt eval time =     259.20 ms /    68 tokens (    3.81 ms per token,   262.35 tokens per second)\n",
            "llama_print_timings:        eval time =    1550.52 ms /    15 runs   (  103.37 ms per token,     9.67 tokens per second)\n",
            "llama_print_timings:       total time =    2028.31 ms /    83 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "I've been stalked before &amp; receive far too many death threats. Working in LPM, I have the resources to fight, most women don't know how. Women need better support when stalking occurs. We need more funding for programs &amp; better police training to deal with it.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.72 ms /    16 runs   (    0.54 ms per token,  1835.49 tokens per second)\n",
            "llama_print_timings: prompt eval time =     236.32 ms /    36 tokens (    6.56 ms per token,   152.34 tokens per second)\n",
            "llama_print_timings:        eval time =    1491.53 ms /    15 runs   (   99.44 ms per token,    10.06 tokens per second)\n",
            "llama_print_timings:       total time =    1904.12 ms /    51 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Male 22 in Lahore today To meet any Girl or Women For Sex https://t.co/bLCwjXhaFA\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.13 ms /    16 runs   (    0.63 ms per token,  1578.84 tokens per second)\n",
            "llama_print_timings: prompt eval time =     250.48 ms /    40 tokens (    6.26 ms per token,   159.69 tokens per second)\n",
            "llama_print_timings:        eval time =    1697.08 ms /    15 runs   (  113.14 ms per token,     8.84 tokens per second)\n",
            "llama_print_timings:       total time =    2133.11 ms /    55 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@tcotPAC @jacksonhinklle So we have to wait for the law to catch up when he's admitted to grooming women for sex work?\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.34 ms /    16 runs   (    0.65 ms per token,  1547.39 tokens per second)\n",
            "llama_print_timings: prompt eval time =     262.05 ms /    43 tokens (    6.09 ms per token,   164.09 tokens per second)\n",
            "llama_print_timings:        eval time =    1596.23 ms /    15 runs   (  106.42 ms per token,     9.40 tokens per second)\n",
            "llama_print_timings:       total time =    2120.49 ms /    58 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Taking a woman on an expensive date with the expectation of sex in return is the same as paying women for sex. But guys don’t want to accept that 😶\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.09 ms /    16 runs   (    0.57 ms per token,  1759.40 tokens per second)\n",
            "llama_print_timings: prompt eval time =     238.99 ms /    42 tokens (    5.69 ms per token,   175.74 tokens per second)\n",
            "llama_print_timings:        eval time =    1615.98 ms /    15 runs   (  107.73 ms per token,     9.28 tokens per second)\n",
            "llama_print_timings:       total time =    2033.20 ms /    57 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "didnt he say he doesn't speak to his sister cos ur only meant to speak to women for sex?? https://t.co/1OpY0sImbG\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.62 ms /    16 runs   (    0.60 ms per token,  1663.37 tokens per second)\n",
            "llama_print_timings: prompt eval time =     272.43 ms /    84 tokens (    3.24 ms per token,   308.33 tokens per second)\n",
            "llama_print_timings:        eval time =    1527.38 ms /    15 runs   (  101.83 ms per token,     9.82 tokens per second)\n",
            "llama_print_timings:       total time =    2047.49 ms /    99 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Muslims/ Islamists targeting non muslim women for sex/ baby Jehad isn't limited to few countries but it's a global phenomena. From Denmark to Nigeria, Egypt to UK is happening everywhere. In northern Nigeria Christian girls are abducted, forcefully converted and used to breed. https://t.co/K9Q4I1ntbR\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.80 ms /    16 runs   (    0.55 ms per token,  1817.15 tokens per second)\n",
            "llama_print_timings: prompt eval time =     743.50 ms /    29 tokens (   25.64 ms per token,    39.00 tokens per second)\n",
            "llama_print_timings:        eval time =    1511.50 ms /    15 runs   (  100.77 ms per token,     9.92 tokens per second)\n",
            "llama_print_timings:       total time =    2385.89 ms /    44 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "She genuinely believes we only pursue women for sex and thats just sad man. If its from personal experience its really really sad\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      12.36 ms /    16 runs   (    0.77 ms per token,  1294.39 tokens per second)\n",
            "llama_print_timings: prompt eval time =     298.38 ms /   107 tokens (    2.79 ms per token,   358.60 tokens per second)\n",
            "llama_print_timings:        eval time =    1659.48 ms /    15 runs   (  110.63 ms per token,     9.04 tokens per second)\n",
            "llama_print_timings:       total time =    2470.80 ms /   122 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@CriquittWalter2 @TexasFBA4Ever @tariqnasheed @TaureanReign @BLKLiberation84 He’s 23 years old he’s probably never experienced anything like that before…his chest was rising up and down really fast which leads me to believe he was scared. Truly sad that some of our young men and women have to deal with this when they’re only trying to make a living.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.18 ms /    16 runs   (    0.57 ms per token,  1742.35 tokens per second)\n",
            "llama_print_timings: prompt eval time =     255.50 ms /    46 tokens (    5.55 ms per token,   180.04 tokens per second)\n",
            "llama_print_timings:        eval time =    1517.96 ms /    15 runs   (  101.20 ms per token,     9.88 tokens per second)\n",
            "llama_print_timings:       total time =    1959.23 ms /    61 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@CleverSwag21 @SundaeDivine Consider the times you are in and the continued fight women have to gain respect, hold onto their rights and compete in a man's world.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.90 ms /    16 runs   (    0.62 ms per token,  1616.00 tokens per second)\n",
            "llama_print_timings: prompt eval time =     244.91 ms /    59 tokens (    4.15 ms per token,   240.91 tokens per second)\n",
            "llama_print_timings:        eval time =    1487.24 ms /    15 runs   (   99.15 ms per token,    10.09 tokens per second)\n",
            "llama_print_timings:       total time =    1940.69 ms /    74 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@WiartonGma @BrandonNbminc @RexChapman Men should be just as concerned about birth control as women have to be. Wait, is the SCOTUS considering eliminating birth control? Like we need more people?\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.13 ms /    16 runs   (    0.57 ms per token,  1752.85 tokens per second)\n",
            "llama_print_timings: prompt eval time =     258.10 ms /    45 tokens (    5.74 ms per token,   174.35 tokens per second)\n",
            "llama_print_timings:        eval time =    1515.58 ms /    15 runs   (  101.04 ms per token,     9.90 tokens per second)\n",
            "llama_print_timings:       total time =    1948.08 ms /    60 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@iamunsolicited @perfectcows @mikeofficial Fine, then women have to work 9 days straight no break, it's what's best for their cycle after all\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.75 ms /    16 runs   (    0.67 ms per token,  1488.23 tokens per second)\n",
            "llama_print_timings: prompt eval time =     245.77 ms /    59 tokens (    4.17 ms per token,   240.06 tokens per second)\n",
            "llama_print_timings:        eval time =    1828.17 ms /    15 runs   (  121.88 ms per token,     8.20 tokens per second)\n",
            "llama_print_timings:       total time =    2305.77 ms /    74 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "I mean men do it, why can’t we? Why should women have to wear something uncomfortable to adjust to your needs? https://t.co/GsxZSG0IQQ https://t.co/FehJgbpAcB\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.06 ms /    16 runs   (    0.57 ms per token,  1765.23 tokens per second)\n",
            "llama_print_timings: prompt eval time =     769.44 ms /    30 tokens (   25.65 ms per token,    38.99 tokens per second)\n",
            "llama_print_timings:        eval time =    1478.21 ms /    15 runs   (   98.55 ms per token,    10.15 tokens per second)\n",
            "llama_print_timings:       total time =    2379.39 ms /    45 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Do all women have to give their car a name? Peggy or some shit. It’s a fucking car mate.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.10 ms /    16 runs   (    0.57 ms per token,  1757.47 tokens per second)\n",
            "llama_print_timings: prompt eval time =     244.80 ms /    47 tokens (    5.21 ms per token,   192.00 tokens per second)\n",
            "llama_print_timings:        eval time =    1552.30 ms /    15 runs   (  103.49 ms per token,     9.66 tokens per second)\n",
            "llama_print_timings:       total time =    1985.95 ms /    62 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "I’m a traditional man women shouldn’t do either they should lightly sip wine with very low alcohol contents everything else is masculine. https://t.co/0L9OiNRPoM\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.81 ms /    16 runs   (    0.55 ms per token,  1815.50 tokens per second)\n",
            "llama_print_timings: prompt eval time =     238.24 ms /    38 tokens (    6.27 ms per token,   159.50 tokens per second)\n",
            "llama_print_timings:        eval time =    1647.44 ms /    15 runs   (  109.83 ms per token,     9.11 tokens per second)\n",
            "llama_print_timings:       total time =    2052.67 ms /    53 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@good_vibes_girl A healthy debate is enjoyable, unapologetic women shouldn't make a guy intimidated. They're role models\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       3.07 ms /     5 runs   (    0.61 ms per token,  1628.13 tokens per second)\n",
            "llama_print_timings: prompt eval time =     292.23 ms /   101 tokens (    2.89 ms per token,   345.62 tokens per second)\n",
            "llama_print_timings:        eval time =     390.20 ms /     4 runs   (   97.55 ms per token,    10.25 tokens per second)\n",
            "llama_print_timings:       total time =     934.19 ms /   105 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@rebzeleanor I've been at away games where he's chanted \"we'll shag all your birds\" (rapey much?) and \"PFC s a geezer's club\" (Oh no it fucking isn't!). He needs to fucking grow up. He also keeps going on that women shouldn't go to games. I've been going for 30 years and bought a share. 🖕\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      12.35 ms /    16 runs   (    0.77 ms per token,  1295.86 tokens per second)\n",
            "llama_print_timings: prompt eval time =     248.16 ms /    56 tokens (    4.43 ms per token,   225.66 tokens per second)\n",
            "llama_print_timings:        eval time =    1776.82 ms /    15 runs   (  118.45 ms per token,     8.44 tokens per second)\n",
            "llama_print_timings:       total time =    2356.90 ms /    71 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@jillmcma045 @thegradmedic @DrGailBusby What sort of harrassment are women receiving? And are you suggesting that vocal women shouldn’t expect responses or should be responded to differently from vocal men?\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.39 ms /    16 runs   (    0.52 ms per token,  1906.35 tokens per second)\n",
            "llama_print_timings: prompt eval time =     775.71 ms /    29 tokens (   26.75 ms per token,    37.39 tokens per second)\n",
            "llama_print_timings:        eval time =    1526.13 ms /    15 runs   (  101.74 ms per token,     9.83 tokens per second)\n",
            "llama_print_timings:       total time =    2439.63 ms /    44 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Beth2point0_ @RepMTG Liberal women shouldn't reproduce.  That's for sure.\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.16 ms /    16 runs   (    0.57 ms per token,  1746.53 tokens per second)\n",
            "llama_print_timings: prompt eval time =     238.03 ms /    48 tokens (    4.96 ms per token,   201.65 tokens per second)\n",
            "llama_print_timings:        eval time =    1630.91 ms /    15 runs   (  108.73 ms per token,     9.20 tokens per second)\n",
            "llama_print_timings:       total time =    2063.18 ms /    63 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@ElleSweetest @HOT97 🧢Grown men don’t talk about people’s daughters. Grown women shouldn’t support grown men acting like females for attention.\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.15 ms /    16 runs   (    0.57 ms per token,  1748.83 tokens per second)\n",
            "llama_print_timings: prompt eval time =     243.16 ms /    43 tokens (    5.65 ms per token,   176.84 tokens per second)\n",
            "llama_print_timings:        eval time =    1576.31 ms /    15 runs   (  105.09 ms per token,     9.52 tokens per second)\n",
            "llama_print_timings:       total time =    2022.99 ms /    58 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Salinger and Polanski are the same kinda guy, same critical acclaim and same taste in \"women\". https://t.co/lPWFoanV5B\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      13.80 ms /    16 runs   (    0.86 ms per token,  1159.42 tokens per second)\n",
            "llama_print_timings: prompt eval time =     276.05 ms /    80 tokens (    3.45 ms per token,   289.80 tokens per second)\n",
            "llama_print_timings:        eval time =    1694.78 ms /    15 runs   (  112.99 ms per token,     8.85 tokens per second)\n",
            "llama_print_timings:       total time =    2236.79 ms /    95 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@stevek3384 @D4VE_UK @Dexerto Tate has said rape is women's fault, he's said women are mens property, that its ok to hit your women, etcAlso randomly encouraged men to slap and rape women that annoy them Idk dude ain't a good or sane person.\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.97 ms /    16 runs   (    0.62 ms per token,  1604.33 tokens per second)\n",
            "llama_print_timings: prompt eval time =     282.76 ms /    66 tokens (    4.28 ms per token,   233.41 tokens per second)\n",
            "llama_print_timings:        eval time =    1467.23 ms /    15 runs   (   97.82 ms per token,    10.22 tokens per second)\n",
            "llama_print_timings:       total time =    2063.43 ms /    81 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Women in #Tehran wave hijabs in air in protest against the custodial death of Mahsa Amini over \"improper hijab\".#مهسا_امینی https://t.co/d47rEwAZIq\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.57 ms /    16 runs   (    0.60 ms per token,  1672.07 tokens per second)\n",
            "llama_print_timings: prompt eval time =     244.67 ms /    48 tokens (    5.10 ms per token,   196.18 tokens per second)\n",
            "llama_print_timings:        eval time =    1556.67 ms /    15 runs   (  103.78 ms per token,     9.64 tokens per second)\n",
            "llama_print_timings:       total time =    1992.32 ms /    63 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "especially when they are pierced, never catch me in a bra. i’m convinced bras were made by men just to make women uncomfortable. https://t.co/P2v3SvCCx7\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.92 ms /    16 runs   (    0.56 ms per token,  1793.32 tokens per second)\n",
            "llama_print_timings: prompt eval time =     740.67 ms /    29 tokens (   25.54 ms per token,    39.15 tokens per second)\n",
            "llama_print_timings:        eval time =    1576.66 ms /    15 runs   (  105.11 ms per token,     9.51 tokens per second)\n",
            "llama_print_timings:       total time =    2444.33 ms /    44 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "A lot of celebs have been getting aggressive ass tans lately… my TL is full of additional black women 😍\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.11 ms /    16 runs   (    0.57 ms per token,  1755.54 tokens per second)\n",
            "llama_print_timings: prompt eval time =     240.35 ms /    48 tokens (    5.01 ms per token,   199.71 tokens per second)\n",
            "llama_print_timings:        eval time =    1509.44 ms /    15 runs   (  100.63 ms per token,     9.94 tokens per second)\n",
            "llama_print_timings:       total time =    1956.25 ms /    63 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@freshwaterpurl @1ezilyamuzed @scrowder A saying I heard as a girl..\"Men are afraid women will laugh at them. Women are afraid men will kill them.\"\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      12.83 ms /    16 runs   (    0.80 ms per token,  1246.98 tokens per second)\n",
            "llama_print_timings: prompt eval time =     295.37 ms /    82 tokens (    3.60 ms per token,   277.62 tokens per second)\n",
            "llama_print_timings:        eval time =    1647.44 ms /    15 runs   (  109.83 ms per token,     9.11 tokens per second)\n",
            "llama_print_timings:       total time =    2348.42 ms /    97 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@PeterLakeMi550 @Wild_Womyn @stellduffy I don’t want to upset anyone unnecessarily. I want the Asian women I used to represent in domestic violence proceedings to be able to use refuges. And a trans woman getting health care is male: messaging about screening and risk needs to be worded simply\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.68 ms /    16 runs   (    0.61 ms per token,  1652.72 tokens per second)\n",
            "llama_print_timings: prompt eval time =     275.10 ms /    82 tokens (    3.35 ms per token,   298.07 tokens per second)\n",
            "llama_print_timings:        eval time =    1677.43 ms /    15 runs   (  111.83 ms per token,     8.94 tokens per second)\n",
            "llama_print_timings:       total time =    2216.43 ms /    97 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "GC make great arguments like \"Wat if a man wants to trick us to thinking he is a womyn &amp; goes on E for 3 years, lives undercover as a secret spy pretending to be Margaret from Basingstoke Bingo Hall, has several surgeries, wins a gold medal at the olympics &amp; then detransitions?\"\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.71 ms /    16 runs   (    0.54 ms per token,  1838.02 tokens per second)\n",
            "llama_print_timings: prompt eval time =     240.17 ms /    41 tokens (    5.86 ms per token,   170.71 tokens per second)\n",
            "llama_print_timings:        eval time =    1553.56 ms /    15 runs   (  103.57 ms per token,     9.66 tokens per second)\n",
            "llama_print_timings:       total time =    1971.77 ms /    56 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Wild_Womyn So interesting that this is Germany. But they write in English.Well done English-speaking people for clearly upsetting violent male cultists.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.38 ms /    16 runs   (    0.59 ms per token,  1706.67 tokens per second)\n",
            "llama_print_timings: prompt eval time =     235.58 ms /    35 tokens (    6.73 ms per token,   148.57 tokens per second)\n",
            "llama_print_timings:        eval time =    1511.00 ms /    15 runs   (  100.73 ms per token,     9.93 tokens per second)\n",
            "llama_print_timings:       total time =    1916.67 ms /    50 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Wild_Womyn @EXXBACKUP @sussex_police He's reminding us who holds all the power here. Men in frocks.\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.10 ms /    16 runs   (    0.69 ms per token,  1441.83 tokens per second)\n",
            "llama_print_timings: prompt eval time =     256.97 ms /    50 tokens (    5.14 ms per token,   194.58 tokens per second)\n",
            "llama_print_timings:        eval time =    1770.35 ms /    15 runs   (  118.02 ms per token,     8.47 tokens per second)\n",
            "llama_print_timings:       total time =    2347.57 ms /    65 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@feline_charm @jk_rowling @Wild_Womyn @TheFamousArtBR @bindelj Both are divine but Northern Tayto onion rings are to die for 🤣🤣🤣\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.85 ms /    16 runs   (    0.55 ms per token,  1807.30 tokens per second)\n",
            "llama_print_timings: prompt eval time =     704.01 ms /    28 tokens (   25.14 ms per token,    39.77 tokens per second)\n",
            "llama_print_timings:        eval time =    1451.28 ms /    15 runs   (   96.75 ms per token,    10.34 tokens per second)\n",
            "llama_print_timings:       total time =    2278.13 ms /    43 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@NationSilico's account is temporarily unavailable because it violates the Twitter Media Policy. Learn more.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.21 ms /    16 runs   (    0.58 ms per token,  1736.30 tokens per second)\n",
            "llama_print_timings: prompt eval time =     235.11 ms /    42 tokens (    5.60 ms per token,   178.64 tokens per second)\n",
            "llama_print_timings:        eval time =    1511.59 ms /    15 runs   (  100.77 ms per token,     9.92 tokens per second)\n",
            "llama_print_timings:       total time =    1929.75 ms /    57 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Artosis @BlizzardCS @StarCraft I think if we all yell \"HELP BLIZZARD\" out of our collective windows it'll help more.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.65 ms /    16 runs   (    0.54 ms per token,  1849.28 tokens per second)\n",
            "llama_print_timings: prompt eval time =     588.11 ms /    24 tokens (   24.50 ms per token,    40.81 tokens per second)\n",
            "llama_print_timings:        eval time =    1481.63 ms /    15 runs   (   98.78 ms per token,    10.12 tokens per second)\n",
            "llama_print_timings:       total time =    2188.28 ms /    39 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "usually when i lose in a game i cuss or yell but moaning works ig\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.81 ms /    16 runs   (    0.61 ms per token,  1630.49 tokens per second)\n",
            "llama_print_timings: prompt eval time =     237.90 ms /    39 tokens (    6.10 ms per token,   163.94 tokens per second)\n",
            "llama_print_timings:        eval time =    1822.35 ms /    15 runs   (  121.49 ms per token,     8.23 tokens per second)\n",
            "llama_print_timings:       total time =    2246.67 ms /    54 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@eraxkeys it does! meaning Sal did too much. I was so confused how we went from the mall to hearing her yell about coffee 😂😂\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.35 ms /    16 runs   (    0.58 ms per token,  1710.68 tokens per second)\n",
            "llama_print_timings: prompt eval time =     824.92 ms /    25 tokens (   33.00 ms per token,    30.31 tokens per second)\n",
            "llama_print_timings:        eval time =    1562.24 ms /    15 runs   (  104.15 ms per token,     9.60 tokens per second)\n",
            "llama_print_timings:       total time =    2549.71 ms /    40 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "I can be in the wrong while driving and still yell at the other car, idc .\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.73 ms /    16 runs   (    0.55 ms per token,  1831.71 tokens per second)\n",
            "llama_print_timings: prompt eval time =     770.53 ms /    31 tokens (   24.86 ms per token,    40.23 tokens per second)\n",
            "llama_print_timings:        eval time =    1511.17 ms /    15 runs   (  100.74 ms per token,     9.93 tokens per second)\n",
            "llama_print_timings:       total time =    2410.47 ms /    46 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@SalemsCellar for christ's sakes south park you liked that movie im gonna go to the park and yell\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.92 ms /    16 runs   (    0.62 ms per token,  1612.90 tokens per second)\n",
            "llama_print_timings: prompt eval time =     247.88 ms /    56 tokens (    4.43 ms per token,   225.92 tokens per second)\n",
            "llama_print_timings:        eval time =    1619.68 ms /    15 runs   (  107.98 ms per token,     9.26 tokens per second)\n",
            "llama_print_timings:       total time =    2079.37 ms /    71 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@BuxtonPDX @packers @Saints He plays through the whistle and with attitude. Teammates will yell you he's not dirty. But please, feel free to continue regurgitating popular national narrative on the player.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.83 ms /    16 runs   (    0.61 ms per token,  1627.01 tokens per second)\n",
            "llama_print_timings: prompt eval time =     651.53 ms /    25 tokens (   26.06 ms per token,    38.37 tokens per second)\n",
            "llama_print_timings:        eval time =    1553.79 ms /    15 runs   (  103.59 ms per token,     9.65 tokens per second)\n",
            "llama_print_timings:       total time =    2339.46 ms /    40 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@JoshuaPotash What are you in the world without Twitter? You look like a bitch\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.04 ms /    16 runs   (    0.56 ms per token,  1770.11 tokens per second)\n",
            "llama_print_timings: prompt eval time =     815.67 ms /    28 tokens (   29.13 ms per token,    34.33 tokens per second)\n",
            "llama_print_timings:        eval time =    1577.61 ms /    15 runs   (  105.17 ms per token,     9.51 tokens per second)\n",
            "llama_print_timings:       total time =    2570.88 ms /    43 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Stop crying Duncan you look like a bitch. https://t.co/BhAVn2yap3\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.20 ms /    16 runs   (    0.64 ms per token,  1568.78 tokens per second)\n",
            "llama_print_timings: prompt eval time =     264.71 ms /    69 tokens (    3.84 ms per token,   260.66 tokens per second)\n",
            "llama_print_timings:        eval time =    1428.23 ms /    15 runs   (   95.22 ms per token,    10.50 tokens per second)\n",
            "llama_print_timings:       total time =    1915.83 ms /    84 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "I do not understand how I am blocked by random ass accounts that I have never interacted with, among others.Also, why not just muting someone? A full block is pretty conspicuous should you cross the blocked persons feed as a QRT or something. Makes you look like a bitch.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.52 ms /    16 runs   (    0.60 ms per token,  1680.14 tokens per second)\n",
            "llama_print_timings: prompt eval time =     273.53 ms /    99 tokens (    2.76 ms per token,   361.94 tokens per second)\n",
            "llama_print_timings:        eval time =    1605.42 ms /    15 runs   (  107.03 ms per token,     9.34 tokens per second)\n",
            "llama_print_timings:       total time =    2145.11 ms /   114 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@On2em_ @Senoras_hombre7 @Saints @NFL @chrisolave_ @OhioStateFB so 2pac look like a female cuz he got piercing make some sense bro it’s like saying you look like a bitch for having tats on your skin… that forehead really got no sense in it bruh… ugly ass who tf shouts themselves out in tweeter 😭😭😭\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.52 ms /    16 runs   (    0.59 ms per token,  1681.20 tokens per second)\n",
            "llama_print_timings: prompt eval time =     494.03 ms /    20 tokens (   24.70 ms per token,    40.48 tokens per second)\n",
            "llama_print_timings:        eval time =    1487.31 ms /    15 runs   (   99.15 ms per token,    10.09 tokens per second)\n",
            "llama_print_timings:       total time =    2092.92 ms /    35 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@RonFilipkowski Yes, you look like a bitch dog.\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.05 ms /    16 runs   (    0.69 ms per token,  1447.83 tokens per second)\n",
            "llama_print_timings: prompt eval time =     270.47 ms /    79 tokens (    3.42 ms per token,   292.08 tokens per second)\n",
            "llama_print_timings:        eval time =    1788.91 ms /    15 runs   (  119.26 ms per token,     8.39 tokens per second)\n",
            "llama_print_timings:       total time =    2433.63 ms /    94 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Jomboy_ Y’all don’t realize how scary it is as the umpire to have a catcher set up that far off the plate. You are completely exposed with the pitcher throwing the ball directly at you and hoping some random 12 year old gets his glove on it lol. And if you flinch you look like a bitch\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.98 ms /    16 runs   (    0.56 ms per token,  1781.74 tokens per second)\n",
            "llama_print_timings: prompt eval time =     248.81 ms /    45 tokens (    5.53 ms per token,   180.86 tokens per second)\n",
            "llama_print_timings:        eval time =    1628.98 ms /    15 runs   (  108.60 ms per token,     9.21 tokens per second)\n",
            "llama_print_timings:       total time =    2048.49 ms /    60 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Mike1878_ @thfcmxtt @NoContextBrits Passive aggressive questions don't make you smart. They just make you look like a cunt.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.66 ms /    16 runs   (    0.54 ms per token,  1846.94 tokens per second)\n",
            "llama_print_timings: prompt eval time =     244.09 ms /    42 tokens (    5.81 ms per token,   172.07 tokens per second)\n",
            "llama_print_timings:        eval time =    1600.13 ms /    15 runs   (  106.68 ms per token,     9.37 tokens per second)\n",
            "llama_print_timings:       total time =    2019.85 ms /    57 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@SteveHofstetter Just checked out your twitter  account. You look like a cunt. I'd say he has a set. you don't.\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.36 ms /    16 runs   (    0.58 ms per token,  1709.95 tokens per second)\n",
            "llama_print_timings: prompt eval time =     258.45 ms /    62 tokens (    4.17 ms per token,   239.89 tokens per second)\n",
            "llama_print_timings:        eval time =    1608.98 ms /    15 runs   (  107.27 ms per token,     9.32 tokens per second)\n",
            "llama_print_timings:       total time =    2088.94 ms /    77 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@kathrynford3 @ConcernedDocMD @AddieShepherd19 @CBSNews As an autistic person myself, the two are not related. Don’t try to stigmatise either group. You look like a cunt.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.71 ms /    16 runs   (    0.73 ms per token,  1366.12 tokens per second)\n",
            "llama_print_timings: prompt eval time =     255.08 ms /    52 tokens (    4.91 ms per token,   203.86 tokens per second)\n",
            "llama_print_timings:        eval time =    1807.49 ms /    15 runs   (  120.50 ms per token,     8.30 tokens per second)\n",
            "llama_print_timings:       total time =    2365.88 ms /    67 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@DuncanHolley @craigthesaint Also, on a separate note, when you correct peoples spelling on twitter, it doesn’t make you look intelligent, it makes you look like a cunt!\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.22 ms /    16 runs   (    0.58 ms per token,  1736.11 tokens per second)\n",
            "llama_print_timings: prompt eval time =     613.47 ms /    24 tokens (   25.56 ms per token,    39.12 tokens per second)\n",
            "llama_print_timings:        eval time =    1474.20 ms /    15 runs   (   98.28 ms per token,    10.18 tokens per second)\n",
            "llama_print_timings:       total time =    2208.45 ms /    39 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@markgoldbridge Your Tweets make you look like a Cunt 😂😂😂😂\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.50 ms /    16 runs   (    0.59 ms per token,  1685.10 tokens per second)\n",
            "llama_print_timings: prompt eval time =     241.94 ms /    46 tokens (    5.26 ms per token,   190.13 tokens per second)\n",
            "llama_print_timings:        eval time =    1470.00 ms /    15 runs   (   98.00 ms per token,    10.20 tokens per second)\n",
            "llama_print_timings:       total time =    1917.39 ms /    61 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@dandefi_wallet @RizerSamantha “Yours looks ouchie” the hell are you talking like a baby, grown ass man smh you look like a cunt though\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.61 ms /    16 runs   (    0.54 ms per token,  1857.87 tokens per second)\n",
            "llama_print_timings: prompt eval time =     237.03 ms /    33 tokens (    7.18 ms per token,   139.22 tokens per second)\n",
            "llama_print_timings:        eval time =    1568.16 ms /    15 runs   (  104.54 ms per token,     9.57 tokens per second)\n",
            "llama_print_timings:       total time =    1962.70 ms /    48 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Y’all males are just anything stop asking to give head like it makes you look like a prostitute get out my dms for real\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.04 ms /    16 runs   (    0.63 ms per token,  1594.10 tokens per second)\n",
            "llama_print_timings: prompt eval time =     637.69 ms /    26 tokens (   24.53 ms per token,    40.77 tokens per second)\n",
            "llama_print_timings:        eval time =    1703.43 ms /    15 runs   (  113.56 ms per token,     8.81 tokens per second)\n",
            "llama_print_timings:       total time =    2483.43 ms /    41 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Lingerie to the club stop, You don't look sexy you look like a prostitute.\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.02 ms /    16 runs   (    0.63 ms per token,  1596.17 tokens per second)\n",
            "llama_print_timings: prompt eval time =     263.65 ms /    46 tokens (    5.73 ms per token,   174.47 tokens per second)\n",
            "llama_print_timings:        eval time =    1638.74 ms /    15 runs   (  109.25 ms per token,     9.15 tokens per second)\n",
            "llama_print_timings:       total time =    2151.54 ms /    61 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@TrumpsTheMan45 @sturmg44 @nypost Also you really shouldn't wear makeup and that dress you have in your pfp as you look like a prostitute\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.61 ms /    16 runs   (    0.60 ms per token,  1665.28 tokens per second)\n",
            "llama_print_timings: prompt eval time =     273.24 ms /    69 tokens (    3.96 ms per token,   252.53 tokens per second)\n",
            "llama_print_timings:        eval time =    1654.74 ms /    15 runs   (  110.32 ms per token,     9.06 tokens per second)\n",
            "llama_print_timings:       total time =    2142.47 ms /    84 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@FejFCB How they wan please these people bikonu. Smashing body is a fat bank account but when men approach u for sex in exchange for money, u call them dogs, perverts and ask if you look like a prostitute but ur statement says otherwise 🙄 Confused people 😏\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.87 ms /    16 runs   (    0.55 ms per token,  1804.04 tokens per second)\n",
            "llama_print_timings: prompt eval time =     781.02 ms /    30 tokens (   26.03 ms per token,    38.41 tokens per second)\n",
            "llama_print_timings:        eval time =    1605.94 ms /    15 runs   (  107.06 ms per token,     9.34 tokens per second)\n",
            "llama_print_timings:       total time =    2528.37 ms /    45 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "You look like a prostitute for wizards 💀 like my third time through new girl and I’m still dying\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.90 ms /    16 runs   (    0.62 ms per token,  1616.81 tokens per second)\n",
            "llama_print_timings: prompt eval time =     244.04 ms /    45 tokens (    5.42 ms per token,   184.39 tokens per second)\n",
            "llama_print_timings:        eval time =    1726.91 ms /    15 runs   (  115.13 ms per token,     8.69 tokens per second)\n",
            "llama_print_timings:       total time =    2160.31 ms /    60 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@ALirezaKHajepo1 @ShinKenRallis @maux_te @uamemesforces you look like a prostitute of Russian assassins\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.21 ms /    16 runs   (    0.64 ms per token,  1567.24 tokens per second)\n",
            "llama_print_timings: prompt eval time =     711.94 ms /    22 tokens (   32.36 ms per token,    30.90 tokens per second)\n",
            "llama_print_timings:        eval time =    1627.90 ms /    15 runs   (  108.53 ms per token,     9.21 tokens per second)\n",
            "llama_print_timings:       total time =    2512.34 ms /    37 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@notmarcelines you look like a whore (in the best way possible)\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.79 ms /    16 runs   (    0.55 ms per token,  1819.84 tokens per second)\n",
            "llama_print_timings: prompt eval time =     246.85 ms /    36 tokens (    6.86 ms per token,   145.84 tokens per second)\n",
            "llama_print_timings:        eval time =    1440.94 ms /    15 runs   (   96.06 ms per token,    10.41 tokens per second)\n",
            "llama_print_timings:       total time =    1850.73 ms /    51 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@AllyMae99 This straight up sounds like “you look like a WHORE!!! Collab with me!!! &gt;:((“\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.78 ms /    16 runs   (    0.55 ms per token,  1823.36 tokens per second)\n",
            "llama_print_timings: prompt eval time =     241.40 ms /    43 tokens (    5.61 ms per token,   178.13 tokens per second)\n",
            "llama_print_timings:        eval time =    1513.58 ms /    15 runs   (  100.91 ms per token,     9.91 tokens per second)\n",
            "llama_print_timings:       total time =    1934.28 ms /    58 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Nathaniel is trying to help me with a new fake club name &amp; he says “hmm what do you look like” “you look like a whore”😭😂\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.48 ms /    16 runs   (    0.59 ms per token,  1687.59 tokens per second)\n",
            "llama_print_timings: prompt eval time =     248.65 ms /    64 tokens (    3.89 ms per token,   257.39 tokens per second)\n",
            "llama_print_timings:        eval time =    1480.26 ms /    15 runs   (   98.68 ms per token,    10.13 tokens per second)\n",
            "llama_print_timings:       total time =    1943.93 ms /    79 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "walkin back from the gym &amp; an older lady shouts to me from her car \"you look like a whore!\" - tell me why my natural reaction was to shout back \"aw thanks!\" 😂😂 https://t.co/PoEcMN6ka3\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.51 ms /    16 runs   (    0.72 ms per token,  1390.34 tokens per second)\n",
            "llama_print_timings: prompt eval time =     245.59 ms /    41 tokens (    5.99 ms per token,   166.95 tokens per second)\n",
            "llama_print_timings:        eval time =    1892.42 ms /    15 runs   (  126.16 ms per token,     7.93 tokens per second)\n",
            "llama_print_timings:       total time =    2359.22 ms /    56 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "You look like a whore of Babylon bc that’s the only requirement for church drummer https://t.co/YbvZV43pMb\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.70 ms /    16 runs   (    0.54 ms per token,  1838.24 tokens per second)\n",
            "llama_print_timings: prompt eval time =     805.52 ms /    30 tokens (   26.85 ms per token,    37.24 tokens per second)\n",
            "llama_print_timings:        eval time =    1501.27 ms /    15 runs   (  100.08 ms per token,     9.99 tokens per second)\n",
            "llama_print_timings:       total time =    2436.93 ms /    45 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@BellaLove823 @lolaoflucia You look like a whore. Stop projecting!\n",
            "[/INST]\n",
            "YES\n"
          ]
        }
      ],
      "source": [
        "replies_list = ['YES','NO']\n",
        "counter = 0\n",
        "\n",
        "# List to store the results.\n",
        "json_result_run1 = []\n",
        "\n",
        "# simple JSON loading\n",
        "with open(test_path, 'r') as istr:\n",
        "    test_json = json.load(istr)\n",
        "num_sample = len(test_json)\n",
        "#print(num_sample)\n",
        "\n",
        "#print(train_1_json[0])\n",
        "for key, value in test_json.items():\n",
        "  counter+=1\n",
        "  tweet = test_json[key]['tweet']\n",
        "  if test_json[key]['lang']=='es':\n",
        "      tweet = GoogleTranslator(source='es', target='en').translate(test_json[key]['tweet'])\n",
        "\n",
        "  current_sample = '[INST]\\n'+tweet+'\\n[/INST]'\n",
        "  prompt = few_shot_samples_run1+current_sample\n",
        "\n",
        "  #print(prompt)\n",
        "\n",
        "  response = lcpp_llm(\n",
        "        prompt=prompt,\n",
        "        temperature= 0.2,\n",
        "        logprobs=1,\n",
        "        #max_tokens =1\n",
        "      )\n",
        "\n",
        "  #print(response)\n",
        "\n",
        "  answer = str(response[\"choices\"][0][\"text\"]).strip().upper()\n",
        "  #print(answer)\n",
        "  answer = answer[:3]\n",
        "  #answer = answer.split()[0]\n",
        "  # Sometime output contains a '.' remove it!\n",
        "  #answer = answer.replace('.','')\n",
        "\n",
        "  # If the predicted word is not in emotion list just replace with neutral.\n",
        "  if answer not in replies_list:\n",
        "        answer = 'NO'\n",
        "\n",
        "  #current_sample += answer + \" \\n \"\n",
        "\n",
        "  print(\"GENERATED: \"+ current_sample+'\\n'+answer)\n",
        "\n",
        "  current_element = {\n",
        "        \"id\": test_json[key]['id_EXIST'],\n",
        "        \"value\": answer,\n",
        "        \"test_case\": \"EXIST2024\"\n",
        "    }\n",
        "  json_result_run1.append(current_element)\n",
        "\n",
        "with open(\"task1_hard_badrock_1.json\", \"w\") as json_file:\n",
        "    json.dump(json_result_run1, json_file, indent=4)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "replies_list = ['YES','NO']\n",
        "counter = 0\n",
        "\n",
        "# List to store the results.\n",
        "json_result_run2 = []\n",
        "\n",
        "# simple JSON loading\n",
        "with open(test_path, 'r') as istr:\n",
        "    test_json = json.load(istr)\n",
        "num_sample = len(test_json)\n",
        "#print(num_sample)\n",
        "\n",
        "#print(train_1_json[0])\n",
        "for key, value in test_json.items():\n",
        "  counter+=1\n",
        "  tweet = test_json[key]['tweet']\n",
        "  if test_json[key]['lang']=='es':\n",
        "      tweet = GoogleTranslator(source='es', target='en').translate(test_json[key]['tweet'])\n",
        "\n",
        "  current_sample = '[INST]\\n'+tweet+'\\n[/INST]'\n",
        "  prompt = few_shot_samples_run2+current_sample\n",
        "\n",
        "  #print(prompt)\n",
        "\n",
        "  response = lcpp_llm(\n",
        "        prompt=prompt,\n",
        "        temperature= 0.2,\n",
        "        logprobs=1,\n",
        "        #max_tokens =1\n",
        "      )\n",
        "\n",
        "  #print(response)\n",
        "\n",
        "  answer = str(response[\"choices\"][0][\"text\"]).strip().upper()\n",
        "  #print(answer)\n",
        "  answer = answer[:3]\n",
        "  #answer = answer.split()[0]\n",
        "  # Sometime output contains a '.' remove it!\n",
        "  #answer = answer.replace('.','')\n",
        "\n",
        "  # If the predicted word is not in emotion list just replace with neutral.\n",
        "  if answer not in replies_list:\n",
        "        answer = 'NO'\n",
        "\n",
        "  #current_sample += answer + \" \\n \"\n",
        "\n",
        "  print(\"GENERATED: \"+ current_sample+'\\n'+answer)\n",
        "\n",
        "  current_element = {\n",
        "        \"id\": test_json[key]['id_EXIST'],\n",
        "        \"value\": answer,\n",
        "        \"test_case\": \"EXIST2024\"\n",
        "    }\n",
        "  json_result_run2.append(current_element)\n",
        "\n",
        "with open(\"task1_hard_badrock_2.json\", \"w\") as json_file:\n",
        "    json.dump(json_result_run2, json_file, indent=4)\n"
      ],
      "metadata": {
        "id": "4SfpJbGEa0R_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dded67e3-b0a0-4020-c67a-ac42833bafa3"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.76 ms /    16 runs   (    0.61 ms per token,  1640.02 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1825.37 ms /  1309 tokens (    1.39 ms per token,   717.12 tokens per second)\n",
            "llama_print_timings:        eval time =    1682.95 ms /    15 runs   (  112.20 ms per token,     8.91 tokens per second)\n",
            "llama_print_timings:       total time =    7063.25 ms /  1324 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "@Eurogamer_es All gamergate from development to game forums, classic in the world of video games.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.93 ms /    16 runs   (    0.62 ms per token,  1611.93 tokens per second)\n",
            "llama_print_timings: prompt eval time =     597.88 ms /    32 tokens (   18.68 ms per token,    53.52 tokens per second)\n",
            "llama_print_timings:        eval time =    1530.68 ms /    15 runs   (  102.05 ms per token,     9.80 tokens per second)\n",
            "llama_print_timings:       total time =    2315.81 ms /    47 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "@ArCaNgEl__23 @Benzenazi Man, it's not comparable, look at Gamergate.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.86 ms /    16 runs   (    0.55 ms per token,  1805.26 tokens per second)\n",
            "llama_print_timings: prompt eval time =     606.38 ms /    24 tokens (   25.27 ms per token,    39.58 tokens per second)\n",
            "llama_print_timings:        eval time =    1479.91 ms /    15 runs   (   98.66 ms per token,    10.14 tokens per second)\n",
            "llama_print_timings:       total time =    2206.88 ms /    39 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "I'm looking for companies involved in gamergate for etc etc to buy all their products\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.66 ms /    16 runs   (    0.60 ms per token,  1656.83 tokens per second)\n",
            "llama_print_timings: prompt eval time =     262.40 ms /    75 tokens (    3.50 ms per token,   285.82 tokens per second)\n",
            "llama_print_timings:        eval time =    1502.38 ms /    15 runs   (  100.16 ms per token,     9.98 tokens per second)\n",
            "llama_print_timings:       total time =    1985.54 ms /    90 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "@jordirico First it was the internet, then the gamergate, the manosphere and its extreme misogyny without the platforms lifting a finger, the incel-murders, the extreme right capitalizing on hate, the mimicry of these ideas with those of a respectable debate and finally here we are\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.66 ms /    16 runs   (    0.60 ms per token,  1655.63 tokens per second)\n",
            "llama_print_timings: prompt eval time =     752.90 ms /    28 tokens (   26.89 ms per token,    37.19 tokens per second)\n",
            "llama_print_timings:        eval time =    1614.81 ms /    15 runs   (  107.65 ms per token,     9.29 tokens per second)\n",
            "llama_print_timings:       total time =    2513.16 ms /    43 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "@AlonsoQuijano12 I was involved in gamergate, so unfortunately I know too much 😭\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.72 ms /    16 runs   (    0.54 ms per token,  1835.70 tokens per second)\n",
            "llama_print_timings: prompt eval time =     812.11 ms /    29 tokens (   28.00 ms per token,    35.71 tokens per second)\n",
            "llama_print_timings:        eval time =    1500.89 ms /    15 runs   (  100.06 ms per token,     9.99 tokens per second)\n",
            "llama_print_timings:       total time =    2447.21 ms /    44 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "@MrSandman1954 @AKN4710 Gamergate screwed the internet forever.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.89 ms /    16 runs   (    0.56 ms per token,  1799.78 tokens per second)\n",
            "llama_print_timings: prompt eval time =     282.34 ms /   102 tokens (    2.77 ms per token,   361.26 tokens per second)\n",
            "llama_print_timings:        eval time =    1580.88 ms /    15 runs   (  105.39 ms per token,     9.49 tokens per second)\n",
            "llama_print_timings:       total time =    2134.48 ms /   117 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "@grupoeldeber @grupoeldeber It would be good if they also said that it was in CANADA🇨🇦 the first country where it was reported that G∆y couples who adopted children abused them in 2008. How selective are they with the crap they publish, right? https://t.co/GPAmLOfcY9 https://t.co/f36aAmxq35\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.11 ms /    16 runs   (    0.57 ms per token,  1756.70 tokens per second)\n",
            "llama_print_timings: prompt eval time =     257.92 ms /    40 tokens (    6.45 ms per token,   155.09 tokens per second)\n",
            "llama_print_timings:        eval time =    1469.98 ms /    15 runs   (   98.00 ms per token,    10.20 tokens per second)\n",
            "llama_print_timings:       total time =    1877.67 ms /    55 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "They, very close together and more alone than ever. The consequences of everything. Mozambique. https://t.co/5nVGTb3Ua3\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.67 ms /    16 runs   (    0.67 ms per token,  1499.39 tokens per second)\n",
            "llama_print_timings: prompt eval time =     566.41 ms /    32 tokens (   17.70 ms per token,    56.50 tokens per second)\n",
            "llama_print_timings:        eval time =    1778.48 ms /    15 runs   (  118.57 ms per token,     8.43 tokens per second)\n",
            "llama_print_timings:       total time =    2564.77 ms /    47 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "DC Children's Hospital Harassed Over Trans Youth Serviceshttps://t.co/RrEtZ5TDDM\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.69 ms /    16 runs   (    0.54 ms per token,  1841.83 tokens per second)\n",
            "llama_print_timings: prompt eval time =     239.96 ms /    45 tokens (    5.33 ms per token,   187.53 tokens per second)\n",
            "llama_print_timings:        eval time =    1525.07 ms /    15 runs   (  101.67 ms per token,     9.84 tokens per second)\n",
            "llama_print_timings:       total time =    1922.89 ms /    60 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "20mins deep into BeReal and I have never felt so pressured to take my phone nope I don't want to feel harassed I say goodbye 🫡\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.36 ms /    16 runs   (    0.58 ms per token,  1709.95 tokens per second)\n",
            "llama_print_timings: prompt eval time =     251.94 ms /    61 tokens (    4.13 ms per token,   242.12 tokens per second)\n",
            "llama_print_timings:        eval time =    1480.93 ms /    15 runs   (   98.73 ms per token,    10.13 tokens per second)\n",
            "llama_print_timings:       total time =    1928.02 ms /    76 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "Anthony Fauci, the leading US infectious disease expert, noted in August 2022 that he had received death threats and that his family was routinely exposed to harassment. https://t.co/EerbO2Px5j\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.83 ms /    16 runs   (    0.55 ms per token,  1811.39 tokens per second)\n",
            "llama_print_timings: prompt eval time =     702.19 ms /    28 tokens (   25.08 ms per token,    39.88 tokens per second)\n",
            "llama_print_timings:        eval time =    1631.44 ms /    15 runs   (  108.76 ms per token,     9.19 tokens per second)\n",
            "llama_print_timings:       total time =    2460.35 ms /    43 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "@dimplerrylover I know but literally the girl was being harassed like how can she smile like that\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.98 ms /    16 runs   (    0.75 ms per token,  1335.11 tokens per second)\n",
            "llama_print_timings: prompt eval time =     276.92 ms /    85 tokens (    3.26 ms per token,   306.94 tokens per second)\n",
            "llama_print_timings:        eval time =    1803.28 ms /    15 runs   (  120.22 ms per token,     8.32 tokens per second)\n",
            "llama_print_timings:       total time =    2499.94 ms /   100 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "@marcela_ruge @_Lamanada_ @Mitocondria1311 @karinin7986 @julibmoya @MissPoirot07 @Adrianaruiz17 @DiaAnimales @marcevalenciar @MONYRODRIGUEZOF Marce do you have daviplata?\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.77 ms /    16 runs   (    0.61 ms per token,  1637.50 tokens per second)\n",
            "llama_print_timings: prompt eval time =     258.81 ms /    64 tokens (    4.04 ms per token,   247.29 tokens per second)\n",
            "llama_print_timings:        eval time =    1528.81 ms /    15 runs   (  101.92 ms per token,     9.81 tokens per second)\n",
            "llama_print_timings:       total time =    1984.82 ms /    79 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "About to see the grand premiere of #Jauría based on the case of #LaManada @anasofihg @RobertoBeck90 @elteatrocdmx #teatromexicano https://t.co/N5Uke18ikQ\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.70 ms /    16 runs   (    0.61 ms per token,  1648.80 tokens per second)\n",
            "llama_print_timings: prompt eval time =     260.14 ms /    64 tokens (    4.06 ms per token,   246.02 tokens per second)\n",
            "llama_print_timings:        eval time =    1527.50 ms /    15 runs   (  101.83 ms per token,     9.82 tokens per second)\n",
            "llama_print_timings:       total time =    1992.92 ms /    79 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "What a bastard our uncle Pablo is with his little jokes. How comfortable we are on the cool grass... mybestfriends #doglove #theyneverabandon #lodaneverythingchangedenada https://t.co/4x20oe7V8D\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.91 ms /    16 runs   (    0.62 ms per token,  1615.18 tokens per second)\n",
            "llama_print_timings: prompt eval time =     280.60 ms /    75 tokens (    3.74 ms per token,   267.28 tokens per second)\n",
            "llama_print_timings:        eval time =    1531.59 ms /    15 runs   (  102.11 ms per token,     9.79 tokens per second)\n",
            "llama_print_timings:       total time =    2047.29 ms /    90 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "@noebermudez_13 @ldacr And we are already looking forward to filling the stands with you everywhere again!!! @LaManada_CR And now distribute balls left and right except to those who gather balls 🥺🤣🤣🤣🤣#VAMOSLEONAS #SOMOSLAMANADA\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.48 ms /    16 runs   (    0.66 ms per token,  1525.99 tokens per second)\n",
            "llama_print_timings: prompt eval time =     284.38 ms /   116 tokens (    2.45 ms per token,   407.90 tokens per second)\n",
            "llama_print_timings:        eval time =    1745.48 ms /    15 runs   (  116.37 ms per token,     8.59 tokens per second)\n",
            "llama_print_timings:       total time =    2375.60 ms /   131 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "#TBT: María Rosa, Gregorio Polanco and Ysabel Verás, back in October 2016, during one of the Kermés held for the team's fundraising. The Pack is tradition, family, unity and joy!🥎🐺🥎🐺#TBT #Auuuuu#LaManada#LobosFansClub#LobosSoftbolClub https://t.co/LwSL4npanZ\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.88 ms /    16 runs   (    0.55 ms per token,  1802.61 tokens per second)\n",
            "llama_print_timings: prompt eval time =     381.98 ms /   129 tokens (    2.96 ms per token,   337.72 tokens per second)\n",
            "llama_print_timings:        eval time =    1589.78 ms /    15 runs   (  105.99 ms per token,     9.44 tokens per second)\n",
            "llama_print_timings:       total time =    2310.30 ms /   144 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "AUGUST 9 Find out everything! 🎙 You can watch the entire segment of 'El Bla, Bla, Bla' with HÉCTOR JOAQUÍN in the #Podcasts section of the LaMusica app. 📲#HectorJoaquin #LaManada #ElBlaBlaBla #LaMusica @la_musica @zeta93fm https://t.co/ZDZM4Qs1zx https://t.co/zqMjKMgN4r\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.54 ms /    16 runs   (    0.60 ms per token,  1676.45 tokens per second)\n",
            "llama_print_timings: prompt eval time =     269.65 ms /    88 tokens (    3.06 ms per token,   326.35 tokens per second)\n",
            "llama_print_timings:        eval time =    1444.79 ms /    15 runs   (   96.32 ms per token,    10.38 tokens per second)\n",
            "llama_print_timings:       total time =    1962.75 ms /   103 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "@Fistroman1 @ElioGatsby Without proof?? What was it in public? What did we all see, what are you telling me? Don't mix churras with merinas. What from now until you come to me with the metoo and the notallmen there is little left and I don't feel like it end up really arguing, I see it coming.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.29 ms /    16 runs   (    0.71 ms per token,  1417.81 tokens per second)\n",
            "llama_print_timings: prompt eval time =     277.81 ms /    83 tokens (    3.35 ms per token,   298.77 tokens per second)\n",
            "llama_print_timings:        eval time =    1750.51 ms /    15 runs   (  116.70 ms per token,     8.57 tokens per second)\n",
            "llama_print_timings:       total time =    2285.21 ms /    98 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "@EstefaniaVeloz ...With the legal process, not to set a person on fire (I don't even know who they are in this case). There are women who are victims but there are also corrupt, violent and victimizers. The #MeToo movement has already fulfilled its mission. What's next? How to advance without it being a weapon of whim?\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.98 ms /    16 runs   (    0.62 ms per token,  1602.56 tokens per second)\n",
            "llama_print_timings: prompt eval time =     302.71 ms /    98 tokens (    3.09 ms per token,   323.74 tokens per second)\n",
            "llama_print_timings:        eval time =    1564.52 ms /    15 runs   (  104.30 ms per token,     9.59 tokens per second)\n",
            "llama_print_timings:       total time =    2136.16 ms /   113 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "@robertoantoniow @JessicaLBedoya Both of you are fired, because you are adults and it is a consensual and transactional relationship. Let them not invent a \"MeToo\" later, because it is not. A couple of thieves and liars. They even had people fired due to the investigation. I well remember the level of power with which that UGLY footprint arrived 🤮\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.44 ms /    16 runs   (    0.59 ms per token,  1695.09 tokens per second)\n",
            "llama_print_timings: prompt eval time =     272.31 ms /    88 tokens (    3.09 ms per token,   323.17 tokens per second)\n",
            "llama_print_timings:        eval time =    1551.31 ms /    15 runs   (  103.42 ms per token,     9.67 tokens per second)\n",
            "llama_print_timings:       total time =    2069.23 ms /   103 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "@geeksterilia From the Olivia who is climbing on bricks for being a director. The video of the call to Shia is like that, all condescending to MY weakness. For this, according to her, she asked Shia to get out of her hair because well, I mean, And then nothing. The girl pretending https://t.co/t9zCKx1IDs\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.64 ms /    16 runs   (    0.54 ms per token,  1851.42 tokens per second)\n",
            "llama_print_timings: prompt eval time =     575.77 ms /    23 tokens (   25.03 ms per token,    39.95 tokens per second)\n",
            "llama_print_timings:        eval time =    1677.73 ms /    15 runs   (  111.85 ms per token,     8.94 tokens per second)\n",
            "llama_print_timings:       total time =    2369.57 ms /    38 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "@jaurxm If you want, tell me some and I'll put them in\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.94 ms /    16 runs   (    0.68 ms per token,  1463.19 tokens per second)\n",
            "llama_print_timings: prompt eval time =     244.18 ms /    40 tokens (    6.10 ms per token,   163.81 tokens per second)\n",
            "llama_print_timings:        eval time =    1849.09 ms /    15 runs   (  123.27 ms per token,     8.11 tokens per second)\n",
            "llama_print_timings:       total time =    2345.78 ms /    55 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "@Aracely54051891 We started another #Metoo movement like you... it wouldn't work, it's only from man to woman\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.89 ms /    16 runs   (    0.56 ms per token,  1800.38 tokens per second)\n",
            "llama_print_timings: prompt eval time =     622.97 ms /    23 tokens (   27.09 ms per token,    36.92 tokens per second)\n",
            "llama_print_timings:        eval time =    1464.94 ms /    15 runs   (   97.66 ms per token,    10.24 tokens per second)\n",
            "llama_print_timings:       total time =    2201.57 ms /    38 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "@SherryWimbleton mgtow people and masculinism should not be compatible\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.93 ms /    16 runs   (    0.56 ms per token,  1792.72 tokens per second)\n",
            "llama_print_timings: prompt eval time =     234.53 ms /    37 tokens (    6.34 ms per token,   157.76 tokens per second)\n",
            "llama_print_timings:        eval time =    1493.32 ms /    15 runs   (   99.55 ms per token,    10.04 tokens per second)\n",
            "llama_print_timings:       total time =    1870.76 ms /    52 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "@al_andr0 @maxveram @turttle_cathyun Maybe if you look at his account clearly in a mgtow\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.19 ms /    16 runs   (    0.57 ms per token,  1740.83 tokens per second)\n",
            "llama_print_timings: prompt eval time =     256.21 ms /    51 tokens (    5.02 ms per token,   199.06 tokens per second)\n",
            "llama_print_timings:        eval time =    1575.09 ms /    15 runs   (  105.01 ms per token,     9.52 tokens per second)\n",
            "llama_print_timings:       total time =    1999.32 ms /    66 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "@RechazoChileno @MGTOW_Chilensis It is true, they were told but they did not listen, now they should ask for forgiveness and ask that we not have any more misfortunes\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.12 ms /    16 runs   (    0.69 ms per token,  1439.50 tokens per second)\n",
            "llama_print_timings: prompt eval time =     252.22 ms /    62 tokens (    4.07 ms per token,   245.82 tokens per second)\n",
            "llama_print_timings:        eval time =    1887.44 ms /    15 runs   (  125.83 ms per token,     7.95 tokens per second)\n",
            "llama_print_timings:       total time =    2357.79 ms /    77 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "Sexists, misogynists, mgtow and other crowd that swarms the world, you are just like the feminazis, bitter beings loaded with bad experiences who only know how to cry and clench your little fists, don't you see it?\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.26 ms /    16 runs   (    0.58 ms per token,  1728.61 tokens per second)\n",
            "llama_print_timings: prompt eval time =     422.25 ms /   191 tokens (    2.21 ms per token,   452.34 tokens per second)\n",
            "llama_print_timings:        eval time =    1550.71 ms /    15 runs   (  103.38 ms per token,     9.67 tokens per second)\n",
            "llama_print_timings:       total time =    2496.62 ms /   206 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "@ArmezHL @Incognito_archi @AntonioMiraflo1 @HellNoveno @tradhusbando @poiu2525 @mund_ola @CaraBM6T0W @Lewdowl1 @die100000 @infer_oficial @Lukas_snob_22 @terminat2_HL @marketfarid @DieJn200519 @grisasexual @MasculinismoLi1 @AliadesAllType @HellDecimoMgtow Let's see if I understand, he is not mgtow, and he has girlfriend, therefore she is not a redpiler? I don't see the punch line, nor the spice. https://t.co/mdNjGe5YKg\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.83 ms /    16 runs   (    0.61 ms per token,  1627.34 tokens per second)\n",
            "llama_print_timings: prompt eval time =     263.85 ms /    73 tokens (    3.61 ms per token,   276.67 tokens per second)\n",
            "llama_print_timings:        eval time =    1551.44 ms /    15 runs   (  103.43 ms per token,     9.67 tokens per second)\n",
            "llama_print_timings:       total time =    2029.09 ms /    88 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "I saw this image on an MGTOW profile and the comment he made didn't seem interesting to me, but the image did. What do you think of these terms? \"Love bombing\" and \"caspering\" seem stupid to me xd https://t.co/Dl04HWqDnd\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.33 ms /    16 runs   (    0.58 ms per token,  1715.63 tokens per second)\n",
            "llama_print_timings: prompt eval time =     247.73 ms /    49 tokens (    5.06 ms per token,   197.79 tokens per second)\n",
            "llama_print_timings:        eval time =    1453.90 ms /    15 runs   (   96.93 ms per token,    10.32 tokens per second)\n",
            "llama_print_timings:       total time =    1873.07 ms /    64 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "It is equally obvious that it is a microaggression that becomes a funny anecdote more than anything, but I would like to have a name for that type of experiences, because it happens a lot!!!\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.69 ms /    16 runs   (    0.73 ms per token,  1368.69 tokens per second)\n",
            "llama_print_timings: prompt eval time =     251.35 ms /    43 tokens (    5.85 ms per token,   171.07 tokens per second)\n",
            "llama_print_timings:        eval time =    1800.33 ms /    15 runs   (  120.02 ms per token,     8.33 tokens per second)\n",
            "llama_print_timings:       total time =    2319.53 ms /    58 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "Oh Boy...Now #MicroAggression is attacking @NotiJuan because he exposed it in a video where you can see what he did and now he denies it.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.51 ms /    16 runs   (    0.59 ms per token,  1682.09 tokens per second)\n",
            "llama_print_timings: prompt eval time =     280.77 ms /    79 tokens (    3.55 ms per token,   281.37 tokens per second)\n",
            "llama_print_timings:        eval time =    1512.28 ms /    15 runs   (  100.82 ms per token,     9.92 tokens per second)\n",
            "llama_print_timings:       total time =    2030.80 ms /    94 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "@tere_marinovic Rejection advertisers, we urge you not to use the expression “like garlic” to reinforce something bad. The AAJ (Association of Garlic Lovers) declares itself in a state of alert and vigilance in the face of this microaggression to its interests. There are millions of votes at stake.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.07 ms /    16 runs   (    0.57 ms per token,  1763.86 tokens per second)\n",
            "llama_print_timings: prompt eval time =     247.98 ms /    43 tokens (    5.77 ms per token,   173.40 tokens per second)\n",
            "llama_print_timings:        eval time =    1557.17 ms /    15 runs   (  103.81 ms per token,     9.63 tokens per second)\n",
            "llama_print_timings:       total time =    1959.29 ms /    58 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "(And yes, I do believe that it can be used as a form of microaggression - like almost everything - but I also think that that generalization is not very brilliant.)\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      12.36 ms /    16 runs   (    0.77 ms per token,  1294.08 tokens per second)\n",
            "llama_print_timings: prompt eval time =     283.67 ms /    71 tokens (    4.00 ms per token,   250.29 tokens per second)\n",
            "llama_print_timings:        eval time =    1871.30 ms /    15 runs   (  124.75 ms per token,     8.02 tokens per second)\n",
            "llama_print_timings:       total time =    2527.01 ms /    86 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "@_Agnosthesia_ Did you completely miss the part about his workplace ostracizing him after disclosing to the director that he was a queer man? Passive coldness is still discrimination. This is called microaggression. Would you like to be treated as inconvenient for existing?\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.26 ms /    16 runs   (    0.58 ms per token,  1727.49 tokens per second)\n",
            "llama_print_timings: prompt eval time =     303.13 ms /   113 tokens (    2.68 ms per token,   372.78 tokens per second)\n",
            "llama_print_timings:        eval time =    1545.82 ms /    15 runs   (  103.05 ms per token,     9.70 tokens per second)\n",
            "llama_print_timings:       total time =    2147.65 ms /   128 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "@sweetsparklesw @_samuel0014 @AcademiaUpdates @ALEXANDERACHA It is microaggression after microaggression that makes homophobia noticeable. The academy chased a group of drag girls because they did not want to dance in men's clothing. Tell me that's not homophobia? They took Dennis out of the closet so forcefully that even Danna Paola cried. That's not homophobia?\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.65 ms /    16 runs   (    0.60 ms per token,  1657.69 tokens per second)\n",
            "llama_print_timings: prompt eval time =     272.04 ms /    73 tokens (    3.73 ms per token,   268.35 tokens per second)\n",
            "llama_print_timings:        eval time =    1448.12 ms /    15 runs   (   96.54 ms per token,    10.36 tokens per second)\n",
            "llama_print_timings:       total time =    1939.37 ms /    88 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "@Celia_Alejandra Yaaaaa I get it! Of course, I still think that may be a stereotype. I don't know if I would have read it as misogyny because for me it is more like micro-machismo but I understand that it may be an outdated stereotype.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.84 ms /    16 runs   (    0.68 ms per token,  1476.29 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1030.27 ms /    31 tokens (   33.23 ms per token,    30.09 tokens per second)\n",
            "llama_print_timings:        eval time =    1853.47 ms /    15 runs   (  123.56 ms per token,     8.09 tokens per second)\n",
            "llama_print_timings:       total time =    3101.35 ms /    46 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "Now they call “micromachismo” the fact of being a gentleman. Those feminists are getting more and more stupid.\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.06 ms /    16 runs   (    0.57 ms per token,  1765.03 tokens per second)\n",
            "llama_print_timings: prompt eval time =     248.07 ms /    42 tokens (    5.91 ms per token,   169.31 tokens per second)\n",
            "llama_print_timings:        eval time =    1596.34 ms /    15 runs   (  106.42 ms per token,     9.40 tokens per second)\n",
            "llama_print_timings:       total time =    2003.02 ms /    57 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "Cormillot did not realize it but he made visible something that is not talked about much: the last intact bastion of the purest micromachismo are the offices.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.21 ms /    16 runs   (    0.58 ms per token,  1737.05 tokens per second)\n",
            "llama_print_timings: prompt eval time =     251.54 ms /    48 tokens (    5.24 ms per token,   190.82 tokens per second)\n",
            "llama_print_timings:        eval time =    1506.25 ms /    15 runs   (  100.42 ms per token,     9.96 tokens per second)\n",
            "llama_print_timings:       total time =    1922.17 ms /    63 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "Today in micromachismo in my friend \"How do you not like to cook, your boyfriend already knows?\" I don't know whether to laugh or ask him if everything is okay at his house.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.44 ms /    16 runs   (    0.59 ms per token,  1694.56 tokens per second)\n",
            "llama_print_timings: prompt eval time =     282.81 ms /    73 tokens (    3.87 ms per token,   258.12 tokens per second)\n",
            "llama_print_timings:        eval time =    1533.20 ms /    15 runs   (  102.21 ms per token,     9.78 tokens per second)\n",
            "llama_print_timings:       total time =    2035.28 ms /    88 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "When a woman denounces sexism because she had consensual sex with a guy who didn't call her again, she is taking the issue to a superficial point. I am aware of what micromachismo is and I would never defend it, but you don't kill an ant with a grenade.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      13.88 ms /    16 runs   (    0.87 ms per token,  1152.65 tokens per second)\n",
            "llama_print_timings: prompt eval time =     244.45 ms /    55 tokens (    4.44 ms per token,   225.00 tokens per second)\n",
            "llama_print_timings:        eval time =    1872.83 ms /    15 runs   (  124.86 ms per token,     8.01 tokens per second)\n",
            "llama_print_timings:       total time =    2421.29 ms /    70 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "@VirginiaG68 You haven't missed much. We remain dedicated to microfascism, micromachismo and aesthetic violence against fat women, prosthetics and mastectomies. #TeamFacha\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.93 ms /    16 runs   (    0.56 ms per token,  1791.11 tokens per second)\n",
            "llama_print_timings: prompt eval time =     299.33 ms /    89 tokens (    3.36 ms per token,   297.33 tokens per second)\n",
            "llama_print_timings:        eval time =    1474.75 ms /    15 runs   (   98.32 ms per token,    10.17 tokens per second)\n",
            "llama_print_timings:       total time =    2016.11 ms /   104 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "@eneksei @Olad_20 @Mariiaa98_ @skeifer You speak of misogyny in the face of a generalization to justify, immediately afterwards, the generalization in a man's complaint about notallmen. In fact, the good old Skiner affects men and women and occurs quite a bit in the narcissistic profiles cited by the gentleman.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.80 ms /    16 runs   (    0.55 ms per token,  1818.39 tokens per second)\n",
            "llama_print_timings: prompt eval time =     252.22 ms /    44 tokens (    5.73 ms per token,   174.45 tokens per second)\n",
            "llama_print_timings:        eval time =    1660.39 ms /    15 runs   (  110.69 ms per token,     9.03 tokens per second)\n",
            "llama_print_timings:       total time =    2068.94 ms /    59 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "@ruthi___ @corleoneRMCF @claudiiwiss_ Leave it, the poor thing doesn't matter any more. This err that errs with notallmen\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       7.64 ms /    16 runs   (    0.48 ms per token,  2094.79 tokens per second)\n",
            "llama_print_timings: prompt eval time =     281.33 ms /    65 tokens (    4.33 ms per token,   231.04 tokens per second)\n",
            "llama_print_timings:        eval time =    1524.08 ms /    15 runs   (  101.61 ms per token,     9.84 tokens per second)\n",
            "llama_print_timings:       total time =    2002.98 ms /    80 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "Which of you was responsible for teaching your uncle Mario to use Twitter? He just tweets pure nonsense, take away his Wi-Fi, he just goes around giving others grief with his \"very necessary\" #NotAllMen comment https://t.co/ 9griMRzSvF\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.19 ms /    16 runs   (    0.57 ms per token,  1740.64 tokens per second)\n",
            "llama_print_timings: prompt eval time =     254.84 ms /    41 tokens (    6.22 ms per token,   160.89 tokens per second)\n",
            "llama_print_timings:        eval time =    1502.73 ms /    15 runs   (  100.18 ms per token,     9.98 tokens per second)\n",
            "llama_print_timings:       total time =    1911.41 ms /    56 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "@CNDH @YndiraSandoval what's going on here? Someone explain please!! #NotAllMen? Does the debtor not exercise economic violence?\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.26 ms /    16 runs   (    0.52 ms per token,  1936.11 tokens per second)\n",
            "llama_print_timings: prompt eval time =     243.51 ms /    36 tokens (    6.76 ms per token,   147.84 tokens per second)\n",
            "llama_print_timings:        eval time =    1601.80 ms /    15 runs   (  106.79 ms per token,     9.36 tokens per second)\n",
            "llama_print_timings:       total time =    1994.14 ms /    51 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "@PenaGariel @ribbonLP imagine if a tweet bothers you 😭😭😭😭😭#Notallmen😭😭😭😭\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.53 ms /    16 runs   (    0.53 ms per token,  1876.61 tokens per second)\n",
            "llama_print_timings: prompt eval time =     240.00 ms /    42 tokens (    5.71 ms per token,   175.00 tokens per second)\n",
            "llama_print_timings:        eval time =    1582.65 ms /    15 runs   (  105.51 ms per token,     9.48 tokens per second)\n",
            "llama_print_timings:       total time =    1975.01 ms /    57 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "@tincho_mg I consider you among the healthy ones! don't wear notallmen, if the suit doesn't fit, don't wear it hahaha\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.57 ms /    16 runs   (    0.66 ms per token,  1514.00 tokens per second)\n",
            "llama_print_timings: prompt eval time =     246.47 ms /    35 tokens (    7.04 ms per token,   142.00 tokens per second)\n",
            "llama_print_timings:        eval time =    1831.41 ms /    15 runs   (  122.09 ms per token,     8.19 tokens per second)\n",
            "llama_print_timings:       total time =    2251.54 ms /    50 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "I shouted fuck the patriarchy surrounded by swifties, the best night of my life https://t.co/ek6OIan1kg\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.83 ms /    16 runs   (    0.55 ms per token,  1812.83 tokens per second)\n",
            "llama_print_timings: prompt eval time =     783.78 ms /    29 tokens (   27.03 ms per token,    37.00 tokens per second)\n",
            "llama_print_timings:        eval time =    1530.37 ms /    15 runs   (  102.02 ms per token,     9.80 tokens per second)\n",
            "llama_print_timings:       total time =    2439.04 ms /    44 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "I love that Mov said Fuck the patriarchy and Meli taught us man jumping, which by the way is really fun.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.28 ms /    16 runs   (    0.58 ms per token,  1723.40 tokens per second)\n",
            "llama_print_timings: prompt eval time =     259.55 ms /    78 tokens (    3.33 ms per token,   300.52 tokens per second)\n",
            "llama_print_timings:        eval time =    1535.15 ms /    15 runs   (  102.34 ms per token,     9.77 tokens per second)\n",
            "llama_print_timings:       total time =    2018.59 ms /    93 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "@pau_army_bts A clear example of the deep-rooted machismo that exists in society, because if the situation were that men bought an album of their favs and we women bought the chips, they would criticize us the same 🤬 as Dr. Swift said fuck the patriarchy, my silver my decision\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.61 ms /    16 runs   (    0.60 ms per token,  1665.28 tokens per second)\n",
            "llama_print_timings: prompt eval time =     252.83 ms /    49 tokens (    5.16 ms per token,   193.81 tokens per second)\n",
            "llama_print_timings:        eval time =    1625.33 ms /    15 runs   (  108.36 ms per token,     9.23 tokens per second)\n",
            "llama_print_timings:       total time =    2051.41 ms /    64 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "I don't want to fuck the patriarchy, I'm tired of the fact that for you penetration is synonymous with humiliation and submission, how deeply violent and phallocentric that conception is.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.90 ms /    16 runs   (    0.68 ms per token,  1468.16 tokens per second)\n",
            "llama_print_timings: prompt eval time =     910.26 ms /    28 tokens (   32.51 ms per token,    30.76 tokens per second)\n",
            "llama_print_timings:        eval time =    1808.18 ms /    15 runs   (  120.55 ms per token,     8.30 tokens per second)\n",
            "llama_print_timings:       total time =    2928.58 ms /    43 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "Every day that passes I understand more the “FUCK THE PATRIARCHY” of all too well\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.62 ms /    16 runs   (    0.54 ms per token,  1855.07 tokens per second)\n",
            "llama_print_timings: prompt eval time =     259.30 ms /    46 tokens (    5.64 ms per token,   177.40 tokens per second)\n",
            "llama_print_timings:        eval time =    1535.83 ms /    15 runs   (  102.39 ms per token,     9.77 tokens per second)\n",
            "llama_print_timings:       total time =    1971.67 ms /    61 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "Patriarchy, Patriarcat, Patriarchy. #Patriarchy, #Patriarcat, #Patriarchy. https://t.co/5tfxatw9UF\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.60 ms /    16 runs   (    0.60 ms per token,  1666.32 tokens per second)\n",
            "llama_print_timings: prompt eval time =     301.65 ms /   108 tokens (    2.79 ms per token,   358.04 tokens per second)\n",
            "llama_print_timings:        eval time =    1509.15 ms /    15 runs   (  100.61 ms per token,     9.94 tokens per second)\n",
            "llama_print_timings:       total time =    2128.82 ms /   123 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "Register to vote: https://t.co/yIjQtrHynP#vote #womensequityday #womensrights #equity #womensday #amandagorman #poem Register to vote: https://t.co/ctcNYGtXz8#vote #equidaddelamujer #equidad #rechosdelamujer #diadelamujer #amardagorman #poem\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.92 ms /    16 runs   (    0.75 ms per token,  1341.94 tokens per second)\n",
            "llama_print_timings: prompt eval time =     290.91 ms /    80 tokens (    3.64 ms per token,   275.00 tokens per second)\n",
            "llama_print_timings:        eval time =    1689.63 ms /    15 runs   (  112.64 ms per token,     8.88 tokens per second)\n",
            "llama_print_timings:       total time =    2370.60 ms /    95 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "This Women's Day in South Africa @Kantar always stands firm in supporting the global issue of equal work between genders. Here's a reminder of International Women's Day in a message from our Middle East &amp; Africa. #WomensDay #GenderEquity…https://t.co/Ma28HYaKuT\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.73 ms /    16 runs   (    0.55 ms per token,  1833.60 tokens per second)\n",
            "llama_print_timings: prompt eval time =     285.17 ms /    74 tokens (    3.85 ms per token,   259.50 tokens per second)\n",
            "llama_print_timings:        eval time =    1565.84 ms /    15 runs   (  104.39 ms per token,     9.58 tokens per second)\n",
            "llama_print_timings:       total time =    2064.60 ms /    89 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "Confiedance #teambuilding #directselling #motivation #nation #republicday #facebook #instagramposts #leadership #WomensDay https://t.co/nCfC6qLB03 https://t.co/LppDv6dylJ\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.39 ms /    16 runs   (    0.52 ms per token,  1907.26 tokens per second)\n",
            "llama_print_timings: prompt eval time =     769.73 ms /    31 tokens (   24.83 ms per token,    40.27 tokens per second)\n",
            "llama_print_timings:        eval time =    1526.22 ms /    15 runs   (  101.75 ms per token,     9.83 tokens per second)\n",
            "llama_print_timings:       total time =    2429.85 ms /    46 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "@nissanza Single Cab#NewNissanNavara #MadeForYourJourney#womensday\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.82 ms /    16 runs   (    0.68 ms per token,  1478.88 tokens per second)\n",
            "llama_print_timings: prompt eval time =     311.99 ms /   122 tokens (    2.56 ms per token,   391.04 tokens per second)\n",
            "llama_print_timings:        eval time =    1857.17 ms /    15 runs   (  123.81 ms per token,     8.08 tokens per second)\n",
            "llama_print_timings:       total time =    2521.18 ms /   137 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "THE VENETIAN Resort | Las Vegas https://t.co/mERvhR7U2Z #NFTs #NFTCommunity #Cryptocomnft #crofam #NBA #WNBA #NYC #California #Crypto #UK #Houston #Calabasas #NewYork #Japan #Stocks #SouthKorea #Milan #ART #Investing # WomensDay #420 https://t.co/PclFsmCT68\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.66 ms /    16 runs   (    0.60 ms per token,  1656.66 tokens per second)\n",
            "llama_print_timings: prompt eval time =     313.76 ms /   128 tokens (    2.45 ms per token,   407.95 tokens per second)\n",
            "llama_print_timings:        eval time =    1551.35 ms /    15 runs   (  103.42 ms per token,     9.67 tokens per second)\n",
            "llama_print_timings:       total time =    2203.66 ms /   143 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "https://t.co/Zd3eFZFbq1We are ONE with the universeAlways forever, always#DiaInternacionalDeLosPueblosIndigenas #PueblosOriginarios#sanaYdespierta 🌟 #09Ago#Health #IndigenousDay #FelizMartesAtodos#IndigenousWomen #ALaTarde #cosmovision #WomensDay #women #tuesdayvibe https://t. co/B84EbKlpKq\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.10 ms /    16 runs   (    0.51 ms per token,  1974.82 tokens per second)\n",
            "llama_print_timings: prompt eval time =     261.22 ms /    60 tokens (    4.35 ms per token,   229.69 tokens per second)\n",
            "llama_print_timings:        eval time =    1570.81 ms /    15 runs   (  104.72 ms per token,     9.55 tokens per second)\n",
            "llama_print_timings:       total time =    2017.12 ms /    75 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "No. No. 1000x No. #WomensRights #WomensRights #WomensRights #WomensRightsAreHumanRights https://t.co/VawqXrPS6o\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.69 ms /    16 runs   (    0.54 ms per token,  1842.04 tokens per second)\n",
            "llama_print_timings: prompt eval time =     274.87 ms /    78 tokens (    3.52 ms per token,   283.77 tokens per second)\n",
            "llama_print_timings:        eval time =    1554.59 ms /    15 runs   (  103.64 ms per token,     9.65 tokens per second)\n",
            "llama_print_timings:       total time =    2059.17 ms /    93 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "Putin hands over power, you can't with Ukraine and you can't with Russia #RusiavsUkraina #Rusia https://t.co/4jKJPQGAG4 #IranProtests2022 #WomensRights #RusiaVsUkraina\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.27 ms /    16 runs   (    0.64 ms per token,  1557.33 tokens per second)\n",
            "llama_print_timings: prompt eval time =     322.47 ms /   128 tokens (    2.52 ms per token,   396.93 tokens per second)\n",
            "llama_print_timings:        eval time =    1634.05 ms /    15 runs   (  108.94 ms per token,     9.18 tokens per second)\n",
            "llama_print_timings:       total time =    2529.23 ms /   143 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "DURADRY - EXCESSIVE PERSPIRATION &amp; ODOR CONTROLhttps://t.co/LpqaZa1JCG #wellness #Health #fitness #healthy #healthy #selfcare #Trending #TrendingNow #lifestyle #yoga #beauty #women #WomensRights #workouts #skincare #weightloss #lifedrawing #organic #natural #HealthyFood https://t.co/0IJJaqKWOX\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.26 ms /    16 runs   (    0.52 ms per token,  1938.22 tokens per second)\n",
            "llama_print_timings: prompt eval time =     305.17 ms /   103 tokens (    2.96 ms per token,   337.52 tokens per second)\n",
            "llama_print_timings:        eval time =    1567.81 ms /    15 runs   (  104.52 ms per token,     9.57 tokens per second)\n",
            "llama_print_timings:       total time =    2148.97 ms /   118 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "@emonioycambio @Nievessebastia1 So between naïf and vindictive💪The 80-year-old lady doing her exercises with her churros...#ArteDeMujeres #WomensArt#Globalwomen#WomensRights#WomensRightsAreHumanRights#LetJulieSwim https://t.co/y31wclW1ZR\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.33 ms /    16 runs   (    0.58 ms per token,  1715.82 tokens per second)\n",
            "llama_print_timings: prompt eval time =     276.65 ms /    86 tokens (    3.22 ms per token,   310.87 tokens per second)\n",
            "llama_print_timings:        eval time =    1592.68 ms /    15 runs   (  106.18 ms per token,     9.42 tokens per second)\n",
            "llama_print_timings:       total time =    2114.44 ms /   101 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "“There are two paths you can take, yours and the one that others choose for you” Enola 🦋#lasniñasCAN #enolaholmes #alone #laciudaddelasdiosas #womensrights #fightlikeagirl 💜💪🏻 https://t.co/YrtOgJ67qg\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.70 ms /    16 runs   (    0.67 ms per token,  1495.47 tokens per second)\n",
            "llama_print_timings: prompt eval time =     284.92 ms /    92 tokens (    3.10 ms per token,   322.90 tokens per second)\n",
            "llama_print_timings:        eval time =    1643.67 ms /    15 runs   (  109.58 ms per token,     9.13 tokens per second)\n",
            "llama_print_timings:       total time =    2222.39 ms /   107 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "https://t.co/eBQis5NnaO👈@purocuentomarce 👈Women's equality and empowerment is one of the 17 Sustainable Development Goals.#MujeresFuertes #women #WomensRights #education https://t.co/lgLa3Z6t4Z\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.24 ms /    16 runs   (    0.58 ms per token,  1732.35 tokens per second)\n",
            "llama_print_timings: prompt eval time =     253.00 ms /    52 tokens (    4.87 ms per token,   205.54 tokens per second)\n",
            "llama_print_timings:        eval time =    1597.00 ms /    15 runs   (  106.47 ms per token,     9.39 tokens per second)\n",
            "llama_print_timings:       total time =    2020.75 ms /    67 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "Come on, friends. Let's help a young champion for whom there are no yositecreo funds.#AnimoaEugenia https://t.co/b6uJ67turr\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.81 ms /    16 runs   (    0.61 ms per token,  1630.99 tokens per second)\n",
            "llama_print_timings: prompt eval time =     261.25 ms /    57 tokens (    4.58 ms per token,   218.18 tokens per second)\n",
            "llama_print_timings:        eval time =    1578.33 ms /    15 runs   (  105.22 ms per token,     9.50 tokens per second)\n",
            "llama_print_timings:       total time =    2043.50 ms /    72 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "#yositeI think what Wednesday is this? Believe without evidence, send men to prison for just being men? I believe that a male collective should be formed that fights at least for equality as the constitutions of the countries surely dictate.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.61 ms /    16 runs   (    0.60 ms per token,  1665.28 tokens per second)\n",
            "llama_print_timings: prompt eval time =     269.35 ms /    67 tokens (    4.02 ms per token,   248.75 tokens per second)\n",
            "llama_print_timings:        eval time =    1449.26 ms /    15 runs   (   96.62 ms per token,    10.35 tokens per second)\n",
            "llama_print_timings:       total time =    1939.24 ms /    82 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "@mariomojc Well, it is true that judging is up to the judge, but the reality is harsher than the case of a comedian because hundreds of women who report being raped are judged every day on networks, in society and in justice. #I do believe you\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.61 ms /    16 runs   (    0.66 ms per token,  1507.44 tokens per second)\n",
            "llama_print_timings: prompt eval time =     266.94 ms /    52 tokens (    5.13 ms per token,   194.80 tokens per second)\n",
            "llama_print_timings:        eval time =    1620.93 ms /    15 runs   (  108.06 ms per token,     9.25 tokens per second)\n",
            "llama_print_timings:       total time =    2167.39 ms /    67 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "We won't let them take the girl. #YoSiTeCreo #ASIEsTortura #JusticiaPorCoiris https://t.co/PCbKw732PM\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.76 ms /    16 runs   (    0.55 ms per token,  1825.86 tokens per second)\n",
            "llama_print_timings: prompt eval time =     240.13 ms /    42 tokens (    5.72 ms per token,   174.90 tokens per second)\n",
            "llama_print_timings:        eval time =    1689.18 ms /    15 runs   (  112.61 ms per token,     8.88 tokens per second)\n",
            "llama_print_timings:       total time =    2083.61 ms /    57 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "How elegant it is... Without saying anything, just pressing play... Inside the video. #YoSiTeCreo #InElNombreDeRocio12\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.87 ms /    16 runs   (    0.62 ms per token,  1621.73 tokens per second)\n",
            "llama_print_timings: prompt eval time =     300.63 ms /   110 tokens (    2.73 ms per token,   365.90 tokens per second)\n",
            "llama_print_timings:        eval time =    1557.58 ms /    15 runs   (  103.84 ms per token,     9.63 tokens per second)\n",
            "llama_print_timings:       total time =    2154.39 ms /   125 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "@JairoDurn16 @CorreAlexandra @ICBFColombia @VivianaVargasVi @yositecreo__ @cristinaplazasm @afectoenlinea @RedPaPaz @DianaLuzBornac1 @Solaris144 @conciliador70 @episcopadocol You find them for “current news”. If you share an email with me I can send them to you right now….\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.59 ms /    16 runs   (    0.72 ms per token,  1380.14 tokens per second)\n",
            "llama_print_timings: prompt eval time =     257.87 ms /    50 tokens (    5.16 ms per token,   193.90 tokens per second)\n",
            "llama_print_timings:        eval time =    1851.83 ms /    15 runs   (  123.46 ms per token,     8.10 tokens per second)\n",
            "llama_print_timings:       total time =    2320.12 ms /    65 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "@biobio But it's true. This thing about women having to be given edoacios is an undeserved privilege. But equal or better workers than men. We don't have to receive charity!!\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.57 ms /    16 runs   (    0.54 ms per token,  1866.54 tokens per second)\n",
            "llama_print_timings: prompt eval time =     609.62 ms /    32 tokens (   19.05 ms per token,    52.49 tokens per second)\n",
            "llama_print_timings:        eval time =    1603.68 ms /    15 runs   (  106.91 ms per token,     9.35 tokens per second)\n",
            "llama_print_timings:       total time =    2362.11 ms /    47 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "You have to make women tremble with pleasure... Right? https://t.co/jJTEOY0tU9\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.72 ms /    16 runs   (    0.55 ms per token,  1834.86 tokens per second)\n",
            "llama_print_timings: prompt eval time =     234.40 ms /    34 tokens (    6.89 ms per token,   145.05 tokens per second)\n",
            "llama_print_timings:        eval time =    1512.79 ms /    15 runs   (  100.85 ms per token,     9.92 tokens per second)\n",
            "llama_print_timings:       total time =    1888.47 ms /    49 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "To know what women are interested in, you have to talk to a champion https://t.co/nQz4lyXY3d\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.28 ms /    16 runs   (    0.58 ms per token,  1723.77 tokens per second)\n",
            "llama_print_timings: prompt eval time =     252.68 ms /    59 tokens (    4.28 ms per token,   233.49 tokens per second)\n",
            "llama_print_timings:        eval time =    1568.81 ms /    15 runs   (  104.59 ms per token,     9.56 tokens per second)\n",
            "llama_print_timings:       total time =    2009.57 ms /    74 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "@JoseMAcevedo Women have to be applauded for everything like a retarded seal so as not to look like an oppressive male; These acts should have legal consequences, that they should be put in jail so that they learn to respect.\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.53 ms /    16 runs   (    0.66 ms per token,  1519.90 tokens per second)\n",
            "llama_print_timings: prompt eval time =     254.21 ms /    35 tokens (    7.26 ms per token,   137.68 tokens per second)\n",
            "llama_print_timings:        eval time =    1842.60 ms /    15 runs   (  122.84 ms per token,     8.14 tokens per second)\n",
            "llama_print_timings:       total time =    2264.55 ms /    50 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "HAHAHAHAHA WOMEN SHOULD BE AFRAID https://t.co/60TBOUEYRg\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.82 ms /    16 runs   (    0.61 ms per token,  1629.16 tokens per second)\n",
            "llama_print_timings: prompt eval time =     281.48 ms /    81 tokens (    3.48 ms per token,   287.76 tokens per second)\n",
            "llama_print_timings:        eval time =    1461.64 ms /    15 runs   (   97.44 ms per token,    10.26 tokens per second)\n",
            "llama_print_timings:       total time =    1975.74 ms /    96 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "@Its_too_cold Isn't it indirectly saying that if a guy doesn't respect women it's because he hasn't touched them, isn't it indirectly saying that to respect women you have to first be able to touch them? It is better to focus on the resentment of some incels than on their celibacy itself\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.00 ms /    16 runs   (    0.56 ms per token,  1778.77 tokens per second)\n",
            "llama_print_timings: prompt eval time =     268.21 ms /    62 tokens (    4.33 ms per token,   231.16 tokens per second)\n",
            "llama_print_timings:        eval time =    1486.12 ms /    15 runs   (   99.07 ms per token,    10.09 tokens per second)\n",
            "llama_print_timings:       total time =    1952.68 ms /    77 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "@SIEBELIS @T13 God, if these people of approval are all mentally ill, temptation is called to abuse someone, that is not temptation clown, one thing is that you get excited by x people and another is that you fall into that supposed temptation\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.47 ms /    16 runs   (    0.59 ms per token,  1689.55 tokens per second)\n",
            "llama_print_timings: prompt eval time =     284.68 ms /    84 tokens (    3.39 ms per token,   295.07 tokens per second)\n",
            "llama_print_timings:        eval time =    1553.12 ms /    15 runs   (  103.54 ms per token,     9.66 tokens per second)\n",
            "llama_print_timings:       total time =    2079.06 ms /    99 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "@rsgarc Thanks for sharing. I had to go through something similar and, yes, as soon as I started giving shit, it was over, when I was 11 years old. Judo helped me. Now... the same thing happened to me, I started abusing one. I cut him off as soon as I realized my shitty attitude. I hope he forgives me.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.45 ms /    16 runs   (    0.59 ms per token,  1694.02 tokens per second)\n",
            "llama_print_timings: prompt eval time =     289.00 ms /    77 tokens (    3.75 ms per token,   266.44 tokens per second)\n",
            "llama_print_timings:        eval time =    1511.18 ms /    15 runs   (  100.75 ms per token,     9.93 tokens per second)\n",
            "llama_print_timings:       total time =    2025.97 ms /    92 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "@Jagarciar14 @_AlexMico for abusing a five-year-old girl when he was 17, claims that the young woman has flatly denied in a letter sent to the Efe agency. If we publish the news, we will do it in full, if it is not manipulation and that is very ugly\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.20 ms /    16 runs   (    0.58 ms per token,  1738.56 tokens per second)\n",
            "llama_print_timings: prompt eval time =     238.09 ms /    36 tokens (    6.61 ms per token,   151.20 tokens per second)\n",
            "llama_print_timings:        eval time =    1586.12 ms /    15 runs   (  105.74 ms per token,     9.46 tokens per second)\n",
            "llama_print_timings:       total time =    1978.89 ms /    51 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "@Juana56973095 @PatriotaSlater Alejandro Vega to prison for abusing the Chilean army.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.78 ms /    16 runs   (    0.61 ms per token,  1635.49 tokens per second)\n",
            "llama_print_timings: prompt eval time =     265.53 ms /    56 tokens (    4.74 ms per token,   210.90 tokens per second)\n",
            "llama_print_timings:        eval time =    1569.60 ms /    15 runs   (  104.64 ms per token,     9.56 tokens per second)\n",
            "llama_print_timings:       total time =    2019.72 ms /    71 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "#RecuentodelasemanaMP Man sentenced to 16 years in prison for sexually abusing his daughter in Yaracuy https://t.co/rXIXm20GQr #29Ago\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.20 ms /    16 runs   (    0.64 ms per token,  1568.63 tokens per second)\n",
            "llama_print_timings: prompt eval time =     281.56 ms /    87 tokens (    3.24 ms per token,   308.99 tokens per second)\n",
            "llama_print_timings:        eval time =    1671.07 ms /    15 runs   (  111.40 ms per token,     8.98 tokens per second)\n",
            "llama_print_timings:       total time =    2226.72 ms /   102 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "@TucitaRules_ Yes, because she also later says that she is leaving with another guy and makes the insinuation that they abused her again... Either she is simply too weak to walk on the street or she is simply the most permissible victim in the world: I mean when a woman doesn't want to, scratch, kick, bite or something, she doesn't.\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.50 ms /    16 runs   (    0.59 ms per token,  1683.86 tokens per second)\n",
            "llama_print_timings: prompt eval time =     255.83 ms /    50 tokens (    5.12 ms per token,   195.44 tokens per second)\n",
            "llama_print_timings:        eval time =    1503.59 ms /    15 runs   (  100.24 ms per token,     9.98 tokens per second)\n",
            "llama_print_timings:       total time =    1934.79 ms /    65 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "@marthaperaltae I come to remind you that #TaxReform is an abuse of the people's pockets. Don't justify it with the story of sugar and then promote the legality of coca\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.33 ms /    16 runs   (    0.58 ms per token,  1714.71 tokens per second)\n",
            "llama_print_timings: prompt eval time =     257.70 ms /    44 tokens (    5.86 ms per token,   170.74 tokens per second)\n",
            "llama_print_timings:        eval time =    1475.95 ms /    15 runs   (   98.40 ms per token,    10.16 tokens per second)\n",
            "llama_print_timings:       total time =    1899.19 ms /    59 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "@EAristeguieta @cruzmaldonado2 Prisoners have to blame the tococo and his police henchmen, for being complicit in this abuse.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.54 ms /    16 runs   (    0.60 ms per token,  1676.45 tokens per second)\n",
            "llama_print_timings: prompt eval time =     285.69 ms /    70 tokens (    4.08 ms per token,   245.02 tokens per second)\n",
            "llama_print_timings:        eval time =    1649.71 ms /    15 runs   (  109.98 ms per token,     9.09 tokens per second)\n",
            "llama_print_timings:       total time =    2147.08 ms /    85 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "@jccay81 @MariettoPonce He uses and abuses power to relieve his trauma, he enjoys being greeted and thanked. Poverty grows, and jobs decrease, inflation rises and food becomes more expensive, he is grateful for what? Is its popularity fair? Does he believe it?\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.84 ms /    16 runs   (    0.61 ms per token,  1626.68 tokens per second)\n",
            "llama_print_timings: prompt eval time =     289.72 ms /    83 tokens (    3.49 ms per token,   286.48 tokens per second)\n",
            "llama_print_timings:        eval time =    1493.48 ms /    15 runs   (   99.57 ms per token,    10.04 tokens per second)\n",
            "llama_print_timings:       total time =    2032.33 ms /    98 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "@GuaroAtravesado @TarekWiliamSaab The @TareckPSUV likes these types of procedures, police excesses. In a country with separation of powers and real justice, these police officers are brought to the attention of the prosecution for abuse. They want to solve everything in a bad way, with blows and with improper procedures.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.12 ms /    16 runs   (    0.57 ms per token,  1754.00 tokens per second)\n",
            "llama_print_timings: prompt eval time =     242.55 ms /    35 tokens (    6.93 ms per token,   144.30 tokens per second)\n",
            "llama_print_timings:        eval time =    1541.03 ms /    15 runs   (  102.74 ms per token,     9.73 tokens per second)\n",
            "llama_print_timings:       total time =    1928.94 ms /    50 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "They investigate a man in Tulancingo for aggravated sexual abuse https://t.co/1Fcx2lqr9g\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.88 ms /    16 runs   (    0.62 ms per token,  1620.09 tokens per second)\n",
            "llama_print_timings: prompt eval time =     253.84 ms /    60 tokens (    4.23 ms per token,   236.37 tokens per second)\n",
            "llama_print_timings:        eval time =    1563.81 ms /    15 runs   (  104.25 ms per token,     9.59 tokens per second)\n",
            "llama_print_timings:       total time =    2016.59 ms /    75 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "What's up, they're telling you that you indirectly or directly defended a woman who psychologically, physically and sexually abused a person and you give the speech about OH BUT THE MEN??? Dude no one is talking about them now\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.04 ms /    16 runs   (    0.63 ms per token,  1593.47 tokens per second)\n",
            "llama_print_timings: prompt eval time =     254.85 ms /    39 tokens (    6.53 ms per token,   153.03 tokens per second)\n",
            "llama_print_timings:        eval time =    1830.03 ms /    15 runs   (  122.00 ms per token,     8.20 tokens per second)\n",
            "llama_print_timings:       total time =    2254.04 ms /    54 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "Hello August; I promise to move forward with determination and patience... I decree that every positive action will bear fruit so that the doors to new opportunities are effectively opened.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.50 ms /    16 runs   (    0.53 ms per token,  1883.46 tokens per second)\n",
            "llama_print_timings: prompt eval time =     725.49 ms /    28 tokens (   25.91 ms per token,    38.59 tokens per second)\n",
            "llama_print_timings:        eval time =    1658.22 ms /    15 runs   (  110.55 ms per token,     9.05 tokens per second)\n",
            "llama_print_timings:       total time =    2511.34 ms /    43 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "Making my bed, the first positive action of the day😊Let's have a nice day my people!\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.67 ms /    16 runs   (    0.54 ms per token,  1845.66 tokens per second)\n",
            "llama_print_timings: prompt eval time =     252.80 ms /    47 tokens (    5.38 ms per token,   185.92 tokens per second)\n",
            "llama_print_timings:        eval time =    1561.67 ms /    15 runs   (  104.11 ms per token,     9.61 tokens per second)\n",
            "llama_print_timings:       total time =    1986.82 ms /    62 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "@MXESTADIOS Why do many people have to detract from some positive action? Why are we like this? Or that the person is bad, or that my team is better? let it be\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      14.14 ms /    16 runs   (    0.88 ms per token,  1131.70 tokens per second)\n",
            "llama_print_timings: prompt eval time =     286.40 ms /    73 tokens (    3.92 ms per token,   254.89 tokens per second)\n",
            "llama_print_timings:        eval time =    1880.38 ms /    15 runs   (  125.36 ms per token,     7.98 tokens per second)\n",
            "llama_print_timings:       total time =    2423.85 ms /    88 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "national judiciary: Call positive action for discrimination. They economically discriminate against #women and #men for life for being #CivilGuard. Their professional career and retirement have to be recognized in salaries and remunerations like police officers… https://t. co/ShDiXpJf6z\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.36 ms /    16 runs   (    0.59 ms per token,  1709.04 tokens per second)\n",
            "llama_print_timings: prompt eval time =     275.49 ms /    74 tokens (    3.72 ms per token,   268.61 tokens per second)\n",
            "llama_print_timings:        eval time =    1530.53 ms /    15 runs   (  102.04 ms per token,     9.80 tokens per second)\n",
            "llama_print_timings:       total time =    2024.46 ms /    89 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "@SebasDrummer This rating is a shame, an analysis of the causes would be good... However, good news does not make headlines, please look for it, it would be a positive action for the benefit of the entire country! Here is one: https://t. co/NMR0oFwIrJ\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.94 ms /    16 runs   (    0.56 ms per token,  1790.11 tokens per second)\n",
            "llama_print_timings: prompt eval time =     260.19 ms /    47 tokens (    5.54 ms per token,   180.64 tokens per second)\n",
            "llama_print_timings:        eval time =    1453.20 ms /    15 runs   (   96.88 ms per token,    10.32 tokens per second)\n",
            "llama_print_timings:       total time =    1883.39 ms /    62 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "The #QuitoConsensus is an agreement between countries to adopt positive action measures and necessary mechanisms, including legislative reforms and budget allocations, to guarantee the participation of women in public positions and political representation\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.22 ms /    16 runs   (    0.58 ms per token,  1734.61 tokens per second)\n",
            "llama_print_timings: prompt eval time =     257.66 ms /    72 tokens (    3.58 ms per token,   279.44 tokens per second)\n",
            "llama_print_timings:        eval time =    1533.66 ms /    15 runs   (  102.24 ms per token,     9.78 tokens per second)\n",
            "llama_print_timings:       total time =    2006.41 ms /    87 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "@EdgarSanchezSV Let the Law be the one that imposes Freedom or Prison! IN THIS COUNTRY YOU CAN NO LONGER DEFAME PEOPLE, YOU SHOULD NOT HARASS WOMEN, AND YOU SHOULD NOT THREATEN OTHERS!\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.29 ms /    16 runs   (    0.71 ms per token,  1416.93 tokens per second)\n",
            "llama_print_timings: prompt eval time =     596.88 ms /    22 tokens (   27.13 ms per token,    36.86 tokens per second)\n",
            "llama_print_timings:        eval time =    1829.27 ms /    15 runs   (  121.95 ms per token,     8.20 tokens per second)\n",
            "llama_print_timings:       total time =    2571.49 ms /    37 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "I just followed a Draven bot, I'm going to sexually harass him\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.72 ms /    16 runs   (    0.61 ms per token,  1646.09 tokens per second)\n",
            "llama_print_timings: prompt eval time =     285.86 ms /    72 tokens (    3.97 ms per token,   251.87 tokens per second)\n",
            "llama_print_timings:        eval time =    1542.08 ms /    15 runs   (  102.81 ms per token,     9.73 tokens per second)\n",
            "llama_print_timings:       total time =    2049.96 ms /    87 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "@Liberalize In other words; ABORTION IS a right, specifically A SEXUAL RIGHT, regardless of who is going to do it and their reasons. What IS NOT A RIGHT is to criticize, insult, harass, etc., someone for deciding about their own life, which does NOT affect yours.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.67 ms /    16 runs   (    0.60 ms per token,  1654.94 tokens per second)\n",
            "llama_print_timings: prompt eval time =     251.89 ms /    62 tokens (    4.06 ms per token,   246.14 tokens per second)\n",
            "llama_print_timings:        eval time =    1526.36 ms /    15 runs   (  101.76 ms per token,     9.83 tokens per second)\n",
            "llama_print_timings:       total time =    1988.20 ms /    77 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "You think you have the right to harass my boyfriend just for being a woman, I think everyone here agrees that being of any sex doesn't make you better than anyone else. #feminist #bullying https://t.co/DbUPc9s0Uz\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.12 ms /    16 runs   (    0.57 ms per token,  1754.77 tokens per second)\n",
            "llama_print_timings: prompt eval time =     280.35 ms /    67 tokens (    4.18 ms per token,   238.99 tokens per second)\n",
            "llama_print_timings:        eval time =    1574.34 ms /    15 runs   (  104.96 ms per token,     9.53 tokens per second)\n",
            "llama_print_timings:       total time =    2057.14 ms /    82 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "@FanboydeJinx But don't give them the pleasure of letting this affect you. Also what did you expect? If they start harassing it is obvious that they are going to gain the block, that's what it's for and you don't have to feel guilty.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.16 ms /    16 runs   (    0.64 ms per token,  1574.49 tokens per second)\n",
            "llama_print_timings: prompt eval time =     253.27 ms /    43 tokens (    5.89 ms per token,   169.78 tokens per second)\n",
            "llama_print_timings:        eval time =    1722.59 ms /    15 runs   (  114.84 ms per token,     8.71 tokens per second)\n",
            "llama_print_timings:       total time =    2215.48 ms /    58 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "Congratulations, I haven't harassed an aunt for doing eyeliner in 19 years https://t.co/O05Pogd1mV\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.46 ms /    16 runs   (    0.59 ms per token,  1691.51 tokens per second)\n",
            "llama_print_timings: prompt eval time =     257.82 ms /    51 tokens (    5.06 ms per token,   197.81 tokens per second)\n",
            "llama_print_timings:        eval time =    1559.85 ms /    15 runs   (  103.99 ms per token,     9.62 tokens per second)\n",
            "llama_print_timings:       total time =    1988.72 ms /    66 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "@Claudit09685351 This is not the first time, a complaint was made with email included to the head of dideco for sexual harassment and they did not take it into account...\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.63 ms /    16 runs   (    0.60 ms per token,  1661.82 tokens per second)\n",
            "llama_print_timings: prompt eval time =     281.25 ms /    78 tokens (    3.61 ms per token,   277.34 tokens per second)\n",
            "llama_print_timings:        eval time =    1531.51 ms /    15 runs   (  102.10 ms per token,     9.79 tokens per second)\n",
            "llama_print_timings:       total time =    2039.64 ms /    93 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "It is urgent to implement a culture of prevention against workplace sexual harassment. Sexual harassment not only causes serious harm to the victim but also affects the productivity of the company. These are not isolated events, there is a system that allows this to happen. #stopacoso https ://t.co/2d5aJ5C7HU\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.87 ms /    16 runs   (    0.68 ms per token,  1471.94 tokens per second)\n",
            "llama_print_timings: prompt eval time =     265.65 ms /    71 tokens (    3.74 ms per token,   267.27 tokens per second)\n",
            "llama_print_timings:        eval time =    1754.77 ms /    15 runs   (  116.98 ms per token,     8.55 tokens per second)\n",
            "llama_print_timings:       total time =    2257.76 ms /    86 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "⚠️TW//Sexual harassment\"The silence that fills Volkov and Foster's patrol car has already become its natural environment. No one speaks, no one even deigns to say a word. Volkov because he has nothing to say (and prefers the calm down rather than force a conversation\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.43 ms /    16 runs   (    0.59 ms per token,  1697.25 tokens per second)\n",
            "llama_print_timings: prompt eval time =     269.27 ms /    59 tokens (    4.56 ms per token,   219.11 tokens per second)\n",
            "llama_print_timings:        eval time =    1502.92 ms /    15 runs   (  100.19 ms per token,     9.98 tokens per second)\n",
            "llama_print_timings:       total time =    1968.75 ms /    74 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "🔴 Michoacán School Director is reported for sexual harassment https://t.co/iB2NvDCpIV #morelia #michoacán #pátzcuaro #uruapan #apatzingán #huiramba\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.29 ms /    16 runs   (    0.58 ms per token,  1721.36 tokens per second)\n",
            "llama_print_timings: prompt eval time =     277.72 ms /    81 tokens (    3.43 ms per token,   291.67 tokens per second)\n",
            "llama_print_timings:        eval time =    1589.25 ms /    15 runs   (  105.95 ms per token,     9.44 tokens per second)\n",
            "llama_print_timings:       total time =    2101.13 ms /    96 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "@David34213465 @Jiobbit A lot of text to conclude nothing. Let me explain to you, it is sexual harassment when you make advances or comments of a sexual nature to a person without their consent, trust is a non-determining factor, they can even be best friends and still do not consent to that type of\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.01 ms /    16 runs   (    0.63 ms per token,  1598.08 tokens per second)\n",
            "llama_print_timings: prompt eval time =     293.66 ms /    86 tokens (    3.41 ms per token,   292.86 tokens per second)\n",
            "llama_print_timings:        eval time =    1628.83 ms /    15 runs   (  108.59 ms per token,     9.21 tokens per second)\n",
            "llama_print_timings:       total time =    2181.07 ms /   101 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "Law 21,369, which regulates sexual harassment, violence and gender discrimination on higher education campuses; It came into effect on September 15, 2021 and marks one year for an implementation that confirms the UAHC's commitment to these standards in its culture https://t.co/qYDHtlgXuK\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.49 ms /    16 runs   (    0.59 ms per token,  1685.45 tokens per second)\n",
            "llama_print_timings: prompt eval time =     264.97 ms /    53 tokens (    5.00 ms per token,   200.02 tokens per second)\n",
            "llama_print_timings:        eval time =    1454.43 ms /    15 runs   (   96.96 ms per token,    10.31 tokens per second)\n",
            "llama_print_timings:       total time =    1897.91 ms /    68 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "@Onlyboy_2 Be careful because the customer can sue the store because his employee harassed him or touched him in a sexual way.... The employee was courteously helpful and attentive,... Leaving work will be different.....\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.65 ms /    16 runs   (    0.54 ms per token,  1849.71 tokens per second)\n",
            "llama_print_timings: prompt eval time =     232.76 ms /    33 tokens (    7.05 ms per token,   141.77 tokens per second)\n",
            "llama_print_timings:        eval time =    1561.16 ms /    15 runs   (  104.08 ms per token,     9.61 tokens per second)\n",
            "llama_print_timings:       total time =    1928.64 ms /    48 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "Sexual harassment in the workplace by the boss and other employees https://t.co/90mnbZjwwD\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.70 ms /    16 runs   (    0.61 ms per token,  1649.65 tokens per second)\n",
            "llama_print_timings: prompt eval time =     270.26 ms /    80 tokens (    3.38 ms per token,   296.01 tokens per second)\n",
            "llama_print_timings:        eval time =    1505.47 ms /    15 runs   (  100.36 ms per token,     9.96 tokens per second)\n",
            "llama_print_timings:       total time =    2004.92 ms /    95 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "@DaMoralesDel @realmalpa4ever Hey, that's okay... Or maybe @Matador000 has already recanted for her harassment of Duque⁉️🤔 I haven't seen Glutona @smilelalis do it either. https://t.co/kqnwuk7cS4\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.16 ms /    16 runs   (    0.63 ms per token,  1575.42 tokens per second)\n",
            "llama_print_timings: prompt eval time =     252.47 ms /    58 tokens (    4.35 ms per token,   229.73 tokens per second)\n",
            "llama_print_timings:        eval time =    1650.03 ms /    15 runs   (  110.00 ms per token,     9.09 tokens per second)\n",
            "llama_print_timings:       total time =    2097.22 ms /    73 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "lazy people who want to live dependent on other people's children, better the famous people who respect the privacy and safety of their children in this horrible world full of child harassment and pedophilia https://t.co/FfqqDBFWnv\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.70 ms /    16 runs   (    0.61 ms per token,  1649.31 tokens per second)\n",
            "llama_print_timings: prompt eval time =     264.08 ms /    57 tokens (    4.63 ms per token,   215.84 tokens per second)\n",
            "llama_print_timings:        eval time =    1662.72 ms /    15 runs   (  110.85 ms per token,     9.02 tokens per second)\n",
            "llama_print_timings:       total time =    2228.57 ms /    72 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "@cantaletica How much I testified in a case of harassment of a friend of his, his reaction was to make comments like “that's why they rape them” “that's why they kill them” ☹️\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.76 ms /    16 runs   (    0.61 ms per token,  1640.18 tokens per second)\n",
            "llama_print_timings: prompt eval time =     287.84 ms /    74 tokens (    3.89 ms per token,   257.09 tokens per second)\n",
            "llama_print_timings:        eval time =    1565.82 ms /    15 runs   (  104.39 ms per token,     9.58 tokens per second)\n",
            "llama_print_timings:       total time =    2076.38 ms /    89 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "#BailaViniJr#ApagonAlChiringuito@RonyVargasV, come on coward, speak out against racism and harassment of one of the best players in the world or continue supporting #PedrerolMafioso! https://t.co/TRrijhy8Qb\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.35 ms /    16 runs   (    0.58 ms per token,  1710.86 tokens per second)\n",
            "llama_print_timings: prompt eval time =     278.23 ms /    70 tokens (    3.97 ms per token,   251.59 tokens per second)\n",
            "llama_print_timings:        eval time =    1622.05 ms /    15 runs   (  108.14 ms per token,     9.25 tokens per second)\n",
            "llama_print_timings:       total time =    2117.63 ms /    85 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "@elperiodico They call it liquid love, you are the worst, bad approach to everything, more unhappiness, empty people in search of permanent satisfaction, chasing the chimera all your fucking life... Good business for selling smokes, psychologists and pharmacists, go ahead and everyone go catch the wind\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.96 ms /    16 runs   (    0.75 ms per token,  1337.46 tokens per second)\n",
            "llama_print_timings: prompt eval time =     381.31 ms /   149 tokens (    2.56 ms per token,   390.76 tokens per second)\n",
            "llama_print_timings:        eval time =    1868.66 ms /    15 runs   (  124.58 ms per token,     8.03 tokens per second)\n",
            "llama_print_timings:       total time =    2924.65 ms /   164 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "KATIA MIRANDA👉 \"Fascinus V\" and \"Amor liquido\" both from the series visual labyrinths, works of art that you can find in our Í𝗔 𝗩𝗜𝗥𝗧𝗨𝗔𝗟! https://t.co/lozR3uKMXs or write to WhatsApp: 4579-9170 #ElAttico #Guatemala #KatiaMiranda #Lienzo #Obrasdearte https://t.co/ptNGLG60yK\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.83 ms /    16 runs   (    0.55 ms per token,  1812.62 tokens per second)\n",
            "llama_print_timings: prompt eval time =     251.29 ms /    33 tokens (    7.61 ms per token,   131.32 tokens per second)\n",
            "llama_print_timings:        eval time =    1563.14 ms /    15 runs   (  104.21 ms per token,     9.60 tokens per second)\n",
            "llama_print_timings:       total time =    1960.41 ms /    48 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "THIS, you feel out of place in this world of liquid love. https://t.co/DFfeslUgIZ\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.00 ms /    16 runs   (    0.56 ms per token,  1778.57 tokens per second)\n",
            "llama_print_timings: prompt eval time =     281.68 ms /    85 tokens (    3.31 ms per token,   301.76 tokens per second)\n",
            "llama_print_timings:        eval time =    1522.28 ms /    15 runs   (  101.49 ms per token,     9.85 tokens per second)\n",
            "llama_print_timings:       total time =    2051.41 ms /   100 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "Not even giving ass is binding, stop writing nonsense that love is not chosen, it is only given, whether they give ass or not, whether they suck it or not, whether they allow themselves to be spit on or not.Liquid Love, Zygmunt Bauman, 2022. https:/ /t.co/y4CCxrbZyd\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.79 ms /    16 runs   (    0.55 ms per token,  1819.42 tokens per second)\n",
            "llama_print_timings: prompt eval time =     781.71 ms /    31 tokens (   25.22 ms per token,    39.66 tokens per second)\n",
            "llama_print_timings:        eval time =    1528.06 ms /    15 runs   (  101.87 ms per token,     9.82 tokens per second)\n",
            "llama_print_timings:       total time =    2441.14 ms /    46 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "I want to read \"Liquid Love\" https://t.co/UR7csNUQ0g #skoob\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      12.08 ms /    16 runs   (    0.76 ms per token,  1324.50 tokens per second)\n",
            "llama_print_timings: prompt eval time =     268.34 ms /    71 tokens (    3.78 ms per token,   264.59 tokens per second)\n",
            "llama_print_timings:        eval time =    1807.81 ms /    15 runs   (  120.52 ms per token,     8.30 tokens per second)\n",
            "llama_print_timings:       total time =    2448.41 ms /    86 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "If you want to think a little more about this you can research \"liquid love\" and \"liquid modernity\" by sociologist Zygmunt Bauman; I also drew some conclusions from the book psychology and economics by Raymundo Campos and from research by neuroscientist Dar Meshi.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.46 ms /    16 runs   (    0.53 ms per token,  1890.14 tokens per second)\n",
            "llama_print_timings: prompt eval time =     710.82 ms /    28 tokens (   25.39 ms per token,    39.39 tokens per second)\n",
            "llama_print_timings:        eval time =    1558.55 ms /    15 runs   (  103.90 ms per token,     9.62 tokens per second)\n",
            "llama_print_timings:       total time =    2397.46 ms /    43 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "going to drama plot to look for recommendations of dramas that make me agonize over romantic love, good night\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.08 ms /    16 runs   (    0.63 ms per token,  1587.93 tokens per second)\n",
            "llama_print_timings: prompt eval time =     263.95 ms /    60 tokens (    4.40 ms per token,   227.31 tokens per second)\n",
            "llama_print_timings:        eval time =    1464.78 ms /    15 runs   (   97.65 ms per token,    10.24 tokens per second)\n",
            "llama_print_timings:       total time =    1926.05 ms /    75 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "Is it more natural to behave like Romeo and Juliet, paradigms of the myth of romantic love? Or like the promiscuous Casanova and Don Juan Tenorio? 🤔https://t.co/8kT545EsLM\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.70 ms /    16 runs   (    0.54 ms per token,  1839.08 tokens per second)\n",
            "llama_print_timings: prompt eval time =     694.64 ms /    26 tokens (   26.72 ms per token,    37.43 tokens per second)\n",
            "llama_print_timings:        eval time =    1513.07 ms /    15 runs   (  100.87 ms per token,     9.91 tokens per second)\n",
            "llama_print_timings:       total time =    2338.90 ms /    41 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "nonono revived romantic love 😭 https://t.co/AhbPO81rCB\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.45 ms /    16 runs   (    0.65 ms per token,  1530.66 tokens per second)\n",
            "llama_print_timings: prompt eval time =     293.75 ms /    81 tokens (    3.63 ms per token,   275.75 tokens per second)\n",
            "llama_print_timings:        eval time =    1692.75 ms /    15 runs   (  112.85 ms per token,     8.86 tokens per second)\n",
            "llama_print_timings:       total time =    2363.22 ms /    96 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "«The loneliness and obligatory solipsistic air of #ConcepciónArenal also has good visual moments, such as the scenes in the forest with her dog and under the northern rain, or her epiphany on the balcony in Madrid, which links potential romantic love, + https ://t.co/dlpAXhqjlk\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.56 ms /    16 runs   (    0.54 ms per token,  1868.50 tokens per second)\n",
            "llama_print_timings: prompt eval time =     734.45 ms /    27 tokens (   27.20 ms per token,    36.76 tokens per second)\n",
            "llama_print_timings:        eval time =    1593.01 ms /    15 runs   (  106.20 ms per token,     9.42 tokens per second)\n",
            "llama_print_timings:       total time =    2456.92 ms /    42 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "And without romantic love taking over the relationship https://t.co/kNxs0hfszH\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.59 ms /    16 runs   (    0.54 ms per token,  1863.50 tokens per second)\n",
            "llama_print_timings: prompt eval time =     773.89 ms /    29 tokens (   26.69 ms per token,    37.47 tokens per second)\n",
            "llama_print_timings:        eval time =    1507.23 ms /    15 runs   (  100.48 ms per token,     9.95 tokens per second)\n",
            "llama_print_timings:       total time =    2417.62 ms /    44 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "the only one that makes romantic love work https://t.co/HdLlXoG5UW\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      12.02 ms /    16 runs   (    0.75 ms per token,  1331.00 tokens per second)\n",
            "llama_print_timings: prompt eval time =     274.44 ms /    72 tokens (    3.81 ms per token,   262.35 tokens per second)\n",
            "llama_print_timings:        eval time =    1874.32 ms /    15 runs   (  124.95 ms per token,     8.00 tokens per second)\n",
            "llama_print_timings:       total time =    2522.13 ms /    87 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "The elimination of sexist language and androcentrism is fundamental for the construction of a law with a gender perspective. #sinperspectivadegeneronohayjusticia #LeyMicaela #feminist lawyers #lawyers https://t.co/VPg05tMvcc\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.18 ms /    16 runs   (    0.57 ms per token,  1743.49 tokens per second)\n",
            "llama_print_timings: prompt eval time =     280.25 ms /    70 tokens (    4.00 ms per token,   249.78 tokens per second)\n",
            "llama_print_timings:        eval time =    1467.22 ms /    15 runs   (   97.81 ms per token,    10.22 tokens per second)\n",
            "llama_print_timings:       total time =    1959.96 ms /    85 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "Generally when there is cultural appropriation of these mystical/philosophical themes there is a tendency to adapt that to the androcentrism of the West. Something that, for example, happens in the Luke saga in Star Wars, where the Jedi issue seems only a matter for gentlemen.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.48 ms /    16 runs   (    0.53 ms per token,  1887.68 tokens per second)\n",
            "llama_print_timings: prompt eval time =     248.68 ms /    33 tokens (    7.54 ms per token,   132.70 tokens per second)\n",
            "llama_print_timings:        eval time =    1524.78 ms /    15 runs   (  101.65 ms per token,     9.84 tokens per second)\n",
            "llama_print_timings:       total time =    1915.63 ms /    48 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "*Feigns surprise*Androcentrism is still valid in the discipline, unfortunately. The fight continues✊🏼💜\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.89 ms /    16 runs   (    0.56 ms per token,  1798.97 tokens per second)\n",
            "llama_print_timings: prompt eval time =     585.65 ms /    23 tokens (   25.46 ms per token,    39.27 tokens per second)\n",
            "llama_print_timings:        eval time =    1571.25 ms /    15 runs   (  104.75 ms per token,     9.55 tokens per second)\n",
            "llama_print_timings:       total time =    2273.28 ms /    38 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "It is unacceptable that women are labeled bitches for facing androcentrism\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.20 ms /    16 runs   (    0.64 ms per token,  1569.09 tokens per second)\n",
            "llama_print_timings: prompt eval time =     254.39 ms /    41 tokens (    6.20 ms per token,   161.17 tokens per second)\n",
            "llama_print_timings:        eval time =    1792.48 ms /    15 runs   (  119.50 ms per token,     8.37 tokens per second)\n",
            "llama_print_timings:       total time =    2297.60 ms /    56 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "@gerardotc In these cases, as in so many others, the punishment always goes in the same direction. #Androcentrism #Misogyny\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.29 ms /    16 runs   (    0.58 ms per token,  1722.10 tokens per second)\n",
            "llama_print_timings: prompt eval time =     261.85 ms /    51 tokens (    5.13 ms per token,   194.77 tokens per second)\n",
            "llama_print_timings:        eval time =    1518.77 ms /    15 runs   (  101.25 ms per token,     9.88 tokens per second)\n",
            "llama_print_timings:       total time =    1956.88 ms /    66 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "Jose Manuel, don't give me a shitty explanation for a situation of real equality when all you are is a sexist saying sexist things, I can smell androcentrism from 8 kilometers away.\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.36 ms /    16 runs   (    0.65 ms per token,  1543.95 tokens per second)\n",
            "llama_print_timings: prompt eval time =     286.42 ms /    84 tokens (    3.41 ms per token,   293.28 tokens per second)\n",
            "llama_print_timings:        eval time =    1493.57 ms /    15 runs   (   99.57 ms per token,    10.04 tokens per second)\n",
            "llama_print_timings:       total time =    2041.82 ms /    99 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "@A_Aguinaga @congresoperu @PedroCastillo YOU ​​GO AND GIVE A CONFERENCE HOW TO KILL WOMEN BY STERILIZATIONS AND HOW TO AVOID POVERTY BY ELIMINATING UNBORN CHILDREN. YOU ARE THE WORST PERUVIAN\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.33 ms /    16 runs   (    0.58 ms per token,  1714.16 tokens per second)\n",
            "llama_print_timings: prompt eval time =     270.34 ms /    77 tokens (    3.51 ms per token,   284.83 tokens per second)\n",
            "llama_print_timings:        eval time =    1527.64 ms /    15 runs   (  101.84 ms per token,     9.82 tokens per second)\n",
            "llama_print_timings:       total time =    2018.12 ms /    92 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "@lamabe_05 La Mabe Mabelita: Go to kidnap, murder women, go to sell public positions, go to destroy health, education and security, go to have debt bonds and pay interest when the country's risk rises, go to steal the iess.LET'S DO WHAT LASSO SAYS!\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.86 ms /    16 runs   (    0.62 ms per token,  1622.55 tokens per second)\n",
            "llama_print_timings: prompt eval time =     674.80 ms /   424 tokens (    1.59 ms per token,   628.34 tokens per second)\n",
            "llama_print_timings:        eval time =    1512.74 ms /    15 runs   (  100.85 ms per token,     9.92 tokens per second)\n",
            "llama_print_timings:       total time =    3337.88 ms /   439 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "@abrilprimavera2 @Veva_leo @bolboreta_7 @beloki_ana @luismi754 @Joanna_S___ @yosoyasin @Ana81548224 @2Royma @Juania37281458 @Circe_______7 @IN100S0_2 @MireReedus @_BrujaAveria @Marimar66842849 @Anitawer2 @Amer9 30249141 @cargadodebalas @Angela17673286 @srtmatorra @AUSSIESYDNEY62 @Jennife46975531 @MdtValeria @Shane7019 @pepiquintanah @lagunadonosol @Dolores92662996 @PaUrdi7 @2021Felina @srtanyi @BeaGonzo @garciapeino @ARlunaris @parequeaclara @DolceFa81306422 @VetaPino @Merilin86445959 @Rosaros81600671 @Pili_Fleitas @encarter76 @Luna5003576 9 @CarmoMariela @xasminmoda @GUS85218471 @christianMHB1 @elReydelchoriso @laguna_donoso @mappaxxe @ChristianMarioH And in Prison should continue, but since the evidence does not seem sufficient, then out on the street. Abusing, raping and murdering women comes very cheap. #SUPPORT5A\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.68 ms /    16 runs   (    0.60 ms per token,  1653.58 tokens per second)\n",
            "llama_print_timings: prompt eval time =     269.44 ms /    74 tokens (    3.64 ms per token,   274.64 tokens per second)\n",
            "llama_print_timings:        eval time =    1593.50 ms /    15 runs   (  106.23 ms per token,     9.41 tokens per second)\n",
            "llama_print_timings:       total time =    2081.73 ms /    89 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "@RicardoMeb Secretary Ricardo Mejía in the morning you said that the case of Debanhi Escobar Basaldua will be brought to the FGR and we do not see this happening. We demand justice in this case as long as nothing is done, crime finds it easy to kidnap and murder women.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.84 ms /    16 runs   (    0.61 ms per token,  1626.51 tokens per second)\n",
            "llama_print_timings: prompt eval time =     277.25 ms /    83 tokens (    3.34 ms per token,   299.37 tokens per second)\n",
            "llama_print_timings:        eval time =    1496.32 ms /    15 runs   (   99.75 ms per token,    10.02 tokens per second)\n",
            "llama_print_timings:       total time =    2008.88 ms /    98 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "@pedrodlop1 @vox_es Hahahaha hahahahahahajananajjajajajja PUERTO DE SANTAMARIA 2. Although you are right, murdering women and children throughout Spain was most unconstitutional, they should have only murdered in Basque countries. Guillotine, dog dead...\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.09 ms /    16 runs   (    0.63 ms per token,  1585.89 tokens per second)\n",
            "llama_print_timings: prompt eval time =     249.92 ms /    36 tokens (    6.94 ms per token,   144.04 tokens per second)\n",
            "llama_print_timings:        eval time =    1709.87 ms /    15 runs   (  113.99 ms per token,     8.77 tokens per second)\n",
            "llama_print_timings:       total time =    2176.62 ms /    51 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "@real_Jepri @hugoesc31475407 Murdering women who knew and thought differently was Heresy\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.93 ms /    16 runs   (    0.56 ms per token,  1791.31 tokens per second)\n",
            "llama_print_timings: prompt eval time =     258.21 ms /    47 tokens (    5.49 ms per token,   182.02 tokens per second)\n",
            "llama_print_timings:        eval time =    1547.81 ms /    15 runs   (  103.19 ms per token,     9.69 tokens per second)\n",
            "llama_print_timings:       total time =    1974.06 ms /    62 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "A person with a mask passed by and I turned to see her because she looked attractive and it turned out that she was my ex, the sociologist, my God, why are you doing this to me?\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.61 ms /    16 runs   (    0.54 ms per token,  1858.52 tokens per second)\n",
            "llama_print_timings: prompt eval time =     238.74 ms /    34 tokens (    7.02 ms per token,   142.42 tokens per second)\n",
            "llama_print_timings:        eval time =    1620.28 ms /    15 runs   (  108.02 ms per token,     9.26 tokens per second)\n",
            "llama_print_timings:       total time =    2002.37 ms /    49 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "@fuedicho FRIDA LAHLO, she was attractive, MEXICAN race ⭐👍🐾💜\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.67 ms /    16 runs   (    0.60 ms per token,  1654.43 tokens per second)\n",
            "llama_print_timings: prompt eval time =     265.98 ms /    57 tokens (    4.67 ms per token,   214.31 tokens per second)\n",
            "llama_print_timings:        eval time =    1530.10 ms /    15 runs   (  102.01 ms per token,     9.80 tokens per second)\n",
            "llama_print_timings:       total time =    1983.29 ms /    72 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "@SperoniIris \".. about atomic energy in our country and the possibilities of creating electrical energy in isolated and low-population places.\" That is why electricity generated by nuclear energy is not attractive for private \"suppliers\": It restricts business ; obvious\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.93 ms /    16 runs   (    0.62 ms per token,  1611.44 tokens per second)\n",
            "llama_print_timings: prompt eval time =     258.12 ms /    36 tokens (    7.17 ms per token,   139.47 tokens per second)\n",
            "llama_print_timings:        eval time =    1700.32 ms /    15 runs   (  113.35 ms per token,     8.82 tokens per second)\n",
            "llama_print_timings:       total time =    2176.72 ms /    51 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "@Mercenary_Ignis Not bad... She's attractive, but they haven't spoken once.Pass... At least for the moment.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.17 ms /    16 runs   (    0.57 ms per token,  1745.01 tokens per second)\n",
            "llama_print_timings: prompt eval time =     257.39 ms /    53 tokens (    4.86 ms per token,   205.91 tokens per second)\n",
            "llama_print_timings:        eval time =    1489.63 ms /    15 runs   (   99.31 ms per token,    10.07 tokens per second)\n",
            "llama_print_timings:       total time =    1921.00 ms /    68 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "Manchester United makes the hiring of Casemiro official: The Brazilian player will be an attractive card for Manchester United who is in crisis Manchester United has made... https://t.co/5NtTYVuZqd\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.23 ms /    16 runs   (    0.58 ms per token,  1733.85 tokens per second)\n",
            "llama_print_timings: prompt eval time =     260.01 ms /    44 tokens (    5.91 ms per token,   169.22 tokens per second)\n",
            "llama_print_timings:        eval time =    1584.68 ms /    15 runs   (  105.65 ms per token,     9.47 tokens per second)\n",
            "llama_print_timings:       total time =    2020.92 ms /    59 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "How beautiful. Are we going to do carpentry? At least make it attractive like the pottery in ghost. https://t.co/vXzwo2AkJr\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.60 ms /    16 runs   (    0.66 ms per token,  1509.15 tokens per second)\n",
            "llama_print_timings: prompt eval time =     247.50 ms /    42 tokens (    5.89 ms per token,   169.70 tokens per second)\n",
            "llama_print_timings:        eval time =    1775.14 ms /    15 runs   (  118.34 ms per token,     8.45 tokens per second)\n",
            "llama_print_timings:       total time =    2194.12 ms /    57 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "He only opens his mouth to say stupid things and embarrass all Peruvians. So they opened his cage.😡 https://t.co/RqmgOVImk6\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.53 ms /    16 runs   (    0.60 ms per token,  1679.61 tokens per second)\n",
            "llama_print_timings: prompt eval time =     267.49 ms /    54 tokens (    4.95 ms per token,   201.88 tokens per second)\n",
            "llama_print_timings:        eval time =    1579.55 ms /    15 runs   (  105.30 ms per token,     9.50 tokens per second)\n",
            "llama_print_timings:       total time =    2036.54 ms /    69 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "@josecarmelopaz @MAVEDRO @CarlRamirezA Someday you will be ashamed of how you tried to justify your idolatry, let's wait for God's time\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.78 ms /    16 runs   (    0.55 ms per token,  1823.15 tokens per second)\n",
            "llama_print_timings: prompt eval time =     248.72 ms /    42 tokens (    5.92 ms per token,   168.86 tokens per second)\n",
            "llama_print_timings:        eval time =    1644.52 ms /    15 runs   (  109.63 ms per token,     9.12 tokens per second)\n",
            "llama_print_timings:       total time =    2051.71 ms /    57 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "@exitosape Hahahaha instead of shaming, take out your claws, iden feline injured, that's how criminals are, they consider themselves offended\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.34 ms /    16 runs   (    0.58 ms per token,  1713.06 tokens per second)\n",
            "llama_print_timings: prompt eval time =     283.11 ms /    96 tokens (    2.95 ms per token,   339.09 tokens per second)\n",
            "llama_print_timings:        eval time =    1585.14 ms /    15 runs   (  105.68 ms per token,     9.46 tokens per second)\n",
            "llama_print_timings:       total time =    2128.58 ms /   111 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "They/Them (2022), another from the Blumhouse factory that is disguised as a slasher and a tribute to Friday the 13th including Kevin Bacon but which is an LGBTQIA+ pamphlet that would embarrass the community itself. The turd of the year. #movies #cinema #news #streaming https://t.co/b0wqKvcvPQ\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.58 ms /    16 runs   (    0.72 ms per token,  1381.69 tokens per second)\n",
            "llama_print_timings: prompt eval time =     983.97 ms /    30 tokens (   32.80 ms per token,    30.49 tokens per second)\n",
            "llama_print_timings:        eval time =    1856.38 ms /    15 runs   (  123.76 ms per token,     8.08 tokens per second)\n",
            "llama_print_timings:       total time =    3054.10 ms /    45 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "How we miss the previous first lady. She never gave cause for criticism. The crazy woman now only serves to embarrass Colombians\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.71 ms /    16 runs   (    0.61 ms per token,  1647.28 tokens per second)\n",
            "llama_print_timings: prompt eval time =     275.51 ms /    71 tokens (    3.88 ms per token,   257.71 tokens per second)\n",
            "llama_print_timings:        eval time =    1531.04 ms /    15 runs   (  102.07 ms per token,     9.80 tokens per second)\n",
            "llama_print_timings:       total time =    2026.21 ms /    86 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "@Xuxipc Fortunately, not all of us from Madrid are sympathizers of Miss IDA who acts as P d M with absurdities, nonsense, falsehoods and demagoguery, she is characterized because common sense is archived no one knows where and this is enough to embarrass some people from Madrid .\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.03 ms /    16 runs   (    0.56 ms per token,  1771.28 tokens per second)\n",
            "llama_print_timings: prompt eval time =     309.06 ms /   122 tokens (    2.53 ms per token,   394.75 tokens per second)\n",
            "llama_print_timings:        eval time =    1489.17 ms /    15 runs   (   99.28 ms per token,    10.07 tokens per second)\n",
            "llama_print_timings:       total time =    2120.30 ms /   137 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "Zee made a joke and sneezed but then Nunew ignored Zee and said :🐱: \"I'll keep eating\" then Z got embarrassed and said 🐺: \"that hurts\" (which NN ignored his joke) and NN said 🐱: \"I'm just joking\" . It's so fucking cute.#VaminoxZeeNuNew#ZeeNuNew #ซนซน https://t.co/Dxua7DVMy6\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.07 ms /    16 runs   (    0.57 ms per token,  1764.45 tokens per second)\n",
            "llama_print_timings: prompt eval time =     269.45 ms /    84 tokens (    3.21 ms per token,   311.74 tokens per second)\n",
            "llama_print_timings:        eval time =    1457.97 ms /    15 runs   (   97.20 ms per token,    10.29 tokens per second)\n",
            "llama_print_timings:       total time =    1964.26 ms /    99 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "@DIRECTVGOMXThe militancy of journalism transcends https://t.co/KB1U5GwEiZ FALSE information about Lula in DirectGoNews (Somos Latino América) embarrassed even the presenter, by comparing the \"persecution\" of Lula with Crist style: CLEPTOCRACIA@DIRECTVGO\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.72 ms /    16 runs   (    0.61 ms per token,  1645.58 tokens per second)\n",
            "llama_print_timings: prompt eval time =     289.62 ms /    77 tokens (    3.76 ms per token,   265.87 tokens per second)\n",
            "llama_print_timings:        eval time =    1473.20 ms /    15 runs   (   98.21 ms per token,    10.18 tokens per second)\n",
            "llama_print_timings:       total time =    1992.82 ms /    92 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "@vladiskld I just broke my cell phone in anger. Salomón Villada (Ferxxo, Feid) embarrassed me in front of my family. My children are crying, scared by my anger as I walk around the room shaking. I can't stand this, call the police because I'm about to do something crazy.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.28 ms /    16 runs   (    0.58 ms per token,  1725.07 tokens per second)\n",
            "llama_print_timings: prompt eval time =     282.10 ms /    88 tokens (    3.21 ms per token,   311.95 tokens per second)\n",
            "llama_print_timings:        eval time =    1524.53 ms /    15 runs   (  101.64 ms per token,     9.84 tokens per second)\n",
            "llama_print_timings:       total time =    2052.63 ms /   103 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "@SuperSecretario @Angelovenami End the patriarchal imposition of \"like a mother...\" I am a mother, I had a wonderful father and my old lady lives! Perhaps she never wanted to be a mother, or being the mother of a Peronist embarrassed her so much that she allied herself with her murderers. Mirta has a dead gay son + for her the same death!\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      15.48 ms /    16 runs   (    0.97 ms per token,  1033.73 tokens per second)\n",
            "llama_print_timings: prompt eval time =     296.24 ms /    98 tokens (    3.02 ms per token,   330.81 tokens per second)\n",
            "llama_print_timings:        eval time =    1863.42 ms /    15 runs   (  124.23 ms per token,     8.05 tokens per second)\n",
            "llama_print_timings:       total time =    2518.73 ms /   113 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "@ElsaKekita @vivicanosaok It's Garbage. He blocked me because I told him the same thing..And that he always had MILEI who accompanied the F. From the book..👍..And BERNI. Last night I was laughing with the latter and it made me sick. I was waiting for the next program and he embarrassed me how he seduces him .. (Not as a journalist??) .. 👍\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.11 ms /    16 runs   (    0.57 ms per token,  1755.73 tokens per second)\n",
            "llama_print_timings: prompt eval time =     261.54 ms /    50 tokens (    5.23 ms per token,   191.18 tokens per second)\n",
            "llama_print_timings:        eval time =    1589.54 ms /    15 runs   (  105.97 ms per token,     9.44 tokens per second)\n",
            "llama_print_timings:       total time =    2021.90 ms /    65 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "@palomaSnchez What if you told him that the secret is in the #Pack? Why do I imagine that she embarrassed you that a little girl without malice dreams of what you achieved in a humiliating way?\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.39 ms /    16 runs   (    0.59 ms per token,  1703.40 tokens per second)\n",
            "llama_print_timings: prompt eval time =     265.67 ms /    79 tokens (    3.36 ms per token,   297.36 tokens per second)\n",
            "llama_print_timings:        eval time =    1624.02 ms /    15 runs   (  108.27 ms per token,     9.24 tokens per second)\n",
            "llama_print_timings:       total time =    2121.58 ms /    94 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "@SergioGaTorres What respect and tolerance you have, majete, stoning, whipping women, treating them like scum, executing gays and lesbians or slaughtering lambs with knives without slaughterhouses and without putting them to sleep, it's fabulous then, isn't it? Go shit on the road.\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.67 ms /    16 runs   (    0.60 ms per token,  1653.92 tokens per second)\n",
            "llama_print_timings: prompt eval time =     261.34 ms /    60 tokens (    4.36 ms per token,   229.58 tokens per second)\n",
            "llama_print_timings:        eval time =    1511.21 ms /    15 runs   (  100.75 ms per token,     9.93 tokens per second)\n",
            "llama_print_timings:       total time =    1962.03 ms /    75 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "Is there a plan to dismember the Islamic states? So they will stop whipping women and hanging homosexuals, very good for both groups and congratulations to those who are promoting these plans https://t.co/5nCJy0JPiz\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.54 ms /    16 runs   (    0.72 ms per token,  1386.00 tokens per second)\n",
            "llama_print_timings: prompt eval time =     262.41 ms /    63 tokens (    4.17 ms per token,   240.08 tokens per second)\n",
            "llama_print_timings:        eval time =    1853.13 ms /    15 runs   (  123.54 ms per token,     8.09 tokens per second)\n",
            "llama_print_timings:       total time =    2455.26 ms /    78 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "@judit_sinhache The one who doesn't like children or families is Pablo, or parks, or grandparents. Except for spanking women, he doesn't like anything. https://t.co/H0MgXqh4dR\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.14 ms /    16 runs   (    0.57 ms per token,  1750.74 tokens per second)\n",
            "llama_print_timings: prompt eval time =     250.92 ms /    36 tokens (    6.97 ms per token,   143.47 tokens per second)\n",
            "llama_print_timings:        eval time =    1540.54 ms /    15 runs   (  102.70 ms per token,     9.74 tokens per second)\n",
            "llama_print_timings:       total time =    1934.86 ms /    51 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "Well, yours likes to spank women and his bosom friend loves to insult them... https://t.co/Hvmoxw9ejv\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.88 ms /    16 runs   (    0.55 ms per token,  1802.82 tokens per second)\n",
            "llama_print_timings: prompt eval time =     291.67 ms /    89 tokens (    3.28 ms per token,   305.14 tokens per second)\n",
            "llama_print_timings:        eval time =    1577.10 ms /    15 runs   (  105.14 ms per token,     9.51 tokens per second)\n",
            "llama_print_timings:       total time =    2110.89 ms /   104 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "@SXTrece @Caputcomunismo @NoaGresiva Where do the Podemitas talk about having the cheapest electricity in Europe? 🤔🤔You were only talking about how with you in the government the electricity bill would go down and you have tripled it 😂😂😂😂It was another joke between colleagues, like the thing about whipping women 😭😭😭😭😭\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.04 ms /    16 runs   (    0.63 ms per token,  1593.63 tokens per second)\n",
            "llama_print_timings: prompt eval time =     265.68 ms /    64 tokens (    4.15 ms per token,   240.89 tokens per second)\n",
            "llama_print_timings:        eval time =    1667.80 ms /    15 runs   (  111.19 ms per token,     8.99 tokens per second)\n",
            "llama_print_timings:       total time =    2143.88 ms /    79 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "@pvallin Ahmmmm…I don't know🤔🤔?? Can we??, well no, those are more about whipping women until they bleed...Bildu maybe?? Refining his old style of shot in the back of the head could very well be one of them\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.12 ms /    16 runs   (    0.63 ms per token,  1581.03 tokens per second)\n",
            "llama_print_timings: prompt eval time =     284.11 ms /    81 tokens (    3.51 ms per token,   285.10 tokens per second)\n",
            "llama_print_timings:        eval time =    1589.72 ms /    15 runs   (  105.98 ms per token,     9.44 tokens per second)\n",
            "llama_print_timings:       total time =    2265.86 ms /    96 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "Great @borjateran touching on functional diversity and copyrights that are being forgotten. The 🏖️ is the space with the most diversity that exists but we must not forget the invisible barriers and those self-inflicted by many due to posting. #Livedejavivir https://t.co/UAr3Fcnn4S\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.20 ms /    16 runs   (    0.57 ms per token,  1739.32 tokens per second)\n",
            "llama_print_timings: prompt eval time =     262.38 ms /    50 tokens (    5.25 ms per token,   190.57 tokens per second)\n",
            "llama_print_timings:        eval time =    1523.18 ms /    15 runs   (  101.55 ms per token,     9.85 tokens per second)\n",
            "llama_print_timings:       total time =    1957.52 ms /    65 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "I think it's the first time we've used Peter in the city. Yes, there are invisible barriers to prevent us from going for a walk. https://t.co/lav9LGGS7U\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.07 ms /    16 runs   (    0.57 ms per token,  1763.47 tokens per second)\n",
            "llama_print_timings: prompt eval time =     268.78 ms /    77 tokens (    3.49 ms per token,   286.48 tokens per second)\n",
            "llama_print_timings:        eval time =    1486.23 ms /    15 runs   (   99.08 ms per token,    10.09 tokens per second)\n",
            "llama_print_timings:       total time =    1976.88 ms /    92 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "@reseteo1234 Obviously, Meloni is just another case. There are millions of \"Melonis\". And \"Obamas\" too. The funny thing is that they are perceived as an \"example\", as an \"advance\". Invisible barriers have always existed, but they are only invisible to the eyes of an idiot.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       6.51 ms /    12 runs   (    0.54 ms per token,  1842.19 tokens per second)\n",
            "llama_print_timings: prompt eval time =     577.16 ms /    21 tokens (   27.48 ms per token,    36.39 tokens per second)\n",
            "llama_print_timings:        eval time =    1230.89 ms /    11 runs   (  111.90 ms per token,     8.94 tokens per second)\n",
            "llama_print_timings:       total time =    1905.77 ms /    32 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "Sometimes we are stuck with invisible barriers created by our own mind.- David Villa\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.42 ms /    16 runs   (    0.65 ms per token,  1535.51 tokens per second)\n",
            "llama_print_timings: prompt eval time =     245.36 ms /    34 tokens (    7.22 ms per token,   138.57 tokens per second)\n",
            "llama_print_timings:        eval time =    1773.11 ms /    15 runs   (  118.21 ms per token,     8.46 tokens per second)\n",
            "llama_print_timings:       total time =    2251.02 ms /    49 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "Invisible Barriers to Healthcare - Derek Prince - https://t.co/laLkgAhfL3 via @YouTube\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.87 ms /    16 runs   (    0.62 ms per token,  1620.75 tokens per second)\n",
            "llama_print_timings: prompt eval time =     285.44 ms /    72 tokens (    3.96 ms per token,   252.24 tokens per second)\n",
            "llama_print_timings:        eval time =    1606.94 ms /    15 runs   (  107.13 ms per token,     9.33 tokens per second)\n",
            "llama_print_timings:       total time =    2109.44 ms /    87 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "\"Women encounter invisible barriers that range from being a minority and not being within formal and informal networks of power\" -@RaquelLagunas_, @pnud Live: https://t.co/S7tdVTptbP https://t.co /Eu84YGVGSj\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.46 ms /    16 runs   (    0.59 ms per token,  1691.51 tokens per second)\n",
            "llama_print_timings: prompt eval time =     258.65 ms /    54 tokens (    4.79 ms per token,   208.78 tokens per second)\n",
            "llama_print_timings:        eval time =    1551.85 ms /    15 runs   (  103.46 ms per token,     9.67 tokens per second)\n",
            "llama_print_timings:       total time =    1993.13 ms /    69 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "If a fat girl uploads photos in a bikini it is \"Body positivity 🥰😍♥️\" but if a thin girl does the same it is \"promoting ED and harmful standards.\" Hypocrites fr.\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      12.28 ms /    16 runs   (    0.77 ms per token,  1303.46 tokens per second)\n",
            "llama_print_timings: prompt eval time =     258.44 ms /    57 tokens (    4.53 ms per token,   220.55 tokens per second)\n",
            "llama_print_timings:        eval time =    1867.82 ms /    15 runs   (  124.52 ms per token,     8.03 tokens per second)\n",
            "llama_print_timings:       total time =    2436.37 ms /    72 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "@taamaraalvarado the body positivity that you talk about and promote so much, where is it? This is also body shaming. If a man says “I saw her tits and I stopped liking her” what would happen?\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.71 ms /    16 runs   (    0.61 ms per token,  1648.30 tokens per second)\n",
            "llama_print_timings: prompt eval time =     292.25 ms /    83 tokens (    3.52 ms per token,   284.01 tokens per second)\n",
            "llama_print_timings:        eval time =    1541.62 ms /    15 runs   (  102.77 ms per token,     9.73 tokens per second)\n",
            "llama_print_timings:       total time =    2082.03 ms /    98 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "@ArteMapacheArt a lot of noise against fatphobia, but it's good that they discriminate against a cripple. what's happening? Can't you let people remember that body positivity isn't just for fat buttery hamburgers who suffer from cardiac arrest? I spit on your intolerance 🖕\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.41 ms /    16 runs   (    0.59 ms per token,  1699.78 tokens per second)\n",
            "llama_print_timings: prompt eval time =     245.99 ms /    54 tokens (    4.56 ms per token,   219.52 tokens per second)\n",
            "llama_print_timings:        eval time =    1549.28 ms /    15 runs   (  103.29 ms per token,     9.68 tokens per second)\n",
            "llama_print_timings:       total time =    1986.64 ms /    69 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "Body positivity until it is with very thin bodies. He doesn't have a TCA but if he did the worst thing you could do is comment on his body https://t.co/XWGO9CwS81\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.58 ms /    16 runs   (    0.60 ms per token,  1670.49 tokens per second)\n",
            "llama_print_timings: prompt eval time =     589.67 ms /    24 tokens (   24.57 ms per token,    40.70 tokens per second)\n",
            "llama_print_timings:        eval time =    1603.95 ms /    15 runs   (  106.93 ms per token,     9.35 tokens per second)\n",
            "llama_print_timings:       total time =    2319.27 ms /    39 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "It seems to me that much of the body positivity movement is pure toxic positivism.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.38 ms /    16 runs   (    0.65 ms per token,  1540.98 tokens per second)\n",
            "llama_print_timings: prompt eval time =     264.79 ms /    61 tokens (    4.34 ms per token,   230.38 tokens per second)\n",
            "llama_print_timings:        eval time =    1628.16 ms /    15 runs   (  108.54 ms per token,     9.21 tokens per second)\n",
            "llama_print_timings:       total time =    2205.10 ms /    76 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "This is what today's feminism creates, like the stupidity of body positivity... etc., a weak, glass society prepared for nothing because they are offended and feel bad about everything. https://t.co/gjQnP1wjKa\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.73 ms /    16 runs   (    0.55 ms per token,  1832.76 tokens per second)\n",
            "llama_print_timings: prompt eval time =     464.26 ms /    16 tokens (   29.02 ms per token,    34.46 tokens per second)\n",
            "llama_print_timings:        eval time =    1587.75 ms /    15 runs   (  105.85 ms per token,     9.45 tokens per second)\n",
            "llama_print_timings:       total time =    2150.75 ms /    31 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "wishing to move so I could go in panties\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.62 ms /    16 runs   (    0.60 ms per token,  1663.55 tokens per second)\n",
            "llama_print_timings: prompt eval time =     284.38 ms /    91 tokens (    3.13 ms per token,   320.00 tokens per second)\n",
            "llama_print_timings:        eval time =    1548.41 ms /    15 runs   (  103.23 ms per token,     9.69 tokens per second)\n",
            "llama_print_timings:       total time =    2090.24 ms /   106 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "@CamelliaRosse @1971mame @maria_patino @sonsolesonega Hahahahaha super professional hahahahaha the roundabout that changes more minds than panties. The one who prefers to make a fool of herself than to work honestly. I study journalism to lie on a network where they don't let them give their opinion freely.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.45 ms /    16 runs   (    0.72 ms per token,  1397.14 tokens per second)\n",
            "llama_print_timings: prompt eval time =     242.91 ms /    43 tokens (    5.65 ms per token,   177.02 tokens per second)\n",
            "llama_print_timings:        eval time =    1862.78 ms /    15 runs   (  124.19 ms per token,     8.05 tokens per second)\n",
            "llama_print_timings:       total time =    2306.03 ms /    58 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "CantabriaHumor is not running out of panties because they don't dry, apparently https://t.co/r4Zd0kRQgF\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.99 ms /    16 runs   (    0.56 ms per token,  1780.35 tokens per second)\n",
            "llama_print_timings: prompt eval time =     262.06 ms /    45 tokens (    5.82 ms per token,   171.72 tokens per second)\n",
            "llama_print_timings:        eval time =    1547.62 ms /    15 runs   (  103.17 ms per token,     9.69 tokens per second)\n",
            "llama_print_timings:       total time =    1971.55 ms /    60 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "Can you stop calling being a shitty transphobe a mistake? that you have not tripped on the panties stall, you have broadcast a podcast aware of the hate speech that the guest has\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.71 ms /    16 runs   (    0.54 ms per token,  1836.13 tokens per second)\n",
            "llama_print_timings: prompt eval time =     254.56 ms /    45 tokens (    5.66 ms per token,   176.78 tokens per second)\n",
            "llama_print_timings:        eval time =    1522.64 ms /    15 runs   (  101.51 ms per token,     9.85 tokens per second)\n",
            "llama_print_timings:       total time =    1936.04 ms /    60 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "Me: *I put on good panties because my period has already gone and I no longer stain* The period: https://t.co/wR0A00KmRu\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.47 ms /    16 runs   (    0.72 ms per token,  1395.06 tokens per second)\n",
            "llama_print_timings: prompt eval time =     257.69 ms /    64 tokens (    4.03 ms per token,   248.36 tokens per second)\n",
            "llama_print_timings:        eval time =    1878.89 ms /    15 runs   (  125.26 ms per token,     7.98 tokens per second)\n",
            "llama_print_timings:       total time =    2369.29 ms /    79 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "@Caliu_A Exactly. His shit is her money, not ours. If not, they'll even have to seize your panties or go to jail. Like any citizen. Aren't we all the same? Alas, let's take x ass\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.80 ms /    16 runs   (    0.55 ms per token,  1817.15 tokens per second)\n",
            "llama_print_timings: prompt eval time =     278.67 ms /    67 tokens (    4.16 ms per token,   240.43 tokens per second)\n",
            "llama_print_timings:        eval time =    1536.03 ms /    15 runs   (  102.40 ms per token,     9.77 tokens per second)\n",
            "llama_print_timings:       total time =    2018.52 ms /    82 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "International Report: Internet against climate change, isolation and the gender gap in the Great American #ChacoNews from #Chaco, #Tarija, #SantaCruz and #Bolivia| #ChacoReport https://t.co/SI7dCBKL0k\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.66 ms /    16 runs   (    0.54 ms per token,  1846.94 tokens per second)\n",
            "llama_print_timings: prompt eval time =     258.60 ms /    46 tokens (    5.62 ms per token,   177.88 tokens per second)\n",
            "llama_print_timings:        eval time =    1633.79 ms /    15 runs   (  108.92 ms per token,     9.18 tokens per second)\n",
            "llama_print_timings:       total time =    2067.09 ms /    61 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "Happy day to the programmers and especially to the brave women programmers who have dared to enter a world with such a gender gap, so that the biases become less and less 💪🏻\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.32 ms /    16 runs   (    0.71 ms per token,  1413.43 tokens per second)\n",
            "llama_print_timings: prompt eval time =     284.70 ms /    93 tokens (    3.06 ms per token,   326.66 tokens per second)\n",
            "llama_print_timings:        eval time =    1835.03 ms /    15 runs   (  122.34 ms per token,     8.17 tokens per second)\n",
            "llama_print_timings:       total time =    2416.53 ms /   108 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "The gender gap does exist. The rate is higher in the lines of: microcredit, consumption and housing. It is incredible that women, who in most cases are in charge of the home economy, find themselves facing this policy of exclusion. Photo: @larepublica_co https://t.co/jkyVEOQiJD https://t.co/e10z5cwCdy\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.90 ms /    16 runs   (    0.56 ms per token,  1796.95 tokens per second)\n",
            "llama_print_timings: prompt eval time =     259.83 ms /    46 tokens (    5.65 ms per token,   177.04 tokens per second)\n",
            "llama_print_timings:        eval time =    1522.88 ms /    15 runs   (  101.53 ms per token,     9.85 tokens per second)\n",
            "llama_print_timings:       total time =    1942.35 ms /    61 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "From different shores one can also agree. Just as the previous points cause concern, I support continuing with public policies to close the gender gap, seeking greater labor participation and better income for #Women.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.49 ms /    16 runs   (    0.59 ms per token,  1686.70 tokens per second)\n",
            "llama_print_timings: prompt eval time =     262.33 ms /    62 tokens (    4.23 ms per token,   236.35 tokens per second)\n",
            "llama_print_timings:        eval time =    1460.03 ms /    15 runs   (   97.34 ms per token,    10.27 tokens per second)\n",
            "llama_print_timings:       total time =    1936.10 ms /    77 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "Curiously, the gender gap in this issue is almost 100/100, but it seems not only to not matter, but it must be the right thing to do when progress is not funny. https://t.co/mbMfb6sOXT\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.37 ms /    16 runs   (    0.59 ms per token,  1707.21 tokens per second)\n",
            "llama_print_timings: prompt eval time =     278.70 ms /    84 tokens (    3.32 ms per token,   301.40 tokens per second)\n",
            "llama_print_timings:        eval time =    1629.79 ms /    15 runs   (  108.65 ms per token,     9.20 tokens per second)\n",
            "llama_print_timings:       total time =    2145.32 ms /    99 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "The gender gap in the technology sector is a reality in 2022... The percentage of #women specialized in #technology does not even reach 20%. 😞👉 https://t.co/TXeKXwlY7EVía: @nuevatribuna https://t.co/sklUUPfMJX\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.69 ms /    16 runs   (    0.73 ms per token,  1369.16 tokens per second)\n",
            "llama_print_timings: prompt eval time =     275.16 ms /    65 tokens (    4.23 ms per token,   236.23 tokens per second)\n",
            "llama_print_timings:        eval time =    1895.50 ms /    15 runs   (  126.37 ms per token,     7.91 tokens per second)\n",
            "llama_print_timings:       total time =    2523.95 ms /    80 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "At EDE Inclusive Employment we join the challenge of reducing the gender #DigitalGap with actions aimed at unemployed women: Introduction to computing and basic digital skills for employment, Social networks as a energizing tool,…https://t.co/82CVSVnzgR\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.86 ms /    16 runs   (    0.55 ms per token,  1805.87 tokens per second)\n",
            "llama_print_timings: prompt eval time =     245.20 ms /    34 tokens (    7.21 ms per token,   138.66 tokens per second)\n",
            "llama_print_timings:        eval time =    1483.35 ms /    15 runs   (   98.89 ms per token,    10.11 tokens per second)\n",
            "llama_print_timings:       total time =    1871.71 ms /    49 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "Digital gender gap and the impact on eCommerce https://t.co/WlExxg2gKR #ecommerce\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.60 ms /    16 runs   (    0.60 ms per token,  1666.84 tokens per second)\n",
            "llama_print_timings: prompt eval time =     284.38 ms /    79 tokens (    3.60 ms per token,   277.80 tokens per second)\n",
            "llama_print_timings:        eval time =    1501.53 ms /    15 runs   (  100.10 ms per token,     9.99 tokens per second)\n",
            "llama_print_timings:       total time =    2015.07 ms /    94 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "📲 #TheCountryWeWant | More than 25% of Peruvian adolescents had to borrow a mobile device to access virtual classes, according to a Hiperderecho study. In the case of their male peers, the figure was 15%.https://t.co/yWDza7f8mN\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.75 ms /    16 runs   (    0.61 ms per token,  1641.87 tokens per second)\n",
            "llama_print_timings: prompt eval time =     283.52 ms /    77 tokens (    3.68 ms per token,   271.58 tokens per second)\n",
            "llama_print_timings:        eval time =    1559.37 ms /    15 runs   (  103.96 ms per token,     9.62 tokens per second)\n",
            "llama_print_timings:       total time =    2068.28 ms /    92 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "Do you know what the digital gender gap is? There is a very low representation of women in the Internet world, so there is still a lot of work to do so that stereotypes in the digital world are defeated.https://t.co/US0tLovynG https://t.co/ GRJHBNaKjm\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.31 ms /    16 runs   (    0.58 ms per token,  1718.77 tokens per second)\n",
            "llama_print_timings: prompt eval time =     297.39 ms /    93 tokens (    3.20 ms per token,   312.72 tokens per second)\n",
            "llama_print_timings:        eval time =    1600.59 ms /    15 runs   (  106.71 ms per token,     9.37 tokens per second)\n",
            "llama_print_timings:       total time =    2158.79 ms /   108 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "#DesafíosPetroTIC “Change is with women,” says the government program of the new president of Colombia Gustavo Petro. But what are the challenges facing closing the digital gender gap? We tell you @MujeresTIC_Col &gt;&gt; https://t.co/6aUEN3iT6U https://t.co/LlKGYfSH1O\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.75 ms /    16 runs   (    0.61 ms per token,  1640.69 tokens per second)\n",
            "llama_print_timings: prompt eval time =     289.58 ms /   104 tokens (    2.78 ms per token,   359.13 tokens per second)\n",
            "llama_print_timings:        eval time =    1601.85 ms /    15 runs   (  106.79 ms per token,     9.36 tokens per second)\n",
            "llama_print_timings:       total time =    2176.10 ms /   119 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "📲 Do you need to learn digital tools for your entrepreneurship? We invite you to participate in the #TodasConectadas 👩🏻‍💻✨ Webinar led by @MinMujeryEG that will train you for free to reduce the digital gender gap🙌Sign up for 👉 https://t.co/uCGGPeQz9n https://t. co/ysSRuu8ZkB\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.49 ms /    16 runs   (    0.66 ms per token,  1524.68 tokens per second)\n",
            "llama_print_timings: prompt eval time =     267.37 ms /    60 tokens (    4.46 ms per token,   224.41 tokens per second)\n",
            "llama_print_timings:        eval time =    1613.23 ms /    15 runs   (  107.55 ms per token,     9.30 tokens per second)\n",
            "llama_print_timings:       total time =    2081.21 ms /    75 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "An alert that it raises is the large gap in the amounts of credit that are granted, to the detriment of women. Which has as one of the main causes the gender pay gap, which we must eradicate. There is no justification, only discrimination.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.21 ms /    16 runs   (    0.58 ms per token,  1737.62 tokens per second)\n",
            "llama_print_timings: prompt eval time =     282.01 ms /    84 tokens (    3.36 ms per token,   297.86 tokens per second)\n",
            "llama_print_timings:        eval time =    1476.76 ms /    15 runs   (   98.45 ms per token,    10.16 tokens per second)\n",
            "llama_print_timings:       total time =    1994.30 ms /    99 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "Worry about the article that the @WSJ puts on the front page. The gender pay gap, a woman on average earns 30% less than a man doing EXACTLY the same thing. The issue with the note is that the study states that men earn twice as much right after leaving university. https://t.co/J5p4x3Ruz4\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.28 ms /    16 runs   (    0.58 ms per token,  1723.40 tokens per second)\n",
            "llama_print_timings: prompt eval time =     280.45 ms /    73 tokens (    3.84 ms per token,   260.30 tokens per second)\n",
            "llama_print_timings:        eval time =    1645.41 ms /    15 runs   (  109.69 ms per token,     9.12 tokens per second)\n",
            "llama_print_timings:       total time =    2148.18 ms /    88 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "Vice President Karen Palma in an International Conversation within the framework of the celebration of the International Day of #EqualSalary. We reflect and share experiences around measures that contribute to reducing the gender wage gap.#SalaryTransparency♀️⚖️ https://t.co/DWe9EQpJzg\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.28 ms /    16 runs   (    0.64 ms per token,  1556.42 tokens per second)\n",
            "llama_print_timings: prompt eval time =     273.52 ms /    80 tokens (    3.42 ms per token,   292.49 tokens per second)\n",
            "llama_print_timings:        eval time =    1685.61 ms /    15 runs   (  112.37 ms per token,     8.90 tokens per second)\n",
            "llama_print_timings:       total time =    2199.72 ms /    95 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "In Quintana Roo, @LuisaAlcalde, head of the @STPS_mx mentioned that there is a wage gap of up to 18% and to combat this behavior a transparent message must be given, because it allows companies to identify the situation and change it.https://t .co/DLlh7Nn3Ff\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.16 ms /    16 runs   (    0.57 ms per token,  1747.11 tokens per second)\n",
            "llama_print_timings: prompt eval time =     270.60 ms /    67 tokens (    4.04 ms per token,   247.60 tokens per second)\n",
            "llama_print_timings:        eval time =    1655.16 ms /    15 runs   (  110.34 ms per token,     9.06 tokens per second)\n",
            "llama_print_timings:       total time =    2129.72 ms /    82 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "We must put an end to job insecurity. This implies a minimum living wage, a living and decent wage and job stability, a transition towards a more equitable pension system; reduce the gender pay gap. This will be the change. https://t.co/zsySfj5VCm\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.00 ms /    16 runs   (    0.56 ms per token,  1777.38 tokens per second)\n",
            "llama_print_timings: prompt eval time =     258.06 ms /    48 tokens (    5.38 ms per token,   186.00 tokens per second)\n",
            "llama_print_timings:        eval time =    1611.39 ms /    15 runs   (  107.43 ms per token,     9.31 tokens per second)\n",
            "llama_print_timings:       total time =    2036.85 ms /    63 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "Concaem promotes reducing the gender wage gap and the state care systemhttps://t.co/CkKjrnNRHu https://t.co/MejPKo1255\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.25 ms /    16 runs   (    0.58 ms per token,  1729.17 tokens per second)\n",
            "llama_print_timings: prompt eval time =     569.56 ms /    32 tokens (   17.80 ms per token,    56.18 tokens per second)\n",
            "llama_print_timings:        eval time =    1538.83 ms /    15 runs   (  102.59 ms per token,     9.75 tokens per second)\n",
            "llama_print_timings:       total time =    2245.27 ms /    47 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "Every time I see a player with a striking last name I think about the bullying that may have been done to him at school.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.85 ms /    16 runs   (    0.68 ms per token,  1475.06 tokens per second)\n",
            "llama_print_timings: prompt eval time =     245.43 ms /    42 tokens (    5.84 ms per token,   171.13 tokens per second)\n",
            "llama_print_timings:        eval time =    1813.23 ms /    15 runs   (  120.88 ms per token,     8.27 tokens per second)\n",
            "llama_print_timings:       total time =    2317.96 ms /    57 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "@sboric Why are you bullying your shitty brother ❓😈😂😂 https://t.co/JG0OKIJIkB\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.55 ms /    16 runs   (    0.60 ms per token,  1675.04 tokens per second)\n",
            "llama_print_timings: prompt eval time =     295.82 ms /    87 tokens (    3.40 ms per token,   294.10 tokens per second)\n",
            "llama_print_timings:        eval time =    1568.39 ms /    15 runs   (  104.56 ms per token,     9.56 tokens per second)\n",
            "llama_print_timings:       total time =    2118.35 ms /   102 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "@mery_soldier @bryanmozz98 @eldiariodedross It's like at school, if they bully you you should let them bully you, you can't defend yourself. Stop screwing around, if someone attacks you you have to respond in equal proportion. Whether at 7 years old or 40 years old, never leave anyone behind.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.56 ms /    16 runs   (    0.60 ms per token,  1674.17 tokens per second)\n",
            "llama_print_timings: prompt eval time =     258.92 ms /    53 tokens (    4.89 ms per token,   204.70 tokens per second)\n",
            "llama_print_timings:        eval time =    1542.07 ms /    15 runs   (  102.80 ms per token,     9.73 tokens per second)\n",
            "llama_print_timings:       total time =    1977.93 ms /    68 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "@patyvasquez @taylorswift13 Hahaha, thank you very much 🥰 and yes, to be able to defend ourselves from the fourteen-year-olds who bully us seniors 😂\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.39 ms /    16 runs   (    0.59 ms per token,  1703.94 tokens per second)\n",
            "llama_print_timings: prompt eval time =     246.21 ms /    47 tokens (    5.24 ms per token,   190.89 tokens per second)\n",
            "llama_print_timings:        eval time =    1544.91 ms /    15 runs   (  102.99 ms per token,     9.71 tokens per second)\n",
            "llama_print_timings:       total time =    1959.83 ms /    62 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "@YosiWright Everyone * bullies him because of how tall he is * Yose remembering that good things come in small packages: https://t.co/GcUzxEjqG6\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.41 ms /    16 runs   (    0.59 ms per token,  1699.96 tokens per second)\n",
            "llama_print_timings: prompt eval time =     295.28 ms /    87 tokens (    3.39 ms per token,   294.64 tokens per second)\n",
            "llama_print_timings:        eval time =    1591.42 ms /    15 runs   (  106.09 ms per token,     9.43 tokens per second)\n",
            "llama_print_timings:       total time =    2135.29 ms /   102 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "In the Colombian, this video came out. Last year, before arriving in Congress, @ISAZULETA assured in the middle of a council that citizens can call State officials \"MOUNTS.\" Today that she is a senator, she says that she is exposed to \"media bullying\" 🤣🤣🤣🤣🤣 https://t.co/vhAcaNGMKv\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.70 ms /    16 runs   (    0.54 ms per token,  1839.08 tokens per second)\n",
            "llama_print_timings: prompt eval time =     579.48 ms /    32 tokens (   18.11 ms per token,    55.22 tokens per second)\n",
            "llama_print_timings:        eval time =    1577.38 ms /    15 runs   (  105.16 ms per token,     9.51 tokens per second)\n",
            "llama_print_timings:       total time =    2297.59 ms /    47 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "@fresitagooner First of all, you need hips to help you, and coincidentally I can do it~\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.34 ms /    16 runs   (    0.58 ms per token,  1713.25 tokens per second)\n",
            "llama_print_timings: prompt eval time =     236.13 ms /    39 tokens (    6.05 ms per token,   165.16 tokens per second)\n",
            "llama_print_timings:        eval time =    1595.62 ms /    15 runs   (  106.37 ms per token,     9.40 tokens per second)\n",
            "llama_print_timings:       total time =    1984.32 ms /    54 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "Today a man decided to wear a cream suit with a pink shirt to move his hips and I couldn't think about anything else for the rest of the day.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.95 ms /    16 runs   (    0.62 ms per token,  1607.72 tokens per second)\n",
            "llama_print_timings: prompt eval time =     637.52 ms /    20 tokens (   31.88 ms per token,    31.37 tokens per second)\n",
            "llama_print_timings:        eval time =    1646.12 ms /    15 runs   (  109.74 ms per token,     9.11 tokens per second)\n",
            "llama_print_timings:       total time =    2443.97 ms /    35 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "That movement of hips with Karolg G in the background is very delicious\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.13 ms /    16 runs   (    0.57 ms per token,  1752.27 tokens per second)\n",
            "llama_print_timings: prompt eval time =     249.59 ms /    56 tokens (    4.46 ms per token,   224.37 tokens per second)\n",
            "llama_print_timings:        eval time =    1471.56 ms /    15 runs   (   98.10 ms per token,    10.19 tokens per second)\n",
            "llama_print_timings:       total time =    1905.32 ms /    71 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "@Vendetta1313_ Because they don't know that women's brains look for that prototype since it is indicative of good nutrition and health, just as a woman with wide hips is indicative of health and fertility.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.67 ms /    16 runs   (    0.60 ms per token,  1654.60 tokens per second)\n",
            "llama_print_timings: prompt eval time =     258.10 ms /    67 tokens (    3.85 ms per token,   259.59 tokens per second)\n",
            "llama_print_timings:        eval time =    1649.94 ms /    15 runs   (  110.00 ms per token,     9.09 tokens per second)\n",
            "llama_print_timings:       total time =    2125.09 ms /    82 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "When I read that \"just to remind you that your boyfriend may be biting his coworker's hips and she laughs every time he does it\" it makes me angry because I imagine that situation and it's horrible 🤣🫣💆🏻 ‍♀️\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.11 ms /    16 runs   (    0.57 ms per token,  1755.54 tokens per second)\n",
            "llama_print_timings: prompt eval time =     756.38 ms /    29 tokens (   26.08 ms per token,    38.34 tokens per second)\n",
            "llama_print_timings:        eval time =    1753.93 ms /    15 runs   (  116.93 ms per token,     8.55 tokens per second)\n",
            "llama_print_timings:       total time =    2652.83 ms /    44 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "Horseback riding you wanted momu then your hips hurt and you don't know why 😂😂😂😂\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.95 ms /    16 runs   (    0.56 ms per token,  1788.11 tokens per second)\n",
            "llama_print_timings: prompt eval time =     252.55 ms /    37 tokens (    6.83 ms per token,   146.50 tokens per second)\n",
            "llama_print_timings:        eval time =    1437.49 ms /    15 runs   (   95.83 ms per token,    10.43 tokens per second)\n",
            "llama_print_timings:       total time =    1832.31 ms /    52 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "@jairocalixto sensei, did you ask the chacha?? https://t.co/BG8kdrOzOd\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.02 ms /    16 runs   (    0.56 ms per token,  1774.23 tokens per second)\n",
            "llama_print_timings: prompt eval time =     289.85 ms /    81 tokens (    3.58 ms per token,   279.45 tokens per second)\n",
            "llama_print_timings:        eval time =    1549.22 ms /    15 runs   (  103.28 ms per token,     9.68 tokens per second)\n",
            "llama_print_timings:       total time =    2078.21 ms /    96 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "It must have made her feel bad because she yelled at me that she wasn't anyone's chacha and that she wasn't going to empty other people's trash. (Ok) I asked her if she didn't mind the smell. She has responded to me, also shouting, that yes but out of pride she has not done it (Ok)\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.25 ms /    16 runs   (    0.52 ms per token,  1939.86 tokens per second)\n",
            "llama_print_timings: prompt eval time =     542.06 ms /    20 tokens (   27.10 ms per token,    36.90 tokens per second)\n",
            "llama_print_timings:        eval time =    1556.02 ms /    15 runs   (  103.73 ms per token,     9.64 tokens per second)\n",
            "llama_print_timings:       total time =    2207.58 ms /    35 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "I highly recommend the white chicken pizza at La Chacha😍😍😍\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      13.27 ms /    16 runs   (    0.83 ms per token,  1205.82 tokens per second)\n",
            "llama_print_timings: prompt eval time =     243.98 ms /    33 tokens (    7.39 ms per token,   135.26 tokens per second)\n",
            "llama_print_timings:        eval time =    1867.86 ms /    15 runs   (  124.52 ms per token,     8.03 tokens per second)\n",
            "llama_print_timings:       total time =    2347.14 ms /    48 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "@Dj_OnixIce @Bragi_Gunlod First stop calling her chacha! Ridiculous\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.42 ms /    16 runs   (    0.59 ms per token,  1697.97 tokens per second)\n",
            "llama_print_timings: prompt eval time =     634.21 ms /    24 tokens (   26.43 ms per token,    37.84 tokens per second)\n",
            "llama_print_timings:        eval time =    1588.18 ms /    15 runs   (  105.88 ms per token,     9.44 tokens per second)\n",
            "llama_print_timings:       total time =    2349.06 ms /    39 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "@AydannaA Chacha really yes, that must be upside down over there.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.07 ms /    16 runs   (    0.50 ms per token,  1982.65 tokens per second)\n",
            "llama_print_timings: prompt eval time =     239.47 ms /    42 tokens (    5.70 ms per token,   175.39 tokens per second)\n",
            "llama_print_timings:        eval time =    1500.67 ms /    15 runs   (  100.04 ms per token,    10.00 tokens per second)\n",
            "llama_print_timings:       total time =    1891.74 ms /    57 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "I LOVE ✨✨chabuya👏👏 chacha 👏Chabuya👏 https://t.co/24KsX2CIHv\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.10 ms /    16 runs   (    0.57 ms per token,  1758.82 tokens per second)\n",
            "llama_print_timings: prompt eval time =     240.46 ms /    51 tokens (    4.71 ms per token,   212.10 tokens per second)\n",
            "llama_print_timings:        eval time =    1550.94 ms /    15 runs   (  103.40 ms per token,     9.67 tokens per second)\n",
            "llama_print_timings:       total time =    1961.62 ms /    66 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "Oh guys, I was a fan of fixed gear when I was a girl, I even have a photo with some cool glasses and now my childhood was ruined in seconds https://t.co/NAlkI9ifBT\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.16 ms /    16 runs   (    0.70 ms per token,  1433.18 tokens per second)\n",
            "llama_print_timings: prompt eval time =     293.90 ms /    72 tokens (    4.08 ms per token,   244.98 tokens per second)\n",
            "llama_print_timings:        eval time =    1810.86 ms /    15 runs   (  120.72 ms per token,     8.28 tokens per second)\n",
            "llama_print_timings:       total time =    2470.56 ms /    87 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "@mike93d @EnMexicoMagico Shut up, don bitterness, we're talking about the support of friends in the face of the girl's rejection, obviously it's a big deal to be told yes or no... That's the least of it😌\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.07 ms /    16 runs   (    0.57 ms per token,  1764.06 tokens per second)\n",
            "llama_print_timings: prompt eval time =     739.70 ms /    28 tokens (   26.42 ms per token,    37.85 tokens per second)\n",
            "llama_print_timings:        eval time =    1616.61 ms /    15 runs   (  107.77 ms per token,     9.28 tokens per second)\n",
            "llama_print_timings:       total time =    2489.15 ms /    43 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "The unattainable beautiful girl on my fb gave a lot of hearts to my story omg 💖\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.76 ms /    16 runs   (    0.61 ms per token,  1638.84 tokens per second)\n",
            "llama_print_timings: prompt eval time =     247.11 ms /    62 tokens (    3.99 ms per token,   250.90 tokens per second)\n",
            "llama_print_timings:        eval time =    1487.71 ms /    15 runs   (   99.18 ms per token,    10.08 tokens per second)\n",
            "llama_print_timings:       total time =    1930.28 ms /    77 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "A couple stopped next to me and he kept saying romantic things in my ear, they thought no one was listening to them but I was there with my ears very sharp until the girl said can we talk about this somewhere else? hahaha thanks sister because it even gave me cringe\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.58 ms /    16 runs   (    0.60 ms per token,  1670.49 tokens per second)\n",
            "llama_print_timings: prompt eval time =     245.50 ms /    54 tokens (    4.55 ms per token,   219.96 tokens per second)\n",
            "llama_print_timings:        eval time =    1499.88 ms /    15 runs   (   99.99 ms per token,    10.00 tokens per second)\n",
            "llama_print_timings:       total time =    1928.23 ms /    69 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "There was a girl who uploaded videos of how she gave gifts to her friend so that when she woke up from a coma she would see them and two hours ago she uploaded one saying goodbye to her :( I'm sad\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.70 ms /    16 runs   (    0.73 ms per token,  1367.29 tokens per second)\n",
            "llama_print_timings: prompt eval time =     279.95 ms /    81 tokens (    3.46 ms per token,   289.34 tokens per second)\n",
            "llama_print_timings:        eval time =    1761.63 ms /    15 runs   (  117.44 ms per token,     8.51 tokens per second)\n",
            "llama_print_timings:       total time =    2446.04 ms /    96 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "Wow, I was really sad today and I went shopping for clothes. After 15 minutes the girl from the showroom sends me a message and she tells me if she could return the jacket I bought because she had already sold it and had forgotten to take it down from the coat rack🤦🏻‍♀️I'm just sad 🤷 🏻‍♀️\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.93 ms /    16 runs   (    0.56 ms per token,  1790.91 tokens per second)\n",
            "llama_print_timings: prompt eval time =     245.89 ms /    38 tokens (    6.47 ms per token,   154.54 tokens per second)\n",
            "llama_print_timings:        eval time =    1503.52 ms /    15 runs   (  100.23 ms per token,     9.98 tokens per second)\n",
            "llama_print_timings:       total time =    1902.76 ms /    53 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "@patrigarx YES, she had so many tickets that the other girls could have gone with their boyfriends, and they still would have had left over\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.78 ms /    16 runs   (    0.55 ms per token,  1822.32 tokens per second)\n",
            "llama_print_timings: prompt eval time =     599.61 ms /    24 tokens (   24.98 ms per token,    40.03 tokens per second)\n",
            "llama_print_timings:        eval time =    1454.32 ms /    15 runs   (   96.95 ms per token,    10.31 tokens per second)\n",
            "llama_print_timings:       total time =    2175.00 ms /    39 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "Seriously, girls, how ugly your boyfriends are, leave them and come with me!\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.27 ms /    16 runs   (    0.58 ms per token,  1726.74 tokens per second)\n",
            "llama_print_timings: prompt eval time =     246.28 ms /    58 tokens (    4.25 ms per token,   235.51 tokens per second)\n",
            "llama_print_timings:        eval time =    1613.42 ms /    15 runs   (  107.56 ms per token,     9.30 tokens per second)\n",
            "llama_print_timings:       total time =    2046.73 ms /    73 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "👏 👏👏Surely, except Papa and daddy 2, we will see them all....the desire and the plot can't help us, right girls? @milyundrama @vanesappantoja @doramatrica\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.47 ms /    16 runs   (    0.72 ms per token,  1395.31 tokens per second)\n",
            "llama_print_timings: prompt eval time =     703.56 ms /    20 tokens (   35.18 ms per token,    28.43 tokens per second)\n",
            "llama_print_timings:        eval time =    1777.22 ms /    15 runs   (  118.48 ms per token,     8.44 tokens per second)\n",
            "llama_print_timings:       total time =    2668.71 ms /    35 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "Do girls whose eyes roll up when they smile know how perfect they are?\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.16 ms /    16 runs   (    0.57 ms per token,  1747.30 tokens per second)\n",
            "llama_print_timings: prompt eval time =     268.55 ms /    70 tokens (    3.84 ms per token,   260.66 tokens per second)\n",
            "llama_print_timings:        eval time =    1579.85 ms /    15 runs   (  105.32 ms per token,     9.49 tokens per second)\n",
            "llama_print_timings:       total time =    2055.13 ms /    85 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "@SonicOne1769 @mateo1209 @orlando80020928 @Mastergabri1 @BigNewsOP Sanji trains his observation haki every day by detecting girls. She has the most advanced radar of the crew when it comes to women.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.76 ms /    16 runs   (    0.55 ms per token,  1825.86 tokens per second)\n",
            "llama_print_timings: prompt eval time =     235.22 ms /    35 tokens (    6.72 ms per token,   148.80 tokens per second)\n",
            "llama_print_timings:        eval time =    1593.97 ms /    15 runs   (  106.26 ms per token,     9.41 tokens per second)\n",
            "llama_print_timings:       total time =    1977.86 ms /    50 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "Team of the doctor and the girls agree on one thing, fora Thomas fora Shay 🤝 #AFazenda14\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.37 ms /    16 runs   (    0.59 ms per token,  1707.94 tokens per second)\n",
            "llama_print_timings: prompt eval time =     395.40 ms /   134 tokens (    2.95 ms per token,   338.90 tokens per second)\n",
            "llama_print_timings:        eval time =    1508.04 ms /    15 runs   (  100.54 ms per token,     9.95 tokens per second)\n",
            "llama_print_timings:       total time =    2269.28 ms /   149 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "#104 c.showing their talent and popularity🔥#BTS #ARMY ✅️#JIN at the Korean Open Tennis Tournament🎾 Eugene Investment &amp; Securities 2022.New talent unlocked🔓🏅 ✅️#TAEHYUNG updated profile, BELLA📸with a great message behind \"Enough🚫 with cyberbullying\" (2.016💋)↘️ https://t.co/nNZIMmF6uF\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.79 ms /    16 runs   (    0.74 ms per token,  1357.08 tokens per second)\n",
            "llama_print_timings: prompt eval time =     268.55 ms /    57 tokens (    4.71 ms per token,   212.25 tokens per second)\n",
            "llama_print_timings:        eval time =    1816.72 ms /    15 runs   (  121.11 ms per token,     8.26 tokens per second)\n",
            "llama_print_timings:       total time =    2397.51 ms /    72 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "In MY point of view, there is more cyberbullying here on Twitter for @EVillegasV than anything else, for the issue of equal marriage. copy-past tweets 🫣 and it's disastrous....\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.36 ms /    16 runs   (    0.59 ms per token,  1709.04 tokens per second)\n",
            "llama_print_timings: prompt eval time =     282.73 ms /    78 tokens (    3.62 ms per token,   275.88 tokens per second)\n",
            "llama_print_timings:        eval time =    1619.98 ms /    15 runs   (  108.00 ms per token,     9.26 tokens per second)\n",
            "llama_print_timings:       total time =    2132.71 ms /    93 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "@dekishira_ @mariocarreteroo okay but that mistake is called cyberbullying and surely the girl to whom you dedicated the thread right now is very screwed while the girl you are trying to defend, who will already be old enough to know how to publicly humiliate someone It's terrible, it will be so good\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.55 ms /    16 runs   (    0.53 ms per token,  1870.91 tokens per second)\n",
            "llama_print_timings: prompt eval time =     593.83 ms /    32 tokens (   18.56 ms per token,    53.89 tokens per second)\n",
            "llama_print_timings:        eval time =    1546.43 ms /    15 runs   (  103.10 ms per token,     9.70 tokens per second)\n",
            "llama_print_timings:       total time =    2271.70 ms /    47 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "Freedom of expression faced 415 attacks, reveals report https://t.co/2zwmGXSO8F\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.87 ms /    16 runs   (    0.55 ms per token,  1803.22 tokens per second)\n",
            "llama_print_timings: prompt eval time =     301.75 ms /    98 tokens (    3.08 ms per token,   324.77 tokens per second)\n",
            "llama_print_timings:        eval time =    1495.51 ms /    15 runs   (   99.70 ms per token,    10.03 tokens per second)\n",
            "llama_print_timings:       total time =    2059.87 ms /   113 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "➡️New entry in #BlogDeBibliotecas by @educaciongob to present the latest issue of the Education Magazine, whose monograph is dedicated to #cyberbullying, an educational, social and health problem.👉Consult the blog and access the articles: https:/ /t.co/yUErf1e3T5 https://t.co/v4qXRz8vYZ\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.05 ms /    16 runs   (    0.63 ms per token,  1592.04 tokens per second)\n",
            "llama_print_timings: prompt eval time =     268.56 ms /    57 tokens (    4.71 ms per token,   212.24 tokens per second)\n",
            "llama_print_timings:        eval time =    1561.56 ms /    15 runs   (  104.10 ms per token,     9.61 tokens per second)\n",
            "llama_print_timings:       total time =    2106.60 ms /    72 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "DPO&amp;itlaw DTI News is available! https://t.co/cZ6gkmiT4p Thanks to @OfeTG @ricardmm @identidadrobada #cyberbullying #crime\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.76 ms /    16 runs   (    0.55 ms per token,  1826.48 tokens per second)\n",
            "llama_print_timings: prompt eval time =     243.50 ms /    38 tokens (    6.41 ms per token,   156.06 tokens per second)\n",
            "llama_print_timings:        eval time =    1548.51 ms /    15 runs   (  103.23 ms per token,     9.69 tokens per second)\n",
            "llama_print_timings:       total time =    1944.87 ms /    53 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "Trans women DO NOT want to erase cisgender women and trans men are NOT traitors.https://t.co/RSuCOTFrYi\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.50 ms /    16 runs   (    0.59 ms per token,  1685.10 tokens per second)\n",
            "llama_print_timings: prompt eval time =     266.95 ms /    60 tokens (    4.45 ms per token,   224.76 tokens per second)\n",
            "llama_print_timings:        eval time =    1672.58 ms /    15 runs   (  111.51 ms per token,     8.97 tokens per second)\n",
            "llama_print_timings:       total time =    2128.94 ms /    75 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "There was constant poor attention from management to the area where I worked and the demands were maximum. They hired people to support us with a new menu, and this is not to exclude, but they were cisgender people who did not make me feel safe in collaboration. ...\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.42 ms /    16 runs   (    0.71 ms per token,  1400.68 tokens per second)\n",
            "llama_print_timings: prompt eval time =     262.01 ms /    48 tokens (    5.46 ms per token,   183.20 tokens per second)\n",
            "llama_print_timings:        eval time =    1845.29 ms /    15 runs   (  123.02 ms per token,     8.13 tokens per second)\n",
            "llama_print_timings:       total time =    2398.29 ms /    63 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "The survey item does not discriminate between men and women, but rather between cisgender and other identities. It's not that difficult. https://t.co/KDbSmStf4u\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.91 ms /    16 runs   (    0.56 ms per token,  1795.53 tokens per second)\n",
            "llama_print_timings: prompt eval time =     279.52 ms /    88 tokens (    3.18 ms per token,   314.82 tokens per second)\n",
            "llama_print_timings:        eval time =    1545.91 ms /    15 runs   (  103.06 ms per token,     9.70 tokens per second)\n",
            "llama_print_timings:       total time =    2069.86 ms /   103 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "@pachusaenzcavia @Karenfiorellanv that means pigeonholing bad people only because they are cisgender 🤔is that also re? blaming others, victimizing yourself, eg: everyone is bad. Accept that you allowed everything they did to you and that you obviously chose wrong. learn from that, don't lock yourself in, they are all bad\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.38 ms /    16 runs   (    0.59 ms per token,  1705.39 tokens per second)\n",
            "llama_print_timings: prompt eval time =     261.38 ms /    57 tokens (    4.59 ms per token,   218.07 tokens per second)\n",
            "llama_print_timings:        eval time =    1564.74 ms /    15 runs   (  104.32 ms per token,     9.59 tokens per second)\n",
            "llama_print_timings:       total time =    2010.29 ms /    72 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "Well nothing, literally having an anxiety attack because I have written that abortion is an experience that cisgender women go through when I wanted to say what NOT ONLY cisgender women go through or what AFAB people go through. How was your Friday?\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.16 ms /    16 runs   (    0.57 ms per token,  1747.30 tokens per second)\n",
            "llama_print_timings: prompt eval time =     250.17 ms /    36 tokens (    6.95 ms per token,   143.90 tokens per second)\n",
            "llama_print_timings:        eval time =    1632.91 ms /    15 runs   (  108.86 ms per token,     9.19 tokens per second)\n",
            "llama_print_timings:       total time =    2040.10 ms /    51 tokens\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATED: [INST]\n",
            "@pedrovillakan Because I am cis and I am lesbian. Being Cisgender is identifying with the sex you were born with.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.86 ms /    16 runs   (    0.55 ms per token,  1805.05 tokens per second)\n",
            "llama_print_timings: prompt eval time =     284.57 ms /    89 tokens (    3.20 ms per token,   312.76 tokens per second)\n",
            "llama_print_timings:        eval time =    1564.26 ms /    15 runs   (  104.28 ms per token,     9.59 tokens per second)\n",
            "llama_print_timings:       total time =    2094.53 ms /   104 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "I remind you that we have a Co-education Congress with CLAVICO on October 1 and 2. If you've never come to one of our conferences, you don't know what you're missing. They are special conferences, sign up, you won't regret it. All the info at: https://t.co/OrA9tm0fi2\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.33 ms /    16 runs   (    0.58 ms per token,  1714.71 tokens per second)\n",
            "llama_print_timings: prompt eval time =     254.18 ms /    59 tokens (    4.31 ms per token,   232.12 tokens per second)\n",
            "llama_print_timings:        eval time =    1533.98 ms /    15 runs   (  102.27 ms per token,     9.78 tokens per second)\n",
            "llama_print_timings:       total time =    1974.88 ms /    74 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "You don't have to (transform) anything, you don't need to invent anything new, the solution is COEDUCATION, this is how you educate in equality 🙌🙌https://t.co/487EMu5ZAl\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.74 ms /    16 runs   (    0.67 ms per token,  1490.17 tokens per second)\n",
            "llama_print_timings: prompt eval time =     271.57 ms /    67 tokens (    4.05 ms per token,   246.71 tokens per second)\n",
            "llama_print_timings:        eval time =    1703.70 ms /    15 runs   (  113.58 ms per token,     8.80 tokens per second)\n",
            "llama_print_timings:       total time =    2309.27 ms /    82 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@IreneMontero That law is stupid. Do women who wantonly fuck with their partners, those who care for them, etc. say no? Submission is consented. What needs to be done is to educate in rebellion and feminism. Coeducation and not trans laws\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.32 ms /    16 runs   (    0.58 ms per token,  1716.19 tokens per second)\n",
            "llama_print_timings: prompt eval time =     276.82 ms /    80 tokens (    3.46 ms per token,   288.99 tokens per second)\n",
            "llama_print_timings:        eval time =    1505.90 ms /    15 runs   (  100.39 ms per token,     9.96 tokens per second)\n",
            "llama_print_timings:       total time =    2019.88 ms /    95 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "📅📅 Are you looking forward to a conference? In October the @IAMJunta 🚺🚺 organizes the third Andalusian congress of #Coeducation in #Cádiz📕📕 https://t.co/NBMq4PI8cw\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.56 ms /    16 runs   (    0.60 ms per token,  1673.12 tokens per second)\n",
            "llama_print_timings: prompt eval time =     266.47 ms /    60 tokens (    4.44 ms per token,   225.17 tokens per second)\n",
            "llama_print_timings:        eval time =    1513.69 ms /    15 runs   (  100.91 ms per token,     9.91 tokens per second)\n",
            "llama_print_timings:       total time =    1969.10 ms /    75 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Feminists will not remain silent. We do not allow you to pornify minors. Real coeducation now! We will continue to denounce the queer anti-feminist agendahttps://t.co/E6RiHRaIMb\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.43 ms /    16 runs   (    0.59 ms per token,  1697.43 tokens per second)\n",
            "llama_print_timings: prompt eval time =     246.05 ms /    51 tokens (    4.82 ms per token,   207.27 tokens per second)\n",
            "llama_print_timings:        eval time =    1490.41 ms /    15 runs   (   99.36 ms per token,    10.06 tokens per second)\n",
            "llama_print_timings:       total time =    1918.64 ms /    66 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "The workshop taught by Ana Magallanes on Coeducation to Prevent Sexist Violence begins 👀 @Gabifcom @unisevilla https://t.co/TAO6GvrOWm\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.16 ms /    16 runs   (    0.63 ms per token,  1574.96 tokens per second)\n",
            "llama_print_timings: prompt eval time =     294.03 ms /    75 tokens (    3.92 ms per token,   255.08 tokens per second)\n",
            "llama_print_timings:        eval time =    1606.01 ms /    15 runs   (  107.07 ms per token,     9.34 tokens per second)\n",
            "llama_print_timings:       total time =    2264.46 ms /    90 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@zarinagpenya @AntonCabrera3 @NarichiHimochi @picanteflipante Don't be ridiculous, you know what I mean, I gave some characteristics but there are more, and a muntiac can be differentiated from a dog. Just like a woman from a man.\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.43 ms /    16 runs   (    0.59 ms per token,  1696.53 tokens per second)\n",
            "llama_print_timings: prompt eval time =     296.55 ms /    92 tokens (    3.22 ms per token,   310.24 tokens per second)\n",
            "llama_print_timings:        eval time =    1528.98 ms /    15 runs   (  101.93 ms per token,     9.81 tokens per second)\n",
            "llama_print_timings:       total time =    2082.06 ms /   107 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "#Guatemala As @HBSsansalvador we join the @fundamyrnamack to honor Myrna Mack, as a woman who with her life gave voice to those who in silence cried out for justice, for a dignified life. #32yearsMyrnaMack Video from the Myrna Mack Foundation. https://t.co/F7ShB7m4FD\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       7.72 ms /    16 runs   (    0.48 ms per token,  2071.73 tokens per second)\n",
            "llama_print_timings: prompt eval time =     249.01 ms /    64 tokens (    3.89 ms per token,   257.01 tokens per second)\n",
            "llama_print_timings:        eval time =    1569.18 ms /    15 runs   (  104.61 ms per token,     9.56 tokens per second)\n",
            "llama_print_timings:       total time =    2025.63 ms /    79 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@LordVacant In fact... they have already confirmed that it is Girlhttps://t.co/fpmx3soAwb\"Nate Bihldorff, senior vice president of development and publishing at Nintendo, announced that the character identifies as a woman\"+\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.19 ms /    16 runs   (    0.64 ms per token,  1570.01 tokens per second)\n",
            "llama_print_timings: prompt eval time =     248.87 ms /    44 tokens (    5.66 ms per token,   176.80 tokens per second)\n",
            "llama_print_timings:        eval time =    1718.54 ms /    15 runs   (  114.57 ms per token,     8.73 tokens per second)\n",
            "llama_print_timings:       total time =    2144.22 ms /    59 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Many people perceive me as a strong, intelligent and determined woman...if they knew that today I cried just because my banana was green and tasted fucking ugly but I was very hungry.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.31 ms /    16 runs   (    0.58 ms per token,  1719.32 tokens per second)\n",
            "llama_print_timings: prompt eval time =     292.75 ms /    86 tokens (    3.40 ms per token,   293.77 tokens per second)\n",
            "llama_print_timings:        eval time =    1452.48 ms /    15 runs   (   96.83 ms per token,    10.33 tokens per second)\n",
            "llama_print_timings:       total time =    2002.61 ms /   101 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@RobertoMerken @Vulcano98263715 Roberto, you fall into the same thing again. You denigrate his arguments just for being a man and Opus Dei. Feminism is above all a philosophical idea, and as such an Opus Dei man has the same right to give his opinion as a radical feminist woman.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.64 ms /    16 runs   (    0.60 ms per token,  1658.89 tokens per second)\n",
            "llama_print_timings: prompt eval time =     267.97 ms /    65 tokens (    4.12 ms per token,   242.57 tokens per second)\n",
            "llama_print_timings:        eval time =    1510.53 ms /    15 runs   (  100.70 ms per token,     9.93 tokens per second)\n",
            "llama_print_timings:       total time =    1981.19 ms /    80 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "\"I would like to be known as an intelligent #woman, a brave woman, a loving woman, a woman who teaches by being.\" 🦸‍♀️-Maya Angelou#ReadingTuesday https://t.co/8zmnXjO2BC\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.71 ms /    16 runs   (    0.54 ms per token,  1835.92 tokens per second)\n",
            "llama_print_timings: prompt eval time =     575.84 ms /    23 tokens (   25.04 ms per token,    39.94 tokens per second)\n",
            "llama_print_timings:        eval time =    1552.44 ms /    15 runs   (  103.50 ms per token,     9.66 tokens per second)\n",
            "llama_print_timings:       total time =    2245.67 ms /    38 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "I'm like a little girl who needs a warm cup of colacao to sleep\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.10 ms /    16 runs   (    0.57 ms per token,  1757.86 tokens per second)\n",
            "llama_print_timings: prompt eval time =     256.65 ms /    37 tokens (    6.94 ms per token,   144.16 tokens per second)\n",
            "llama_print_timings:        eval time =    1549.22 ms /    15 runs   (  103.28 ms per token,     9.68 tokens per second)\n",
            "llama_print_timings:       total time =    1955.60 ms /    52 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@soonabineri and the remorse of N's 💩 seeing how a girl witnessed the baseness he did to her mom\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.26 ms /    16 runs   (    0.58 ms per token,  1727.30 tokens per second)\n",
            "llama_print_timings: prompt eval time =     277.80 ms /    75 tokens (    3.70 ms per token,   269.98 tokens per second)\n",
            "llama_print_timings:        eval time =    1458.43 ms /    15 runs   (   97.23 ms per token,    10.29 tokens per second)\n",
            "llama_print_timings:       total time =    1952.62 ms /    90 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "At 43 I will change many things (some of you already know my new resolutions). Because the important thing is the people, I promise to do better and I'm sorry for not being up to par with some people until now. Ah, tomorrow I plan to celebrate like a girl! #friends #family #next43\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.71 ms /    16 runs   (    0.54 ms per token,  1836.76 tokens per second)\n",
            "llama_print_timings: prompt eval time =     265.59 ms /    58 tokens (    4.58 ms per token,   218.39 tokens per second)\n",
            "llama_print_timings:        eval time =    1476.63 ms /    15 runs   (   98.44 ms per token,    10.16 tokens per second)\n",
            "llama_print_timings:       total time =    1948.79 ms /    73 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "When someone dies, I almost always hold back my tears, even though I know it shouldn't be done, I do it... But a year ago I couldn't do it, I cried like a girl and I had that horrible pain in my chest...\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.00 ms /    16 runs   (    0.69 ms per token,  1454.55 tokens per second)\n",
            "llama_print_timings: prompt eval time =     307.44 ms /    87 tokens (    3.53 ms per token,   282.98 tokens per second)\n",
            "llama_print_timings:        eval time =    1679.07 ms /    15 runs   (  111.94 ms per token,     8.93 tokens per second)\n",
            "llama_print_timings:       total time =    2389.66 ms /   102 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Metropoles @marcondesbrito They are pats of affection, they look at her like a child, they are pampering her, I don't know why there is so much evil in the human eye, has no one spanked their baby? It is not a lack of respect, but of Surely with this they will never celebrate that way again, people of bad living\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.66 ms /    16 runs   (    0.54 ms per token,  1846.72 tokens per second)\n",
            "llama_print_timings: prompt eval time =     677.56 ms /    28 tokens (   24.20 ms per token,    41.32 tokens per second)\n",
            "llama_print_timings:        eval time =    1473.23 ms /    15 runs   (   98.22 ms per token,    10.18 tokens per second)\n",
            "llama_print_timings:       total time =    2279.15 ms /    43 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "My sister's boss's family sees me as a little girl who doesn't pull any punches.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.55 ms /    16 runs   (    0.60 ms per token,  1674.87 tokens per second)\n",
            "llama_print_timings: prompt eval time =     754.27 ms /    29 tokens (   26.01 ms per token,    38.45 tokens per second)\n",
            "llama_print_timings:        eval time =    1540.15 ms /    15 runs   (  102.68 ms per token,     9.74 tokens per second)\n",
            "llama_print_timings:       total time =    2426.53 ms /    44 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@HizukiMiu how can I slack off?... miu bad, give yourself respect like a lady\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.90 ms /    16 runs   (    0.56 ms per token,  1797.95 tokens per second)\n",
            "llama_print_timings: prompt eval time =     240.81 ms /    35 tokens (    6.88 ms per token,   145.34 tokens per second)\n",
            "llama_print_timings:        eval time =    1581.89 ms /    15 runs   (  105.46 ms per token,     9.48 tokens per second)\n",
            "llama_print_timings:       total time =    1967.46 ms /    50 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "I just realized that I have people on social media who know me as an adult and serious lady, and I upload every story 🤦‍♀️\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.88 ms /    16 runs   (    0.62 ms per token,  1618.61 tokens per second)\n",
            "llama_print_timings: prompt eval time =     268.20 ms /    60 tokens (    4.47 ms per token,   223.71 tokens per second)\n",
            "llama_print_timings:        eval time =    1472.37 ms /    15 runs   (   98.16 ms per token,    10.19 tokens per second)\n",
            "llama_print_timings:       total time =    1929.32 ms /    75 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Sit like a Miss Shaoni... at this point you want to \"get attention\" but clearly there is only me in my house and that's how I felt like sitting down first. More comfortable https://t.co/uydR6sEebi\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.24 ms /    16 runs   (    0.51 ms per token,  1941.98 tokens per second)\n",
            "llama_print_timings: prompt eval time =     748.35 ms /    29 tokens (   25.81 ms per token,    38.75 tokens per second)\n",
            "llama_print_timings:        eval time =    1482.46 ms /    15 runs   (   98.83 ms per token,    10.12 tokens per second)\n",
            "llama_print_timings:       total time =    2358.87 ms /    44 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "I swear that today I ate the ice cream like a \"lady\" but I still got stains on it.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.81 ms /    16 runs   (    0.55 ms per token,  1816.32 tokens per second)\n",
            "llama_print_timings: prompt eval time =     256.42 ms /    50 tokens (    5.13 ms per token,   194.99 tokens per second)\n",
            "llama_print_timings:        eval time =    1565.41 ms /    15 runs   (  104.36 ms per token,     9.58 tokens per second)\n",
            "llama_print_timings:       total time =    1990.26 ms /    65 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@tomascasascm Haha. What innocence... \"Madam, stop charging 5 thousand a month, I will give you a thousand euros if you behave like a lady and stop sleeping with men.\"\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.27 ms /    16 runs   (    0.64 ms per token,  1558.69 tokens per second)\n",
            "llama_print_timings: prompt eval time =     255.00 ms /    40 tokens (    6.37 ms per token,   156.86 tokens per second)\n",
            "llama_print_timings:        eval time =    1793.68 ms /    15 runs   (  119.58 ms per token,     8.36 tokens per second)\n",
            "llama_print_timings:       total time =    2219.22 ms /    55 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "X: Kane you go to a fancy restaurant behave like a ladyAlso Kane: https://t.co/1FhO4HfWqN\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.06 ms /    16 runs   (    0.57 ms per token,  1766.39 tokens per second)\n",
            "llama_print_timings: prompt eval time =     273.92 ms /    69 tokens (    3.97 ms per token,   251.90 tokens per second)\n",
            "llama_print_timings:        eval time =    1533.05 ms /    15 runs   (  102.20 ms per token,     9.78 tokens per second)\n",
            "llama_print_timings:       total time =    2012.74 ms /    84 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Give Mexican cinema a chance and go see \"WHEN IT'S YOUNG\", a remake with our humor, a lot of reflection and emotions about youth, parents, old age, conciliation, opportunities, changes with the times and with a soundtrack and vintage films super pretty 🤩\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.20 ms /    16 runs   (    0.58 ms per token,  1738.75 tokens per second)\n",
            "llama_print_timings: prompt eval time =     261.12 ms /    54 tokens (    4.84 ms per token,   206.80 tokens per second)\n",
            "llama_print_timings:        eval time =    1641.55 ms /    15 runs   (  109.44 ms per token,     9.14 tokens per second)\n",
            "llama_print_timings:       total time =    2083.12 ms /    69 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "And although it seems that Chavismo is not to blame in this, the Peace Courts disappeared as best they could, which were effective instruments for conciliation between neighbors https://t.co/JMdgbaJNxM\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.03 ms /    16 runs   (    0.63 ms per token,  1595.69 tokens per second)\n",
            "llama_print_timings: prompt eval time =     263.78 ms /    58 tokens (    4.55 ms per token,   219.88 tokens per second)\n",
            "llama_print_timings:        eval time =    1482.02 ms /    15 runs   (   98.80 ms per token,    10.12 tokens per second)\n",
            "llama_print_timings:       total time =    1948.89 ms /    73 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "They support the solution of neighborhood conflicts with mediation and conciliation tables in the capital of Puebla 👬🏽🫱🏻‍🫲🏽 https://t.co/mGNmQ8POZe\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.21 ms /    14 runs   (    0.73 ms per token,  1371.61 tokens per second)\n",
            "llama_print_timings: prompt eval time =     277.06 ms /    68 tokens (    4.07 ms per token,   245.43 tokens per second)\n",
            "llama_print_timings:        eval time =    1491.60 ms /    13 runs   (  114.74 ms per token,     8.72 tokens per second)\n",
            "llama_print_timings:       total time =    2115.04 ms /    81 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "How important a good relationship with our labor conciliation authorities, the very good relations between the private sector and our authorities, bear fruit in harmony, work together, and always seeking to improve, congratulations to our president C Villaseñor!! https://t.co/e2PsLkxDrx\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.81 ms /    16 runs   (    0.61 ms per token,  1630.99 tokens per second)\n",
            "llama_print_timings: prompt eval time =     276.28 ms /    79 tokens (    3.50 ms per token,   285.94 tokens per second)\n",
            "llama_print_timings:        eval time =    1502.58 ms /    15 runs   (  100.17 ms per token,     9.98 tokens per second)\n",
            "llama_print_timings:       total time =    2004.17 ms /    94 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "I have always defended that people without children should be able to reconcile the same as those who do have them, but honestly the individualistic and selfish current that exists in the \"you have decided to have children, your reconciliation is not more important than mine\" bothers me a lot. . https://t.co/nhHR1Igt9S\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.67 ms /    16 runs   (    0.60 ms per token,  1655.46 tokens per second)\n",
            "llama_print_timings: prompt eval time =     296.57 ms /    89 tokens (    3.33 ms per token,   300.10 tokens per second)\n",
            "llama_print_timings:        eval time =    1462.43 ms /    15 runs   (   97.50 ms per token,    10.26 tokens per second)\n",
            "llama_print_timings:       total time =    2009.12 ms /   104 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Espeansa Welcome to Disney World.R-33 I usually do 10 guards a month and sometimes more. 190-200 hours per month on duty. My life as a sleepwalker and family conciliation, a myth. There will be someone who will say that I am rich.... Why continue... https://t.co/2SPpo0vi4L\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.71 ms /    16 runs   (    0.73 ms per token,  1366.70 tokens per second)\n",
            "llama_print_timings: prompt eval time =     282.98 ms /    82 tokens (    3.45 ms per token,   289.77 tokens per second)\n",
            "llama_print_timings:        eval time =    1814.19 ms /    15 runs   (  120.95 ms per token,     8.27 tokens per second)\n",
            "llama_print_timings:       total time =    2496.70 ms /    97 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "We are short of places in the public We are having difficulties in reconciling studies/work We are cheap labor during internships Today's vocational training needs the organization of the student body to ensure that it is at their service, and not the other way around. #YoSoyFP https:/ /t.co/qBfGOciPzT\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.67 ms /    16 runs   (    0.54 ms per token,  1845.02 tokens per second)\n",
            "llama_print_timings: prompt eval time =     762.52 ms /    31 tokens (   24.60 ms per token,    40.65 tokens per second)\n",
            "llama_print_timings:        eval time =    1516.98 ms /    15 runs   (  101.13 ms per token,     9.89 tokens per second)\n",
            "llama_print_timings:       total time =    2411.14 ms /    46 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "I wish you a quality of life such that you masturbate out of desire and not out of the need to fall asleep.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.41 ms /    16 runs   (    0.59 ms per token,  1699.78 tokens per second)\n",
            "llama_print_timings: prompt eval time =     264.29 ms /    80 tokens (    3.30 ms per token,   302.70 tokens per second)\n",
            "llama_print_timings:        eval time =    1566.92 ms /    15 runs   (  104.46 ms per token,     9.57 tokens per second)\n",
            "llama_print_timings:       total time =    2070.39 ms /    95 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@delosquesobran I'm going to record it: I have tried with \"white noise\" to fall asleep but nothing. With this I hope that by article #30 I will be well asleep...., or turning off the computer to watch something on \"Ñefla\" https ://t.co/kUGC0tWdqg\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.93 ms /    16 runs   (    0.62 ms per token,  1611.77 tokens per second)\n",
            "llama_print_timings: prompt eval time =     265.96 ms /    60 tokens (    4.43 ms per token,   225.59 tokens per second)\n",
            "llama_print_timings:        eval time =    1526.16 ms /    15 runs   (  101.74 ms per token,     9.83 tokens per second)\n",
            "llama_print_timings:       total time =    1995.03 ms /    75 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "I will not be the one to take a position against women's rights, however, as a single mother from the beginning of pregnancy, it would be advisable to think: How can families, single-parent mothers, try to reconcile and get their children forward?\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.96 ms /    16 runs   (    0.75 ms per token,  1337.35 tokens per second)\n",
            "llama_print_timings: prompt eval time =     251.15 ms /    45 tokens (    5.58 ms per token,   179.18 tokens per second)\n",
            "llama_print_timings:        eval time =    1793.39 ms /    15 runs   (  119.56 ms per token,     8.36 tokens per second)\n",
            "llama_print_timings:       total time =    2319.49 ms /    60 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Monica_Garcia_G Madam, as long as you don't assimilate the defeat of 4M, you won't be able to sleep, right?\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.49 ms /    16 runs   (    0.59 ms per token,  1685.81 tokens per second)\n",
            "llama_print_timings: prompt eval time =     258.78 ms /    62 tokens (    4.17 ms per token,   239.59 tokens per second)\n",
            "llama_print_timings:        eval time =    1461.29 ms /    15 runs   (   97.42 ms per token,    10.26 tokens per second)\n",
            "llama_print_timings:       total time =    1916.35 ms /    77 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Impossible to reconcile anything with Iran, it has brought shame on Argentina's foreign policy in recent years. The president of Iran questioned the Holocaust and said it still needs to be investigated - Infobae https://t.co/vQFTQNRrHS\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.57 ms /    16 runs   (    0.60 ms per token,  1671.37 tokens per second)\n",
            "llama_print_timings: prompt eval time =     286.68 ms /    81 tokens (    3.54 ms per token,   282.55 tokens per second)\n",
            "llama_print_timings:        eval time =    1547.12 ms /    15 runs   (  103.14 ms per token,     9.70 tokens per second)\n",
            "llama_print_timings:       total time =    2066.75 ms /    96 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "The relevant question is who gave the orders to the boys representing the Mayor's Office. Did they act like this on their own initiative? , which makes them complicit with the attackers or did they act on the instructions of a superior? In any case there is co-responsibility of @Bogota https://t.co/S9kkPtpa1X\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.88 ms /    16 runs   (    0.68 ms per token,  1471.13 tokens per second)\n",
            "llama_print_timings: prompt eval time =     284.92 ms /    84 tokens (    3.39 ms per token,   294.82 tokens per second)\n",
            "llama_print_timings:        eval time =    1625.38 ms /    15 runs   (  108.36 ms per token,     9.23 tokens per second)\n",
            "llama_print_timings:       total time =    2299.12 ms /    99 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "#SubTrabenMedios 🗞️ | Undersecretary @gboccardobosoni, in an interview with the Diario @elsurcl, highlights the principles that drive the #40Hours project related to more time for effective rest, economic responsibility and social co-responsibility. https://t.co/kIPizN9a22\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.96 ms /    16 runs   (    0.56 ms per token,  1785.32 tokens per second)\n",
            "llama_print_timings: prompt eval time =     258.09 ms /    48 tokens (    5.38 ms per token,   185.98 tokens per second)\n",
            "llama_print_timings:        eval time =    1524.62 ms /    15 runs   (  101.64 ms per token,     9.84 tokens per second)\n",
            "llama_print_timings:       total time =    1952.35 ms /    63 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "The big question remains how do we manage risks from co-responsibility? What happened between Friday and Saturday should not be the norm but the exception. https://t.co/kChpc4whDt\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.47 ms /    16 runs   (    0.65 ms per token,  1528.03 tokens per second)\n",
            "llama_print_timings: prompt eval time =     258.92 ms /    63 tokens (    4.11 ms per token,   243.32 tokens per second)\n",
            "llama_print_timings:        eval time =    1754.28 ms /    15 runs   (  116.95 ms per token,     8.55 tokens per second)\n",
            "llama_print_timings:       total time =    2222.45 ms /    78 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "and community, as well as to promote social and gender co-responsibility, so that women are not the ones who assume domestic and care work. In addition, job insecurity is prohibited. So let's participate actively and we will win. #Vote #Approve!\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.43 ms /    16 runs   (    0.59 ms per token,  1696.35 tokens per second)\n",
            "llama_print_timings: prompt eval time =     286.68 ms /    85 tokens (    3.37 ms per token,   296.50 tokens per second)\n",
            "llama_print_timings:        eval time =    1519.22 ms /    15 runs   (  101.28 ms per token,     9.87 tokens per second)\n",
            "llama_print_timings:       total time =    2044.84 ms /   100 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "📝 | Bill on Co-Responsibility in Parenting ✅ We share part of the basis for the affirmative vote of our Senator @Carmensangui in yesterday's session🔗 Full intervention: https://t.co/DYcVD74B0H https://t.co/ bdL7aSJ8c4\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.43 ms /    16 runs   (    0.59 ms per token,  1696.35 tokens per second)\n",
            "llama_print_timings: prompt eval time =     303.61 ms /   101 tokens (    3.01 ms per token,   332.67 tokens per second)\n",
            "llama_print_timings:        eval time =    1576.35 ms /    15 runs   (  105.09 ms per token,     9.52 tokens per second)\n",
            "llama_print_timings:       total time =    2149.40 ms /   116 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "👉Would you like to raise awareness among your company's staff about Equality?💡Are you interested in training on conciliation and co-responsibility? ⭐️Do you want to make your commitment to Equality visible?#PracticaLaIgualdad #MarcaLaDifferencehttps://t.co/UhbrwEd3Ip https:/ /t.co/T8j805fNT8\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.62 ms /    16 runs   (    0.60 ms per token,  1663.89 tokens per second)\n",
            "llama_print_timings: prompt eval time =     243.66 ms /    45 tokens (    5.41 ms per token,   184.68 tokens per second)\n",
            "llama_print_timings:        eval time =    1602.92 ms /    15 runs   (  106.86 ms per token,     9.36 tokens per second)\n",
            "llama_print_timings:       total time =    2012.71 ms /    60 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "The Summer Course 'Gender Violence' by @unirioja will address the objectification of the female body https://t.co/w2xRhR9096\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.60 ms /    16 runs   (    0.60 ms per token,  1667.54 tokens per second)\n",
            "llama_print_timings: prompt eval time =     259.64 ms /    41 tokens (    6.33 ms per token,   157.91 tokens per second)\n",
            "llama_print_timings:        eval time =    1701.95 ms /    15 runs   (  113.46 ms per token,     8.81 tokens per second)\n",
            "llama_print_timings:       total time =    2196.47 ms /    56 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@sofilopiccolo But The Patriarchy, the objectification of the female body and El Coso??? Haaaa there is money involved...freedom empower...Art!!!!\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.15 ms /    16 runs   (    0.57 ms per token,  1748.63 tokens per second)\n",
            "llama_print_timings: prompt eval time =     251.39 ms /    33 tokens (    7.62 ms per token,   131.27 tokens per second)\n",
            "llama_print_timings:        eval time =    1494.81 ms /    15 runs   (   99.65 ms per token,    10.03 tokens per second)\n",
            "llama_print_timings:       total time =    1884.06 ms /    48 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@AmarantaHankTw Before reading this book, it may help you to look up what the objectification of the female body means.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.53 ms /    16 runs   (    0.60 ms per token,  1679.44 tokens per second)\n",
            "llama_print_timings: prompt eval time =     261.06 ms /    66 tokens (    3.96 ms per token,   252.81 tokens per second)\n",
            "llama_print_timings:        eval time =    1662.16 ms /    15 runs   (  110.81 ms per token,     9.02 tokens per second)\n",
            "llama_print_timings:       total time =    2122.78 ms /    81 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@gmaemejota Fear, disgust, sorrow, and everything together. Wonderful consequences of the sexualization and objectification of the female body (regardless of age) since it produces economic return. But yes, then defending reproductive health rights and sexual education is pederasty.\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.06 ms /    16 runs   (    0.63 ms per token,  1590.93 tokens per second)\n",
            "llama_print_timings: prompt eval time =     284.76 ms /    98 tokens (    2.91 ms per token,   344.15 tokens per second)\n",
            "llama_print_timings:        eval time =    1595.70 ms /    15 runs   (  106.38 ms per token,     9.40 tokens per second)\n",
            "llama_print_timings:       total time =    2158.71 ms /   113 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@cienlargosdias @Alvaro00813623 @_zerdo @eltivipata Madam, may I remind you that this conversation began due to the objectification of the female body where I defended the elimination of a normative canon and you did not? If you want to translate it into a misogynistic act, okay, but you think your ideology prevents you from seeing this clearly.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.17 ms /    16 runs   (    0.64 ms per token,  1573.56 tokens per second)\n",
            "llama_print_timings: prompt eval time =     293.46 ms /    80 tokens (    3.67 ms per token,   272.61 tokens per second)\n",
            "llama_print_timings:        eval time =    1587.47 ms /    15 runs   (  105.83 ms per token,     9.45 tokens per second)\n",
            "llama_print_timings:       total time =    2244.58 ms /    95 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@amigadatecuen1 @Ashura_chan @Lalauralis @AlicciaDs You are wrong. And I think that is your problem of understanding. One thing is the objectification of the female body (something that occurs in hospital births, by the way) and another is deciding what to do with them, as in abortion.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.35 ms /    16 runs   (    0.52 ms per token,  1916.86 tokens per second)\n",
            "llama_print_timings: prompt eval time =     589.50 ms /    24 tokens (   24.56 ms per token,    40.71 tokens per second)\n",
            "llama_print_timings:        eval time =    1503.65 ms /    15 runs   (  100.24 ms per token,     9.98 tokens per second)\n",
            "llama_print_timings:       total time =    2213.50 ms /    39 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@saintloyal I would happily work as a Panda caregiver 🥰🥰🥰\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.45 ms /    16 runs   (    0.53 ms per token,  1893.94 tokens per second)\n",
            "llama_print_timings: prompt eval time =     692.31 ms /    27 tokens (   25.64 ms per token,    39.00 tokens per second)\n",
            "llama_print_timings:        eval time =    1494.46 ms /    15 runs   (   99.63 ms per token,    10.04 tokens per second)\n",
            "llama_print_timings:       total time =    2321.37 ms /    42 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "I want to be a panda keeper https://t.co/vKcmoz6LT5\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.83 ms /    16 runs   (    0.55 ms per token,  1811.39 tokens per second)\n",
            "llama_print_timings: prompt eval time =     500.61 ms /    20 tokens (   25.03 ms per token,    39.95 tokens per second)\n",
            "llama_print_timings:        eval time =    1581.39 ms /    15 runs   (  105.43 ms per token,     9.49 tokens per second)\n",
            "llama_print_timings:       total time =    2197.69 ms /    35 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "I don't know how I became all my neighbors' cat sitter.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.32 ms /    16 runs   (    0.58 ms per token,  1716.00 tokens per second)\n",
            "llama_print_timings: prompt eval time =     250.10 ms /    40 tokens (    6.25 ms per token,   159.94 tokens per second)\n",
            "llama_print_timings:        eval time =    1663.36 ms /    15 runs   (  110.89 ms per token,     9.02 tokens per second)\n",
            "llama_print_timings:       total time =    2139.50 ms /    55 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "She is Margarita and she is cute, despite her caregiver's poor skills. https://t.co/xANwgmK3aC\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.07 ms /    16 runs   (    0.57 ms per token,  1764.45 tokens per second)\n",
            "llama_print_timings: prompt eval time =     254.21 ms /    42 tokens (    6.05 ms per token,   165.22 tokens per second)\n",
            "llama_print_timings:        eval time =    1511.76 ms /    15 runs   (  100.78 ms per token,     9.92 tokens per second)\n",
            "llama_print_timings:       total time =    1920.14 ms /    57 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "The sound of inclusion: How to be a 24/7 caregiver mom and not die trying? https://t.co/xDv0GHsRpm\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.19 ms /    16 runs   (    0.57 ms per token,  1741.78 tokens per second)\n",
            "llama_print_timings: prompt eval time =     259.13 ms /    50 tokens (    5.18 ms per token,   192.95 tokens per second)\n",
            "llama_print_timings:        eval time =    1488.87 ms /    15 runs   (   99.26 ms per token,    10.07 tokens per second)\n",
            "llama_print_timings:       total time =    1916.89 ms /    65 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Convicted in #Murcia for #attacking his father's caregiver📰@diariolaopinion https://t.co/YD2vKuHNzI\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.11 ms /    16 runs   (    0.57 ms per token,  1757.08 tokens per second)\n",
            "llama_print_timings: prompt eval time =     244.34 ms /    38 tokens (    6.43 ms per token,   155.52 tokens per second)\n",
            "llama_print_timings:        eval time =    1573.20 ms /    15 runs   (  104.88 ms per token,     9.53 tokens per second)\n",
            "llama_print_timings:       total time =    1981.53 ms /    53 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@maxiluzbelito_ @RiverLPM The dead don't speak, you died in Madrid, broken ass, pent-up hahaha\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.92 ms /    16 runs   (    0.62 ms per token,  1613.07 tokens per second)\n",
            "llama_print_timings: prompt eval time =     264.90 ms /    53 tokens (    5.00 ms per token,   200.07 tokens per second)\n",
            "llama_print_timings:        eval time =    1533.25 ms /    15 runs   (  102.22 ms per token,     9.78 tokens per second)\n",
            "llama_print_timings:       total time =    2075.42 ms /    68 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@MAndreaNieto And when they said that foreign investment would fall due to fear that Petro would be president, what? That's what Bolivar is referring to, they definitely have the understanding in their asses.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.41 ms /    16 runs   (    0.59 ms per token,  1700.14 tokens per second)\n",
            "llama_print_timings: prompt eval time =     299.95 ms /   105 tokens (    2.86 ms per token,   350.06 tokens per second)\n",
            "llama_print_timings:        eval time =    1477.24 ms /    15 runs   (   98.48 ms per token,    10.15 tokens per second)\n",
            "llama_print_timings:       total time =    2052.60 ms /   120 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@_nao_nao12 @Danny49645523 @MatasCornejo5 @tere_marinovic. Production was stopped by the idiotic illiterate \"comrades\" who took control of expropriated companies..Then they took the \"comrades\" to the UP marches..They didn't know how to wipe their asses , but they managed the companies... Today the same people try to govern...\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.60 ms /    16 runs   (    0.60 ms per token,  1667.36 tokens per second)\n",
            "llama_print_timings: prompt eval time =     255.80 ms /    65 tokens (    3.94 ms per token,   254.11 tokens per second)\n",
            "llama_print_timings:        eval time =    1551.63 ms /    15 runs   (  103.44 ms per token,     9.67 tokens per second)\n",
            "llama_print_timings:       total time =    2013.83 ms /    80 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@moraflorezlucia @ELTIEMPO Oh, shut up, it's obvious that you don't know a damn thing about national history. Rather, she opens an onlyfans, which is the only thing that half a neuron he has is useful for.\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.57 ms /    16 runs   (    0.72 ms per token,  1382.53 tokens per second)\n",
            "llama_print_timings: prompt eval time =     285.39 ms /    75 tokens (    3.81 ms per token,   262.80 tokens per second)\n",
            "llama_print_timings:        eval time =    1676.89 ms /    15 runs   (  111.79 ms per token,     8.95 tokens per second)\n",
            "llama_print_timings:       total time =    2223.31 ms /    90 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "THE COCK BLOWER WHO IS SHOOTING ROCKETS AT 2 IN THE MORNING, WHY DON'T HE THROW IT ON HIS DICK AND END HIS SHIT LIFE??? OR DO YOU HAVE TO FUCK AND SCARED THE BITCH OUT OF ME??\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.85 ms /    16 runs   (    0.55 ms per token,  1807.50 tokens per second)\n",
            "llama_print_timings: prompt eval time =     761.82 ms /    29 tokens (   26.27 ms per token,    38.07 tokens per second)\n",
            "llama_print_timings:        eval time =    1521.81 ms /    15 runs   (  101.45 ms per token,     9.86 tokens per second)\n",
            "llama_print_timings:       total time =    2420.26 ms /    44 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "What a closed ass mijooo hahaha https://t.co/9lcw7zbckZ\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.46 ms /    16 runs   (    0.59 ms per token,  1691.33 tokens per second)\n",
            "llama_print_timings: prompt eval time =     274.24 ms /    77 tokens (    3.56 ms per token,   280.77 tokens per second)\n",
            "llama_print_timings:        eval time =    1562.48 ms /    15 runs   (  104.17 ms per token,     9.60 tokens per second)\n",
            "llama_print_timings:       total time =    2060.61 ms /    92 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@flacovrgncol @estudiantehotSV @TaxiCalienteSV And who are you fighting against that you come out to defend? You were there? Do you know if that is fake or not? Acted or not, this continues to feed rape culture, which is why we have so many idiots who rape instead of fucking\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.51 ms /    16 runs   (    0.66 ms per token,  1522.21 tokens per second)\n",
            "llama_print_timings: prompt eval time =     264.23 ms /    54 tokens (    4.89 ms per token,   204.37 tokens per second)\n",
            "llama_print_timings:        eval time =    1785.39 ms /    15 runs   (  119.03 ms per token,     8.40 tokens per second)\n",
            "llama_print_timings:       total time =    2246.04 ms /    69 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "In the news they keep saying \"the young people\" to refer to victims of chemical submission. Wtf shut up now, stop whitewashing rape culture, out of every 10 cases 9 are women.✨Symbolical violence✨\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.75 ms /    16 runs   (    0.55 ms per token,  1828.78 tokens per second)\n",
            "llama_print_timings: prompt eval time =     591.46 ms /    32 tokens (   18.48 ms per token,    54.10 tokens per second)\n",
            "llama_print_timings:        eval time =    1485.23 ms /    15 runs   (   99.02 ms per token,    10.10 tokens per second)\n",
            "llama_print_timings:       total time =    2217.52 ms /    47 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "When you say no to fucking because you don't have it and they get angry. That culture of rape and violence is stupid.\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.15 ms /    16 runs   (    0.57 ms per token,  1749.21 tokens per second)\n",
            "llama_print_timings: prompt eval time =     237.11 ms /    34 tokens (    6.97 ms per token,   143.39 tokens per second)\n",
            "llama_print_timings:        eval time =    1498.70 ms /    15 runs   (   99.91 ms per token,    10.01 tokens per second)\n",
            "llama_print_timings:       total time =    1875.65 ms /    49 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@zaratus_FF10 @GracielaPaggi We understand that rape culture is bestiality, always, right?\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.18 ms /    16 runs   (    0.57 ms per token,  1743.87 tokens per second)\n",
            "llama_print_timings: prompt eval time =     284.21 ms /    94 tokens (    3.02 ms per token,   330.74 tokens per second)\n",
            "llama_print_timings:        eval time =    1494.84 ms /    15 runs   (   99.66 ms per token,    10.03 tokens per second)\n",
            "llama_print_timings:       total time =    2048.08 ms /   109 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "🟣Campaign to prevent sexual abuse in adolescents and young people with the theme: Rape culture. We talk about what it is, how to recognize it and tips to not encourage it. Help us make this message viral and give it a \"like\". #adavas #adavascontigo #adavassalamanca https://t.co/fXz89gSDK1\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.33 ms /    14 runs   (    0.60 ms per token,  1680.07 tokens per second)\n",
            "llama_print_timings: prompt eval time =     272.17 ms /    70 tokens (    3.89 ms per token,   257.20 tokens per second)\n",
            "llama_print_timings:        eval time =    1324.16 ms /    13 runs   (  101.86 ms per token,     9.82 tokens per second)\n",
            "llama_print_timings:       total time =    1806.56 ms /    83 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Another RAPIST UBER driver. He abused a student on Friday night. She had requested a transfer from her work to the student residence. He was detained. THE CULTURE OF RAPE.And apps without control or security. https://t.co/QlVUVBsiqt\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.80 ms /    16 runs   (    0.55 ms per token,  1817.56 tokens per second)\n",
            "llama_print_timings: prompt eval time =     244.67 ms /    50 tokens (    4.89 ms per token,   204.36 tokens per second)\n",
            "llama_print_timings:        eval time =    1628.15 ms /    15 runs   (  108.54 ms per token,     9.21 tokens per second)\n",
            "llama_print_timings:       total time =    2040.41 ms /    65 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Dexdexdex10 @MPerronegrito @Mister_Wolf_0 Hahaha, you would be happy with your house expropriated in 12 installments to build a road\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.72 ms /    16 runs   (    0.55 ms per token,  1834.65 tokens per second)\n",
            "llama_print_timings: prompt eval time =     257.40 ms /    35 tokens (    7.35 ms per token,   135.97 tokens per second)\n",
            "llama_print_timings:        eval time =    1571.39 ms /    15 runs   (  104.76 ms per token,     9.55 tokens per second)\n",
            "llama_print_timings:       total time =    1971.16 ms /    50 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@latinus_us Today there are no medications, equipment, etc. For those who pay their dues, with this decree it will be worse\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.01 ms /    16 runs   (    0.69 ms per token,  1453.49 tokens per second)\n",
            "llama_print_timings: prompt eval time =     258.75 ms /    46 tokens (    5.63 ms per token,   177.78 tokens per second)\n",
            "llama_print_timings:        eval time =    1734.96 ms /    15 runs   (  115.66 ms per token,     8.65 tokens per second)\n",
            "llama_print_timings:       total time =    2192.34 ms /    61 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Please study the resumes carefully, or justify your appointments. Do we continue with political quotas or is it due to capacity? https://t.co/UI3wxmK71l\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.99 ms /    16 runs   (    0.56 ms per token,  1779.16 tokens per second)\n",
            "llama_print_timings: prompt eval time =     253.31 ms /    48 tokens (    5.28 ms per token,   189.49 tokens per second)\n",
            "llama_print_timings:        eval time =    1495.20 ms /    15 runs   (   99.68 ms per token,    10.03 tokens per second)\n",
            "llama_print_timings:       total time =    1916.60 ms /    63 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@skoda_es 47 installments and stayed 48 months? I don't have to change cars, but if I had to, there's no way it would be that one.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.83 ms /    16 runs   (    0.55 ms per token,  1812.62 tokens per second)\n",
            "llama_print_timings: prompt eval time =     253.45 ms /    38 tokens (    6.67 ms per token,   149.93 tokens per second)\n",
            "llama_print_timings:        eval time =    1634.73 ms /    15 runs   (  108.98 ms per token,     9.18 tokens per second)\n",
            "llama_print_timings:       total time =    2034.49 ms /    53 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Robert_f_1 For OLIMPIA 5 million, for Cerrito and Laundry 500 thousand and in installments\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.48 ms /    16 runs   (    0.53 ms per token,  1887.01 tokens per second)\n",
            "llama_print_timings: prompt eval time =     643.93 ms /    25 tokens (   25.76 ms per token,    38.82 tokens per second)\n",
            "llama_print_timings:        eval time =    1462.52 ms /    15 runs   (   97.50 ms per token,    10.26 tokens per second)\n",
            "llama_print_timings:       total time =    2226.41 ms /    40 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@PatriotaPatito buying on credit and in comfortable installments Everything is Possible in Life Champion\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.01 ms /    16 runs   (    0.63 ms per token,  1598.56 tokens per second)\n",
            "llama_print_timings: prompt eval time =     259.11 ms /    72 tokens (    3.60 ms per token,   277.88 tokens per second)\n",
            "llama_print_timings:        eval time =    1674.40 ms /    15 runs   (  111.63 ms per token,     8.96 tokens per second)\n",
            "llama_print_timings:       total time =    2165.31 ms /    87 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "It did not win in the prison population despite recognizing civic rights for prisoners. It did not win in PETORCA despite changing the entire water regulation regime. It did not win in regions despite being decentralizing and quasi-federal. It did not win among women despite being a democracy parity22/n\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.87 ms /    16 runs   (    0.55 ms per token,  1803.83 tokens per second)\n",
            "llama_print_timings: prompt eval time =     269.12 ms /    64 tokens (    4.21 ms per token,   237.81 tokens per second)\n",
            "llama_print_timings:        eval time =    1515.84 ms /    15 runs   (  101.06 ms per token,     9.90 tokens per second)\n",
            "llama_print_timings:       total time =    1985.16 ms /    79 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Margarita Cedeño said: \"I reiterate in this forum my commitment to promote equal democracy. I will work from my party to motivate the political participation of women, because the more women, the better democracy. And where there are empowered women, societies progress.\"\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.37 ms /    16 runs   (    0.59 ms per token,  1707.58 tokens per second)\n",
            "llama_print_timings: prompt eval time =     288.32 ms /    76 tokens (    3.79 ms per token,   263.60 tokens per second)\n",
            "llama_print_timings:        eval time =    1626.32 ms /    15 runs   (  108.42 ms per token,     9.22 tokens per second)\n",
            "llama_print_timings:       total time =    2140.28 ms /    91 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Parity democracy establishes that parity and equality are central axes of an inclusive State. It is not a women's issue, nor even a relationship between genders, but an opportunity to decide on the State model we want. For an equal Ushuaia! https://t.co/yjZCPMVoEo\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.76 ms /    16 runs   (    0.61 ms per token,  1639.51 tokens per second)\n",
            "llama_print_timings: prompt eval time =     304.74 ms /   109 tokens (    2.80 ms per token,   357.68 tokens per second)\n",
            "llama_print_timings:        eval time =    1538.58 ms /    15 runs   (  102.57 ms per token,     9.75 tokens per second)\n",
            "llama_print_timings:       total time =    2144.01 ms /   124 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Day 4. Camila Moreno – Let's burn the kingdom (Art. 6, 25, 27, 30, 61, 161, 163, 242, 312 and 350. Women's rights and parity democracy). “This land belongs to my son, paganism.” and wild eroticism”https://t.co/X2RNIH3pYd\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.35 ms /    16 runs   (    0.58 ms per token,  1711.78 tokens per second)\n",
            "llama_print_timings: prompt eval time =     280.36 ms /    64 tokens (    4.38 ms per token,   228.27 tokens per second)\n",
            "llama_print_timings:        eval time =    1474.41 ms /    15 runs   (   98.29 ms per token,    10.17 tokens per second)\n",
            "llama_print_timings:       total time =    2064.17 ms /    79 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Joyce_S_Berger 🧵The fact that there are women political leaders contributes to generating new roles and prototypes of women, different from the traditional ones. Redistributing power in a balanced way between men and women as proposed by parity democracy\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.57 ms /    16 runs   (    0.54 ms per token,  1867.20 tokens per second)\n",
            "llama_print_timings: prompt eval time =     243.57 ms /    33 tokens (    7.38 ms per token,   135.48 tokens per second)\n",
            "llama_print_timings:        eval time =    1634.56 ms /    15 runs   (  108.97 ms per token,     9.18 tokens per second)\n",
            "llama_print_timings:       total time =    2016.01 ms /    48 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Do not be afraidRepeat after me: Paritarian Democracy Paritarian Democracy Paritarian Democracy #AprueboCrece\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.80 ms /    16 runs   (    0.61 ms per token,  1632.65 tokens per second)\n",
            "llama_print_timings: prompt eval time =     262.44 ms /    63 tokens (    4.17 ms per token,   240.05 tokens per second)\n",
            "llama_print_timings:        eval time =    1639.20 ms /    15 runs   (  109.28 ms per token,     9.15 tokens per second)\n",
            "llama_print_timings:       total time =    2096.22 ms /    78 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Imagine feeling good because the only thing you do for your children is provide financially thanks to the job you have in your parents' company. Oh, but the girl who gave birth to those two children with postpartum depression, right? How dare you feel anything other than gratitude!!!\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.88 ms /    16 runs   (    0.56 ms per token,  1801.80 tokens per second)\n",
            "llama_print_timings: prompt eval time =     292.30 ms /    92 tokens (    3.18 ms per token,   314.74 tokens per second)\n",
            "llama_print_timings:        eval time =    1478.21 ms /    15 runs   (   98.55 ms per token,    10.15 tokens per second)\n",
            "llama_print_timings:       total time =    2024.94 ms /   107 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "My mother always goes for the jugular with the little thing. She didn't want to have them and doing so caused horrible postpartum depression. She always says that she can't miss what she doesn't know. Once I was born she loved me, but if she hadn't had me she wouldn't have regretted it. https://t.co/aEGPAfTS0g\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.42 ms /    16 runs   (    0.59 ms per token,  1699.42 tokens per second)\n",
            "llama_print_timings: prompt eval time =     270.75 ms /    62 tokens (    4.37 ms per token,   228.99 tokens per second)\n",
            "llama_print_timings:        eval time =    1486.31 ms /    15 runs   (   99.09 ms per token,    10.09 tokens per second)\n",
            "llama_print_timings:       total time =    1949.06 ms /    77 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Friends who have friends in the postpartum period: always keep an eye out, offer a shoulder, an extra pair of arms, listen attentively and affectionately, and address any needs that you can cover, etc. No one is immune to postpartum depression.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.44 ms /    16 runs   (    0.53 ms per token,  1895.06 tokens per second)\n",
            "llama_print_timings: prompt eval time =     568.57 ms /    32 tokens (   17.77 ms per token,    56.28 tokens per second)\n",
            "llama_print_timings:        eval time =    1476.82 ms /    15 runs   (   98.45 ms per token,    10.16 tokens per second)\n",
            "llama_print_timings:       total time =    2180.17 ms /    47 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Postpartum depression affects about 20% of mothers in Chile https://t.co/hGBhieD3iz\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.35 ms /    16 runs   (    0.58 ms per token,  1711.78 tokens per second)\n",
            "llama_print_timings: prompt eval time =     609.58 ms /    32 tokens (   19.05 ms per token,    52.49 tokens per second)\n",
            "llama_print_timings:        eval time =    1591.77 ms /    15 runs   (  106.12 ms per token,     9.42 tokens per second)\n",
            "llama_print_timings:       total time =    2399.14 ms /    47 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "🌵 Men also suffer from postpartum depression... https://t.co/bOm9fFEIJP\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.87 ms /    16 runs   (    0.55 ms per token,  1804.04 tokens per second)\n",
            "llama_print_timings: prompt eval time =     754.11 ms /    30 tokens (   25.14 ms per token,    39.78 tokens per second)\n",
            "llama_print_timings:        eval time =    1526.85 ms /    15 runs   (  101.79 ms per token,     9.82 tokens per second)\n",
            "llama_print_timings:       total time =    2415.46 ms /    45 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Kylie Jenner confesses she had postpartum depression https://t.co/guhcHRVwBe\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.09 ms /    16 runs   (    0.51 ms per token,  1978.48 tokens per second)\n",
            "llama_print_timings: prompt eval time =     275.34 ms /    77 tokens (    3.58 ms per token,   279.66 tokens per second)\n",
            "llama_print_timings:        eval time =    1616.59 ms /    15 runs   (  107.77 ms per token,     9.28 tokens per second)\n",
            "llama_print_timings:       total time =    2115.08 ms /    92 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "🌿Coordinating on-the-ground actions for the training and promotion of Human Rights and intersectoral work for the Sites of Memory, Undersecretary @HOberreuter met with various organizations in the O`Higgins Region 🙌🏽 https://t.co/ mM60gNq4KU\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.36 ms /    16 runs   (    0.58 ms per token,  1709.40 tokens per second)\n",
            "llama_print_timings: prompt eval time =     290.15 ms /    75 tokens (    3.87 ms per token,   258.48 tokens per second)\n",
            "llama_print_timings:        eval time =    1497.43 ms /    15 runs   (   99.83 ms per token,    10.02 tokens per second)\n",
            "llama_print_timings:       total time =    2015.65 ms /    90 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Our friend @adan_augusto at the #PlenariaMorena. I took the opportunity to deliver letters on educational matters from the Education Commission. We are committed to guaranteeing human rights, as well as ensuring a social policy in favor of all. https://t.co/sIv1Y7jpLb\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.29 ms /    16 runs   (    0.58 ms per token,  1722.84 tokens per second)\n",
            "llama_print_timings: prompt eval time =     258.86 ms /    63 tokens (    4.11 ms per token,   243.37 tokens per second)\n",
            "llama_print_timings:        eval time =    1515.28 ms /    15 runs   (  101.02 ms per token,     9.90 tokens per second)\n",
            "llama_print_timings:       total time =    1965.55 ms /    78 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Last night a friend was robbed. They ruined it in the middle of the crisis. Today while we were having mates she went from the wildest punitivism to non-stop guaranteeism. In the end that is what we are, contradictions and human rights.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.45 ms /    16 runs   (    0.59 ms per token,  1693.66 tokens per second)\n",
            "llama_print_timings: prompt eval time =     247.77 ms /    52 tokens (    4.76 ms per token,   209.87 tokens per second)\n",
            "llama_print_timings:        eval time =    1534.99 ms /    15 runs   (  102.33 ms per token,     9.77 tokens per second)\n",
            "llama_print_timings:       total time =    1958.46 ms /    67 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Download and consult the Protocol for Judging from the perspective of sexual orientation, gender identity and expression, and sexual characteristics (SOGIECS) here 🔗 https://t.co/ZZnwhSTOiI\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.93 ms /    16 runs   (    0.62 ms per token,  1612.09 tokens per second)\n",
            "llama_print_timings: prompt eval time =     396.21 ms /   138 tokens (    2.87 ms per token,   348.30 tokens per second)\n",
            "llama_print_timings:        eval time =    1644.61 ms /    15 runs   (  109.64 ms per token,     9.12 tokens per second)\n",
            "llama_print_timings:       total time =    2699.67 ms /   153 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "🔴The #PearlIsland megaproject in #Panama, questioned for human rights violations on the island where it is located, obtains millionaire tax benefits from the State to build a five-star hotel.History in #TierraDeResistenteshttps://t.co/mjugU70mX7 https://t.co/mjugU70mX7 https://t.co/mjugU70mX7 https://t.co/mjugU70mX7 ://t.co/iV9pVHVKdJ\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.47 ms /    16 runs   (    0.59 ms per token,  1688.65 tokens per second)\n",
            "llama_print_timings: prompt eval time =     290.48 ms /    76 tokens (    3.82 ms per token,   261.64 tokens per second)\n",
            "llama_print_timings:        eval time =    1527.87 ms /    15 runs   (  101.86 ms per token,     9.82 tokens per second)\n",
            "llama_print_timings:       total time =    2040.08 ms /    91 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Frente_Amplio The model that failed since the Bolshevik revolution to the present is the one proposed by the FA: Cuba, Venezuela... A model that only brings dictatorships, violation of human rights, poverty and backwardness. Name a single country that, with its model, has brought freedom, progress and prosperity.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.80 ms /    16 runs   (    0.61 ms per token,  1631.99 tokens per second)\n",
            "llama_print_timings: prompt eval time =     276.31 ms /    71 tokens (    3.89 ms per token,   256.96 tokens per second)\n",
            "llama_print_timings:        eval time =    1540.32 ms /    15 runs   (  102.69 ms per token,     9.74 tokens per second)\n",
            "llama_print_timings:       total time =    2029.44 ms /    86 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@sosa_tortuga @Nosti01303346 @elgandalfillo @asturexiliao @Xuxipc In her previous sentences she talks about the sexual and reproductive rights of women. https://t.co/w9RikT5xjm\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.53 ms /    16 runs   (    0.72 ms per token,  1388.05 tokens per second)\n",
            "llama_print_timings: prompt eval time =     281.33 ms /    70 tokens (    4.02 ms per token,   248.81 tokens per second)\n",
            "llama_print_timings:        eval time =    1814.66 ms /    15 runs   (  120.98 ms per token,     8.27 tokens per second)\n",
            "llama_print_timings:       total time =    2336.95 ms /    85 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "The Commission on the Status of Women made an explicit connection between climate justice, care, health, sexual and reproductive rights and the climate crisis in the lives of women and girls. Check: https://t.co/ftTkUN3xy8 https://t.co/HcAPoyP1zd\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.49 ms /    14 runs   (    0.61 ms per token,  1649.58 tokens per second)\n",
            "llama_print_timings: prompt eval time =     285.85 ms /    72 tokens (    3.97 ms per token,   251.88 tokens per second)\n",
            "llama_print_timings:        eval time =    1284.29 ms /    13 runs   (   98.79 ms per token,    10.12 tokens per second)\n",
            "llama_print_timings:       total time =    1775.71 ms /    85 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@fefaagul False, the proposal takes full charge of the Integrated Public Health of all Chileans, in nutritious food, mental health, disabilities of all spectrum, neurodivergents, women and sexual and reproductive rights, senior citizens, etc. #ApproveIn30Days\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.64 ms /    16 runs   (    0.60 ms per token,  1659.58 tokens per second)\n",
            "llama_print_timings: prompt eval time =     261.06 ms /    74 tokens (    3.53 ms per token,   283.46 tokens per second)\n",
            "llama_print_timings:        eval time =    1552.72 ms /    15 runs   (  103.51 ms per token,     9.66 tokens per second)\n",
            "llama_print_timings:       total time =    2050.63 ms /    89 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "#TODAY The last day of the Course - Workshop: \"Capacity Strengthening Conferences on Sexual and Reproductive Rights\" was successfully held. With the support of @JusticiaverdepePúblico: Judicial counselors https://t.co/pwT4vP3x0c\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.52 ms /    16 runs   (    0.53 ms per token,  1877.27 tokens per second)\n",
            "llama_print_timings: prompt eval time =     283.54 ms /    91 tokens (    3.12 ms per token,   320.94 tokens per second)\n",
            "llama_print_timings:        eval time =    1607.32 ms /    15 runs   (  107.15 ms per token,     9.33 tokens per second)\n",
            "llama_print_timings:       total time =    2151.63 ms /   106 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "We are just a few days away from #Zarelia2022 starting ✨. Check out the first day's activities. 🌼 With that approach that we have from @ruda_gt, I will teach a content creation workshop on sexual and reproductive rights 🌿✊🏽. https://t.co/0dGfdDh1rM\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.44 ms /    16 runs   (    0.59 ms per token,  1695.81 tokens per second)\n",
            "llama_print_timings: prompt eval time =     295.81 ms /    89 tokens (    3.32 ms per token,   300.87 tokens per second)\n",
            "llama_print_timings:        eval time =    1543.12 ms /    15 runs   (  102.87 ms per token,     9.72 tokens per second)\n",
            "llama_print_timings:       total time =    2091.40 ms /   104 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "🗣In favor of the Sexual and Reproductive Health and Rights of Women with Disabilities, we dismantle beliefs and demand:✔️Comprehensive sexual education.✔️Access to health with inclusive care protocols. ✔️Updated information ✔️Comprehensive reproductive care. https://t.co/WMvgBvx8Om\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.01 ms /    16 runs   (    0.63 ms per token,  1598.72 tokens per second)\n",
            "llama_print_timings: prompt eval time =     290.23 ms /    79 tokens (    3.67 ms per token,   272.20 tokens per second)\n",
            "llama_print_timings:        eval time =    1590.91 ms /    15 runs   (  106.06 ms per token,     9.43 tokens per second)\n",
            "llama_print_timings:       total time =    2115.54 ms /    94 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Why are you so ridiculous? Don't you get tired of embarrassing others? I really enjoyed reading you. Do you know about indirect discrimination based on gender? I see that no, I'm not going to continue arguing with an asshole who is 0 practical and who only knows the theory. https://t.co/MGsmhVBCvA\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.43 ms /    16 runs   (    0.59 ms per token,  1697.61 tokens per second)\n",
            "llama_print_timings: prompt eval time =     264.03 ms /    55 tokens (    4.80 ms per token,   208.31 tokens per second)\n",
            "llama_print_timings:        eval time =    1521.96 ms /    15 runs   (  101.46 ms per token,     9.86 tokens per second)\n",
            "llama_print_timings:       total time =    1968.01 ms /    70 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Minister, ask, is it correct, in the first instance at work, to rule and invalidate a promotion call because there is indirect discrimination against women? Or could it be invalidated only through protection? @ArturoZaldivarL\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.60 ms /    16 runs   (    0.60 ms per token,  1665.97 tokens per second)\n",
            "llama_print_timings: prompt eval time =     266.32 ms /    78 tokens (    3.41 ms per token,   292.88 tokens per second)\n",
            "llama_print_timings:        eval time =    1505.38 ms /    15 runs   (  100.36 ms per token,     9.96 tokens per second)\n",
            "llama_print_timings:       total time =    2001.07 ms /    93 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "One of the things that is present in Mexican society is discrimination (indirectly and directly) due to skin color. TV shows like the rose of Guadalupe shit on me, since they continue to instill these ideas.\"Clear\" = Rich, Brown and mestizos = Poor https://t.co/3jjEcR9Mem\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.58 ms /    16 runs   (    0.72 ms per token,  1381.57 tokens per second)\n",
            "llama_print_timings: prompt eval time =     291.55 ms /    75 tokens (    3.89 ms per token,   257.25 tokens per second)\n",
            "llama_print_timings:        eval time =    1903.40 ms /    15 runs   (  126.89 ms per token,     7.88 tokens per second)\n",
            "llama_print_timings:       total time =    2569.13 ms /    90 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Second JCR magazine to reject a text on indirect discrimination in the field of HIV. I accept it. It is part of the rules of the game. But I disagree that reviewers make statements lightly without substantiating them. Who controls the quality of the evaluations? https://t.co/3uK3Io6IzU\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.76 ms /    16 runs   (    0.55 ms per token,  1827.11 tokens per second)\n",
            "llama_print_timings: prompt eval time =     249.57 ms /    38 tokens (    6.57 ms per token,   152.26 tokens per second)\n",
            "llama_print_timings:        eval time =    1585.63 ms /    15 runs   (  105.71 ms per token,     9.46 tokens per second)\n",
            "llama_print_timings:       total time =    1978.90 ms /    53 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Indirect discrimination in the incompatibility of permanent disability pensions within the same public Social Security regimehttps://t.co/ErSLBjaZ55\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.58 ms /    16 runs   (    0.60 ms per token,  1669.80 tokens per second)\n",
            "llama_print_timings: prompt eval time =     255.44 ms /    56 tokens (    4.56 ms per token,   219.23 tokens per second)\n",
            "llama_print_timings:        eval time =    1492.73 ms /    15 runs   (   99.52 ms per token,    10.05 tokens per second)\n",
            "llama_print_timings:       total time =    1942.66 ms /    71 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@MundoArbitrato @ReglaXVIII_ We must not confuse equality with indirect discrimination. Making everything within the organization exactly the same for boys and girls would be, practically, the \"extinction\" of the girl referee.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.68 ms /    16 runs   (    0.54 ms per token,  1843.32 tokens per second)\n",
            "llama_print_timings: prompt eval time =     257.94 ms /    42 tokens (    6.14 ms per token,   162.83 tokens per second)\n",
            "llama_print_timings:        eval time =    1421.39 ms /    15 runs   (   94.76 ms per token,    10.55 tokens per second)\n",
            "llama_print_timings:       total time =    1838.84 ms /    57 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "🟢 The Human Rights Commission approves three opinions on affirmative actions, discrimination during health emergencies and multiple discrimination. https://t.co/bzprobrtBv\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.69 ms /    16 runs   (    0.67 ms per token,  1496.59 tokens per second)\n",
            "llama_print_timings: prompt eval time =     266.83 ms /    57 tokens (    4.68 ms per token,   213.62 tokens per second)\n",
            "llama_print_timings:        eval time =    1643.52 ms /    15 runs   (  109.57 ms per token,     9.13 tokens per second)\n",
            "llama_print_timings:       total time =    2202.33 ms /    72 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@saskianino @asulvanam Yes, @saskianino is used as an element similar to intersectionality and multiple discrimination. Plus, they almost always go hand in hand. That you and I do not experience racism is another issue.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.63 ms /    16 runs   (    0.54 ms per token,  1854.00 tokens per second)\n",
            "llama_print_timings: prompt eval time =     253.60 ms /    40 tokens (    6.34 ms per token,   157.73 tokens per second)\n",
            "llama_print_timings:        eval time =    1590.00 ms /    15 runs   (  106.00 ms per token,     9.43 tokens per second)\n",
            "llama_print_timings:       total time =    1992.11 ms /    55 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "When two or more factors are analyzed, it is multiple discrimination; If the intersection is analyzed, the unique and different results produced from these factors simultaneously: intersectional study of discrimination\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.53 ms /    16 runs   (    0.60 ms per token,  1679.26 tokens per second)\n",
            "llama_print_timings: prompt eval time =     262.25 ms /    58 tokens (    4.52 ms per token,   221.16 tokens per second)\n",
            "llama_print_timings:        eval time =    1530.04 ms /    15 runs   (  102.00 ms per token,     9.80 tokens per second)\n",
            "llama_print_timings:       total time =    1978.49 ms /    73 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "The term “multiple/intersectional discrimination” is not recognized in transnational EU law, as it would be in the horizontal Directive proposed in 2008, not yet adopted, which seeks to equalize levels of protection on several issues.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.20 ms /    16 runs   (    0.70 ms per token,  1428.19 tokens per second)\n",
            "llama_print_timings: prompt eval time =     250.86 ms /    48 tokens (    5.23 ms per token,   191.34 tokens per second)\n",
            "llama_print_timings:        eval time =    1876.00 ms /    15 runs   (  125.07 ms per token,     8.00 tokens per second)\n",
            "llama_print_timings:       total time =    2313.47 ms /    63 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "When do we talk about multiple discrimination in the workplace? When there are factors of age, gender and physical appearance 👇🏾 Czech. https://t.co/T1atizqPEo\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.57 ms /    16 runs   (    0.54 ms per token,  1866.98 tokens per second)\n",
            "llama_print_timings: prompt eval time =     248.19 ms /    33 tokens (    7.52 ms per token,   132.96 tokens per second)\n",
            "llama_print_timings:        eval time =    1496.00 ms /    15 runs   (   99.73 ms per token,    10.03 tokens per second)\n",
            "llama_print_timings:       total time =    1881.21 ms /    48 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "The objective was to identify relevant opportunities that the Central American private sector is offering to young people, mainly belonging to groups that face multiple discrimination.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.81 ms /    16 runs   (    0.55 ms per token,  1816.32 tokens per second)\n",
            "llama_print_timings: prompt eval time =     386.91 ms /   135 tokens (    2.87 ms per token,   348.92 tokens per second)\n",
            "llama_print_timings:        eval time =    1635.70 ms /    15 runs   (  109.05 ms per token,     9.17 tokens per second)\n",
            "llama_print_timings:       total time =    2394.07 ms /   150 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "📌JOB OFFER: FIRST BASIN AND CONSTRUCTION LABOR WITH FUNCTIONAL #DIVERSITY in #Málaga via @ArrabalAID #DIVERSITY and #INTEGRATION PROJECT IN SOCIAL ENTITIES @EgualdadAND 👇👇👇https://t.co/tXgKXqwwLv#inclusion #sociolaboral #Network #bricklayer #laborer https://t.co/ZE02kEt2lC\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.47 ms /    16 runs   (    0.59 ms per token,  1689.01 tokens per second)\n",
            "llama_print_timings: prompt eval time =     277.21 ms /    98 tokens (    2.83 ms per token,   353.52 tokens per second)\n",
            "llama_print_timings:        eval time =    1649.09 ms /    15 runs   (  109.94 ms per token,     9.10 tokens per second)\n",
            "llama_print_timings:       total time =    2191.90 ms /   113 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@mysteryorigin @lola_mamen Don't tell it to us, but to those who have achieved that: Inclusive language is not Braille and if speaking with \"e\" or \"x\" Functional diversity is a scourge, and not a different behavior TELL IT TO THE MINISTRY ABOUT INEQUALITY. TELL IT TO: @IreneMontero @ionebelarra\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      13.39 ms /    16 runs   (    0.84 ms per token,  1195.10 tokens per second)\n",
            "llama_print_timings: prompt eval time =     292.06 ms /    89 tokens (    3.28 ms per token,   304.73 tokens per second)\n",
            "llama_print_timings:        eval time =    1864.49 ms /    15 runs   (  124.30 ms per token,     8.05 tokens per second)\n",
            "llama_print_timings:       total time =    2582.63 ms /   104 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@AytoFuenlabrada @Fn_noticias We have already started the Friday routine, those who come to the bar believe that this functional diversity square on Gerona Street is so that when they leave drunk the car is closer to them, I would call but I lost faith in that @ Fuenla Police is going to come https://t.co/wPmpXLM11k\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.84 ms /    16 runs   (    0.55 ms per token,  1809.55 tokens per second)\n",
            "llama_print_timings: prompt eval time =     276.57 ms /    70 tokens (    3.95 ms per token,   253.10 tokens per second)\n",
            "llama_print_timings:        eval time =    1527.14 ms /    15 runs   (  101.81 ms per token,     9.82 tokens per second)\n",
            "llama_print_timings:       total time =    2012.32 ms /    85 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@JuntOnDemEspRep You mention that it has intellectual functional diversity. That mother has rights, also from there. But from the point of view of Social Services she is someone who is very manageable in files. That is, if you look at it that way you will see that the point is different. Look.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.22 ms /    16 runs   (    0.58 ms per token,  1735.73 tokens per second)\n",
            "llama_print_timings: prompt eval time =     265.33 ms /    77 tokens (    3.45 ms per token,   290.21 tokens per second)\n",
            "llama_print_timings:        eval time =    1693.67 ms /    15 runs   (  112.91 ms per token,     8.86 tokens per second)\n",
            "llama_print_timings:       total time =    2196.55 ms /    92 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "It is extreme violence, allying yourself with the pack and trying to harm Rocío Carrasco through her functionally diverse son. What ignorance has is that it is cruelty, disguised as innocence.#PrisonforAntonioDavid#OlgaMorenoSinEscrupulos #APOYOROCIO17A\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.97 ms /    16 runs   (    0.56 ms per token,  1784.12 tokens per second)\n",
            "llama_print_timings: prompt eval time =     252.77 ms /    63 tokens (    4.01 ms per token,   249.24 tokens per second)\n",
            "llama_print_timings:        eval time =    1479.93 ms /    15 runs   (   98.66 ms per token,    10.14 tokens per second)\n",
            "llama_print_timings:       total time =    1941.76 ms /    78 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Editorial Móstoles - Móstoles continues working for the socio-labor inclusion of people with functional diversity - https://t.co/4Hg3jiO2jN https://t.co/G0R5DYyWKY\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      12.02 ms /    16 runs   (    0.75 ms per token,  1330.89 tokens per second)\n",
            "llama_print_timings: prompt eval time =     289.07 ms /    88 tokens (    3.28 ms per token,   304.42 tokens per second)\n",
            "llama_print_timings:        eval time =    1877.86 ms /    15 runs   (  125.19 ms per token,     7.99 tokens per second)\n",
            "llama_print_timings:       total time =    2593.94 ms /   103 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "A 36-year-old woman who goes partying generates more confidence in me than a 60-year-old alcoholic man. Being a woman and being young, double discriminationWhat the Sanna Marin 'scandal' evidences: the sexist scrutiny against young politicians @ElPeriodico_Esp https://t.co/roR9XW3VNb\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.01 ms /    16 runs   (    0.56 ms per token,  1776.00 tokens per second)\n",
            "llama_print_timings: prompt eval time =     269.52 ms /    51 tokens (    5.28 ms per token,   189.22 tokens per second)\n",
            "llama_print_timings:        eval time =    1483.15 ms /    15 runs   (   98.88 ms per token,    10.11 tokens per second)\n",
            "llama_print_timings:       total time =    1933.52 ms /    66 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "More precariousness and zero conciliation: the double discrimination of women in rural environments https://t.co/OaarRwr2cH https://t.co/YBndG3nSMH\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.73 ms /    16 runs   (    0.61 ms per token,  1644.23 tokens per second)\n",
            "llama_print_timings: prompt eval time =     265.89 ms /    81 tokens (    3.28 ms per token,   304.64 tokens per second)\n",
            "llama_print_timings:        eval time =    1488.46 ms /    15 runs   (   99.23 ms per token,    10.08 tokens per second)\n",
            "llama_print_timings:       total time =    1996.05 ms /    96 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "For the Ambassador of Spain in Mexico @EmbEspMex, Juan Duarte Cuadrado @DuarteCuadrado highlighted that the #BartoloméDeLasCasas Award recognizes organizations that fight against double discrimination, for being a woman and for being indigenous https://t.co/BLVjp3ckl1\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.07 ms /    16 runs   (    0.57 ms per token,  1764.45 tokens per second)\n",
            "llama_print_timings: prompt eval time =     274.62 ms /    76 tokens (    3.61 ms per token,   276.75 tokens per second)\n",
            "llama_print_timings:        eval time =    1630.68 ms /    15 runs   (  108.71 ms per token,     9.20 tokens per second)\n",
            "llama_print_timings:       total time =    2128.81 ms /    91 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@cr0quetica \"those people don't suffer any discrimination\" he says while he discriminates against us, calling us sex addicts, vicious and zoophiles 😂😂😂 we have double discrimination, from straight people but also from the collective, but we are \"invisible\" because they don't give us a voice\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.41 ms /    16 runs   (    0.59 ms per token,  1701.04 tokens per second)\n",
            "llama_print_timings: prompt eval time =     294.44 ms /    85 tokens (    3.46 ms per token,   288.69 tokens per second)\n",
            "llama_print_timings:        eval time =    1589.00 ms /    15 runs   (  105.93 ms per token,     9.44 tokens per second)\n",
            "llama_print_timings:       total time =    2121.47 ms /   100 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "#IndigenousWomen'sDay 👩🏽👧🏽 Indigenous women face double discrimination, affecting their development in the home and family, as well as in the political, social, economic and cultural spheres. The vindication of their rights is still valid. All rights for all! https://t.co/uw2KPtCqiI\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.65 ms /    16 runs   (    0.60 ms per token,  1657.34 tokens per second)\n",
            "llama_print_timings: prompt eval time =     256.63 ms /    59 tokens (    4.35 ms per token,   229.90 tokens per second)\n",
            "llama_print_timings:        eval time =    1486.53 ms /    15 runs   (   99.10 ms per token,    10.09 tokens per second)\n",
            "llama_print_timings:       total time =    1930.29 ms /    74 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "“We must make the community understand that we can also be LGBTI” The double discrimination that LGBTIQ indigenous people face via: @quevedo_sara18 https://t.co/TvBSK2P14X\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.71 ms /    16 runs   (    0.54 ms per token,  1838.02 tokens per second)\n",
            "llama_print_timings: prompt eval time =     638.18 ms /    25 tokens (   25.53 ms per token,    39.17 tokens per second)\n",
            "llama_print_timings:        eval time =    1552.19 ms /    15 runs   (  103.48 ms per token,     9.66 tokens per second)\n",
            "llama_print_timings:       total time =    2313.92 ms /    40 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@mateoburgos07 I heard rumors that they are going to start working double shifts\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.05 ms /    16 runs   (    0.69 ms per token,  1447.83 tokens per second)\n",
            "llama_print_timings: prompt eval time =     290.92 ms /    79 tokens (    3.68 ms per token,   271.55 tokens per second)\n",
            "llama_print_timings:        eval time =    1754.15 ms /    15 runs   (  116.94 ms per token,     8.55 tokens per second)\n",
            "llama_print_timings:       total time =    2426.76 ms /    94 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Double day at the Rivaben! Lots of football on Wednesday at the Agustín Rivaben. There will be canteen service by our First Division players. Tickets: $150 pesos. FREE members. Vaaaaamoooo dean 🔴⚫️ https://t.co/N2orDnbf9U\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.52 ms /    16 runs   (    0.59 ms per token,  1681.56 tokens per second)\n",
            "llama_print_timings: prompt eval time =     278.01 ms /    83 tokens (    3.35 ms per token,   298.55 tokens per second)\n",
            "llama_print_timings:        eval time =    1624.37 ms /    15 runs   (  108.29 ms per token,     9.23 tokens per second)\n",
            "llama_print_timings:       total time =    2138.03 ms /    98 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Cautious teacher came to the extra hour that Kicillof establishes in schools. The Unity Front gives the green light, but without effusiveness. Make it optional, the key. Focus on the demand for a full double day. Who is on strike. 20 days after the celebrated increase announcement made https://t.co/hnBDzaMaey\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.40 ms /    16 runs   (    0.59 ms per token,  1702.31 tokens per second)\n",
            "llama_print_timings: prompt eval time =     286.56 ms /    83 tokens (    3.45 ms per token,   289.65 tokens per second)\n",
            "llama_print_timings:        eval time =    1632.44 ms /    15 runs   (  108.83 ms per token,     9.19 tokens per second)\n",
            "llama_print_timings:       total time =    2156.79 ms /    98 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "⚜️With any of our plans we add you to our groups in which we can make you grow better https://t.co/IAeEFXhGrw first month: day....⚜️Promo 2: Double day is done..⚜️Consult for more info.You can also follow us @Adultiing_mkt\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.70 ms /    16 runs   (    0.61 ms per token,  1648.97 tokens per second)\n",
            "llama_print_timings: prompt eval time =     303.54 ms /    94 tokens (    3.23 ms per token,   309.68 tokens per second)\n",
            "llama_print_timings:        eval time =    1536.46 ms /    15 runs   (  102.43 ms per token,     9.76 tokens per second)\n",
            "llama_print_timings:       total time =    2263.60 ms /   109 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "🎯 A double day of the Outdoor Modality Tournament was held. On Saturday the 1st date of the Provincial League and on Sunday the Federates in the Fatarco homologated (national) Rankeable Tournament. Our #ArqueríaCapri archers shined! #ComunidadCapri #ClubCapri https://t.co/zuourmMNFm\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.69 ms /    16 runs   (    0.54 ms per token,  1840.56 tokens per second)\n",
            "llama_print_timings: prompt eval time =     249.91 ms /    44 tokens (    5.68 ms per token,   176.06 tokens per second)\n",
            "llama_print_timings:        eval time =    1503.91 ms /    15 runs   (  100.26 ms per token,     9.97 tokens per second)\n",
            "llama_print_timings:       total time =    1914.74 ms /    59 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Give it to your trusted #EspacioAzulFemenil, double shift. 1 pt of 6. https://t.co/q53Jhp7Qia\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.62 ms /    16 runs   (    0.60 ms per token,  1663.89 tokens per second)\n",
            "llama_print_timings: prompt eval time =     258.85 ms /    62 tokens (    4.18 ms per token,   239.52 tokens per second)\n",
            "llama_print_timings:        eval time =    1493.34 ms /    15 runs   (   99.56 ms per token,    10.04 tokens per second)\n",
            "llama_print_timings:       total time =    1946.59 ms /    77 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@liliasolanor A recognition of this process of women in the territory who are like butterflies whose entrepreneurship and leadership has cost them like caterpillars an entire metamorphosis to reveal the beautiful leadership that makes them strong from ecofeminism!!\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.77 ms /    16 runs   (    0.67 ms per token,  1485.47 tokens per second)\n",
            "llama_print_timings: prompt eval time =     279.29 ms /    66 tokens (    4.23 ms per token,   236.32 tokens per second)\n",
            "llama_print_timings:        eval time =    1529.44 ms /    15 runs   (  101.96 ms per token,     9.81 tokens per second)\n",
            "llama_print_timings:       total time =    2036.60 ms /    81 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "It's time to take care of it and conserve it better.#ECOFEMINISM or BARBARIE!!!#BuenosDias 💪🏽💚💜💚💪🏽 https://t.co/fg8KlrroXc\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.36 ms /    16 runs   (    0.58 ms per token,  1710.32 tokens per second)\n",
            "llama_print_timings: prompt eval time =     286.36 ms /    74 tokens (    3.87 ms per token,   258.42 tokens per second)\n",
            "llama_print_timings:        eval time =    1585.60 ms /    15 runs   (  105.71 ms per token,     9.46 tokens per second)\n",
            "llama_print_timings:       total time =    2167.56 ms /    89 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "#Column 🌲Popular Environmentalism🌍📢🟢what are we talking about when we refer to systematic persecution against environmental defenders? @micaelaegarcia tells us and explains the concept of #ecofeminism 🎙️ @tamiastascro 🔥\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.55 ms /    16 runs   (    0.60 ms per token,  1675.92 tokens per second)\n",
            "llama_print_timings: prompt eval time =     302.57 ms /    99 tokens (    3.06 ms per token,   327.20 tokens per second)\n",
            "llama_print_timings:        eval time =    1510.39 ms /    15 runs   (  100.69 ms per token,     9.93 tokens per second)\n",
            "llama_print_timings:       total time =    2083.09 ms /   114 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "New item! Since the beginning of September at Vita we have been talking about the concept of “matrix” and claiming the rights over our bodies-territories. We want to talk about #ecofeminism. Do you know it? https://t.co/JgZwYHAy8G#vitaactivaorg #lineadeayuda #cuerpa https://t.co/LgcOtfi2vr\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.42 ms /    16 runs   (    0.59 ms per token,  1698.33 tokens per second)\n",
            "llama_print_timings: prompt eval time =     281.35 ms /    86 tokens (    3.27 ms per token,   305.67 tokens per second)\n",
            "llama_print_timings:        eval time =    1530.59 ms /    15 runs   (  102.04 ms per token,     9.80 tokens per second)\n",
            "llama_print_timings:       total time =    2053.12 ms /   101 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "I just saw this great report from @InformeSemanal. #ecofeminism has been defending 'slow fashion' and the sustainability of textiles for years. If you missed it, it will be out soon on @rtveplay 🔝🔝🔝 https://t.co/1LwXHnTX45\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.94 ms /    16 runs   (    0.62 ms per token,  1610.31 tokens per second)\n",
            "llama_print_timings: prompt eval time =     299.01 ms /    92 tokens (    3.25 ms per token,   307.69 tokens per second)\n",
            "llama_print_timings:        eval time =    1539.07 ms /    15 runs   (  102.60 ms per token,     9.75 tokens per second)\n",
            "llama_print_timings:       total time =    2102.27 ms /   107 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Is there a link between the subordination of women and the destructive exploitation of nature? Let's reflect together with Ninfa Ambiental (@melissadez_), at the conference \"Mexiquense Ecofeminism\"; this August 19th through our Facebook Live. #SeMujeresEdoméx https://t.co/JXBZ72eeY2\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.55 ms /    16 runs   (    0.60 ms per token,  1675.04 tokens per second)\n",
            "llama_print_timings: prompt eval time =     294.31 ms /    89 tokens (    3.31 ms per token,   302.41 tokens per second)\n",
            "llama_print_timings:        eval time =    1548.63 ms /    15 runs   (  103.24 ms per token,     9.69 tokens per second)\n",
            "llama_print_timings:       total time =    2094.47 ms /   104 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "THEY DISGUISE affective-sexual education based on gender ideology 🏳️‍🌈 in \"respect for diversity\" and the reality is that it is INDOCTRINATION and ATTACKING against the cognitive capacity of children and against the moral and religious principles that we transmit to our children. https://t.co/bToUrqWHm9\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.05 ms /    16 runs   (    0.57 ms per token,  1768.15 tokens per second)\n",
            "llama_print_timings: prompt eval time =     243.92 ms /    49 tokens (    4.98 ms per token,   200.89 tokens per second)\n",
            "llama_print_timings:        eval time =    1521.41 ms /    15 runs   (  101.43 ms per token,     9.86 tokens per second)\n",
            "llama_print_timings:       total time =    1951.90 ms /    64 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "About Montero: Of course, emotional sexual education is needed, adapted to the different stages of development, but starting the earlier the better. The rest is nonsense from far-rightists and meapilas.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.54 ms /    16 runs   (    0.60 ms per token,  1678.03 tokens per second)\n",
            "llama_print_timings: prompt eval time =     276.16 ms /    70 tokens (    3.95 ms per token,   253.47 tokens per second)\n",
            "llama_print_timings:        eval time =    1507.13 ms /    15 runs   (  100.48 ms per token,     9.95 tokens per second)\n",
            "llama_print_timings:       total time =    2059.20 ms /    85 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "We need urgent measures against the insecurity that the chemical submission that is recently practiced in nightclubs is giving us. We have to continue working for quality emotional-sexual education, with global training, and that educates us from a young age https:// t.co/qykk0KgnvQ\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.41 ms /    16 runs   (    0.59 ms per token,  1700.50 tokens per second)\n",
            "llama_print_timings: prompt eval time =     282.67 ms /    88 tokens (    3.21 ms per token,   311.31 tokens per second)\n",
            "llama_print_timings:        eval time =    1534.48 ms /    15 runs   (  102.30 ms per token,     9.78 tokens per second)\n",
            "llama_print_timings:       total time =    2066.22 ms /   103 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@elespanolcom 🤦‍♀️ This is a big hurry, but not a comprehensive affective-sexual education within the school curriculum. To a training that educates so that these types of laws are not necessary, right? That's for what?! It seems unfortunate to me that due to the belief of “because of my ovaries”, this is like this 😖\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.45 ms /    16 runs   (    0.59 ms per token,  1692.41 tokens per second)\n",
            "llama_print_timings: prompt eval time =     251.84 ms /    48 tokens (    5.25 ms per token,   190.60 tokens per second)\n",
            "llama_print_timings:        eval time =    1603.04 ms /    15 runs   (  106.87 ms per token,     9.36 tokens per second)\n",
            "llama_print_timings:       total time =    2022.91 ms /    63 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Consent is submission. A good emotional-sexual education involves knowing and wanting, it is not based on consent #CoeducaciónRealYa https://t.co/mjfuugWFtD\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      12.05 ms /    16 runs   (    0.75 ms per token,  1327.25 tokens per second)\n",
            "llama_print_timings: prompt eval time =     249.90 ms /    56 tokens (    4.46 ms per token,   224.09 tokens per second)\n",
            "llama_print_timings:        eval time =    1858.42 ms /    15 runs   (  123.89 ms per token,     8.07 tokens per second)\n",
            "llama_print_timings:       total time =    2325.79 ms /    71 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Sexual crimes by minors have increased by 58%. 😱Affective-sexual education is essential and changing the referential models of adult society.https://t.co/CLLO0lcbP5\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       7.63 ms /    14 runs   (    0.54 ms per token,  1835.82 tokens per second)\n",
            "llama_print_timings: prompt eval time =     276.08 ms /    70 tokens (    3.94 ms per token,   253.55 tokens per second)\n",
            "llama_print_timings:        eval time =    1385.56 ms /    13 runs   (  106.58 ms per token,     9.38 tokens per second)\n",
            "llama_print_timings:       total time =    1875.87 ms /    83 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@nacolets Remember: feminism is a multi-dimensional movement, not a religion. Its principle is equal rights between women and men. Radicalizing the principle does not make you a feminist, it makes you a fanatic. Defending the principle makes you a feminist, no matter who you are.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.77 ms /    16 runs   (    0.55 ms per token,  1825.03 tokens per second)\n",
            "llama_print_timings: prompt eval time =     246.42 ms /    40 tokens (    6.16 ms per token,   162.32 tokens per second)\n",
            "llama_print_timings:        eval time =    1494.30 ms /    15 runs   (   99.62 ms per token,    10.04 tokens per second)\n",
            "llama_print_timings:       total time =    1893.23 ms /    55 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@ArtOfNe so much stupidity and selfishness in a tweet, the truth is it's time to eliminate little shits like you, feminism is cancer.\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.61 ms /    16 runs   (    0.60 ms per token,  1664.76 tokens per second)\n",
            "llama_print_timings: prompt eval time =     252.35 ms /    47 tokens (    5.37 ms per token,   186.25 tokens per second)\n",
            "llama_print_timings:        eval time =    1494.05 ms /    15 runs   (   99.60 ms per token,    10.04 tokens per second)\n",
            "llama_print_timings:       total time =    1913.83 ms /    62 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Juanaafanador1 @petrogustavo Hahaha, how stupid this is. Feminism is even worse than machismo, sectarian groups full of hate against the opposite gender.\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.83 ms /    16 runs   (    0.61 ms per token,  1628.33 tokens per second)\n",
            "llama_print_timings: prompt eval time =     269.69 ms /    64 tokens (    4.21 ms per token,   237.31 tokens per second)\n",
            "llama_print_timings:        eval time =    1515.12 ms /    15 runs   (  101.01 ms per token,     9.90 tokens per second)\n",
            "llama_print_timings:       total time =    1989.54 ms /    79 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@AngelicaLozanoC and what do you say about this co-partisan? When machismo belongs to those in your group, is it okay? Is feminism only when it comes from the left? https://t.co/wS2V7CSw3L\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.19 ms /    16 runs   (    0.57 ms per token,  1740.64 tokens per second)\n",
            "llama_print_timings: prompt eval time =     268.45 ms /    72 tokens (    3.73 ms per token,   268.21 tokens per second)\n",
            "llama_print_timings:        eval time =    1458.36 ms /    15 runs   (   97.22 ms per token,    10.29 tokens per second)\n",
            "llama_print_timings:       total time =    1948.54 ms /    87 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Adonis_MAM @Ant52529536Jose @Doncactus22 Feminism is as diverse as everything human, and as always, what steals the most attention is what will steal the most cameras and publicity. Stereotyping him is a serious mistake!\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.89 ms /    16 runs   (    0.56 ms per token,  1798.97 tokens per second)\n",
            "llama_print_timings: prompt eval time =     766.50 ms /    30 tokens (   25.55 ms per token,    39.14 tokens per second)\n",
            "llama_print_timings:        eval time =    1521.02 ms /    15 runs   (  101.40 ms per token,     9.86 tokens per second)\n",
            "llama_print_timings:       total time =    2417.13 ms /    45 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Alfredolara29 I believe that feminism is an important communicating vessel between FA and Kirchenrismo.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.77 ms /    16 runs   (    0.74 ms per token,  1358.93 tokens per second)\n",
            "llama_print_timings: prompt eval time =     790.88 ms /    24 tokens (   32.95 ms per token,    30.35 tokens per second)\n",
            "llama_print_timings:        eval time =    1688.65 ms /    15 runs   (  112.58 ms per token,     8.88 tokens per second)\n",
            "llama_print_timings:       total time =    2662.03 ms /    39 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Since I dreamed of being pregnant, I have had this existential doubt about motherhood.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.72 ms /    16 runs   (    0.55 ms per token,  1833.81 tokens per second)\n",
            "llama_print_timings: prompt eval time =     240.87 ms /    44 tokens (    5.47 ms per token,   182.67 tokens per second)\n",
            "llama_print_timings:        eval time =    1582.15 ms /    15 runs   (  105.48 ms per token,     9.48 tokens per second)\n",
            "llama_print_timings:       total time =    1987.65 ms /    59 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "As the rule in medicine “every woman of childbearing age is pregnant until proven otherwise” In life it should be “every bandit is pregnant until proven otherwise” 🐸\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.48 ms /    16 runs   (    0.53 ms per token,  1887.24 tokens per second)\n",
            "llama_print_timings: prompt eval time =     246.36 ms /    56 tokens (    4.40 ms per token,   227.31 tokens per second)\n",
            "llama_print_timings:        eval time =    1551.54 ms /    15 runs   (  103.44 ms per token,     9.67 tokens per second)\n",
            "llama_print_timings:       total time =    1980.45 ms /    71 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "I'm at 1 am in the morning reading information about the pelvic floor and exercises, I also started watching exercises for pregnant women when I don't have pelvic floor problems nor am I pregnant HAHAHAHAHAHAHA\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.56 ms /    16 runs   (    0.60 ms per token,  1673.47 tokens per second)\n",
            "llama_print_timings: prompt eval time =     262.10 ms /    57 tokens (    4.60 ms per token,   217.48 tokens per second)\n",
            "llama_print_timings:        eval time =    1670.11 ms /    15 runs   (  111.34 ms per token,     8.98 tokens per second)\n",
            "llama_print_timings:       total time =    2131.07 ms /    72 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "We went to the polleria with Martina, she ran into a friend and told him that she was going to have a sister, and then she told him my mom got pregnant out of nowhere! Yes mommy out of nowhere. Hahahahaha\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.11 ms /    16 runs   (    0.57 ms per token,  1755.93 tokens per second)\n",
            "llama_print_timings: prompt eval time =     277.48 ms /    67 tokens (    4.14 ms per token,   241.46 tokens per second)\n",
            "llama_print_timings:        eval time =    1562.47 ms /    15 runs   (  104.16 ms per token,     9.60 tokens per second)\n",
            "llama_print_timings:       total time =    2046.65 ms /    82 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@matildemarti But it is not because that site is reserved for those cases, but rather it is for education!! Just as I know it should be given to an elderly person (or that is what is ethical and correct), also to a pregnant person, it is not that complicated to understand!!!\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.56 ms /    16 runs   (    0.54 ms per token,  1868.50 tokens per second)\n",
            "llama_print_timings: prompt eval time =     257.12 ms /    41 tokens (    6.27 ms per token,   159.46 tokens per second)\n",
            "llama_print_timings:        eval time =    1562.15 ms /    15 runs   (  104.14 ms per token,     9.60 tokens per second)\n",
            "llama_print_timings:       total time =    1972.45 ms /    56 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Now getting together to eat with friends is going out of fun and I can't go because I'm pregnant says the dad dw he blessed her naaaaa this is a lot\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.77 ms /    16 runs   (    0.61 ms per token,  1637.00 tokens per second)\n",
            "llama_print_timings: prompt eval time =     252.65 ms /    51 tokens (    4.95 ms per token,   201.86 tokens per second)\n",
            "llama_print_timings:        eval time =    1612.16 ms /    15 runs   (  107.48 ms per token,     9.30 tokens per second)\n",
            "llama_print_timings:       total time =    2042.84 ms /    66 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@ChaotiColombian @lovek_os12 They always try to female empowerment, when she is with a misogynist who recorded her, cheated on her, and there she continues with the\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.48 ms /    16 runs   (    0.59 ms per token,  1688.48 tokens per second)\n",
            "llama_print_timings: prompt eval time =     237.49 ms /    42 tokens (    5.65 ms per token,   176.85 tokens per second)\n",
            "llama_print_timings:        eval time =    1695.02 ms /    15 runs   (  113.00 ms per token,     8.85 tokens per second)\n",
            "llama_print_timings:       total time =    2099.13 ms /    57 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "(L)Earn ''NEAR Sputnik DAO: community empowerment'' via @LearnNEAR https://t.co/bdEN5LMMBF\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.27 ms /    16 runs   (    0.58 ms per token,  1726.74 tokens per second)\n",
            "llama_print_timings: prompt eval time =     260.66 ms /    60 tokens (    4.34 ms per token,   230.19 tokens per second)\n",
            "llama_print_timings:        eval time =    1545.58 ms /    15 runs   (  103.04 ms per token,     9.71 tokens per second)\n",
            "llama_print_timings:       total time =    2000.77 ms /    75 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Verito_Quimera People don't understand anything. He lacked trans. Lesbo scenes. Female empowerment. There was no LGBT Hannibal. Nah, joke. In reality it was too dark for the tender little hearts of the viewers.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.03 ms /    16 runs   (    0.56 ms per token,  1772.66 tokens per second)\n",
            "llama_print_timings: prompt eval time =     264.08 ms /    54 tokens (    4.89 ms per token,   204.49 tokens per second)\n",
            "llama_print_timings:        eval time =    1591.50 ms /    15 runs   (  106.10 ms per token,     9.43 tokens per second)\n",
            "llama_print_timings:       total time =    2049.21 ms /    69 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "I was listening to salute and I was and what: THAT VOCAL RANGE??????THAT EMPOWERMENT?????THAT TALENT?????THOSE VISUALS????\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.83 ms /    16 runs   (    0.55 ms per token,  1812.42 tokens per second)\n",
            "llama_print_timings: prompt eval time =     259.29 ms /    45 tokens (    5.76 ms per token,   173.55 tokens per second)\n",
            "llama_print_timings:        eval time =    1683.17 ms /    15 runs   (  112.21 ms per token,     8.91 tokens per second)\n",
            "llama_print_timings:       total time =    2108.89 ms /    60 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "(L)Earn ''NEAR Sputnik DAO: community empowerment'' via @LearnNEAR https://t.co/hCgu0cZrBq\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.91 ms /    16 runs   (    0.56 ms per token,  1795.13 tokens per second)\n",
            "llama_print_timings: prompt eval time =     791.35 ms /    30 tokens (   26.38 ms per token,    37.91 tokens per second)\n",
            "llama_print_timings:        eval time =    1565.84 ms /    15 runs   (  104.39 ms per token,     9.58 tokens per second)\n",
            "llama_print_timings:       total time =    2488.86 ms /    45 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@LucianoRevoredo @abeja_peru Caviarín without power. Need \"empowerment\".😎\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.56 ms /    16 runs   (    0.53 ms per token,  1870.03 tokens per second)\n",
            "llama_print_timings: prompt eval time =     618.05 ms /    23 tokens (   26.87 ms per token,    37.21 tokens per second)\n",
            "llama_print_timings:        eval time =    1515.10 ms /    15 runs   (  101.01 ms per token,     9.90 tokens per second)\n",
            "llama_print_timings:       total time =    2251.57 ms /    38 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Today I woke up thinking that I would bring you food on your days on duty.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.84 ms /    16 runs   (    0.68 ms per token,  1476.56 tokens per second)\n",
            "llama_print_timings: prompt eval time =     295.15 ms /    92 tokens (    3.21 ms per token,   311.70 tokens per second)\n",
            "llama_print_timings:        eval time =    1671.43 ms /    15 runs   (  111.43 ms per token,     8.97 tokens per second)\n",
            "llama_print_timings:       total time =    2394.70 ms /   107 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@giiolopezz @willyhands17 @z001110011100 @Santiahi2 @AnarkoAlpiniste @1708Jhonjairo But don't cry, because you cry so much @giiolopezz are you in your days are you menstruating 🩸 or because you cry a lot\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.34 ms /    16 runs   (    0.58 ms per token,  1713.25 tokens per second)\n",
            "llama_print_timings: prompt eval time =     267.29 ms /    61 tokens (    4.38 ms per token,   228.22 tokens per second)\n",
            "llama_print_timings:        eval time =    1517.88 ms /    15 runs   (  101.19 ms per token,     9.88 tokens per second)\n",
            "llama_print_timings:       total time =    1988.65 ms /    76 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@PMunozLedo I'm glad to know that you have a family Give them that pleasure that you are and love Mexico You listened to yourself And know history Don't be the worst or trash when trying to hang out with TRAITORS Think back on your days\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.12 ms /    16 runs   (    0.57 ms per token,  1755.16 tokens per second)\n",
            "llama_print_timings: prompt eval time =     265.84 ms /    75 tokens (    3.54 ms per token,   282.13 tokens per second)\n",
            "llama_print_timings:        eval time =    1515.17 ms /    15 runs   (  101.01 ms per token,     9.90 tokens per second)\n",
            "llama_print_timings:       total time =    2016.44 ms /    90 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Keep me❣️In your eyesAnd remember all my imagesKeep me in your earsAnd hear my voice againAgain and againKeep me in your mouthWith hundreds of \"I love you\"Keep me in your nightsThat have witnessed the most ardent desiresKeep me in your daysThose who are calm ⬇️\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.73 ms /    16 runs   (    0.55 ms per token,  1831.71 tokens per second)\n",
            "llama_print_timings: prompt eval time =     245.84 ms /    37 tokens (    6.64 ms per token,   150.51 tokens per second)\n",
            "llama_print_timings:        eval time =    1645.74 ms /    15 runs   (  109.72 ms per token,     9.11 tokens per second)\n",
            "llama_print_timings:       total time =    2043.38 ms /    52 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Pros of being in your days: you shit all day 👍🏻Con: I have a 3-month pregnant belly 👎🏻\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.65 ms /    16 runs   (    0.60 ms per token,  1657.69 tokens per second)\n",
            "llama_print_timings: prompt eval time =     291.51 ms /    76 tokens (    3.84 ms per token,   260.71 tokens per second)\n",
            "llama_print_timings:        eval time =    1534.28 ms /    15 runs   (  102.29 ms per token,     9.78 tokens per second)\n",
            "llama_print_timings:       total time =    2189.35 ms /    91 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "\"And if just one day you feel bad, you don't want to talk or whatever, tell me and I will understand you even on your bad days🥹. Don't thank me, I do it from the heart because it comes from me\" Healing messages, I am surrounded of beautiful people, I have no doubts.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.10 ms /    16 runs   (    0.57 ms per token,  1758.82 tokens per second)\n",
            "llama_print_timings: prompt eval time =     292.82 ms /    82 tokens (    3.57 ms per token,   280.04 tokens per second)\n",
            "llama_print_timings:        eval time =    1454.95 ms /    15 runs   (   97.00 ms per token,    10.31 tokens per second)\n",
            "llama_print_timings:       total time =    1988.13 ms /    97 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@nataliaFHN Natalia I have two of my mom's. I worked in Oncology and I am a nurse, my life is normal, I am very free of illness if you want to talk, cry or laugh at your disposal, I am from Spain. A hug and I hope for your reference and tell me what country you are from.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       7.70 ms /    16 runs   (    0.48 ms per token,  2077.38 tokens per second)\n",
            "llama_print_timings: prompt eval time =     246.74 ms /    54 tokens (    4.57 ms per token,   218.86 tokens per second)\n",
            "llama_print_timings:        eval time =    1508.56 ms /    15 runs   (  100.57 ms per token,     9.94 tokens per second)\n",
            "llama_print_timings:       total time =    1936.60 ms /    69 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Shit but Ernesto has a different parrot for each nurse AHAHAHAHAHAHAHAHAHA what a guy this is 😹😹😹😹😹\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.19 ms /    16 runs   (    0.64 ms per token,  1569.70 tokens per second)\n",
            "llama_print_timings: prompt eval time =     296.63 ms /    98 tokens (    3.03 ms per token,   330.38 tokens per second)\n",
            "llama_print_timings:        eval time =    1596.96 ms /    15 runs   (  106.46 ms per token,     9.39 tokens per second)\n",
            "llama_print_timings:       total time =    2370.66 ms /   113 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Did someone call a nurse? 💉💕There is a birthday PROMO 🎂💕 40% OFF in my OF ✨. https://t.co/pnnmvjNAbp for this week only ~I will be uploading many photos 🌡️🔥 of this outfit, you can't miss them 💖. https://t.co/VhrhoBZ3KW\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.49 ms /    16 runs   (    0.53 ms per token,  1885.01 tokens per second)\n",
            "llama_print_timings: prompt eval time =     239.37 ms /    34 tokens (    7.04 ms per token,   142.04 tokens per second)\n",
            "llama_print_timings:        eval time =    1542.16 ms /    15 runs   (  102.81 ms per token,     9.73 tokens per second)\n",
            "llama_print_timings:       total time =    1931.56 ms /    49 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Me in the hospital: sick of seeing nursesMy dad: your girlfriend is a nurse😐In my defense my girlfriend is cute😍\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.88 ms /    16 runs   (    0.62 ms per token,  1619.93 tokens per second)\n",
            "llama_print_timings: prompt eval time =     281.61 ms /    94 tokens (    3.00 ms per token,   333.79 tokens per second)\n",
            "llama_print_timings:        eval time =    1488.03 ms /    15 runs   (   99.20 ms per token,    10.08 tokens per second)\n",
            "llama_print_timings:       total time =    2035.85 ms /   109 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "THE KILLER OF THE YOUNG NURSE EDILENIA CAPELLAN IS ALREADY ARRESTED Confirmed from Fantino Cotui that the named Carlos Manuel Peguero is in the hands of the Police there, who this morning murdered his partner with a stab, the now deceased EDILENIA CAPELLAN https:/ /t.co/BArRCZAlYH\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.80 ms /    16 runs   (    0.61 ms per token,  1631.99 tokens per second)\n",
            "llama_print_timings: prompt eval time =     250.27 ms /    46 tokens (    5.44 ms per token,   183.80 tokens per second)\n",
            "llama_print_timings:        eval time =    1517.31 ms /    15 runs   (  101.15 ms per token,     9.89 tokens per second)\n",
            "llama_print_timings:       total time =    1940.33 ms /    61 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "A Cuban doctor, a nurse and a patient's relative died after an armed attack in a hospital in Ecatepec, #EdoMéx #AzucenaxFórmula\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.11 ms /    16 runs   (    0.57 ms per token,  1755.54 tokens per second)\n",
            "llama_print_timings: prompt eval time =     644.64 ms /    18 tokens (   35.81 ms per token,    27.92 tokens per second)\n",
            "llama_print_timings:        eval time =    1547.57 ms /    15 runs   (  103.17 ms per token,     9.69 tokens per second)\n",
            "llama_print_timings:       total time =    2339.27 ms /    33 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Women will never understand men and men think they understand women.\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.94 ms /    16 runs   (    0.56 ms per token,  1789.91 tokens per second)\n",
            "llama_print_timings: prompt eval time =     602.51 ms /    24 tokens (   25.10 ms per token,    39.83 tokens per second)\n",
            "llama_print_timings:        eval time =    1445.43 ms /    15 runs   (   96.36 ms per token,    10.38 tokens per second)\n",
            "llama_print_timings:       total time =    2169.50 ms /    39 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "I will never understand women who get angry because their partners play Play or some other console 😀\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.42 ms /    16 runs   (    0.53 ms per token,  1899.34 tokens per second)\n",
            "llama_print_timings: prompt eval time =     246.81 ms /    60 tokens (    4.11 ms per token,   243.10 tokens per second)\n",
            "llama_print_timings:        eval time =    1638.66 ms /    15 runs   (  109.24 ms per token,     9.15 tokens per second)\n",
            "llama_print_timings:       total time =    2082.82 ms /    75 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "I will never understand women part 100000 If you give her attention, love, you're one more of the bunch Now treat her badly, don't look at her, don't make room for her Bye, you're the love of her life...\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.41 ms /    16 runs   (    0.65 ms per token,  1536.39 tokens per second)\n",
            "llama_print_timings: prompt eval time =     285.62 ms /    72 tokens (    3.97 ms per token,   252.08 tokens per second)\n",
            "llama_print_timings:        eval time =    1667.08 ms /    15 runs   (  111.14 ms per token,     9.00 tokens per second)\n",
            "llama_print_timings:       total time =    2183.25 ms /    87 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Yesterday a friend from work told me about her relationship problems and with a lot of frustration she told me: “Oh Spençer, no matter how hard I try, I can't understand women” And I was like: “Girl, you're a woman” Neta… I got freaked out.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.11 ms /    16 runs   (    0.57 ms per token,  1755.73 tokens per second)\n",
            "llama_print_timings: prompt eval time =     260.51 ms /    52 tokens (    5.01 ms per token,   199.61 tokens per second)\n",
            "llama_print_timings:        eval time =    1623.44 ms /    15 runs   (  108.23 ms per token,     9.24 tokens per second)\n",
            "llama_print_timings:       total time =    2065.57 ms /    67 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@diliarlozano @Mimi07141 From the same writer of the book: HOW TO UNDERSTAND WOMEN, 😄😄😄😄😄😄😄😄🍻\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.03 ms /    16 runs   (    0.56 ms per token,  1772.85 tokens per second)\n",
            "llama_print_timings: prompt eval time =     461.75 ms /    14 tokens (   32.98 ms per token,    30.32 tokens per second)\n",
            "llama_print_timings:        eval time =    1703.93 ms /    15 runs   (  113.60 ms per token,     8.80 tokens per second)\n",
            "llama_print_timings:       total time =    2266.96 ms /    29 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "I give up, I will never understand women\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.24 ms /    16 runs   (    0.58 ms per token,  1732.16 tokens per second)\n",
            "llama_print_timings: prompt eval time =     244.99 ms /    44 tokens (    5.57 ms per token,   179.60 tokens per second)\n",
            "llama_print_timings:        eval time =    1638.40 ms /    15 runs   (  109.23 ms per token,     9.16 tokens per second)\n",
            "llama_print_timings:       total time =    2043.16 ms /    59 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@BTxorri @ConsuorF @ertzaintzaEJGV @EuskalMemoria Those who write those tweets are the biggest scum of this society\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.35 ms /    16 runs   (    0.71 ms per token,  1409.69 tokens per second)\n",
            "llama_print_timings: prompt eval time =     260.96 ms /    47 tokens (    5.55 ms per token,   180.10 tokens per second)\n",
            "llama_print_timings:        eval time =    1831.91 ms /    15 runs   (  122.13 ms per token,     8.19 tokens per second)\n",
            "llama_print_timings:       total time =    2322.76 ms /    62 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@MariettoPonce The vulgar Lilly Téllez who, as long as they fight her, invents self-attacks, the truth is that she does represent scum like Marietto\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.34 ms /    16 runs   (    0.58 ms per token,  1712.33 tokens per second)\n",
            "llama_print_timings: prompt eval time =     259.98 ms /    47 tokens (    5.53 ms per token,   180.79 tokens per second)\n",
            "llama_print_timings:        eval time =    1568.18 ms /    15 runs   (  104.55 ms per token,     9.57 tokens per second)\n",
            "llama_print_timings:       total time =    1995.95 ms /    62 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@franmb1 @Radioesport914 Why the hell do you listen to that scum? For your mental health, stop listening to the ultra that has run down. Fuck the orellut\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.50 ms /    16 runs   (    0.59 ms per token,  1683.68 tokens per second)\n",
            "llama_print_timings: prompt eval time =     283.33 ms /    75 tokens (    3.78 ms per token,   264.71 tokens per second)\n",
            "llama_print_timings:        eval time =    1564.17 ms /    15 runs   (  104.28 ms per token,     9.59 tokens per second)\n",
            "llama_print_timings:       total time =    2070.92 ms /    90 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@javiernegre10 @Macarena_Olona If I were those people I would keep an eye on the wallet in case the right-wing chorizos infiltrate among them. It is clear that your colleague on the camera was waiting for some mistake. Crime is what you scumbags do best.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.78 ms /    16 runs   (    0.74 ms per token,  1358.12 tokens per second)\n",
            "llama_print_timings: prompt eval time =     300.76 ms /    97 tokens (    3.10 ms per token,   322.51 tokens per second)\n",
            "llama_print_timings:        eval time =    1817.04 ms /    15 runs   (  121.14 ms per token,     8.26 tokens per second)\n",
            "llama_print_timings:       total time =    2593.28 ms /   112 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "#FerrerasGate You have lied to us, manipulated us, harassed, defamed and threatened our @PODEMOS Politicians 8 years, 8 years of harassment and demolition, we will not get tired of reminding you that you are scum, if it has to be 8 years we will do it because not I'm sorry https://t.co/eQsAVXv3Bn\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.07 ms /    16 runs   (    0.57 ms per token,  1763.47 tokens per second)\n",
            "llama_print_timings: prompt eval time =     249.33 ms /    46 tokens (    5.42 ms per token,   184.50 tokens per second)\n",
            "llama_print_timings:        eval time =    1489.40 ms /    15 runs   (   99.29 ms per token,    10.07 tokens per second)\n",
            "llama_print_timings:       total time =    1913.21 ms /    61 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@CaIIejonDeIGato @VengansaCoyote @Rita_Maestre Just as you say, no wonder you have such horrible karma. Human waste.\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.04 ms /    16 runs   (    0.57 ms per token,  1769.91 tokens per second)\n",
            "llama_print_timings: prompt eval time =     243.20 ms /    40 tokens (    6.08 ms per token,   164.47 tokens per second)\n",
            "llama_print_timings:        eval time =    1486.48 ms /    15 runs   (   99.10 ms per token,    10.09 tokens per second)\n",
            "llama_print_timings:       total time =    1886.00 ms /    55 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@AguilarDassaev @XiomaraCastroZ Now the stereotype is a narco-state, before with them, after them and now with them\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.85 ms /    16 runs   (    0.62 ms per token,  1624.37 tokens per second)\n",
            "llama_print_timings: prompt eval time =     269.03 ms /    63 tokens (    4.27 ms per token,   234.18 tokens per second)\n",
            "llama_print_timings:        eval time =    1557.59 ms /    15 runs   (  103.84 ms per token,     9.63 tokens per second)\n",
            "llama_print_timings:       total time =    2037.28 ms /    78 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Juani_17 @EstebanCervi @Uber_ES @cabify_espana It took me 10 years to fight against the Stereotype, but the newcomers are taking charge of renewing it. We have no solution.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.69 ms /    16 runs   (    0.61 ms per token,  1651.36 tokens per second)\n",
            "llama_print_timings: prompt eval time =     294.44 ms /    98 tokens (    3.00 ms per token,   332.84 tokens per second)\n",
            "llama_print_timings:        eval time =    1503.74 ms /    15 runs   (  100.25 ms per token,     9.98 tokens per second)\n",
            "llama_print_timings:       total time =    2072.47 ms /   113 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "There are no Koreans on my ranch and if there were, they would look for teenagers or people who are very skinny and of the stereotype that their country and culture has. And it's pretty and it's fine. I like them tighter, with beards, cumbersome but with a suit. Elegant as silk and indomitable like the sea. https://t.co/tihtJLUOOQ\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.06 ms /    16 runs   (    0.57 ms per token,  1766.39 tokens per second)\n",
            "llama_print_timings: prompt eval time =     253.33 ms /    42 tokens (    6.03 ms per token,   165.79 tokens per second)\n",
            "llama_print_timings:        eval time =    1593.57 ms /    15 runs   (  106.24 ms per token,     9.41 tokens per second)\n",
            "llama_print_timings:       total time =    2008.18 ms /    57 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Walking down the street a biker called me \"fat lesbian\" and I never felt so flattered, so much effort to fall into the fat stereotype paid off people\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.56 ms /    16 runs   (    0.60 ms per token,  1673.82 tokens per second)\n",
            "llama_print_timings: prompt eval time =     257.72 ms /    64 tokens (    4.03 ms per token,   248.34 tokens per second)\n",
            "llama_print_timings:        eval time =    1588.93 ms /    15 runs   (  105.93 ms per token,     9.44 tokens per second)\n",
            "llama_print_timings:       total time =    2044.15 ms /    79 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@LibretaNegraMx The stereotype of the Archaeologist is a constant in cinema. It would be good if a film script began with some Luz y Fuerza workers finding a \"stone\" that won't let them put in their cables. 😁\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.41 ms /    16 runs   (    0.65 ms per token,  1536.54 tokens per second)\n",
            "llama_print_timings: prompt eval time =     255.94 ms /    47 tokens (    5.45 ms per token,   183.63 tokens per second)\n",
            "llama_print_timings:        eval time =    1688.06 ms /    15 runs   (  112.54 ms per token,     8.89 tokens per second)\n",
            "llama_print_timings:       total time =    2206.88 ms /    62 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Dua's boyfriends were always horrible shit, come on guys, any of you have a chance then!!! They fulfill the stereotype perfectly https://t.co/Cmo2YAYjCC\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.55 ms /    16 runs   (    0.60 ms per token,  1676.09 tokens per second)\n",
            "llama_print_timings: prompt eval time =     283.97 ms /    65 tokens (    4.37 ms per token,   228.89 tokens per second)\n",
            "llama_print_timings:        eval time =    1538.20 ms /    15 runs   (  102.55 ms per token,     9.75 tokens per second)\n",
            "llama_print_timings:       total time =    2023.11 ms /    80 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "My mother never read me stories, we created stories. She asked me the questions on the intelligence test from the age of 3 and I knew them all (she never put earrings on me until I wanted to buy Barbies or pink clothes because of gender stereotypes, what a crack?\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.88 ms /    16 runs   (    0.62 ms per token,  1619.60 tokens per second)\n",
            "llama_print_timings: prompt eval time =     254.41 ms /    55 tokens (    4.63 ms per token,   216.19 tokens per second)\n",
            "llama_print_timings:        eval time =    1533.43 ms /    15 runs   (  102.23 ms per token,     9.78 tokens per second)\n",
            "llama_print_timings:       total time =    1972.06 ms /    70 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "The aim is to counteract the historical inequalities suffered by women, girls and people of sexual dissidence, as a result of prior conceptions or gender stereotypes that police officials sometimes possess when hearing about specific cases (2/6).\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.80 ms /    16 runs   (    0.61 ms per token,  1632.82 tokens per second)\n",
            "llama_print_timings: prompt eval time =     264.81 ms /    58 tokens (    4.57 ms per token,   219.02 tokens per second)\n",
            "llama_print_timings:        eval time =    1520.76 ms /    15 runs   (  101.38 ms per token,     9.86 tokens per second)\n",
            "llama_print_timings:       total time =    1980.46 ms /    73 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "At the #BancadaOrange we propose to end this #SexistTax, inequality based on gender stereotypes must disappear. #BancadaOrange 🍊 https://t.co/OUCmWy86AL\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.14 ms /    16 runs   (    0.57 ms per token,  1750.16 tokens per second)\n",
            "llama_print_timings: prompt eval time =     276.51 ms /    68 tokens (    4.07 ms per token,   245.92 tokens per second)\n",
            "llama_print_timings:        eval time =    1634.96 ms /    15 runs   (  109.00 ms per token,     9.17 tokens per second)\n",
            "llama_print_timings:       total time =    2118.97 ms /    83 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "If you want to respect rights, take up the fight against gender stereotypes and do not invent movies like \"gender expression\": a child who plays with dolls is a child. A girl who plays soccer is a girl. She better analyzes those \"rapid-onset gender dysphorias.\"\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.83 ms /    16 runs   (    0.61 ms per token,  1628.33 tokens per second)\n",
            "llama_print_timings: prompt eval time =     287.17 ms /   109 tokens (    2.63 ms per token,   379.57 tokens per second)\n",
            "llama_print_timings:        eval time =    1569.35 ms /    15 runs   (  104.62 ms per token,     9.56 tokens per second)\n",
            "llama_print_timings:       total time =    2147.55 ms /   124 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Meli_Coulter @coolturabasura Inclusive language is FOR EVERYONE, otherwise it is not inclusive😉 And wait for me to finish you off ⬇️Inclusive Language: \"Way of expressing oneself without discriminating against a particular sex, social gender or gender identity and without perpetuating stereotypes of gender\". Greetings, my little ignorant one🤣 https://t.co/aTZ1w6yNtE\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.08 ms /    16 runs   (    0.57 ms per token,  1763.09 tokens per second)\n",
            "llama_print_timings: prompt eval time =     266.16 ms /    65 tokens (    4.09 ms per token,   244.22 tokens per second)\n",
            "llama_print_timings:        eval time =    1555.88 ms /    15 runs   (  103.73 ms per token,     9.64 tokens per second)\n",
            "llama_print_timings:       total time =    2020.85 ms /    80 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "CBT No. 2 Zinacantepec is working on the Gender Equality program, with the theme of gender role and gender stereotypes. @geramonro05 @IsraelJeroL https://t.co/Se1GJJH0sG\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.46 ms /    16 runs   (    0.72 ms per token,  1396.16 tokens per second)\n",
            "llama_print_timings: prompt eval time =     252.90 ms /    33 tokens (    7.66 ms per token,   130.49 tokens per second)\n",
            "llama_print_timings:        eval time =    1776.31 ms /    15 runs   (  118.42 ms per token,     8.44 tokens per second)\n",
            "llama_print_timings:       total time =    2262.88 ms /    48 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@upelienta_sss For me it is a clear example of the close relationship that exists between Spanish and Chilean fascism\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.47 ms /    16 runs   (    0.53 ms per token,  1889.91 tokens per second)\n",
            "llama_print_timings: prompt eval time =     251.66 ms /    35 tokens (    7.19 ms per token,   139.08 tokens per second)\n",
            "llama_print_timings:        eval time =    1476.40 ms /    15 runs   (   98.43 ms per token,    10.16 tokens per second)\n",
            "llama_print_timings:       total time =    1868.41 ms /    50 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "I was putting the propolis in my mouth and I gagged? It must be because I am sensitive and narrow-throated.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.66 ms /    16 runs   (    0.54 ms per token,  1847.15 tokens per second)\n",
            "llama_print_timings: prompt eval time =     630.24 ms /    23 tokens (   27.40 ms per token,    36.49 tokens per second)\n",
            "llama_print_timings:        eval time =    1557.88 ms /    15 runs   (  103.86 ms per token,     9.63 tokens per second)\n",
            "llama_print_timings:       total time =    2304.55 ms /    38 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Don't make yourself small to try to fit into someone else's narrow mind.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.46 ms /    16 runs   (    0.65 ms per token,  1529.78 tokens per second)\n",
            "llama_print_timings: prompt eval time =     271.37 ms /    72 tokens (    3.77 ms per token,   265.32 tokens per second)\n",
            "llama_print_timings:        eval time =    1706.44 ms /    15 runs   (  113.76 ms per token,     8.79 tokens per second)\n",
            "llama_print_timings:       total time =    2205.06 ms /    87 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@febra0621 @selusan @UnaiYus That the guy ahead with a car in front tells you that he probably didn't have time to brake. It's not the cyclist's fault. It is the fault of allowing such different speeds on such a narrow road.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.45 ms /    16 runs   (    0.59 ms per token,  1693.84 tokens per second)\n",
            "llama_print_timings: prompt eval time =     280.62 ms /    69 tokens (    4.07 ms per token,   245.88 tokens per second)\n",
            "llama_print_timings:        eval time =    1496.19 ms /    15 runs   (   99.75 ms per token,    10.03 tokens per second)\n",
            "llama_print_timings:       total time =    2014.74 ms /    84 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Rest in peace. “Hereditary monarchies have a great advantage: the particular interest of a family is constantly closely linked to the interest of the State. Never a single moment passes in which it is left to itself.\" Tocqueville https://t.co/kmjGXfiBTC\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.67 ms /    16 runs   (    0.60 ms per token,  1654.26 tokens per second)\n",
            "llama_print_timings: prompt eval time =     265.23 ms /    58 tokens (    4.57 ms per token,   218.68 tokens per second)\n",
            "llama_print_timings:        eval time =    1532.43 ms /    15 runs   (  102.16 ms per token,     9.79 tokens per second)\n",
            "llama_print_timings:       total time =    1985.50 ms /    73 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Capri is the opposite of Libra, everyone loves this sign for its sociability and supposed beauty, so no, I don't have a close relationship with my cousins ​​because they obviously don't understand my seriousness and asociality.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.56 ms /    16 runs   (    0.54 ms per token,  1868.50 tokens per second)\n",
            "llama_print_timings: prompt eval time =     245.68 ms /    37 tokens (    6.64 ms per token,   150.60 tokens per second)\n",
            "llama_print_timings:        eval time =    1526.10 ms /    15 runs   (  101.74 ms per token,     9.83 tokens per second)\n",
            "llama_print_timings:       total time =    1924.13 ms /    52 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@IsabelArugula I don't know yet haha ​​but I'm looking at options for gender studies, international studies or public policy\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.78 ms /    16 runs   (    0.74 ms per token,  1357.77 tokens per second)\n",
            "llama_print_timings: prompt eval time =     299.46 ms /   105 tokens (    2.85 ms per token,   350.63 tokens per second)\n",
            "llama_print_timings:        eval time =    1871.78 ms /    15 runs   (  124.79 ms per token,     8.01 tokens per second)\n",
            "llama_print_timings:       total time =    2660.02 ms /   120 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Postgraduate Refresher CourseDesign, Feminist Theory and Gender Studies.Start: 01/11, 18hsRegistration and fee consultation: centrocap@fadu.uba.ar#UBA #UBAPosgrados #FADU #architecture #design #urbanism #gender #feminist #theory #studies #course #postgraduate https://t.co/h7XLicRXaL\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.52 ms /    16 runs   (    0.53 ms per token,  1878.60 tokens per second)\n",
            "llama_print_timings: prompt eval time =     256.96 ms /    42 tokens (    6.12 ms per token,   163.45 tokens per second)\n",
            "llama_print_timings:        eval time =    1473.95 ms /    15 runs   (   98.26 ms per token,    10.18 tokens per second)\n",
            "llama_print_timings:       total time =    1883.23 ms /    57 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "La salle inviting a MAN specialized in (attention): gender studies! to explain the historical context of feminism. What a laugh, what a tremendous laugh 💀.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.08 ms /    16 runs   (    0.57 ms per token,  1761.34 tokens per second)\n",
            "llama_print_timings: prompt eval time =     286.69 ms /   102 tokens (    2.81 ms per token,   355.79 tokens per second)\n",
            "llama_print_timings:        eval time =    1558.62 ms /    15 runs   (  103.91 ms per token,     9.62 tokens per second)\n",
            "llama_print_timings:       total time =    2117.30 ms /   117 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@ServiciosSevip @adrianalg83 @urielesqueda4 Hahahahahaha biological reality hahahahahaLook brut0, first of all it would be good for you to read about gender studies, not to agree, but so that you UNDERSTAND what they refer to, one thing is sex and another is gender and your example of Asian man is wrong, that is transage. 🤦🏻‍♂️\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.77 ms /    16 runs   (    0.55 ms per token,  1824.61 tokens per second)\n",
            "llama_print_timings: prompt eval time =     724.35 ms /    27 tokens (   26.83 ms per token,    37.27 tokens per second)\n",
            "llama_print_timings:        eval time =    1486.47 ms /    15 runs   (   99.10 ms per token,    10.09 tokens per second)\n",
            "llama_print_timings:       total time =    2335.49 ms /    42 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "If the minister is so ugly, why doesn't she work at the Gender Studies Officer? 🤔\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.32 ms /    16 runs   (    0.58 ms per token,  1716.92 tokens per second)\n",
            "llama_print_timings: prompt eval time =     282.67 ms /    72 tokens (    3.93 ms per token,   254.72 tokens per second)\n",
            "llama_print_timings:        eval time =    1521.48 ms /    15 runs   (  101.43 ms per token,     9.86 tokens per second)\n",
            "llama_print_timings:       total time =    2035.81 ms /    87 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "In apocalyptic terms taken from the ortho, it is more important to know about gender studies to build a surviving society that is not so horrendous and more equitable, obviously. The bread would be made in community for the consumption of the community itself https://t.co/CJja0ITosT\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.44 ms /    16 runs   (    0.59 ms per token,  1694.20 tokens per second)\n",
            "llama_print_timings: prompt eval time =     295.91 ms /    89 tokens (    3.32 ms per token,   300.77 tokens per second)\n",
            "llama_print_timings:        eval time =    1519.94 ms /    15 runs   (  101.33 ms per token,     9.87 tokens per second)\n",
            "llama_print_timings:       total time =    2083.72 ms /   104 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "#MelodyBarreraPresente! Police officer Darío Jesús Chaves Rubio received life for the crime of homicide aggravated by hatred of gender expression or gender identity. Triumph of the movement of women and diversities and their family. #enoughcrimesofhate #FueTravesticidio https://t.co/FXUyreJtD5\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.39 ms /    16 runs   (    0.59 ms per token,  1703.21 tokens per second)\n",
            "llama_print_timings: prompt eval time =     239.91 ms /    41 tokens (    5.85 ms per token,   170.90 tokens per second)\n",
            "llama_print_timings:        eval time =    1578.20 ms /    15 runs   (  105.21 ms per token,     9.50 tokens per second)\n",
            "llama_print_timings:       total time =    1981.01 ms /    56 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "anyone with feminine gender expression, or clear feminine/masculine energy soft person, in general https://t.co/j89o6fwWLR\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.06 ms /    16 runs   (    0.63 ms per token,  1590.14 tokens per second)\n",
            "llama_print_timings: prompt eval time =     294.42 ms /    78 tokens (    3.77 ms per token,   264.93 tokens per second)\n",
            "llama_print_timings:        eval time =    1508.27 ms /    15 runs   (  100.55 ms per token,     9.95 tokens per second)\n",
            "llama_print_timings:       total time =    2184.62 ms /    93 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@ddeschouw Art. 25: \"All forms of discrimination are prohibited, especially when based on one or more grounds such as nationality or statelessness, age, sex, sexual characteristics, sexual or emotional orientation, gender identity and expression, etc. . \" and then: https://t.co/XR7x8slfyi\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.76 ms /    16 runs   (    0.55 ms per token,  1826.90 tokens per second)\n",
            "llama_print_timings: prompt eval time =     284.85 ms /    92 tokens (    3.10 ms per token,   322.98 tokens per second)\n",
            "llama_print_timings:        eval time =    1593.34 ms /    15 runs   (  106.22 ms per token,     9.41 tokens per second)\n",
            "llama_print_timings:       total time =    2131.05 ms /   107 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@PedroVictor9210 @JuankarlitoGago @ElBohioMio Pedro Víctor, mijo, you have exposed yourself and made a fool of yourself. Stop feeling bad and learn not to give opinions about what you are not even basically informed about. If you are interested, there is a lot of literature on the topic. Sex, gender, gender identity and expression.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.64 ms /    16 runs   (    0.54 ms per token,  1850.78 tokens per second)\n",
            "llama_print_timings: prompt eval time =     716.12 ms /    25 tokens (   28.64 ms per token,    34.91 tokens per second)\n",
            "llama_print_timings:        eval time =    1470.33 ms /    15 runs   (   98.02 ms per token,    10.20 tokens per second)\n",
            "llama_print_timings:       total time =    2312.09 ms /    40 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@anderelcane @carpediemcr People whose gender identity and expression coincides with sex...\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.72 ms /    16 runs   (    0.61 ms per token,  1646.77 tokens per second)\n",
            "llama_print_timings: prompt eval time =     263.26 ms /    45 tokens (    5.85 ms per token,   170.93 tokens per second)\n",
            "llama_print_timings:        eval time =    1714.84 ms /    15 runs   (  114.32 ms per token,     8.75 tokens per second)\n",
            "llama_print_timings:       total time =    2229.55 ms /    60 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@MarianaBelda @DWiehls That's not what I said. When I mentioned gender expression it was because I wanted to understand what @DWiehls was referring to\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.50 ms /    16 runs   (    0.53 ms per token,  1883.46 tokens per second)\n",
            "llama_print_timings: prompt eval time =     689.10 ms /    27 tokens (   25.52 ms per token,    39.18 tokens per second)\n",
            "llama_print_timings:        eval time =    1469.76 ms /    15 runs   (   97.98 ms per token,    10.21 tokens per second)\n",
            "llama_print_timings:       total time =    2280.10 ms /    42 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@citrikav She always had her forehead very high, her tongue very long... And her skirt was very short\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.34 ms /    16 runs   (    0.58 ms per token,  1713.80 tokens per second)\n",
            "llama_print_timings: prompt eval time =     234.39 ms /    35 tokens (    6.70 ms per token,   149.33 tokens per second)\n",
            "llama_print_timings:        eval time =    1614.55 ms /    15 runs   (  107.64 ms per token,     9.29 tokens per second)\n",
            "llama_print_timings:       total time =    1993.83 ms /    50 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Danielus678 @IleanaSchinder Ileana says it's Argentinians' fault for wearing very short skirts\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.97 ms /    16 runs   (    0.56 ms per token,  1782.73 tokens per second)\n",
            "llama_print_timings: prompt eval time =     748.35 ms /    30 tokens (   24.94 ms per token,    40.09 tokens per second)\n",
            "llama_print_timings:        eval time =    1494.17 ms /    15 runs   (   99.61 ms per token,    10.04 tokens per second)\n",
            "llama_print_timings:       total time =    2375.88 ms /    45 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@laci_beles @liusivaya @javiersolana I'm sure Japan wore her skirt very short\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.45 ms /    16 runs   (    0.59 ms per token,  1692.76 tokens per second)\n",
            "llama_print_timings: prompt eval time =     581.77 ms /    32 tokens (   18.18 ms per token,    55.00 tokens per second)\n",
            "llama_print_timings:        eval time =    1621.79 ms /    15 runs   (  108.12 ms per token,     9.25 tokens per second)\n",
            "llama_print_timings:       total time =    2400.05 ms /    47 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@PJoliCo @davidgambarte They wore their skirts very short and that's why they were squatted...\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.14 ms /    16 runs   (    0.57 ms per token,  1749.59 tokens per second)\n",
            "llama_print_timings: prompt eval time =     241.85 ms /    35 tokens (    6.91 ms per token,   144.72 tokens per second)\n",
            "llama_print_timings:        eval time =    1638.42 ms /    15 runs   (  109.23 ms per token,     9.16 tokens per second)\n",
            "llama_print_timings:       total time =    2025.12 ms /    50 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@eldiarioes She wore her skirt very short, like Ciudadanos in the Basque Country or like VOX in Vallecas.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.73 ms /    16 runs   (    0.55 ms per token,  1832.55 tokens per second)\n",
            "llama_print_timings: prompt eval time =     758.04 ms /    29 tokens (   26.14 ms per token,    38.26 tokens per second)\n",
            "llama_print_timings:        eval time =    1475.21 ms /    15 runs   (   98.35 ms per token,    10.17 tokens per second)\n",
            "llama_print_timings:       total time =    2360.41 ms /    44 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@CanalUGR The speaker had a very short skirt and incited the violent, right? You're nasty.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.02 ms /    16 runs   (    0.69 ms per token,  1452.56 tokens per second)\n",
            "llama_print_timings: prompt eval time =     759.94 ms /    31 tokens (   24.51 ms per token,    40.79 tokens per second)\n",
            "llama_print_timings:        eval time =    1796.85 ms /    15 runs   (  119.79 ms per token,     8.35 tokens per second)\n",
            "llama_print_timings:       total time =    2736.42 ms /    46 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@SmokingGolem People so big and in skirts, how come you are a bunny girl on your back?\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.32 ms /    16 runs   (    0.58 ms per token,  1716.00 tokens per second)\n",
            "llama_print_timings: prompt eval time =     283.62 ms /    68 tokens (    4.17 ms per token,   239.76 tokens per second)\n",
            "llama_print_timings:        eval time =    1578.09 ms /    15 runs   (  105.21 ms per token,     9.51 tokens per second)\n",
            "llama_print_timings:       total time =    2080.04 ms /    83 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Those who go to school and sit their children in a separate seat that takes up space instead of sitting them on their lap? Sister, don't you see that I've been standing for half an hour? It's hard for you, God, I can't keep dealing with these people.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.17 ms /    16 runs   (    0.57 ms per token,  1745.20 tokens per second)\n",
            "llama_print_timings: prompt eval time =     263.81 ms /    76 tokens (    3.47 ms per token,   288.09 tokens per second)\n",
            "llama_print_timings:        eval time =    1544.19 ms /    15 runs   (  102.95 ms per token,     9.71 tokens per second)\n",
            "llama_print_timings:       total time =    2030.04 ms /    91 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@alexiarivass What a shame you are, women who talk like that and go against another. I don't know if I should call it envy or that you don't have a life. Namaste I wish you learned from Cristina Porta that you are missing boards and they are not exactly the ones on your skirt.\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.38 ms /    16 runs   (    0.52 ms per token,  1909.54 tokens per second)\n",
            "llama_print_timings: prompt eval time =     261.41 ms /    51 tokens (    5.13 ms per token,   195.10 tokens per second)\n",
            "llama_print_timings:        eval time =    1470.51 ms /    15 runs   (   98.03 ms per token,    10.20 tokens per second)\n",
            "llama_print_timings:       total time =    1907.57 ms /    66 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@EsposasPuebla Exquista to hike up her skirt and kiss her ass mmm 😋😋😛😛😛😈😈😈\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      13.48 ms /    16 runs   (    0.84 ms per token,  1187.21 tokens per second)\n",
            "llama_print_timings: prompt eval time =     264.08 ms /    75 tokens (    3.52 ms per token,   284.00 tokens per second)\n",
            "llama_print_timings:        eval time =    1766.74 ms /    15 runs   (  117.78 ms per token,     8.49 tokens per second)\n",
            "llama_print_timings:       total time =    2278.63 ms /    90 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "That 👏🏿 first to address relevant issues!! Now that you can choose whether to wear a skirt or not, you will be able to comfortably go out and do your activities without fear of being shot or disappeared by hitmen in Caborca ​​https://t.co/uEhTYzlIQi\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.65 ms /    16 runs   (    0.60 ms per token,  1658.72 tokens per second)\n",
            "llama_print_timings: prompt eval time =     300.69 ms /   101 tokens (    2.98 ms per token,   335.90 tokens per second)\n",
            "llama_print_timings:        eval time =    1496.72 ms /    15 runs   (   99.78 ms per token,    10.02 tokens per second)\n",
            "llama_print_timings:       total time =    2067.53 ms /   116 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "I recommend Smoked Brisket, Smoked Rib-eye, Smoked T-bone, even Smoked Turkey or any other 🥩 but smoked. We have a smoker, it is very Anglo-Saxon culture. You'll like it, I guarantee it👌🏽. Apart from the 🇺🇸 USA, it has the best breeds of cows, and Japan🇯🇵.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.92 ms /    16 runs   (    0.56 ms per token,  1793.52 tokens per second)\n",
            "llama_print_timings: prompt eval time =     253.87 ms /    66 tokens (    3.85 ms per token,   259.98 tokens per second)\n",
            "llama_print_timings:        eval time =    1492.14 ms /    15 runs   (   99.48 ms per token,    10.05 tokens per second)\n",
            "llama_print_timings:       total time =    1951.54 ms /    81 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@HuancaYorkTimes Poor Castillo, so much coupism, racism, classism, discrimination, machismo, phallocentrism, fatphobia, cacaphobia, etc, etc, etc, no more poor people in a rich country. GAAAAA!\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.81 ms /    16 runs   (    0.68 ms per token,  1479.84 tokens per second)\n",
            "llama_print_timings: prompt eval time =     268.91 ms /    64 tokens (    4.20 ms per token,   238.00 tokens per second)\n",
            "llama_print_timings:        eval time =    1637.50 ms /    15 runs   (  109.17 ms per token,     9.16 tokens per second)\n",
            "llama_print_timings:       total time =    2117.68 ms /    79 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Bart045603771 @jagarrogomez Due to transcription problems, a phallus for companies...the lighthouses are more coastal, in Madrid and the Complutense they are more phallocentrism since Podemos arrived.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.08 ms /    16 runs   (    0.63 ms per token,  1586.67 tokens per second)\n",
            "llama_print_timings: prompt eval time =     284.37 ms /    74 tokens (    3.84 ms per token,   260.23 tokens per second)\n",
            "llama_print_timings:        eval time =    1529.88 ms /    15 runs   (  101.99 ms per token,     9.80 tokens per second)\n",
            "llama_print_timings:       total time =    2037.24 ms /    89 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "“And I always speak with evidence,” says Villavicencio, the fugitive who slipped into the jungle. Together with his friend Vivanco, he does not delay in setting up a new smokescreen to divert attention from his corrupt activities. They will flirt about phallocentrism: who has it bigger.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       7.96 ms /    16 runs   (    0.50 ms per token,  2008.79 tokens per second)\n",
            "llama_print_timings: prompt eval time =     235.90 ms /    37 tokens (    6.38 ms per token,   156.85 tokens per second)\n",
            "llama_print_timings:        eval time =    1470.02 ms /    15 runs   (   98.00 ms per token,    10.20 tokens per second)\n",
            "llama_print_timings:       total time =    1846.84 ms /    52 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "so much phallocentrism and there is no phallocentrism in the places that matter ‼️‼️‼️\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.40 ms /    16 runs   (    0.59 ms per token,  1702.31 tokens per second)\n",
            "llama_print_timings: prompt eval time =     253.26 ms /    54 tokens (    4.69 ms per token,   213.22 tokens per second)\n",
            "llama_print_timings:        eval time =    1428.30 ms /    15 runs   (   95.22 ms per token,    10.50 tokens per second)\n",
            "llama_print_timings:       total time =    1864.19 ms /    69 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "I feel that there are many heterosexuals due to the issue of modesty and society because women are beautiful, more intelligent, with more emotional responsibility, sex lasts longer and orgasm is guaranteed. Phallocentrism bothers me.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.80 ms /    16 runs   (    0.67 ms per token,  1481.76 tokens per second)\n",
            "llama_print_timings: prompt eval time =     259.00 ms /    51 tokens (    5.08 ms per token,   196.91 tokens per second)\n",
            "llama_print_timings:        eval time =    1801.79 ms /    15 runs   (  120.12 ms per token,     8.33 tokens per second)\n",
            "llama_print_timings:       total time =    2289.75 ms /    66 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "and my penis and my penis and my penis and my penis, that's all they know how to say, even the ovary of their phallocentrism https://t.co/bqobpeteO1\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.10 ms /    16 runs   (    0.57 ms per token,  1758.82 tokens per second)\n",
            "llama_print_timings: prompt eval time =     678.71 ms /    27 tokens (   25.14 ms per token,    39.78 tokens per second)\n",
            "llama_print_timings:        eval time =    1498.17 ms /    15 runs   (   99.88 ms per token,    10.01 tokens per second)\n",
            "llama_print_timings:       total time =    2303.65 ms /    42 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@AntonioMautor You reek of a false ally seeking approval. We have you very interested.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.55 ms /    16 runs   (    0.60 ms per token,  1675.74 tokens per second)\n",
            "llama_print_timings: prompt eval time =     243.98 ms /    50 tokens (    4.88 ms per token,   204.93 tokens per second)\n",
            "llama_print_timings:        eval time =    1459.57 ms /    15 runs   (   97.30 ms per token,    10.28 tokens per second)\n",
            "llama_print_timings:       total time =    1870.61 ms /    65 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@antigua_roma \"...Christianity is a false ally of Rome. Roman structures are for the church only a context, a base on which to rely, an instrument to assert itself\" Jacques Le Goff\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.51 ms /    16 runs   (    0.66 ms per token,  1521.93 tokens per second)\n",
            "llama_print_timings: prompt eval time =     294.77 ms /    85 tokens (    3.47 ms per token,   288.36 tokens per second)\n",
            "llama_print_timings:        eval time =    1665.30 ms /    15 runs   (  111.02 ms per token,     9.01 tokens per second)\n",
            "llama_print_timings:       total time =    2223.03 ms /   100 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@MatildeyMilagro @petrogustavo @cielo_rusinque @petrogustavo since he arrived late to the feminist debate and did not know the difference between gender identity and sexual identity I knew he was a false ally. Listen. Educate yourself. It is not our job to do it for you. That's not the change we wanted.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.09 ms /    16 runs   (    0.57 ms per token,  1760.76 tokens per second)\n",
            "llama_print_timings: prompt eval time =     256.22 ms /    52 tokens (    4.93 ms per token,   202.95 tokens per second)\n",
            "llama_print_timings:        eval time =    1553.33 ms /    15 runs   (  103.56 ms per token,     9.66 tokens per second)\n",
            "llama_print_timings:       total time =    1988.28 ms /    67 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Jaim2326Y @DiegoQuispeSanc @menoscanas Excellent unmasking @menoscanas, increasingly equidistance ends up being a danger more than a false “ally”\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.25 ms /    16 runs   (    0.58 ms per token,  1729.73 tokens per second)\n",
            "llama_print_timings: prompt eval time =     261.84 ms /    50 tokens (    5.24 ms per token,   190.96 tokens per second)\n",
            "llama_print_timings:        eval time =    1548.59 ms /    15 runs   (  103.24 ms per token,     9.69 tokens per second)\n",
            "llama_print_timings:       total time =    1989.49 ms /    65 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Misogynistic Comumacho and false ally. That's what should apply to you. Go away, Mr. Eggs. https://t.co/ysydDRJMg8\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.53 ms /    16 runs   (    0.60 ms per token,  1679.61 tokens per second)\n",
            "llama_print_timings: prompt eval time =     787.38 ms /    30 tokens (   26.25 ms per token,    38.10 tokens per second)\n",
            "llama_print_timings:        eval time =    1614.67 ms /    15 runs   (  107.64 ms per token,     9.29 tokens per second)\n",
            "llama_print_timings:       total time =    2545.95 ms /    45 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@jananeme Q it was better to have an enemy or adversary than just a treacherous false ally!!!\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.38 ms /    16 runs   (    0.52 ms per token,  1909.76 tokens per second)\n",
            "llama_print_timings: prompt eval time =     888.29 ms /    29 tokens (   30.63 ms per token,    32.65 tokens per second)\n",
            "llama_print_timings:        eval time =    1467.68 ms /    15 runs   (   97.85 ms per token,    10.22 tokens per second)\n",
            "llama_print_timings:       total time =    2490.46 ms /    44 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "My boyfriend came to Santa Fe to meet my family and they adore him. Very in love 🤍\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.54 ms /    16 runs   (    0.53 ms per token,  1874.19 tokens per second)\n",
            "llama_print_timings: prompt eval time =     241.56 ms /    39 tokens (    6.19 ms per token,   161.45 tokens per second)\n",
            "llama_print_timings:        eval time =    1535.22 ms /    15 runs   (  102.35 ms per token,     9.77 tokens per second)\n",
            "llama_print_timings:       total time =    1927.10 ms /    54 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "OH NOOOO I made a tiktok AND MY FAMILY SAW IT I forced myself to come out of the closet🤡🤡🤡🤡🤡\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.04 ms /    16 runs   (    0.56 ms per token,  1770.69 tokens per second)\n",
            "llama_print_timings: prompt eval time =     252.28 ms /    64 tokens (    3.94 ms per token,   253.69 tokens per second)\n",
            "llama_print_timings:        eval time =    1538.31 ms /    15 runs   (  102.55 ms per token,     9.75 tokens per second)\n",
            "llama_print_timings:       total time =    1988.07 ms /    79 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "My father-in-law had to go to my brother-in-law's school because he got into a fight at school and he came and told him \"don't fight inside the school when you leave school, you have to beat them up\" a normal family wanted me🤣\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.03 ms /    16 runs   (    0.56 ms per token,  1771.09 tokens per second)\n",
            "llama_print_timings: prompt eval time =     243.16 ms /    45 tokens (    5.40 ms per token,   185.06 tokens per second)\n",
            "llama_print_timings:        eval time =    1568.05 ms /    15 runs   (  104.54 ms per token,     9.57 tokens per second)\n",
            "llama_print_timings:       total time =    1981.35 ms /    60 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "FOR ADOPTION ♥️He is LEON, a beautiful puppy who is looking for that family that is for him. https://t.co/jeKdChYVvH\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.41 ms /    16 runs   (    0.59 ms per token,  1700.86 tokens per second)\n",
            "llama_print_timings: prompt eval time =     626.45 ms /    22 tokens (   28.47 ms per token,    35.12 tokens per second)\n",
            "llama_print_timings:        eval time =    1563.67 ms /    15 runs   (  104.24 ms per token,     9.59 tokens per second)\n",
            "llama_print_timings:       total time =    2307.97 ms /    37 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Objective: have money Difficulty: my family treats me like an ATM\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       7.35 ms /    13 runs   (    0.57 ms per token,  1769.67 tokens per second)\n",
            "llama_print_timings: prompt eval time =     254.67 ms /    36 tokens (    7.07 ms per token,   141.36 tokens per second)\n",
            "llama_print_timings:        eval time =    1206.80 ms /    12 runs   (  100.57 ms per token,     9.94 tokens per second)\n",
            "llama_print_timings:       total time =    1598.35 ms /    48 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Jenniffer That wasn't the stupid fucking National Guard, it was neighbors who risked everything to rescue a family in a state of emergency.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.32 ms /    16 runs   (    0.52 ms per token,  1923.08 tokens per second)\n",
            "llama_print_timings: prompt eval time =     767.41 ms /    29 tokens (   26.46 ms per token,    37.79 tokens per second)\n",
            "llama_print_timings:        eval time =    1537.43 ms /    15 runs   (  102.50 ms per token,     9.76 tokens per second)\n",
            "llama_print_timings:       total time =    2434.95 ms /    44 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@soymsbaby Wow but I'm not a bitch, what an ugly carnal attitude 🤣🤣🤣\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.32 ms /    16 runs   (    0.65 ms per token,  1550.24 tokens per second)\n",
            "llama_print_timings: prompt eval time =     913.66 ms /    31 tokens (   29.47 ms per token,    33.93 tokens per second)\n",
            "llama_print_timings:        eval time =    1803.05 ms /    15 runs   (  120.20 ms per token,     8.32 tokens per second)\n",
            "llama_print_timings:       total time =    2932.51 ms /    46 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "I don't know if the route to come to Bolson is uglier or the streets of Bolson, how unfortunate\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.61 ms /    16 runs   (    0.54 ms per token,  1859.17 tokens per second)\n",
            "llama_print_timings: prompt eval time =     246.86 ms /    33 tokens (    7.48 ms per token,   133.68 tokens per second)\n",
            "llama_print_timings:        eval time =    1539.42 ms /    15 runs   (  102.63 ms per token,     9.74 tokens per second)\n",
            "llama_print_timings:       total time =    1922.36 ms /    48 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@OtraAcida And they leave you with a super ugly doubt. Those types of people are not worth it. Cheer up!\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.22 ms /    16 runs   (    0.51 ms per token,  1947.42 tokens per second)\n",
            "llama_print_timings: prompt eval time =     760.11 ms /    29 tokens (   26.21 ms per token,    38.15 tokens per second)\n",
            "llama_print_timings:        eval time =    1607.58 ms /    15 runs   (  107.17 ms per token,     9.33 tokens per second)\n",
            "llama_print_timings:       total time =    2496.47 ms /    44 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "An ugly, hairy, slimy spider. https://t.co/TxC4jfdDEn\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.48 ms /    16 runs   (    0.72 ms per token,  1393.49 tokens per second)\n",
            "llama_print_timings: prompt eval time =     287.03 ms /    72 tokens (    3.99 ms per token,   250.85 tokens per second)\n",
            "llama_print_timings:        eval time =    1763.58 ms /    15 runs   (  117.57 ms per token,     8.51 tokens per second)\n",
            "llama_print_timings:       total time =    2296.92 ms /    87 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "I'm going to meet a friend who I haven't seen in a long time but she has me waiting for more than 30 minutes. MK DON'T be like that, what an ugly thing to be unpunctual!!! https://t.co/FQT7lt8b2D\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.66 ms /    16 runs   (    0.54 ms per token,  1848.00 tokens per second)\n",
            "llama_print_timings: prompt eval time =     572.98 ms /    21 tokens (   27.28 ms per token,    36.65 tokens per second)\n",
            "llama_print_timings:        eval time =    1471.25 ms /    15 runs   (   98.08 ms per token,    10.20 tokens per second)\n",
            "llama_print_timings:       total time =    2155.87 ms /    36 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@OfeFernandez_ Only plane parasites, ugly fat woman\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.32 ms /    16 runs   (    0.58 ms per token,  1717.11 tokens per second)\n",
            "llama_print_timings: prompt eval time =     284.76 ms /    82 tokens (    3.47 ms per token,   287.96 tokens per second)\n",
            "llama_print_timings:        eval time =    1597.98 ms /    15 runs   (  106.53 ms per token,     9.39 tokens per second)\n",
            "llama_print_timings:       total time =    2117.67 ms /    97 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Liatanis Rojipardo is a category that is used to disqualify any political rival with whom one does not agree and does not buy the ideological pack of progressivism. Reminds me of TERF/feminazi. I'm not saying there aren't any, but it's used very happily with anyone you disagree with.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.19 ms /    16 runs   (    0.57 ms per token,  1741.97 tokens per second)\n",
            "llama_print_timings: prompt eval time =     256.26 ms /    41 tokens (    6.25 ms per token,   160.00 tokens per second)\n",
            "llama_print_timings:        eval time =    1485.88 ms /    15 runs   (   99.06 ms per token,    10.09 tokens per second)\n",
            "llama_print_timings:       total time =    1895.19 ms /    56 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@EvaArenales @conha_no @oscar_puente_ I'll make you a drawing, Eva??? From machirulo to feminazi.\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.62 ms /    16 runs   (    0.60 ms per token,  1663.72 tokens per second)\n",
            "llama_print_timings: prompt eval time =     282.42 ms /    87 tokens (    3.25 ms per token,   308.06 tokens per second)\n",
            "llama_print_timings:        eval time =    1472.64 ms /    15 runs   (   98.18 ms per token,    10.19 tokens per second)\n",
            "llama_print_timings:       total time =    2016.54 ms /   102 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "I was going to make a bad joke about this but we don't know what she has... I was going to say that it was the metamorphosis to feminazi... but no, the poor thing has problems, I hope she finds a solution with the people who love her. And no matter what happens, you will recover. https://t.co/ZCgLSXvipp\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.48 ms /    16 runs   (    0.59 ms per token,  1687.94 tokens per second)\n",
            "llama_print_timings: prompt eval time =     251.17 ms /    52 tokens (    4.83 ms per token,   207.03 tokens per second)\n",
            "llama_print_timings:        eval time =    1483.14 ms /    15 runs   (   98.88 ms per token,    10.11 tokens per second)\n",
            "llama_print_timings:       total time =    1909.81 ms /    67 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@tangoenkimono @VictorF40868938 @mvacarezza A feminazi says that husbands should “educate” their wives 😉… ‘tay clear dog.\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.68 ms /    16 runs   (    0.54 ms per token,  1843.74 tokens per second)\n",
            "llama_print_timings: prompt eval time =     251.03 ms /    45 tokens (    5.58 ms per token,   179.27 tokens per second)\n",
            "llama_print_timings:        eval time =    1479.88 ms /    15 runs   (   98.66 ms per token,    10.14 tokens per second)\n",
            "llama_print_timings:       total time =    1895.68 ms /    60 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "What happens is that a red man cannot buy a house and a feminazi cannot enjoy herself without a man in the middle. https://t.co/4XKdaXJ56Z\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.71 ms /    16 runs   (    0.73 ms per token,  1366.47 tokens per second)\n",
            "llama_print_timings: prompt eval time =     289.20 ms /    83 tokens (    3.48 ms per token,   286.99 tokens per second)\n",
            "llama_print_timings:        eval time =    1809.31 ms /    15 runs   (  120.62 ms per token,     8.29 tokens per second)\n",
            "llama_print_timings:       total time =    2510.91 ms /    98 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@nachocastillo87 @cisneitzel28 Exactly. What if, after reading many books, your son/daughter, instead of being an atheist, queer, lesbian, socialist or feminazi, decides to be a full-fledged Christian and devoted to his God? Are you going to repudiate him?\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.85 ms /    16 runs   (    0.62 ms per token,  1624.20 tokens per second)\n",
            "llama_print_timings: prompt eval time =     268.21 ms /    61 tokens (    4.40 ms per token,   227.43 tokens per second)\n",
            "llama_print_timings:        eval time =    1531.98 ms /    15 runs   (  102.13 ms per token,     9.79 tokens per second)\n",
            "llama_print_timings:       total time =    1996.59 ms /    76 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "They locate a lifeless woman inside a hotel on Col. Verde Valle de Gdl. She had a blow to the head and the Femicide protocol was activated @nmasguadalajara https://t.co/8txvauwa9B\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.83 ms /    16 runs   (    0.55 ms per token,  1811.39 tokens per second)\n",
            "llama_print_timings: prompt eval time =     245.44 ms /    41 tokens (    5.99 ms per token,   167.05 tokens per second)\n",
            "llama_print_timings:        eval time =    1546.35 ms /    15 runs   (  103.09 ms per token,     9.70 tokens per second)\n",
            "llama_print_timings:       total time =    1946.07 ms /    56 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@kenialopezr @Claudiashein First learn that it is a feminicide and then you make garbage for your 420 PAN spectators.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.70 ms /    16 runs   (    0.61 ms per token,  1649.99 tokens per second)\n",
            "llama_print_timings: prompt eval time =     288.70 ms /    75 tokens (    3.85 ms per token,   259.79 tokens per second)\n",
            "llama_print_timings:        eval time =    1548.86 ms /    15 runs   (  103.26 ms per token,     9.68 tokens per second)\n",
            "llama_print_timings:       total time =    2060.45 ms /    90 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "This moment Stand in front of the @FiscaliaEcuador of relatives of missing persons @covidefem1 and @AsfadecEc for the Femicide of #MariaBelenBernalWAS A STATE CRIME https://t.co/OqYf9Ftfg9\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      12.34 ms /    16 runs   (    0.77 ms per token,  1296.60 tokens per second)\n",
            "llama_print_timings: prompt eval time =     264.38 ms /    45 tokens (    5.88 ms per token,   170.21 tokens per second)\n",
            "llama_print_timings:        eval time =    1865.23 ms /    15 runs   (  124.35 ms per token,     8.04 tokens per second)\n",
            "llama_print_timings:       total time =    2399.45 ms /    60 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "The case of the femicide of Luz Raquel Padilla in Zapopan registers more doubts than certainty https://t.co/9N1939vDZM\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.03 ms /    16 runs   (    0.56 ms per token,  1771.48 tokens per second)\n",
            "llama_print_timings: prompt eval time =     254.08 ms /    38 tokens (    6.69 ms per token,   149.56 tokens per second)\n",
            "llama_print_timings:        eval time =    1535.19 ms /    15 runs   (  102.35 ms per token,     9.77 tokens per second)\n",
            "llama_print_timings:       total time =    1938.66 ms /    53 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Suspects arrested over the weekend for robberies, rape and attempted feminicide https://t.co/9ZqmWgXtFi\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.59 ms /    16 runs   (    0.60 ms per token,  1669.10 tokens per second)\n",
            "llama_print_timings: prompt eval time =     259.51 ms /    52 tokens (    4.99 ms per token,   200.38 tokens per second)\n",
            "llama_print_timings:        eval time =    1523.22 ms /    15 runs   (  101.55 ms per token,     9.85 tokens per second)\n",
            "llama_print_timings:       total time =    1965.89 ms /    67 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Nooo 💔 TikTok user finds a dialogue in The Flintstones that is generating a lot of discontent. Did you notice it?https://t.co/SZ7CDNPLho\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.53 ms /    16 runs   (    0.60 ms per token,  1678.38 tokens per second)\n",
            "llama_print_timings: prompt eval time =     272.01 ms /    82 tokens (    3.32 ms per token,   301.46 tokens per second)\n",
            "llama_print_timings:        eval time =    1550.18 ms /    15 runs   (  103.35 ms per token,     9.68 tokens per second)\n",
            "llama_print_timings:       total time =    2062.95 ms /    97 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Dra_Blink @theblinksuprema Because... How is it that blnk is using the \"feminist\" discourse again (honestly it is stupid because feminism goes much further than what the discourse of bourgeois feminism says) and at the same time he is defending a pimp like the CEO of y/g?\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.86 ms /    16 runs   (    0.74 ms per token,  1348.62 tokens per second)\n",
            "llama_print_timings: prompt eval time =     269.16 ms /    64 tokens (    4.21 ms per token,   237.77 tokens per second)\n",
            "llama_print_timings:        eval time =    1818.28 ms /    15 runs   (  121.22 ms per token,     8.25 tokens per second)\n",
            "llama_print_timings:       total time =    2427.10 ms /    79 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Aemon3428 They are the same ones who screwed Hollman Morris and made Claudia López mayor. If a woman reaches a position through her own merit and without personal interests in having a contract, they attack her, what an empowered and inclusive feminism.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.21 ms /    16 runs   (    0.58 ms per token,  1737.62 tokens per second)\n",
            "llama_print_timings: prompt eval time =     261.06 ms /    48 tokens (    5.44 ms per token,   183.87 tokens per second)\n",
            "llama_print_timings:        eval time =    1636.55 ms /    15 runs   (  109.10 ms per token,     9.17 tokens per second)\n",
            "llama_print_timings:       total time =    2066.80 ms /    63 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@BSepulvedaHales I mean if they are left-handed they have feminist support, otherwise they have the hatred of women hahahaha that is not feminism, it is just cheap politics\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.95 ms /    16 runs   (    0.62 ms per token,  1608.20 tokens per second)\n",
            "llama_print_timings: prompt eval time =     252.26 ms /    52 tokens (    4.85 ms per token,   206.14 tokens per second)\n",
            "llama_print_timings:        eval time =    1598.89 ms /    15 runs   (  106.59 ms per token,     9.38 tokens per second)\n",
            "llama_print_timings:       total time =    2036.41 ms /    67 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "CHRISTIANIST OR CRETINIST FEMINISM IS THE DENIAL OF EVITA'S THOUGHT. https://t.co/O4mDlNKoxJ\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.73 ms /    16 runs   (    0.55 ms per token,  1831.71 tokens per second)\n",
            "llama_print_timings: prompt eval time =     244.46 ms /    35 tokens (    6.98 ms per token,   143.17 tokens per second)\n",
            "llama_print_timings:        eval time =    1588.37 ms /    15 runs   (  105.89 ms per token,     9.44 tokens per second)\n",
            "llama_print_timings:       total time =    1976.09 ms /    50 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "It doesn't fail that all the aunts who are ultra radicalized with feminism have daddy issues.ToDasToDiTas\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.63 ms /    16 runs   (    0.60 ms per token,  1661.82 tokens per second)\n",
            "llama_print_timings: prompt eval time =     288.86 ms /    77 tokens (    3.75 ms per token,   266.57 tokens per second)\n",
            "llama_print_timings:        eval time =    1538.67 ms /    15 runs   (  102.58 ms per token,     9.75 tokens per second)\n",
            "llama_print_timings:       total time =    2057.04 ms /    92 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@TheBloodyStone @ivan_unalcoyano Aaaah. Anti-feminism profile and false complaints everywhere. More claustrophobic attire than reading the Metamorphosis or taking the Madrid circular. I met him at a fachaparty in Madrid. What a lazy guy. Me with Gilbert\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.91 ms /    16 runs   (    0.56 ms per token,  1796.14 tokens per second)\n",
            "llama_print_timings: prompt eval time =     565.06 ms /    21 tokens (   26.91 ms per token,    37.16 tokens per second)\n",
            "llama_print_timings:        eval time =    1544.01 ms /    15 runs   (  102.93 ms per token,     9.71 tokens per second)\n",
            "llama_print_timings:       total time =    2226.11 ms /    36 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@RahulkMex Wow for a moment I thought it was a photo\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.62 ms /    16 runs   (    0.60 ms per token,  1663.20 tokens per second)\n",
            "llama_print_timings: prompt eval time =     249.66 ms /    61 tokens (    4.09 ms per token,   244.33 tokens per second)\n",
            "llama_print_timings:        eval time =    1449.63 ms /    15 runs   (   96.64 ms per token,    10.35 tokens per second)\n",
            "llama_print_timings:       total time =    1905.70 ms /    76 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@FJalifas @ThisIsMarsella Better say that they are from somewhere in Nuevo León, there if Carta Blanca is taken (and those in the photo look like they are from Los Cardenales de NL)... 😆 🙄\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.46 ms /    16 runs   (    0.72 ms per token,  1396.16 tokens per second)\n",
            "llama_print_timings: prompt eval time =     259.43 ms /    58 tokens (    4.47 ms per token,   223.57 tokens per second)\n",
            "llama_print_timings:        eval time =    1802.19 ms /    15 runs   (  120.15 ms per token,     8.32 tokens per second)\n",
            "llama_print_timings:       total time =    2384.26 ms /    73 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@ismaelr37811372 @Corruptos_NoMas @SARGENTOCHALA @ESMIC_EJC In your photo the only officer I see is the corrupt one from Zapateiro\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.93 ms /    16 runs   (    0.56 ms per token,  1792.52 tokens per second)\n",
            "llama_print_timings: prompt eval time =     795.28 ms /    29 tokens (   27.42 ms per token,    36.47 tokens per second)\n",
            "llama_print_timings:        eval time =    1623.74 ms /    15 runs   (  108.25 ms per token,     9.24 tokens per second)\n",
            "llama_print_timings:       total time =    2552.72 ms /    44 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "My personality is literally reflected in a photo with Mickey who says not to touch and poses like a gym bro.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.72 ms /    16 runs   (    0.55 ms per token,  1834.86 tokens per second)\n",
            "llama_print_timings: prompt eval time =     712.44 ms /    27 tokens (   26.39 ms per token,    37.90 tokens per second)\n",
            "llama_print_timings:        eval time =    1490.77 ms /    15 runs   (   99.38 ms per token,    10.06 tokens per second)\n",
            "llama_print_timings:       total time =    2337.97 ms /    42 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@QuKaNegrita Of course I ask because I suppose he wore it like that for the photo\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.37 ms /    16 runs   (    0.65 ms per token,  1542.91 tokens per second)\n",
            "llama_print_timings: prompt eval time =     249.25 ms /    61 tokens (    4.09 ms per token,   244.73 tokens per second)\n",
            "llama_print_timings:        eval time =    1619.02 ms /    15 runs   (  107.93 ms per token,     9.26 tokens per second)\n",
            "llama_print_timings:       total time =    2083.70 ms /    76 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Pride_JA Hey sir, this is too much, I was watching nopor to my liking, and now I get this, instead of messing around with a video of an old woman, I finished it and came back with your photo 😳😳😳\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.89 ms /    16 runs   (    0.56 ms per token,  1799.57 tokens per second)\n",
            "llama_print_timings: prompt eval time =     245.44 ms /    35 tokens (    7.01 ms per token,   142.60 tokens per second)\n",
            "llama_print_timings:        eval time =    1549.12 ms /    15 runs   (  103.27 ms per token,     9.68 tokens per second)\n",
            "llama_print_timings:       total time =    1941.16 ms /    50 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@90minutosdpCSE @teleamazonasec Noo, she is frigid. Ben soldier commtando😂😂😂\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.82 ms /    16 runs   (    0.61 ms per token,  1629.00 tokens per second)\n",
            "llama_print_timings: prompt eval time =     286.14 ms /    67 tokens (    4.27 ms per token,   234.15 tokens per second)\n",
            "llama_print_timings:        eval time =    1629.37 ms /    15 runs   (  108.62 ms per token,     9.21 tokens per second)\n",
            "llama_print_timings:       total time =    2129.15 ms /    82 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "They never really touched even one of my tits because a girl is very frigid; They were power relationships and I had blocked many of them. As a result of that chapter I began to relive images and I finally understood why I was the whore despite being surrounded by people who hurt themselves.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.17 ms /    16 runs   (    0.57 ms per token,  1744.25 tokens per second)\n",
            "llama_print_timings: prompt eval time =     279.48 ms /    66 tokens (    4.23 ms per token,   236.15 tokens per second)\n",
            "llama_print_timings:        eval time =    1483.02 ms /    15 runs   (   98.87 ms per token,    10.11 tokens per second)\n",
            "llama_print_timings:       total time =    1978.51 ms /    81 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@ladyprecarizada Frigid progress of the other, if I don't contribute, I don't have to have the right to a retirement. It is unfair to everyone who contributed their entire lives, and it is UNSUSTAINABLE financially for the government. Fool\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.04 ms /    16 runs   (    0.63 ms per token,  1594.26 tokens per second)\n",
            "llama_print_timings: prompt eval time =     254.21 ms /    40 tokens (    6.36 ms per token,   157.35 tokens per second)\n",
            "llama_print_timings:        eval time =    1689.93 ms /    15 runs   (  112.66 ms per token,     8.88 tokens per second)\n",
            "llama_print_timings:       total time =    2182.42 ms /    55 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "poor latorre who of all the cats he could have ended up with married this frigid https://t.co/I4UWURNDk0\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.25 ms /    16 runs   (    0.58 ms per token,  1729.36 tokens per second)\n",
            "llama_print_timings: prompt eval time =     259.27 ms /    46 tokens (    5.64 ms per token,   177.42 tokens per second)\n",
            "llama_print_timings:        eval time =    1576.96 ms /    15 runs   (  105.13 ms per token,     9.51 tokens per second)\n",
            "llama_print_timings:       total time =    2004.92 ms /    61 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@hamaxx1 SINCE THE FATHER EATEN MORIA, SHE IS MORE FRIGID EVER.. LIKE THE BOSS OF THE BAND 😂\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.18 ms /    16 runs   (    0.57 ms per token,  1743.68 tokens per second)\n",
            "llama_print_timings: prompt eval time =     265.61 ms /    60 tokens (    4.43 ms per token,   225.90 tokens per second)\n",
            "llama_print_timings:        eval time =    1568.93 ms /    15 runs   (  104.60 ms per token,     9.56 tokens per second)\n",
            "llama_print_timings:       total time =    2036.89 ms /    75 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@charovargas_ That is why she will eat and the years will eat her, because she is frustrated, frigid and stupid.😌🥳❤️❤️ https://t.co/8xkHaO8dAg\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.98 ms /    16 runs   (    0.56 ms per token,  1781.14 tokens per second)\n",
            "llama_print_timings: prompt eval time =     699.74 ms /    26 tokens (   26.91 ms per token,    37.16 tokens per second)\n",
            "llama_print_timings:        eval time =    1571.04 ms /    15 runs   (  104.74 ms per token,     9.55 tokens per second)\n",
            "llama_print_timings:       total time =    2401.71 ms /    41 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "This means doing it at gulf time https://t.co/Vk7fyqtfnS\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.64 ms /    16 runs   (    0.67 ms per token,  1503.48 tokens per second)\n",
            "llama_print_timings: prompt eval time =     269.98 ms /    55 tokens (    4.91 ms per token,   203.72 tokens per second)\n",
            "llama_print_timings:        eval time =    1664.65 ms /    15 runs   (  110.98 ms per token,     9.01 tokens per second)\n",
            "llama_print_timings:       total time =    2227.92 ms /    70 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Carlitos Alcaraz returns with a desire for revenge. And here we are to see it. Night live, golf nights in CincinnatiVamooosss https://t.co/NiqWGkvQ2m\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.65 ms /    16 runs   (    0.54 ms per token,  1849.50 tokens per second)\n",
            "llama_print_timings: prompt eval time =     251.38 ms /    37 tokens (    6.79 ms per token,   147.19 tokens per second)\n",
            "llama_print_timings:        eval time =    1545.06 ms /    15 runs   (  103.00 ms per token,     9.71 tokens per second)\n",
            "llama_print_timings:       total time =    1949.03 ms /    52 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@ionebelarra Apparently for Belarra these deserved it, she will be a bitchhttps://t.co/ETOmASgol5\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.02 ms /    16 runs   (    0.56 ms per token,  1773.84 tokens per second)\n",
            "llama_print_timings: prompt eval time =     681.19 ms /    27 tokens (   25.23 ms per token,    39.64 tokens per second)\n",
            "llama_print_timings:        eval time =    1566.53 ms /    15 runs   (  104.44 ms per token,     9.58 tokens per second)\n",
            "llama_print_timings:       total time =    2383.13 ms /    42 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Jojare2 Sarna Hernández Golfa has Colombian nationality, unfortunately it is not there.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.42 ms /    16 runs   (    0.65 ms per token,  1535.51 tokens per second)\n",
            "llama_print_timings: prompt eval time =     282.55 ms /    70 tokens (    4.04 ms per token,   247.74 tokens per second)\n",
            "llama_print_timings:        eval time =    1721.93 ms /    15 runs   (  114.80 ms per token,     8.71 tokens per second)\n",
            "llama_print_timings:       total time =    2240.58 ms /    85 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "How sorry I am for those people who believe that you share their value system and assume that you are like them, yes, one of those people who exchange their bodies so that they are loved. It's so nice to be a slut and fuck the guy you like, just like that 💅🏼\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.90 ms /    16 runs   (    0.56 ms per token,  1797.75 tokens per second)\n",
            "llama_print_timings: prompt eval time =     687.65 ms /    26 tokens (   26.45 ms per token,    37.81 tokens per second)\n",
            "llama_print_timings:        eval time =    1528.31 ms /    15 runs   (  101.89 ms per token,     9.81 tokens per second)\n",
            "llama_print_timings:       total time =    2342.97 ms /    41 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@TonoSVJ A third-rate slut and her pimp. Could anyone think otherwise?\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.41 ms /    16 runs   (    0.59 ms per token,  1700.68 tokens per second)\n",
            "llama_print_timings: prompt eval time =     770.55 ms /    29 tokens (   26.57 ms per token,    37.64 tokens per second)\n",
            "llama_print_timings:        eval time =    1545.63 ms /    15 runs   (  103.04 ms per token,     9.70 tokens per second)\n",
            "llama_print_timings:       total time =    2454.69 ms /    44 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Pounding the mud and slamming it on the table is fucking therapeutic, it's just that\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.50 ms /    16 runs   (    0.53 ms per token,  1882.80 tokens per second)\n",
            "llama_print_timings: prompt eval time =     241.30 ms /    33 tokens (    7.31 ms per token,   136.76 tokens per second)\n",
            "llama_print_timings:        eval time =    1498.25 ms /    15 runs   (   99.88 ms per token,    10.01 tokens per second)\n",
            "llama_print_timings:       total time =    1884.01 ms /    48 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@rmgarciav On a street of minimal dimensions. As a gift, they knocked down the street lamp when it hit the pole.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.07 ms /    16 runs   (    0.69 ms per token,  1445.61 tokens per second)\n",
            "llama_print_timings: prompt eval time =     240.68 ms /    45 tokens (    5.35 ms per token,   186.97 tokens per second)\n",
            "llama_print_timings:        eval time =    1847.99 ms /    15 runs   (  123.20 ms per token,     8.12 tokens per second)\n",
            "llama_print_timings:       total time =    2285.36 ms /    60 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@_____ErenJaeger Empathic psychopath yes, like when the mother says before hitting the child \"this is going to hurt me more than it will hurt you\" 🙃\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.33 ms /    16 runs   (    0.58 ms per token,  1714.16 tokens per second)\n",
            "llama_print_timings: prompt eval time =     287.14 ms /    71 tokens (    4.04 ms per token,   247.26 tokens per second)\n",
            "llama_print_timings:        eval time =    1474.85 ms /    15 runs   (   98.32 ms per token,    10.17 tokens per second)\n",
            "llama_print_timings:       total time =    1984.37 ms /    86 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Rabona is an art of Argentine origin, a different way of hitting the ball with one foot that passes behind the leg that supports the entire weight of the body, that is, crossing both legs. There are many reasons why a player opts... https://t.co/THTkNB9s9w\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.56 ms /    16 runs   (    0.60 ms per token,  1673.29 tokens per second)\n",
            "llama_print_timings: prompt eval time =     284.12 ms /    81 tokens (    3.51 ms per token,   285.09 tokens per second)\n",
            "llama_print_timings:        eval time =    1550.36 ms /    15 runs   (  103.36 ms per token,     9.68 tokens per second)\n",
            "llama_print_timings:       total time =    2075.45 ms /    96 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@rojasdiazduran What militarization. You are a cretin, where are you seeing that the army is used to repress, beat or intimidate citizens, the president wants and the majority of us support him so that he protects our institution @GN_MEXICO_ from bad rulers #ProtejamosLaGuardiaNacional\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.71 ms /    16 runs   (    0.54 ms per token,  1837.39 tokens per second)\n",
            "llama_print_timings: prompt eval time =     697.93 ms /    26 tokens (   26.84 ms per token,    37.25 tokens per second)\n",
            "llama_print_timings:        eval time =    1493.53 ms /    15 runs   (   99.57 ms per token,    10.04 tokens per second)\n",
            "llama_print_timings:       total time =    2312.40 ms /    41 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "A bike just hit me at university and my back hurts like hell HAHAHAHAHAHAHA\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      12.24 ms /    16 runs   (    0.76 ms per token,  1307.51 tokens per second)\n",
            "llama_print_timings: prompt eval time =     281.15 ms /    67 tokens (    4.20 ms per token,   238.30 tokens per second)\n",
            "llama_print_timings:        eval time =    1745.35 ms /    15 runs   (  116.36 ms per token,     8.59 tokens per second)\n",
            "llama_print_timings:       total time =    2383.82 ms /    82 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "#MariaBelenBernal-A woman is brutally beaten in Guayaquil.- A police officer on active duty beat his partner on the Vinces boardwalk.- A lieutenant killed his wife in a training school. Disgust of society!! They are killing us. How many more?\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.85 ms /    16 runs   (    0.55 ms per token,  1807.71 tokens per second)\n",
            "llama_print_timings: prompt eval time =     243.50 ms /    43 tokens (    5.66 ms per token,   176.59 tokens per second)\n",
            "llama_print_timings:        eval time =    1572.43 ms /    15 runs   (  104.83 ms per token,     9.54 tokens per second)\n",
            "llama_print_timings:       total time =    1970.84 ms /    58 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "In the best moment of the Uruguayan team, the dragão struck first with Pereira who sent a cross for Luiz Fernando to connect with a header at the near post.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.81 ms /    16 runs   (    0.55 ms per token,  1816.12 tokens per second)\n",
            "llama_print_timings: prompt eval time =     292.64 ms /    97 tokens (    3.02 ms per token,   331.46 tokens per second)\n",
            "llama_print_timings:        eval time =    1509.37 ms /    15 runs   (  100.62 ms per token,     9.94 tokens per second)\n",
            "llama_print_timings:       total time =    2075.19 ms /   112 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@EvyMedinz @aycomochingas @nadadetuiter But that is not respectful parenting, I correct my son and actions that are wrong have consequences, I do not hit him and I educate him with love, those misbehaved children are generally not raised by their parents that is why they are like that , they are raised by TV, games, babysitters and they do not receive love.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.92 ms /    16 runs   (    0.56 ms per token,  1793.72 tokens per second)\n",
            "llama_print_timings: prompt eval time =     261.79 ms /    51 tokens (    5.13 ms per token,   194.82 tokens per second)\n",
            "llama_print_timings:        eval time =    1529.54 ms /    15 runs   (  101.97 ms per token,     9.81 tokens per second)\n",
            "llama_print_timings:       total time =    1963.37 ms /    66 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Minister @Vi11atoro reports the capture of a motorcyclist who hit a person in the Antiguo Cuscatlán area. https://t.co/Pu6cjsCpzu\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.00 ms /    16 runs   (    0.63 ms per token,  1599.84 tokens per second)\n",
            "llama_print_timings: prompt eval time =     266.50 ms /    58 tokens (    4.59 ms per token,   217.64 tokens per second)\n",
            "llama_print_timings:        eval time =    1714.62 ms /    15 runs   (  114.31 ms per token,     8.75 tokens per second)\n",
            "llama_print_timings:       total time =    2284.97 ms /    73 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@iBanishedHero ⠀⠀⠀⠀   ⠀ ───He just rolled his eyes and started serving the customers who took a long time and while walking behind the counter, he accidentally hit the guy a couple of times.───\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.94 ms /    16 runs   (    0.56 ms per token,  1790.11 tokens per second)\n",
            "llama_print_timings: prompt eval time =     643.79 ms /    23 tokens (   27.99 ms per token,    35.73 tokens per second)\n",
            "llama_print_timings:        eval time =    1529.93 ms /    15 runs   (  102.00 ms per token,     9.80 tokens per second)\n",
            "llama_print_timings:       total time =    2295.95 ms /    38 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "I hit the ATM keys, sweaters with holes, always a new mambo\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.63 ms /    16 runs   (    0.54 ms per token,  1853.14 tokens per second)\n",
            "llama_print_timings: prompt eval time =     610.91 ms /    23 tokens (   26.56 ms per token,    37.65 tokens per second)\n",
            "llama_print_timings:        eval time =    1515.00 ms /    15 runs   (  101.00 ms per token,     9.90 tokens per second)\n",
            "llama_print_timings:       total time =    2252.24 ms /    38 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "my fat fan weekend officially ended. Belén, 16, would be very proud\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.28 ms /    16 runs   (    0.64 ms per token,  1557.18 tokens per second)\n",
            "llama_print_timings: prompt eval time =     247.11 ms /    56 tokens (    4.41 ms per token,   226.62 tokens per second)\n",
            "llama_print_timings:        eval time =    1611.21 ms /    15 runs   (  107.41 ms per token,     9.31 tokens per second)\n",
            "llama_print_timings:       total time =    2063.77 ms /    71 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@WilsonMendez86 She's a fat girl who sucks dick instead of first saying, \"It's perfect for theirs, no, always defending, but then it's their turn and the fat girl goes crazy.\"\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.93 ms /    16 runs   (    0.56 ms per token,  1792.52 tokens per second)\n",
            "llama_print_timings: prompt eval time =     257.34 ms /    37 tokens (    6.96 ms per token,   143.78 tokens per second)\n",
            "llama_print_timings:        eval time =    1541.03 ms /    15 runs   (  102.74 ms per token,     9.73 tokens per second)\n",
            "llama_print_timings:       total time =    2009.95 ms /    52 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@ultramacrista23 @marce01971 @infobae She is a fat woman who hates women who prefer men\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.71 ms /    16 runs   (    0.61 ms per token,  1648.46 tokens per second)\n",
            "llama_print_timings: prompt eval time =     256.92 ms /    59 tokens (    4.35 ms per token,   229.64 tokens per second)\n",
            "llama_print_timings:        eval time =    1478.56 ms /    15 runs   (   98.57 ms per token,    10.14 tokens per second)\n",
            "llama_print_timings:       total time =    1925.80 ms /    74 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@ugharufck JSJDKAKDJSJS we have the same illness, only I justify it with end-of-year fatigue!!! It doesn't matter if the fat woman here becomes very delirious or we all immolate ourselves directly.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.65 ms /    16 runs   (    0.60 ms per token,  1658.55 tokens per second)\n",
            "llama_print_timings: prompt eval time =     777.12 ms /    31 tokens (   25.07 ms per token,    39.89 tokens per second)\n",
            "llama_print_timings:        eval time =    1505.58 ms /    15 runs   (  100.37 ms per token,     9.96 tokens per second)\n",
            "llama_print_timings:       total time =    2425.83 ms /    46 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@hugomndzz @follacamiones24 @solmorote and a fat cock who knows Asturias\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.52 ms /    16 runs   (    0.66 ms per token,  1520.62 tokens per second)\n",
            "llama_print_timings: prompt eval time =     756.09 ms /    30 tokens (   25.20 ms per token,    39.68 tokens per second)\n",
            "llama_print_timings:        eval time =    1785.64 ms /    15 runs   (  119.04 ms per token,     8.40 tokens per second)\n",
            "llama_print_timings:       total time =    2704.93 ms /    45 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "How I hate going out in short sleeves and having to come back with a fat jacket, the fucking motherfucker.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.20 ms /    16 runs   (    0.57 ms per token,  1739.51 tokens per second)\n",
            "llama_print_timings: prompt eval time =     252.54 ms /    52 tokens (    4.86 ms per token,   205.91 tokens per second)\n",
            "llama_print_timings:        eval time =    1484.21 ms /    15 runs   (   98.95 ms per token,    10.11 tokens per second)\n",
            "llama_print_timings:       total time =    1912.97 ms /    67 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@1312caba @daanifdzz_ @secoweedcodein @dgarcian08 I think I'm eating slut, pass me the ketchup hahahahaha\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.03 ms /    16 runs   (    0.56 ms per token,  1771.48 tokens per second)\n",
            "llama_print_timings: prompt eval time =     310.02 ms /   121 tokens (    2.56 ms per token,   390.30 tokens per second)\n",
            "llama_print_timings:        eval time =    1506.30 ms /    15 runs   (  100.42 ms per token,     9.96 tokens per second)\n",
            "llama_print_timings:       total time =    2162.02 ms /   136 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Old slut plays Twitch in rankeds Come see me https://t.co/xd1VavJcGN.#smallstreamer #twitch #twitchaffiliate #TwitchStreaming #twitchenlinea #twitchtv #LeagueOfLegends #twitchcommunity@twitchpr0mo@Promo_Twitch_RT@StreamersApoyo@ComunidadTwitch@streamsspain@lol_es https:/ /t.co/AmraYcloCm\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.94 ms /    16 runs   (    0.56 ms per token,  1789.51 tokens per second)\n",
            "llama_print_timings: prompt eval time =     691.01 ms /    26 tokens (   26.58 ms per token,    37.63 tokens per second)\n",
            "llama_print_timings:        eval time =    1494.45 ms /    15 runs   (   99.63 ms per token,    10.04 tokens per second)\n",
            "llama_print_timings:       total time =    2308.23 ms /    41 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "The dirty joke of removing Griezmann in the 64th minute is worth it eh\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.37 ms /    16 runs   (    0.71 ms per token,  1406.96 tokens per second)\n",
            "llama_print_timings: prompt eval time =     241.93 ms /    34 tokens (    7.12 ms per token,   140.53 tokens per second)\n",
            "llama_print_timings:        eval time =    1847.02 ms /    15 runs   (  123.13 ms per token,     8.12 tokens per second)\n",
            "llama_print_timings:       total time =    2324.53 ms /    49 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@GamberrosATM @chasalSDH The one who really looks like a slut that you freak out about is your mother\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.59 ms /    16 runs   (    0.54 ms per token,  1862.20 tokens per second)\n",
            "llama_print_timings: prompt eval time =     788.20 ms /    30 tokens (   26.27 ms per token,    38.06 tokens per second)\n",
            "llama_print_timings:        eval time =    1499.34 ms /    15 runs   (   99.96 ms per token,    10.00 tokens per second)\n",
            "llama_print_timings:       total time =    2419.15 ms /    45 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@mblopezz3 BUT YOU SAY YOU PIECE OF A SLUT, LOUIE😎🤘\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.97 ms /    16 runs   (    0.56 ms per token,  1784.52 tokens per second)\n",
            "llama_print_timings: prompt eval time =     735.16 ms /    30 tokens (   24.51 ms per token,    40.81 tokens per second)\n",
            "llama_print_timings:        eval time =    1524.06 ms /    15 runs   (  101.60 ms per token,     9.84 tokens per second)\n",
            "llama_print_timings:       total time =    2398.86 ms /    45 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Beatriz_co_14 But slut... in the literal sense of the word slut? My mother?\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.59 ms /    16 runs   (    0.60 ms per token,  1667.88 tokens per second)\n",
            "llama_print_timings: prompt eval time =     250.23 ms /    51 tokens (    4.91 ms per token,   203.81 tokens per second)\n",
            "llama_print_timings:        eval time =    1589.26 ms /    15 runs   (  105.95 ms per token,     9.44 tokens per second)\n",
            "llama_print_timings:       total time =    2014.53 ms /    66 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@ElisaLoncon Thank you so much Elisa....you are one of the people who generated hives in Chileans and contributed to the rejection today...thank you!!! #LONCON #REJECTION\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.00 ms /    16 runs   (    0.62 ms per token,  1600.80 tokens per second)\n",
            "llama_print_timings: prompt eval time =     280.39 ms /    64 tokens (    4.38 ms per token,   228.25 tokens per second)\n",
            "llama_print_timings:        eval time =    1744.48 ms /    15 runs   (  116.30 ms per token,     8.60 tokens per second)\n",
            "llama_print_timings:       total time =    2366.44 ms /    79 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@bartije These ladies are a shame for the genre! 🤮🤬🤬🤬🤬 And the worst thing is that they are not even useful to society 🤮🤮🤮\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.17 ms /    16 runs   (    0.57 ms per token,  1745.58 tokens per second)\n",
            "llama_print_timings: prompt eval time =     280.50 ms /    82 tokens (    3.42 ms per token,   292.33 tokens per second)\n",
            "llama_print_timings:        eval time =    1537.05 ms /    15 runs   (  102.47 ms per token,     9.76 tokens per second)\n",
            "llama_print_timings:       total time =    2072.91 ms /    97 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Luis22373580 @bereaguilarv @lopezobrador_ It is not a simulation, the lack of water was generated when in 2019 they fired many technicians from Conagua de Nuevo León, due to austerity, they avoided the theft of water and took care of the dams.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.72 ms /    16 runs   (    0.55 ms per token,  1834.65 tokens per second)\n",
            "llama_print_timings: prompt eval time =     252.57 ms /    36 tokens (    7.02 ms per token,   142.53 tokens per second)\n",
            "llama_print_timings:        eval time =    1475.71 ms /    15 runs   (   98.38 ms per token,    10.16 tokens per second)\n",
            "llama_print_timings:       total time =    1875.66 ms /    51 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "My next birthday has me thinking about all the unnecessary emotional and physical wear and tear that living doing masking without knowing for 36 years caused me.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      12.05 ms /    16 runs   (    0.75 ms per token,  1327.91 tokens per second)\n",
            "llama_print_timings: prompt eval time =     260.82 ms /    57 tokens (    4.58 ms per token,   218.54 tokens per second)\n",
            "llama_print_timings:        eval time =    1929.18 ms /    15 runs   (  128.61 ms per token,     7.78 tokens per second)\n",
            "llama_print_timings:       total time =    2484.73 ms /    72 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@inigobastida @veronicafumanal What nonsense. First you ask that they be treated with discipline and then about the rooms. I used Capello as mister. You always orient everything to gender. Capello towards military concentrations\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.22 ms /    16 runs   (    0.58 ms per token,  1735.55 tokens per second)\n",
            "llama_print_timings: prompt eval time =     259.81 ms /    59 tokens (    4.40 ms per token,   227.09 tokens per second)\n",
            "llama_print_timings:        eval time =    1459.11 ms /    15 runs   (   97.27 ms per token,    10.28 tokens per second)\n",
            "llama_print_timings:       total time =    1910.80 ms /    74 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Victimization continues, apparently Carrera is going to change sex, to be able to victimize herself with the issue of gender violence, it is the only thing she has left. https://t.co/Qa1SQj2wJj\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.83 ms /    16 runs   (    0.55 ms per token,  1812.42 tokens per second)\n",
            "llama_print_timings: prompt eval time =     260.61 ms /    48 tokens (    5.43 ms per token,   184.18 tokens per second)\n",
            "llama_print_timings:        eval time =    1685.94 ms /    15 runs   (  112.40 ms per token,     8.90 tokens per second)\n",
            "llama_print_timings:       total time =    2114.71 ms /    63 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@AntonioMautor Hembrism is not totally transversal. He understands ideologies. It is true that it abounds in some more than in others, but unfortunately it knocks on all doors.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.22 ms /    16 runs   (    0.70 ms per token,  1425.52 tokens per second)\n",
            "llama_print_timings: prompt eval time =     293.07 ms /    87 tokens (    3.37 ms per token,   296.85 tokens per second)\n",
            "llama_print_timings:        eval time =    1676.60 ms /    15 runs   (  111.77 ms per token,     8.95 tokens per second)\n",
            "llama_print_timings:       total time =    2249.07 ms /   102 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@AfricaCuevasR Hembrism without further ado.... a man, just because he is a man, does not have the right to deductions even if he has children, let's be clear about what he says, you have to be homosexual or a woman. I love them both but where is the real feminism? Another attack on man for the fact of being one 🤷\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.64 ms /    16 runs   (    0.60 ms per token,  1659.06 tokens per second)\n",
            "llama_print_timings: prompt eval time =     264.72 ms /    56 tokens (    4.73 ms per token,   211.55 tokens per second)\n",
            "llama_print_timings:        eval time =    1486.50 ms /    15 runs   (   99.10 ms per token,    10.09 tokens per second)\n",
            "llama_print_timings:       total time =    1938.95 ms /    71 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@IsaMellen That is fembrism... feminism is equity, let's stop talking about the rights of women/men and let it be just RIGHTS OF PEOPLE. Something so simple and that even today we have to fight\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.76 ms /    16 runs   (    0.61 ms per token,  1640.02 tokens per second)\n",
            "llama_print_timings: prompt eval time =     260.87 ms /    55 tokens (    4.74 ms per token,   210.84 tokens per second)\n",
            "llama_print_timings:        eval time =    1463.31 ms /    15 runs   (   97.55 ms per token,    10.25 tokens per second)\n",
            "llama_print_timings:       total time =    1909.84 ms /    70 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Roinaldinho4 @LocksleyRober @interiorgob @guardiacivil You are wrong. Hembrism only seeks privileges for women. Feminism seeks equality in criteria of real and well-understood justice.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.43 ms /    16 runs   (    0.53 ms per token,  1897.98 tokens per second)\n",
            "llama_print_timings: prompt eval time =     776.68 ms /    30 tokens (   25.89 ms per token,    38.63 tokens per second)\n",
            "llama_print_timings:        eval time =    1498.46 ms /    15 runs   (   99.90 ms per token,    10.01 tokens per second)\n",
            "llama_print_timings:       total time =    2403.15 ms /    45 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Profecampusano It is not feminism... It is hembrism, another empty progressive movement without arguments...\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.46 ms /    16 runs   (    0.59 ms per token,  1690.80 tokens per second)\n",
            "llama_print_timings: prompt eval time =     280.53 ms /    82 tokens (    3.42 ms per token,   292.30 tokens per second)\n",
            "llama_print_timings:        eval time =    1561.61 ms /    15 runs   (  104.11 ms per token,     9.61 tokens per second)\n",
            "llama_print_timings:       total time =    2087.52 ms /    97 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@YoBramanta @charovargas_ False. They achieved equality and now they are about to achieve hembrism, the imposition of women over men. They ended equality before the law, they eliminated the presumption of innocence, they continue to ask for Alliemoney and even alimony for children who do not belong to their husbands. They passed\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.29 ms /    16 runs   (    0.58 ms per token,  1721.54 tokens per second)\n",
            "llama_print_timings: prompt eval time =     273.33 ms /    68 tokens (    4.02 ms per token,   248.78 tokens per second)\n",
            "llama_print_timings:        eval time =    1619.38 ms /    15 runs   (  107.96 ms per token,     9.26 tokens per second)\n",
            "llama_print_timings:       total time =    2107.21 ms /    83 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@rosaruizarmi @AFBohorquez I think that is partly what Antonio says. The school is organized so that we all have access to a type of education, not just some. If that freedom of education and respect for an ideology are not ensured, the concert has no meaning.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.85 ms /    16 runs   (    0.62 ms per token,  1624.37 tokens per second)\n",
            "llama_print_timings: prompt eval time =     257.13 ms /    48 tokens (    5.36 ms per token,   186.68 tokens per second)\n",
            "llama_print_timings:        eval time =    1642.46 ms /    15 runs   (  109.50 ms per token,     9.13 tokens per second)\n",
            "llama_print_timings:       total time =    2070.11 ms /    63 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@PedroCastilloTe Very late now you want to put out your corruption with handouts, broad base when from the beginning you didn't care about Peru, only your ideology and destroying the economy.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.78 ms /    16 runs   (    0.55 ms per token,  1821.91 tokens per second)\n",
            "llama_print_timings: prompt eval time =     696.96 ms /    23 tokens (   30.30 ms per token,    33.00 tokens per second)\n",
            "llama_print_timings:        eval time =    1590.03 ms /    15 runs   (  106.00 ms per token,     9.43 tokens per second)\n",
            "llama_print_timings:       total time =    2437.65 ms /    38 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@EdySmol I think your fashion idea is in line with your political ideology...\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.64 ms /    16 runs   (    0.60 ms per token,  1659.41 tokens per second)\n",
            "llama_print_timings: prompt eval time =     289.15 ms /    78 tokens (    3.71 ms per token,   269.75 tokens per second)\n",
            "llama_print_timings:        eval time =    1523.13 ms /    15 runs   (  101.54 ms per token,     9.85 tokens per second)\n",
            "llama_print_timings:       total time =    2041.68 ms /    93 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Talk about the ideology of the conservative and liberal parties; It's talking about more than 100 years ago. That is obsolete in the world of civility, science, information, communications. The mocha heads were far away #camiloelbreve. https://t.co/fsZhKbb7b6\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.50 ms /    16 runs   (    0.72 ms per token,  1391.30 tokens per second)\n",
            "llama_print_timings: prompt eval time =     277.40 ms /    67 tokens (    4.14 ms per token,   241.53 tokens per second)\n",
            "llama_print_timings:        eval time =    1851.49 ms /    15 runs   (  123.43 ms per token,     8.10 tokens per second)\n",
            "llama_print_timings:       total time =    2478.40 ms /    82 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@parlaencatala @arqueoleg Territory that has welcomed him. What a flower-eating shit that is. The territory, neither the land nor anything welcomed them, they came to work and were exploited by the businessmen as always happens. Fuck your host land ideology.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.21 ms /    16 runs   (    0.58 ms per token,  1737.62 tokens per second)\n",
            "llama_print_timings: prompt eval time =     261.39 ms /    52 tokens (    5.03 ms per token,   198.94 tokens per second)\n",
            "llama_print_timings:        eval time =    1567.98 ms /    15 runs   (  104.53 ms per token,     9.57 tokens per second)\n",
            "llama_print_timings:       total time =    2001.58 ms /    67 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Lu19_92 @Kabroneitor That doesn't exist here and I don't think it exists because every time you want to build that popular ideology, someone powerful comes to set it on fire...\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.95 ms /    16 runs   (    0.56 ms per token,  1787.91 tokens per second)\n",
            "llama_print_timings: prompt eval time =     588.38 ms /    21 tokens (   28.02 ms per token,    35.69 tokens per second)\n",
            "llama_print_timings:        eval time =    1453.12 ms /    15 runs   (   96.87 ms per token,    10.32 tokens per second)\n",
            "llama_print_timings:       total time =    2152.44 ms /    36 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@interiorgob @guardiacivil Well, you have destroyed equal opportunities.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.97 ms /    16 runs   (    0.62 ms per token,  1604.49 tokens per second)\n",
            "llama_print_timings: prompt eval time =     279.72 ms /    76 tokens (    3.68 ms per token,   271.70 tokens per second)\n",
            "llama_print_timings:        eval time =    1683.19 ms /    15 runs   (  112.21 ms per token,     8.91 tokens per second)\n",
            "llama_print_timings:       total time =    2197.80 ms /    91 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@NataliGuissen @murra22 @isidoraalcalde It is not because of a more patriarchal society. It is because men and women have different interests. Women are more inclined towards people and men towards things. The greater the equality of opportunities, the greater the gender difference in the different occupations in society!\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.59 ms /    16 runs   (    0.60 ms per token,  1668.23 tokens per second)\n",
            "llama_print_timings: prompt eval time =     284.89 ms /    78 tokens (    3.65 ms per token,   273.79 tokens per second)\n",
            "llama_print_timings:        eval time =    1466.70 ms /    15 runs   (   97.78 ms per token,    10.23 tokens per second)\n",
            "llama_print_timings:       total time =    1985.56 ms /    93 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@mlevyholden @zeinu1 @oasisdehorror + these difficulties translate into inequality of opportunities and it is not about just saying “study and try hard” because not everyone can and it is evident in the fact that the average salary is $7,500. It is about increasing equal opportunities to stop being a developing country\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.43 ms /    16 runs   (    0.59 ms per token,  1697.61 tokens per second)\n",
            "llama_print_timings: prompt eval time =     287.11 ms /    77 tokens (    3.73 ms per token,   268.19 tokens per second)\n",
            "llama_print_timings:        eval time =    1508.35 ms /    15 runs   (  100.56 ms per token,     9.94 tokens per second)\n",
            "llama_print_timings:       total time =    2022.41 ms /    92 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@user17700871792 @mparracgmailcom @maylwino @mmlagoscc The socialist term \"Substantive equality\" implies equalizing results (taking from some to give to others) not equality of opportunities, that is reason enough to reject that ideologized and poorly written text\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.02 ms /    16 runs   (    0.56 ms per token,  1774.43 tokens per second)\n",
            "llama_print_timings: prompt eval time =     253.89 ms /    49 tokens (    5.18 ms per token,   192.99 tokens per second)\n",
            "llama_print_timings:        eval time =    1599.24 ms /    15 runs   (  106.62 ms per token,     9.38 tokens per second)\n",
            "llama_print_timings:       total time =    2022.57 ms /    64 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@MariaMar_2020 @natumader I agree with that, hopefully one day there will be equal opportunities, then over the years it will be seen that it is more popular and profitable as a show\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.72 ms /    16 runs   (    0.61 ms per token,  1646.43 tokens per second)\n",
            "llama_print_timings: prompt eval time =     288.67 ms /    66 tokens (    4.37 ms per token,   228.63 tokens per second)\n",
            "llama_print_timings:        eval time =    1679.02 ms /    15 runs   (  111.93 ms per token,     8.93 tokens per second)\n",
            "llama_print_timings:       total time =    2287.84 ms /    81 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@romoyluna @Claudiashein Because I have always been on the left, I have always supported the fight for equal opportunities, the main characteristic of the left, while the right sees inequality as something Normal, something that is given and therefore always the strongest eats the \"weakest\"\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.69 ms /    16 runs   (    0.61 ms per token,  1651.70 tokens per second)\n",
            "llama_print_timings: prompt eval time =     268.49 ms /    61 tokens (    4.40 ms per token,   227.19 tokens per second)\n",
            "llama_print_timings:        eval time =    1496.17 ms /    15 runs   (   99.74 ms per token,    10.03 tokens per second)\n",
            "llama_print_timings:       total time =    1956.09 ms /    76 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@gonzalofullu Did anyone get hurt? Compare on equal terms and with a little judgment, can Parra end his career because of the killers that your team has as barrists and do you say that it is comparable to entering and facing the players themselves?\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.23 ms /    16 runs   (    0.58 ms per token,  1732.54 tokens per second)\n",
            "llama_print_timings: prompt eval time =     265.09 ms /    64 tokens (    4.14 ms per token,   241.42 tokens per second)\n",
            "llama_print_timings:        eval time =    1541.73 ms /    15 runs   (  102.78 ms per token,     9.73 tokens per second)\n",
            "llama_print_timings:       total time =    2003.78 ms /    79 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "for a future of politics that meets each person without violence of any kind, in equality and equity. I thank @CarolinaMoises and each of the people who were part of this beautiful, federal and horizontal day for a better Argentina ✌️🇦🇷\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.22 ms /    16 runs   (    0.64 ms per token,  1565.56 tokens per second)\n",
            "llama_print_timings: prompt eval time =     285.71 ms /    67 tokens (    4.26 ms per token,   234.50 tokens per second)\n",
            "llama_print_timings:        eval time =    1560.16 ms /    15 runs   (  104.01 ms per token,     9.61 tokens per second)\n",
            "llama_print_timings:       total time =    2155.72 ms /    82 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@mermelber @VFuture But I'm ashamed of having more than one man when we've been crowing about equality all our lives. Now we dont want her? Is the armchair of the extra rights of being able to fleece and destroy them more cool? Not me!\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.54 ms /    16 runs   (    0.60 ms per token,  1676.27 tokens per second)\n",
            "llama_print_timings: prompt eval time =     267.16 ms /    60 tokens (    4.45 ms per token,   224.58 tokens per second)\n",
            "llama_print_timings:        eval time =    1503.94 ms /    15 runs   (  100.26 ms per token,     9.97 tokens per second)\n",
            "llama_print_timings:       total time =    1961.81 ms /    75 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@marticasaspino The only ones it violates are those “mothers” who hold their children hostage against their parents! Equal rights, both emotional and economic! That's called justice, I understand you don't know what I'm talking about!\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.76 ms /    16 runs   (    0.61 ms per token,  1639.18 tokens per second)\n",
            "llama_print_timings: prompt eval time =     282.13 ms /    85 tokens (    3.32 ms per token,   301.28 tokens per second)\n",
            "llama_print_timings:        eval time =    1593.20 ms /    15 runs   (  106.21 ms per token,     9.42 tokens per second)\n",
            "llama_print_timings:       total time =    2115.46 ms /   100 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Party for all the boys and girls organized by the Noble Equality MPA Cooperative, thank God for so much blessing, we were overwhelmed with joy to see so many families sharing with us a special afternoon full of surprises for the little ones 😊♥️🇦🇷 https:/ /t.co/L4IzRQwtvv\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.23 ms /    16 runs   (    0.58 ms per token,  1733.10 tokens per second)\n",
            "llama_print_timings: prompt eval time =     300.54 ms /   105 tokens (    2.86 ms per token,   349.37 tokens per second)\n",
            "llama_print_timings:        eval time =    1473.72 ms /    15 runs   (   98.25 ms per token,    10.18 tokens per second)\n",
            "llama_print_timings:       total time =    2052.65 ms /   120 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Child Development: Rights of the present, future possibilities.This #UltimoBondi is a joint production of Colectivo +igualdad and @el_lado_fWe are accompanied by Anabella Santoro and Mira Colacce.Here is the link👇🔗 https://t.co/gO9JykEDw2 🧵 https:// t.co/uwRXhc4oSX\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.41 ms /    16 runs   (    0.59 ms per token,  1700.68 tokens per second)\n",
            "llama_print_timings: prompt eval time =     254.48 ms /    54 tokens (    4.71 ms per token,   212.20 tokens per second)\n",
            "llama_print_timings:        eval time =    1539.83 ms /    15 runs   (  102.66 ms per token,     9.74 tokens per second)\n",
            "llama_print_timings:       total time =    1970.62 ms /    69 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@AntonioMautor If you believe in the free market, in equal opportunities, that it does not produce results and queer feminism or intersectionality seems like nonsense to you, you are an unredeemed fascist who eats children\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.58 ms /    16 runs   (    0.60 ms per token,  1670.84 tokens per second)\n",
            "llama_print_timings: prompt eval time =     286.99 ms /    73 tokens (    3.93 ms per token,   254.36 tokens per second)\n",
            "llama_print_timings:        eval time =    1512.30 ms /    15 runs   (  100.82 ms per token,     9.92 tokens per second)\n",
            "llama_print_timings:       total time =    2021.36 ms /    88 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "The theory of intersectionality refers to complex processes that in each situation derive from the interaction of factors of various kinds. In fact, every phenomenon is the product of multiple causes (multicausality) according to the materialist dialectic on which science is based. https://t.co/W6ySZvXrm0\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.46 ms /    16 runs   (    0.59 ms per token,  1690.80 tokens per second)\n",
            "llama_print_timings: prompt eval time =     281.45 ms /    80 tokens (    3.52 ms per token,   284.25 tokens per second)\n",
            "llama_print_timings:        eval time =    1533.88 ms /    15 runs   (  102.26 ms per token,     9.78 tokens per second)\n",
            "llama_print_timings:       total time =    2186.57 ms /    95 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Exactly. It doesn't matter the color of your skin, the problem is the cult of the categories of gender, ethnicity or sexual orientation that promotes the theory of intersectionality and other garbage that comes out of universities in the USA. This is the opposite of what Luther King Jr. preached. https://t.co/OOcLmeFPND\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.17 ms /    16 runs   (    0.57 ms per token,  1744.63 tokens per second)\n",
            "llama_print_timings: prompt eval time =     242.54 ms /    45 tokens (    5.39 ms per token,   185.53 tokens per second)\n",
            "llama_print_timings:        eval time =    1557.30 ms /    15 runs   (  103.82 ms per token,     9.63 tokens per second)\n",
            "llama_print_timings:       total time =    1961.55 ms /    60 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Start of the Diploma in Gender Intersectionality and Citizenship #MovimientoCiudadano https://t.co/Wa85rUqOfF\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.97 ms /    16 runs   (    0.56 ms per token,  1783.52 tokens per second)\n",
            "llama_print_timings: prompt eval time =     284.10 ms /    77 tokens (    3.69 ms per token,   271.03 tokens per second)\n",
            "llama_print_timings:        eval time =    1554.79 ms /    15 runs   (  103.65 ms per token,     9.65 tokens per second)\n",
            "llama_print_timings:       total time =    2059.88 ms /    92 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Today Gloria Jean Watkins, known as bell hooks, would turn 70 years old. She is an American writer, feminist and social activist. The intersectionality between race, class and gender, in education, art, history, sexuality, media and feminism. https://t.co/snQjfrre4r\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.36 ms /    16 runs   (    0.65 ms per token,  1545.15 tokens per second)\n",
            "llama_print_timings: prompt eval time =     267.20 ms /    53 tokens (    5.04 ms per token,   198.35 tokens per second)\n",
            "llama_print_timings:        eval time =    1621.08 ms /    15 runs   (  108.07 ms per token,     9.25 tokens per second)\n",
            "llama_print_timings:       total time =    2160.36 ms /    68 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@nicalibe I am surprised by the number of people who are giving their opinion without even having any knowledge of intersectionality or black history, struggles and resistance. One of the most incredible things is that people think that reverse racism exists.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.10 ms /    16 runs   (    0.57 ms per token,  1758.43 tokens per second)\n",
            "llama_print_timings: prompt eval time =     282.72 ms /    84 tokens (    3.37 ms per token,   297.12 tokens per second)\n",
            "llama_print_timings:        eval time =    1564.56 ms /    15 runs   (  104.30 ms per token,     9.59 tokens per second)\n",
            "llama_print_timings:       total time =    2090.12 ms /    99 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Margaritarosadf I want equality between men and women but for it to be in everything, and for this not to become like in Spain where a man is bad just because he is a man, tough on the abuser, the harasser, the abuser, but highlighting those who are not. Long live human equality, which dignifies humanity and not sex.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.63 ms /    16 runs   (    0.60 ms per token,  1660.78 tokens per second)\n",
            "llama_print_timings: prompt eval time =     265.39 ms /    59 tokens (    4.50 ms per token,   222.32 tokens per second)\n",
            "llama_print_timings:        eval time =    1647.06 ms /    15 runs   (  109.80 ms per token,     9.11 tokens per second)\n",
            "llama_print_timings:       total time =    2106.88 ms /    74 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "society of that time, given that Roscio was determined to defend equality between all human beings, pointing out merit as the only valid difference between people, an unacceptable situation at that time with such established caste prejudices. This case is one of the\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.87 ms /    16 runs   (    0.55 ms per token,  1804.85 tokens per second)\n",
            "llama_print_timings: prompt eval time =     258.15 ms /    54 tokens (    4.78 ms per token,   209.18 tokens per second)\n",
            "llama_print_timings:        eval time =    1534.74 ms /    15 runs   (  102.32 ms per token,     9.77 tokens per second)\n",
            "llama_print_timings:       total time =    1972.57 ms /    69 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Rumbalion @PapiTorru Imagine. Equality between the sexes destroyed the family. That men and women have the same rights destroyed the family. The traditional family depended on the woman being subjugated. Okay.\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.12 ms /    16 runs   (    0.57 ms per token,  1754.58 tokens per second)\n",
            "llama_print_timings: prompt eval time =     285.29 ms /    70 tokens (    4.08 ms per token,   245.36 tokens per second)\n",
            "llama_print_timings:        eval time =    1504.14 ms /    15 runs   (  100.28 ms per token,     9.97 tokens per second)\n",
            "llama_print_timings:       total time =    2002.18 ms /    85 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "You're sure it's not about that? Isn't it the ministry of equality? So everything you say is equality between all of us, so that's what the poster is about, but isn't that the case? Why not? https://t.co/MCaGE6l3bl\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.58 ms /    16 runs   (    0.60 ms per token,  1669.97 tokens per second)\n",
            "llama_print_timings: prompt eval time =     292.98 ms /    88 tokens (    3.33 ms per token,   300.37 tokens per second)\n",
            "llama_print_timings:        eval time =    1577.99 ms /    15 runs   (  105.20 ms per token,     9.51 tokens per second)\n",
            "llama_print_timings:       total time =    2117.69 ms /   103 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Speech by Calmen Calvo at the Rota Feminist Congress. Review of the feminist struggle, for equality between the male and female sex, because women are half of the population, not a minority. They are not going to make us invisible To do +++ retwitter ✊💜🌹https://t.co/wZ01xrdH5y\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.18 ms /    16 runs   (    0.64 ms per token,  1572.33 tokens per second)\n",
            "llama_print_timings: prompt eval time =     281.85 ms /    76 tokens (    3.71 ms per token,   269.65 tokens per second)\n",
            "llama_print_timings:        eval time =    1556.07 ms /    15 runs   (  103.74 ms per token,     9.64 tokens per second)\n",
            "llama_print_timings:       total time =    2086.00 ms /    91 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "No one is going to read it because my account is locked and I'm not going to change it but: being a feminist is not going against the oppressive sex or I don't know how the hell they say it, feminism seeks equality between all. Let's see if we study, because then there are always problems+\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.16 ms /    16 runs   (    0.57 ms per token,  1747.11 tokens per second)\n",
            "llama_print_timings: prompt eval time =     248.58 ms /    58 tokens (    4.29 ms per token,   233.32 tokens per second)\n",
            "llama_print_timings:        eval time =    1561.59 ms /    15 runs   (  104.11 ms per token,     9.61 tokens per second)\n",
            "llama_print_timings:       total time =    2006.19 ms /    73 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@MariahM64685386 @Avefeni38769590 Most of the women who participate in these protests end up being prostitutes or criminals!!! Those women are an additional burden on society!!!\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.05 ms /    16 runs   (    0.63 ms per token,  1592.52 tokens per second)\n",
            "llama_print_timings: prompt eval time =     245.91 ms /    33 tokens (    7.45 ms per token,   134.20 tokens per second)\n",
            "llama_print_timings:        eval time =    1712.14 ms /    15 runs   (  114.14 ms per token,     8.76 tokens per second)\n",
            "llama_print_timings:       total time =    2112.57 ms /    48 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@victoriacaracev Most women are not going to be happy, not with love, not with money, not with sex.\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.77 ms /    16 runs   (    0.55 ms per token,  1823.78 tokens per second)\n",
            "llama_print_timings: prompt eval time =     248.30 ms /    40 tokens (    6.21 ms per token,   161.10 tokens per second)\n",
            "llama_print_timings:        eval time =    1544.13 ms /    15 runs   (  102.94 ms per token,     9.71 tokens per second)\n",
            "llama_print_timings:       total time =    1945.60 ms /    55 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "People who clearly don't know strength or contact sports, in which most women look like that. https://t.co/xAw9qXQMtU\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.41 ms /    16 runs   (    0.59 ms per token,  1700.32 tokens per second)\n",
            "llama_print_timings: prompt eval time =     269.89 ms /    65 tokens (    4.15 ms per token,   240.84 tokens per second)\n",
            "llama_print_timings:        eval time =    1531.60 ms /    15 runs   (  102.11 ms per token,     9.79 tokens per second)\n",
            "llama_print_timings:       total time =    2012.10 ms /    80 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@chan_ougi @Nosue18 @David_D4C @TheDarkraimola Considerable perhaps xD.But the difference is only 10 years and I already told you that at 43 years old most women don't usually look like that.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.41 ms /    16 runs   (    0.65 ms per token,  1536.39 tokens per second)\n",
            "llama_print_timings: prompt eval time =     254.58 ms /    48 tokens (    5.30 ms per token,   188.54 tokens per second)\n",
            "llama_print_timings:        eval time =    1886.50 ms /    15 runs   (  125.77 ms per token,     7.95 tokens per second)\n",
            "llama_print_timings:       total time =    2326.87 ms /    63 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@deunhidoret Exactly! And how do these people think the majority of white women in Europe live? How do you think Eastern women live? Single mothers? Victims of abuse? What clowns.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.06 ms /    16 runs   (    0.57 ms per token,  1765.42 tokens per second)\n",
            "llama_print_timings: prompt eval time =     261.39 ms /    50 tokens (    5.23 ms per token,   191.29 tokens per second)\n",
            "llama_print_timings:        eval time =    1473.04 ms /    15 runs   (   98.20 ms per token,    10.18 tokens per second)\n",
            "llama_print_timings:       total time =    1905.19 ms /    65 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Humanity is mediocre. Most women are neither superior nor inferior to most men. We are equal. We all deserve the same contempt. https://t.co/nRRuqawbvq\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.33 ms /    16 runs   (    0.58 ms per token,  1715.27 tokens per second)\n",
            "llama_print_timings: prompt eval time =     276.05 ms /    66 tokens (    4.18 ms per token,   239.08 tokens per second)\n",
            "llama_print_timings:        eval time =    1622.31 ms /    15 runs   (  108.15 ms per token,     9.25 tokens per second)\n",
            "llama_print_timings:       total time =    2103.21 ms /    81 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@mariaFFreijo It sounds harsh to hear it and it is tremendous, but on a day-to-day basis it is like this, without such a specific speech but with other actions, society acts like this. Not only can women not be desired, but they also have no desires.\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.35 ms /    16 runs   (    0.65 ms per token,  1546.04 tokens per second)\n",
            "llama_print_timings: prompt eval time =     242.78 ms /    36 tokens (    6.74 ms per token,   148.28 tokens per second)\n",
            "llama_print_timings:        eval time =    1843.40 ms /    15 runs   (  122.89 ms per token,     8.14 tokens per second)\n",
            "llama_print_timings:       total time =    2253.02 ms /    51 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@TatianaAstengoB For many Women, women Can't have sex Just for pleasure... This is how we are Worse, worse\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      12.18 ms /    16 runs   (    0.76 ms per token,  1314.06 tokens per second)\n",
            "llama_print_timings: prompt eval time =     290.18 ms /    78 tokens (    3.72 ms per token,   268.80 tokens per second)\n",
            "llama_print_timings:        eval time =    1519.12 ms /    15 runs   (  101.27 ms per token,     9.87 tokens per second)\n",
            "llama_print_timings:       total time =    2056.13 ms /    93 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "To the woke friends of the “very good” in international relations and who celebrate the stupidity of not receiving the credentials of the Ambassador of Israel, I tell you that at the same event those of the Ambassador of Saudi Arabia were received, a country where women cannot drive. . https://t.co/qXA5Hb1jjp\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.71 ms /    16 runs   (    0.54 ms per token,  1836.55 tokens per second)\n",
            "llama_print_timings: prompt eval time =     254.84 ms /    39 tokens (    6.53 ms per token,   153.04 tokens per second)\n",
            "llama_print_timings:        eval time =    1500.28 ms /    15 runs   (  100.02 ms per token,    10.00 tokens per second)\n",
            "llama_print_timings:       total time =    1902.46 ms /    54 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Women can't make anything hot, men automatically want to give you a 4?? how delicious write to me put photos of the chistri calm down please\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.53 ms /    16 runs   (    0.60 ms per token,  1679.61 tokens per second)\n",
            "llama_print_timings: prompt eval time =     249.82 ms /    60 tokens (    4.16 ms per token,   240.17 tokens per second)\n",
            "llama_print_timings:        eval time =    1535.67 ms /    15 runs   (  102.38 ms per token,     9.77 tokens per second)\n",
            "llama_print_timings:       total time =    1978.52 ms /    75 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Women can't do black kissing, Madonna in 1992 pretending to black kiss a model, women can do it all and even more trans ones 🏳‍⚧ https://t.co/hYeYFtnE0f\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.58 ms /    16 runs   (    0.66 ms per token,  1512.86 tokens per second)\n",
            "llama_print_timings: prompt eval time =     247.94 ms /    38 tokens (    6.52 ms per token,   153.26 tokens per second)\n",
            "llama_print_timings:        eval time =    1780.67 ms /    15 runs   (  118.71 ms per token,     8.42 tokens per second)\n",
            "llama_print_timings:       total time =    2203.77 ms /    53 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@keilin_mota Abel Martínez said that women cannot govern this country, what a mistake made by his friend Abel Martínez.\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.81 ms /    16 runs   (    0.55 ms per token,  1815.50 tokens per second)\n",
            "llama_print_timings: prompt eval time =     254.17 ms /    34 tokens (    7.48 ms per token,   133.77 tokens per second)\n",
            "llama_print_timings:        eval time =    1638.47 ms /    15 runs   (  109.23 ms per token,     9.15 tokens per second)\n",
            "llama_print_timings:       total time =    2035.98 ms /    49 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "That like means that you still love me and that you are going to leave your little lizard and come back to me, right? 😭\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.65 ms /    16 runs   (    0.54 ms per token,  1849.28 tokens per second)\n",
            "llama_print_timings: prompt eval time =     777.39 ms /    30 tokens (   25.91 ms per token,    38.59 tokens per second)\n",
            "llama_print_timings:        eval time =    1475.79 ms /    15 runs   (   98.39 ms per token,    10.16 tokens per second)\n",
            "llama_print_timings:       total time =    2387.08 ms /    45 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@CynthiaRivarol5 Shut up corrupt lizard. You should be a little ashamed.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.42 ms /    16 runs   (    0.59 ms per token,  1699.24 tokens per second)\n",
            "llama_print_timings: prompt eval time =     242.78 ms /    43 tokens (    5.65 ms per token,   177.12 tokens per second)\n",
            "llama_print_timings:        eval time =    1520.65 ms /    15 runs   (  101.38 ms per token,     9.86 tokens per second)\n",
            "llama_print_timings:       total time =    1920.28 ms /    58 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@VicenteFoxHow shameless it was that your stepsons and your lagartona wife have benefited from Pemex and other corruption, beggar shits devils\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.33 ms /    16 runs   (    0.71 ms per token,  1412.30 tokens per second)\n",
            "llama_print_timings: prompt eval time =     289.88 ms /    76 tokens (    3.81 ms per token,   262.18 tokens per second)\n",
            "llama_print_timings:        eval time =    1729.24 ms /    15 runs   (  115.28 ms per token,     8.67 tokens per second)\n",
            "llama_print_timings:       total time =    2409.46 ms /    91 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "The Other, The Lover, The Hidden One, The Small House, The Husband Stealer, The Home Breaker, The Buscona, The Small Detail, The Lagartona sometimes they can fulfill their Fairy Tale ccp @weblade https://t.co/HsjnARIe1o\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.08 ms /    16 runs   (    0.57 ms per token,  1761.73 tokens per second)\n",
            "llama_print_timings: prompt eval time =     243.56 ms /    36 tokens (    6.77 ms per token,   147.81 tokens per second)\n",
            "llama_print_timings:        eval time =    1510.48 ms /    15 runs   (  100.70 ms per token,     9.93 tokens per second)\n",
            "llama_print_timings:       total time =    1900.51 ms /    51 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@PosaTres Blonde doesn't suit Gigi. It looks better on a lizard redhead brunette hahahaha.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.68 ms /    16 runs   (    0.61 ms per token,  1652.21 tokens per second)\n",
            "llama_print_timings: prompt eval time =     280.88 ms /    86 tokens (    3.27 ms per token,   306.18 tokens per second)\n",
            "llama_print_timings:        eval time =    1515.42 ms /    15 runs   (  101.03 ms per token,     9.90 tokens per second)\n",
            "llama_print_timings:       total time =    2039.72 ms /   101 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Are they going to study or are they going to gossip? If a teacher commits any improper act, it should be investigated and the complainants should be investigated. There are many lizards pretending to be dead. #Cuernavaca #Morelos #Jiutepec #Temixco https://t.co/iRgYeIrXAw\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.40 ms /    16 runs   (    0.59 ms per token,  1702.49 tokens per second)\n",
            "llama_print_timings: prompt eval time =     266.78 ms /    73 tokens (    3.65 ms per token,   273.64 tokens per second)\n",
            "llama_print_timings:        eval time =    1525.66 ms /    15 runs   (  101.71 ms per token,     9.83 tokens per second)\n",
            "llama_print_timings:       total time =    2009.43 ms /    88 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "I just finished the drawing that I will post tomorrow. Girls can't do this and don't do anything about it, first and last warning @LadyReahOfi @Christerva @terduki @Dangelisa @meieff this has only just begun 😈😈\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.01 ms /    16 runs   (    0.69 ms per token,  1452.83 tokens per second)\n",
            "llama_print_timings: prompt eval time =     268.47 ms /    59 tokens (    4.55 ms per token,   219.77 tokens per second)\n",
            "llama_print_timings:        eval time =    1766.94 ms /    15 runs   (  117.80 ms per token,     8.49 tokens per second)\n",
            "llama_print_timings:       total time =    2334.58 ms /    74 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "The worst thing is that after the tour they have a Japanese comeback, or BBC does something or we orbits have to get our act together and demand a good rest for the girls, because seriously, the girls can't continue overexerting themselves.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.53 ms /    16 runs   (    0.53 ms per token,  1875.95 tokens per second)\n",
            "llama_print_timings: prompt eval time =     266.37 ms /    58 tokens (    4.59 ms per token,   217.74 tokens per second)\n",
            "llama_print_timings:        eval time =    1578.95 ms /    15 runs   (  105.26 ms per token,     9.50 tokens per second)\n",
            "llama_print_timings:       total time =    2034.32 ms /    73 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@AnibalMortera Well, I feel offended because you said guys, what is it that girls can't respond to your Tweet? 🚩🚩🚩🚩🚩\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.40 ms /    16 runs   (    0.52 ms per token,  1905.44 tokens per second)\n",
            "llama_print_timings: prompt eval time =     243.73 ms /    40 tokens (    6.09 ms per token,   164.11 tokens per second)\n",
            "llama_print_timings:        eval time =    1500.43 ms /    15 runs   (  100.03 ms per token,    10.00 tokens per second)\n",
            "llama_print_timings:       total time =    1891.64 ms /    55 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "They are a very professional and high quality group, the girls couldn't be in better hands! https://t.co/R6eYvpiR07\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.55 ms /    16 runs   (    0.72 ms per token,  1385.64 tokens per second)\n",
            "llama_print_timings: prompt eval time =     287.79 ms /    73 tokens (    3.94 ms per token,   253.65 tokens per second)\n",
            "llama_print_timings:        eval time =    1743.14 ms /    15 runs   (  116.21 ms per token,     8.61 tokens per second)\n",
            "llama_print_timings:       total time =    2404.67 ms /    88 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Girls cannot play football in many schools in the United Kingdom because they can only do 'girls' sports. I found out when I had to substitute in Physical Education. I was amazed. 💪🏼 Very good initiative from the English players. https://t.co/NQQm7U62Fb\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.87 ms /    16 runs   (    0.55 ms per token,  1804.85 tokens per second)\n",
            "llama_print_timings: prompt eval time =     705.54 ms /    26 tokens (   27.14 ms per token,    36.85 tokens per second)\n",
            "llama_print_timings:        eval time =    1540.24 ms /    15 runs   (  102.68 ms per token,     9.74 tokens per second)\n",
            "llama_print_timings:       total time =    2368.46 ms /    41 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@adrianabravist6 Girls can't differentiate between discriminatory and descriptive\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.12 ms /    16 runs   (    0.57 ms per token,  1754.58 tokens per second)\n",
            "llama_print_timings: prompt eval time =     249.80 ms /    39 tokens (    6.41 ms per token,   156.13 tokens per second)\n",
            "llama_print_timings:        eval time =    1492.48 ms /    15 runs   (   99.50 ms per token,    10.05 tokens per second)\n",
            "llama_print_timings:       total time =    1886.92 ms /    54 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@DanannOficial you have to make a Sketch of what feminists think men's meetings are like and what it really is like... Hahahahaha\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.94 ms /    16 runs   (    0.56 ms per token,  1790.51 tokens per second)\n",
            "llama_print_timings: prompt eval time =     609.18 ms /    24 tokens (   25.38 ms per token,    39.40 tokens per second)\n",
            "llama_print_timings:        eval time =    1516.63 ms /    15 runs   (  101.11 ms per token,     9.89 tokens per second)\n",
            "llama_print_timings:       total time =    2248.37 ms /    39 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@laubenavidesg I love it when feminists attack a woman over a man.\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.71 ms /    16 runs   (    0.61 ms per token,  1647.62 tokens per second)\n",
            "llama_print_timings: prompt eval time =     301.13 ms /   113 tokens (    2.66 ms per token,   375.26 tokens per second)\n",
            "llama_print_timings:        eval time =    1615.12 ms /    15 runs   (  107.67 ms per token,     9.29 tokens per second)\n",
            "llama_print_timings:       total time =    2218.46 ms /   128 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@segoviag969 @EstherPedroche @Nievessebastia1 @madredecabrones @ElenaValenciano @carmencalvo_ @PSOE They have not been silent. You criticize them precisely because they have spoken, but you want them to tear up their cards. The PSOE feminists are not the enemy and it is certainly outrageous to say that they reinforce patriarchy. This is also reinforced by fundamentalism of any kind.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.28 ms /    16 runs   (    0.58 ms per token,  1724.32 tokens per second)\n",
            "llama_print_timings: prompt eval time =     276.89 ms /    74 tokens (    3.74 ms per token,   267.26 tokens per second)\n",
            "llama_print_timings:        eval time =    1617.18 ms /    15 runs   (  107.81 ms per token,     9.28 tokens per second)\n",
            "llama_print_timings:       total time =    2117.32 ms /    89 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Feminists take advantage of any shit to get into trouble, they don't understand that we are not getting involved with a woman, but with a position. For the same reasons, they must be fine with the despicable Boris Johnson's parties https://t.co/2f2xCl0i3V\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.90 ms /    16 runs   (    0.68 ms per token,  1467.62 tokens per second)\n",
            "llama_print_timings: prompt eval time =     292.08 ms /    82 tokens (    3.56 ms per token,   280.74 tokens per second)\n",
            "llama_print_timings:        eval time =    1673.34 ms /    15 runs   (  111.56 ms per token,     8.96 tokens per second)\n",
            "llama_print_timings:       total time =    2220.51 ms /    97 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "I don't see the Argentine feminists protesting for Mahsa Amini. I don't see the Argentine progressivity supporting the epic rebellion in which the Iranian people are bravely embarking against a theocratic, medieval, bloodthirsty and misogynistic dictatorship. The left and its double standard are disgusting.\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.21 ms /    16 runs   (    0.58 ms per token,  1737.43 tokens per second)\n",
            "llama_print_timings: prompt eval time =     287.69 ms /    84 tokens (    3.42 ms per token,   291.99 tokens per second)\n",
            "llama_print_timings:        eval time =    1519.14 ms /    15 runs   (  101.28 ms per token,     9.87 tokens per second)\n",
            "llama_print_timings:       total time =    2052.16 ms /    99 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "\"Wherever there is gender inequality, there is inequality in the laws. Wherever you see sexism, in your own daily life, in your private life. Don't let it go. In my own life, once I saw it, I never let it go pass\": Vivian Gornick 💜https://t.co/3x9Vssw9bP\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.46 ms /    16 runs   (    0.59 ms per token,  1690.80 tokens per second)\n",
            "llama_print_timings: prompt eval time =     264.10 ms /    69 tokens (    3.83 ms per token,   261.27 tokens per second)\n",
            "llama_print_timings:        eval time =    1519.45 ms /    15 runs   (  101.30 ms per token,     9.87 tokens per second)\n",
            "llama_print_timings:       total time =    1992.40 ms /    84 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@ericaasgg_ @Cobratate I like several things he says (not all of them) there are things I disagree with but he does say many times realistic things that no one says because women today want to see most of them like Kim kardashian and that shit about being lazy and worse\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.58 ms /    16 runs   (    0.60 ms per token,  1670.49 tokens per second)\n",
            "llama_print_timings: prompt eval time =     259.27 ms /    65 tokens (    3.99 ms per token,   250.71 tokens per second)\n",
            "llama_print_timings:        eval time =    1479.19 ms /    15 runs   (   98.61 ms per token,    10.14 tokens per second)\n",
            "llama_print_timings:       total time =    1944.06 ms /    80 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "woman: she does not have children because she cannot balance work/family life or due to economic instabilitypeople: women today are selfish, they prefer to travel and party than have children mothernophobia blablabla https://t.co/iyMWG3OArH\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.54 ms /    16 runs   (    0.72 ms per token,  1386.36 tokens per second)\n",
            "llama_print_timings: prompt eval time =     278.53 ms /    71 tokens (    3.92 ms per token,   254.91 tokens per second)\n",
            "llama_print_timings:        eval time =    1891.52 ms /    15 runs   (  126.10 ms per token,     7.93 tokens per second)\n",
            "llama_print_timings:       total time =    2413.07 ms /    86 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Above all, unsubmissive... well, she is a totally valid and independent woman... what women are today, despite the sinister Montero. This dictator does not allow anyone to make him see that he is wrong and contradict him. https://t.co/cURGFnO6wc\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.72 ms /    16 runs   (    0.61 ms per token,  1646.09 tokens per second)\n",
            "llama_print_timings: prompt eval time =     252.89 ms /    49 tokens (    5.16 ms per token,   193.76 tokens per second)\n",
            "llama_print_timings:        eval time =    1516.31 ms /    15 runs   (  101.09 ms per token,     9.89 tokens per second)\n",
            "llama_print_timings:       total time =    1942.77 ms /    64 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@interiorgob @guardiacivil Olazas that uterus carriers or modern-day women like these will opt for? https://t.co/rXQ2ZwZBTg\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.43 ms /    16 runs   (    0.53 ms per token,  1899.11 tokens per second)\n",
            "llama_print_timings: prompt eval time =     678.84 ms /    26 tokens (   26.11 ms per token,    38.30 tokens per second)\n",
            "llama_print_timings:        eval time =    1490.54 ms /    15 runs   (   99.37 ms per token,    10.06 tokens per second)\n",
            "llama_print_timings:       total time =    2289.05 ms /    41 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "AJSHAHAHAHAHA but whateeee happens to women today? 😂😂😂\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.41 ms /    16 runs   (    0.59 ms per token,  1701.04 tokens per second)\n",
            "llama_print_timings: prompt eval time =     263.75 ms /    61 tokens (    4.32 ms per token,   231.28 tokens per second)\n",
            "llama_print_timings:        eval time =    1524.20 ms /    15 runs   (  101.61 ms per token,     9.84 tokens per second)\n",
            "llama_print_timings:       total time =    2001.02 ms /    76 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@natiibedoya @smilelalis Have women today not burned down churches \"fighting\" for equality? The bullying was started by that cachalte...that suck. https://t.co/S9788rDFoA\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.57 ms /    16 runs   (    0.60 ms per token,  1671.37 tokens per second)\n",
            "llama_print_timings: prompt eval time =     305.74 ms /   106 tokens (    2.88 ms per token,   346.70 tokens per second)\n",
            "llama_print_timings:        eval time =    1613.51 ms /    15 runs   (  107.57 ms per token,     9.30 tokens per second)\n",
            "llama_print_timings:       total time =    2213.92 ms /   121 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@javitagracia @thezampah @terfforever @bcscienceiscool Are you medicated? Don't you understand that given the VULNERABILITY of the FEMALE SEX, Women SHOULD NOT BE MIXED WITH PEOPLE OF THE MALE SEX precisely to PREVENT ABUSE AND RAPE??? What's on your mind? Are you a defender of feelings instead of REALITIES???\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.93 ms /    16 runs   (    0.56 ms per token,  1791.31 tokens per second)\n",
            "llama_print_timings: prompt eval time =     281.83 ms /    73 tokens (    3.86 ms per token,   259.02 tokens per second)\n",
            "llama_print_timings:        eval time =    1535.64 ms /    15 runs   (  102.38 ms per token,     9.77 tokens per second)\n",
            "llama_print_timings:       total time =    2032.42 ms /    88 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Freedom of expression has limits, if you don't want to understand it, it's not our problem. It is not freedom of expression to say, for example, that I hate black people, that women should not work, among other things, do not try to make a victim of the person who is the complete opposite.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.13 ms /    16 runs   (    0.63 ms per token,  1579.16 tokens per second)\n",
            "llama_print_timings: prompt eval time =     265.54 ms /    56 tokens (    4.74 ms per token,   210.89 tokens per second)\n",
            "llama_print_timings:        eval time =    1540.43 ms /    15 runs   (  102.70 ms per token,     9.74 tokens per second)\n",
            "llama_print_timings:       total time =    1994.46 ms /    71 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "For a couple of months I have been living an experience that has allowed me to reaffirm my decision not to be a mother and has made me respect those who play that role even more. In short, women should not be forced to become mothers.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.17 ms /    16 runs   (    0.57 ms per token,  1744.44 tokens per second)\n",
            "llama_print_timings: prompt eval time =     596.21 ms /    32 tokens (   18.63 ms per token,    53.67 tokens per second)\n",
            "llama_print_timings:        eval time =    1621.88 ms /    15 runs   (  108.13 ms per token,     9.25 tokens per second)\n",
            "llama_print_timings:       total time =    2407.78 ms /    47 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Women should not waste time forgiving men because when the roles are reversed, men actually protect their peace and put themselves first.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.46 ms /    16 runs   (    0.59 ms per token,  1690.97 tokens per second)\n",
            "llama_print_timings: prompt eval time =     286.88 ms /    85 tokens (    3.38 ms per token,   296.30 tokens per second)\n",
            "llama_print_timings:        eval time =    1522.18 ms /    15 runs   (  101.48 ms per token,     9.85 tokens per second)\n",
            "llama_print_timings:       total time =    2063.17 ms /   100 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@JB_Lenoir @frannn34 @diagoabiel @CLMerlo You must be the typical one who thinks that because there are rapists in the streets, women should not go out in skirts on the street. A sexist idiot who doesn't know he's sexist. Or he knows it and wants to hide it. One of two.\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.64 ms /    16 runs   (    0.54 ms per token,  1852.28 tokens per second)\n",
            "llama_print_timings: prompt eval time =     598.72 ms /    32 tokens (   18.71 ms per token,    53.45 tokens per second)\n",
            "llama_print_timings:        eval time =    1492.90 ms /    15 runs   (   99.53 ms per token,    10.05 tokens per second)\n",
            "llama_print_timings:       total time =    2225.74 ms /    47 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "“Women should NOT look muscular like a man” https://t.co/aJ527yDAWo\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.40 ms /    16 runs   (    0.59 ms per token,  1701.95 tokens per second)\n",
            "llama_print_timings: prompt eval time =     287.17 ms /    88 tokens (    3.26 ms per token,   306.44 tokens per second)\n",
            "llama_print_timings:        eval time =    1567.23 ms /    15 runs   (  104.48 ms per token,     9.57 tokens per second)\n",
            "llama_print_timings:       total time =    2120.31 ms /   103 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@SheldonEXastor These miserable rats are causing... We are outraged and we beat them up on RRSS... They manage to get on the agenda and get us to talk about them. I wouldn't be surprised if they end up declaring that women shouldn't vote, and we'll take the bait again. The background: attention 🤬🤡\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.12 ms /    16 runs   (    0.57 ms per token,  1755.35 tokens per second)\n",
            "llama_print_timings: prompt eval time =     251.31 ms /    40 tokens (    6.28 ms per token,   159.17 tokens per second)\n",
            "llama_print_timings:        eval time =    1544.00 ms /    15 runs   (  102.93 ms per token,     9.72 tokens per second)\n",
            "llama_print_timings:       total time =    1944.55 ms /    55 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@LauraMex This guy is violent with women. They shouldn't leave it in Image. #GustavoAdolfoInfante @ImagenTVMex\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.95 ms /    16 runs   (    0.68 ms per token,  1460.79 tokens per second)\n",
            "llama_print_timings: prompt eval time =     272.28 ms /    68 tokens (    4.00 ms per token,   249.74 tokens per second)\n",
            "llama_print_timings:        eval time =    1832.80 ms /    15 runs   (  122.19 ms per token,     8.18 tokens per second)\n",
            "llama_print_timings:       total time =    2333.25 ms /    83 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Alberto_Fallen yes but that depends on your perception too. Remember that in the end they are matters of opinion, obviously if I say that women should not be protagonists of films, it is clear the type of person I am. but there are comments that remain in the gray and are condemned\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.81 ms /    16 runs   (    0.55 ms per token,  1816.74 tokens per second)\n",
            "llama_print_timings: prompt eval time =     609.73 ms /    22 tokens (   27.71 ms per token,    36.08 tokens per second)\n",
            "llama_print_timings:        eval time =    1550.12 ms /    15 runs   (  103.34 ms per token,     9.68 tokens per second)\n",
            "llama_print_timings:       total time =    2273.67 ms /    37 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@europapress Women should not even have the right to have their own phones.\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.02 ms /    16 runs   (    0.56 ms per token,  1773.64 tokens per second)\n",
            "llama_print_timings: prompt eval time =     243.75 ms /    55 tokens (    4.43 ms per token,   225.64 tokens per second)\n",
            "llama_print_timings:        eval time =    1479.70 ms /    15 runs   (   98.65 ms per token,    10.14 tokens per second)\n",
            "llama_print_timings:       total time =    1900.12 ms /    70 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "What a stress the \"high value\" girls on tiktok wn because they keep appearing to me JAJDKDJ like they force me to say that all women should not pay a single peso in a relationship that is cool\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.50 ms /    16 runs   (    0.59 ms per token,  1684.39 tokens per second)\n",
            "llama_print_timings: prompt eval time =     284.46 ms /    75 tokens (    3.79 ms per token,   263.66 tokens per second)\n",
            "llama_print_timings:        eval time =    1552.03 ms /    15 runs   (  103.47 ms per token,     9.66 tokens per second)\n",
            "llama_print_timings:       total time =    2063.01 ms /    90 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "They have no right to tell women how to dress, much less \"teach\" them by beating... it makes me very helpless to see these types of cases, women should not die for the simple fact of not following moral rules imposed by men, they They deserve to be free https://t.co/ecKl4HO4VX\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.67 ms /    16 runs   (    0.67 ms per token,  1499.11 tokens per second)\n",
            "llama_print_timings: prompt eval time =     241.36 ms /    34 tokens (    7.10 ms per token,   140.87 tokens per second)\n",
            "llama_print_timings:        eval time =    1856.69 ms /    15 runs   (  123.78 ms per token,     8.08 tokens per second)\n",
            "llama_print_timings:       total time =    2329.19 ms /    49 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@NotRuka Women don't know how to write scripts, finally https://t.co/1mKygduTzy\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.67 ms /    16 runs   (    0.54 ms per token,  1845.23 tokens per second)\n",
            "llama_print_timings: prompt eval time =     255.52 ms /    43 tokens (    5.94 ms per token,   168.29 tokens per second)\n",
            "llama_print_timings:        eval time =    1481.98 ms /    15 runs   (   98.80 ms per token,    10.12 tokens per second)\n",
            "llama_print_timings:       total time =    1894.05 ms /    58 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Women don't know what us guys suffer after the handjob HAHAHA the world is coming to you https://t.co/aC03q30Sdz\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.17 ms /    16 runs   (    0.57 ms per token,  1744.63 tokens per second)\n",
            "llama_print_timings: prompt eval time =     243.61 ms /    46 tokens (    5.30 ms per token,   188.83 tokens per second)\n",
            "llama_print_timings:        eval time =    1487.63 ms /    15 runs   (   99.18 ms per token,    10.08 tokens per second)\n",
            "llama_print_timings:       total time =    1897.44 ms /    61 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "BECAUSE OF MAJORS LIKE YOU THEY MAKE YOU BELIEVE THAT WOMEN DON'T KNOW ABOUT FOOTBALL, ASSHOLE\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.21 ms /    16 runs   (    0.58 ms per token,  1736.30 tokens per second)\n",
            "llama_print_timings: prompt eval time =     263.06 ms /    52 tokens (    5.06 ms per token,   197.68 tokens per second)\n",
            "llama_print_timings:        eval time =    1558.86 ms /    15 runs   (  103.92 ms per token,     9.62 tokens per second)\n",
            "llama_print_timings:       total time =    1994.28 ms /    67 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@bufanogero all kids answer you, that's because women don't know how to truly appreciate beauty and true men like you can only appreciate it as peers like us who know well what a gentleman should be like.\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.60 ms /    16 runs   (    0.60 ms per token,  1666.67 tokens per second)\n",
            "llama_print_timings: prompt eval time =     256.19 ms /    40 tokens (    6.40 ms per token,   156.13 tokens per second)\n",
            "llama_print_timings:        eval time =    1682.49 ms /    15 runs   (  112.17 ms per token,     8.92 tokens per second)\n",
            "llama_print_timings:       total time =    2172.28 ms /    55 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "1 women don't know how to chamuyar 2 pretty ones don't need it https://t.co/4WymRE4D0u\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.67 ms /    16 runs   (    0.54 ms per token,  1844.81 tokens per second)\n",
            "llama_print_timings: prompt eval time =     620.90 ms /    22 tokens (   28.22 ms per token,    35.43 tokens per second)\n",
            "llama_print_timings:        eval time =    1498.18 ms /    15 runs   (   99.88 ms per token,    10.01 tokens per second)\n",
            "llama_print_timings:       total time =    2237.47 ms /    37 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Santy_Calfu Women do not know how to value good men\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.41 ms /    16 runs   (    0.59 ms per token,  1699.60 tokens per second)\n",
            "llama_print_timings: prompt eval time =     297.08 ms /   100 tokens (    2.97 ms per token,   336.61 tokens per second)\n",
            "llama_print_timings:        eval time =    1501.29 ms /    15 runs   (  100.09 ms per token,     9.99 tokens per second)\n",
            "llama_print_timings:       total time =    2064.05 ms /   115 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Hey @searsmexico... What's wrong with your language... men are UNIVERSITY GUYS while women are YOUNG GIRLS... #machismo #machista advertising #micromachismos #girlpower I share this art with you, if it looks cool the other way around, ask your market manly if that makes sense to you. https://t.co/k9z5gsPPNU\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.73 ms /    16 runs   (    0.55 ms per token,  1832.34 tokens per second)\n",
            "llama_print_timings: prompt eval time =     248.93 ms /    37 tokens (    6.73 ms per token,   148.64 tokens per second)\n",
            "llama_print_timings:        eval time =    1637.41 ms /    15 runs   (  109.16 ms per token,     9.16 tokens per second)\n",
            "llama_print_timings:       total time =    2039.27 ms /    52 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "All women are perverts in the right hands, but not all men are the right ones, not all hands have magic. Vogard Pastelin F.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.60 ms /    16 runs   (    0.60 ms per token,  1667.36 tokens per second)\n",
            "llama_print_timings: prompt eval time =     271.42 ms /    72 tokens (    3.77 ms per token,   265.27 tokens per second)\n",
            "llama_print_timings:        eval time =    1524.20 ms /    15 runs   (  101.61 ms per token,     9.84 tokens per second)\n",
            "llama_print_timings:       total time =    2015.49 ms /    87 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@AntoniramonMol1 @DanyDani3l @COTESFERRO @luisagoenaga1 Women are simple beings if you only want them for sex, pay them and that's it, but yes, it does good because otherwise they block you or start treating you as a \"friend\"\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.75 ms /    16 runs   (    0.55 ms per token,  1828.15 tokens per second)\n",
            "llama_print_timings: prompt eval time =     671.47 ms /    26 tokens (   25.83 ms per token,    38.72 tokens per second)\n",
            "llama_print_timings:        eval time =    1463.16 ms /    15 runs   (   97.54 ms per token,    10.25 tokens per second)\n",
            "llama_print_timings:       total time =    2263.83 ms /    41 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Mood: excitedBut that doesn't mean I'm going to say that women are the worst\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.22 ms /    16 runs   (    0.58 ms per token,  1734.98 tokens per second)\n",
            "llama_print_timings: prompt eval time =     255.69 ms /    43 tokens (    5.95 ms per token,   168.17 tokens per second)\n",
            "llama_print_timings:        eval time =    1511.74 ms /    15 runs   (  100.78 ms per token,     9.92 tokens per second)\n",
            "llama_print_timings:       total time =    1929.81 ms /    58 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "All wrong! 🥲 | Women are the main victims of modern slavery in the mining areas of Venezuela | https://t.co/WV2lVrehbi\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.10 ms /    16 runs   (    0.63 ms per token,  1584.00 tokens per second)\n",
            "llama_print_timings: prompt eval time =     262.39 ms /    49 tokens (    5.35 ms per token,   186.74 tokens per second)\n",
            "llama_print_timings:        eval time =    1599.90 ms /    15 runs   (  106.66 ms per token,     9.38 tokens per second)\n",
            "llama_print_timings:       total time =    2130.35 ms /    64 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@samuel_arqui @PedroHe64552161 @MexicoLGBTTTI I think so, as women are also the ones who support women the least…\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.41 ms /    16 runs   (    0.59 ms per token,  1700.14 tokens per second)\n",
            "llama_print_timings: prompt eval time =     254.47 ms /    51 tokens (    4.99 ms per token,   200.42 tokens per second)\n",
            "llama_print_timings:        eval time =    1495.92 ms /    15 runs   (   99.73 ms per token,    10.03 tokens per second)\n",
            "llama_print_timings:       total time =    1923.40 ms /    66 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Yes, you would be surprised. I always wanted to practice some but my grandmother wouldn't let me. She said that the ladies didn't kick. https://t.co/8hH7qvBPok\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.36 ms /    16 runs   (    0.52 ms per token,  1913.42 tokens per second)\n",
            "llama_print_timings: prompt eval time =     558.54 ms /    32 tokens (   17.45 ms per token,    57.29 tokens per second)\n",
            "llama_print_timings:        eval time =    1565.87 ms /    15 runs   (  104.39 ms per token,     9.58 tokens per second)\n",
            "llama_print_timings:       total time =    2261.02 ms /    47 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "- Mom at school they say you're bullshitting me. - Who? - The ladies - No, who asked you?\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      13.13 ms /    16 runs   (    0.82 ms per token,  1218.40 tokens per second)\n",
            "llama_print_timings: prompt eval time =     241.23 ms /    50 tokens (    4.82 ms per token,   207.27 tokens per second)\n",
            "llama_print_timings:        eval time =    1828.53 ms /    15 runs   (  121.90 ms per token,     8.20 tokens per second)\n",
            "llama_print_timings:       total time =    2342.79 ms /    65 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Thegirlins Aimed!!! Likewise, the ladies don't eat arugula and only Bamboo likes lamb's lettuce, but we'll try it 😂💙\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.75 ms /    16 runs   (    0.55 ms per token,  1828.15 tokens per second)\n",
            "llama_print_timings: prompt eval time =     254.80 ms /    37 tokens (    6.89 ms per token,   145.21 tokens per second)\n",
            "llama_print_timings:        eval time =    1498.83 ms /    15 runs   (   99.92 ms per token,    10.01 tokens per second)\n",
            "llama_print_timings:       total time =    1897.56 ms /    52 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "The ladies can't deal with Iran, kids; It takes time to take care of succulents, buy faso and look for clone recipes.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.97 ms /    16 runs   (    0.56 ms per token,  1784.32 tokens per second)\n",
            "llama_print_timings: prompt eval time =     256.73 ms /    70 tokens (    3.67 ms per token,   272.66 tokens per second)\n",
            "llama_print_timings:        eval time =    1511.05 ms /    15 runs   (  100.74 ms per token,     9.93 tokens per second)\n",
            "llama_print_timings:       total time =    1980.65 ms /    85 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Since you managed to divert the focus from #VildaOUT, could you tell me if the ladies, I'm not puppets, are going to referee the second date https://t.co/XxEJgADo59 https://t.co/mQml9zwEWq\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      12.28 ms /    16 runs   (    0.77 ms per token,  1302.51 tokens per second)\n",
            "llama_print_timings: prompt eval time =     283.52 ms /    81 tokens (    3.50 ms per token,   285.69 tokens per second)\n",
            "llama_print_timings:        eval time =    1816.55 ms /    15 runs   (  121.10 ms per token,     8.26 tokens per second)\n",
            "llama_print_timings:       total time =    2369.05 ms /    96 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "She slaps him—The ladies don't shout or say bad words. Don't you see that I'm doing this for your own good? You won't find any man in your life who loves you if you're that big-mouthed. You have to be helpful to the man. Be there for him at all timesClick your tongue+\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.34 ms /    16 runs   (    0.58 ms per token,  1713.06 tokens per second)\n",
            "llama_print_timings: prompt eval time =     284.60 ms /    68 tokens (    4.19 ms per token,   238.93 tokens per second)\n",
            "llama_print_timings:        eval time =    1514.62 ms /    15 runs   (  100.97 ms per token,     9.90 tokens per second)\n",
            "llama_print_timings:       total time =    2008.08 ms /    83 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "It makes me laugh that in Mexico they take out the RAE for everything, not even the Spanish respect it that much, I have met people who believe that in Latin America they had some independent academy 🙄. Use inclusive language if you want, the RAE doesn't even know who they are.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.83 ms /    16 runs   (    0.55 ms per token,  1812.62 tokens per second)\n",
            "llama_print_timings: prompt eval time =     715.12 ms /    27 tokens (   26.49 ms per token,    37.76 tokens per second)\n",
            "llama_print_timings:        eval time =    1467.99 ms /    15 runs   (   97.87 ms per token,    10.22 tokens per second)\n",
            "llama_print_timings:       total time =    2313.32 ms /    42 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "There are more people using inclusive language as a joke than with the intention of integrating it into the language.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.50 ms /    16 runs   (    0.53 ms per token,  1883.46 tokens per second)\n",
            "llama_print_timings: prompt eval time =     237.87 ms /    34 tokens (    7.00 ms per token,   142.93 tokens per second)\n",
            "llama_print_timings:        eval time =    1561.77 ms /    15 runs   (  104.12 ms per token,     9.60 tokens per second)\n",
            "llama_print_timings:       total time =    1936.07 ms /    49 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@davidrianov Someone who says 'all' deserves to be a contractor for much longer, what a visual cancer inclusive language is.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.76 ms /    16 runs   (    0.67 ms per token,  1486.71 tokens per second)\n",
            "llama_print_timings: prompt eval time =     497.04 ms /    19 tokens (   26.16 ms per token,    38.23 tokens per second)\n",
            "llama_print_timings:        eval time =    1776.43 ms /    15 runs   (  118.43 ms per token,     8.44 tokens per second)\n",
            "llama_print_timings:       total time =    2410.01 ms /    34 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@LaInsolenta I love seeing heteres collapse because of inclusive language\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.32 ms /    16 runs   (    0.58 ms per token,  1716.92 tokens per second)\n",
            "llama_print_timings: prompt eval time =     254.66 ms /    58 tokens (    4.39 ms per token,   227.76 tokens per second)\n",
            "llama_print_timings:        eval time =    1550.64 ms /    15 runs   (  103.38 ms per token,     9.67 tokens per second)\n",
            "llama_print_timings:       total time =    1998.03 ms /    73 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@luchofigo1742 @Vengador2100 Just because custom normalizes its use does not mean that it is okay, same case of inclusive language (everyone for example), printed is another example, words that damage the language\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.74 ms /    16 runs   (    0.55 ms per token,  1830.24 tokens per second)\n",
            "llama_print_timings: prompt eval time =     245.94 ms /    35 tokens (    7.03 ms per token,   142.31 tokens per second)\n",
            "llama_print_timings:        eval time =    1534.37 ms /    15 runs   (  102.29 ms per token,     9.78 tokens per second)\n",
            "llama_print_timings:       total time =    1920.78 ms /    50 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@_VicenteViloni VICENTE VILONI USING INCLUSIVE LANGUAGE TOTAL CRACK\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.64 ms /    16 runs   (    0.54 ms per token,  1852.28 tokens per second)\n",
            "llama_print_timings: prompt eval time =     611.49 ms /    32 tokens (   19.11 ms per token,    52.33 tokens per second)\n",
            "llama_print_timings:        eval time =    1610.95 ms /    15 runs   (  107.40 ms per token,     9.31 tokens per second)\n",
            "llama_print_timings:       total time =    2356.86 ms /    47 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@LaLaithYagami https://t.co/3h4smCeTIo I send a hug from a distance\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.30 ms /    16 runs   (    0.64 ms per token,  1552.95 tokens per second)\n",
            "llama_print_timings: prompt eval time =     903.47 ms /    29 tokens (   31.15 ms per token,    32.10 tokens per second)\n",
            "llama_print_timings:        eval time =    1775.02 ms /    15 runs   (  118.33 ms per token,     8.45 tokens per second)\n",
            "llama_print_timings:       total time =    2879.41 ms /    44 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Don't gaslight someone who overthinks things a lot, because you're not going to achieve anything.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.32 ms /    16 runs   (    0.58 ms per token,  1716.19 tokens per second)\n",
            "llama_print_timings: prompt eval time =     283.29 ms /    70 tokens (    4.05 ms per token,   247.10 tokens per second)\n",
            "llama_print_timings:        eval time =    1502.82 ms /    15 runs   (  100.19 ms per token,     9.98 tokens per second)\n",
            "llama_print_timings:       total time =    1996.99 ms /    85 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@adrian_cordoba7 @SoyUnMitoGenia1 @Shine_McShine Much would have to be erased from historical memories signed by the Pope and others. It would be like saying now that the Berlin Wall did not exist. A very large gas light would have to be installed.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.37 ms /    16 runs   (    0.59 ms per token,  1708.31 tokens per second)\n",
            "llama_print_timings: prompt eval time =     280.06 ms /    67 tokens (    4.18 ms per token,   239.23 tokens per second)\n",
            "llama_print_timings:        eval time =    1553.42 ms /    15 runs   (  103.56 ms per token,     9.66 tokens per second)\n",
            "llama_print_timings:       total time =    2047.31 ms /    82 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@BrujaPiruja1234 @Vanessa_Naveira I have asked you where he laughed, as you say, I have already explained to you that he has not denied the obvious link but the 'magical' link and am I the one who gaslights? Oh\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.39 ms /    16 runs   (    0.71 ms per token,  1404.12 tokens per second)\n",
            "llama_print_timings: prompt eval time =     258.16 ms /    45 tokens (    5.74 ms per token,   174.31 tokens per second)\n",
            "llama_print_timings:        eval time =    1781.69 ms /    15 runs   (  118.78 ms per token,     8.42 tokens per second)\n",
            "llama_print_timings:       total time =    2243.72 ms /    60 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Not everything is misinformation, obstetric violence by professionals exists and denying it and wanting to make those who have experienced it question their experience is gaslighting like a piano. End of matter.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.01 ms /    16 runs   (    0.56 ms per token,  1776.59 tokens per second)\n",
            "llama_print_timings: prompt eval time =     297.44 ms /    90 tokens (    3.30 ms per token,   302.58 tokens per second)\n",
            "llama_print_timings:        eval time =    1501.76 ms /    15 runs   (  100.12 ms per token,     9.99 tokens per second)\n",
            "llama_print_timings:       total time =    2061.56 ms /   105 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@salvameoficial @BelenEstebanM Lidia looks like the old lady of the Simson cats. She falls asleep from the night's hangover and when she wakes up she comes out screaming yes, Princess Leonor, yes, the gas light... When what is being talked about? It's from Paquirrin kicking the girl in the audience hahahahahaha\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.30 ms /    16 runs   (    0.58 ms per token,  1720.80 tokens per second)\n",
            "llama_print_timings: prompt eval time =     246.84 ms /    60 tokens (    4.11 ms per token,   243.07 tokens per second)\n",
            "llama_print_timings:        eval time =    1489.68 ms /    15 runs   (   99.31 ms per token,    10.07 tokens per second)\n",
            "llama_print_timings:       total time =    1927.87 ms /    75 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@CatalinaSuarezB It's not machismo, it's that the minister doesn't help herself. When she doesn't screw up, her ambiguous and unfocused statements leave the impression that that purse is too big for her.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.79 ms /    16 runs   (    0.55 ms per token,  1820.04 tokens per second)\n",
            "llama_print_timings: prompt eval time =     288.18 ms /    80 tokens (    3.60 ms per token,   277.61 tokens per second)\n",
            "llama_print_timings:        eval time =    1488.81 ms /    15 runs   (   99.25 ms per token,    10.08 tokens per second)\n",
            "llama_print_timings:       total time =    2006.60 ms /    95 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@MafeCarrascal Unlearning this you with your problems, the reality is that you see machismo where it does not exist, classism where there is none, racism and structural problems that you use in the campaign... Today you do not use them and you want to correct them 🤣🤣🤣typical hypocritical dynamic of the politician🤣🤣🤣\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.66 ms /    16 runs   (    0.60 ms per token,  1655.63 tokens per second)\n",
            "llama_print_timings: prompt eval time =     928.52 ms /    31 tokens (   29.95 ms per token,    33.39 tokens per second)\n",
            "llama_print_timings:        eval time =    1608.40 ms /    15 runs   (  107.23 ms per token,     9.33 tokens per second)\n",
            "llama_print_timings:       total time =    2740.73 ms /    46 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@veintimillapier What if my dog ​​says yes? And with enthusiasm. That's dog machismo\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.71 ms /    16 runs   (    0.54 ms per token,  1836.34 tokens per second)\n",
            "llama_print_timings: prompt eval time =     280.98 ms /    87 tokens (    3.23 ms per token,   309.63 tokens per second)\n",
            "llama_print_timings:        eval time =    1518.99 ms /    15 runs   (  101.27 ms per token,     9.87 tokens per second)\n",
            "llama_print_timings:       total time =    2043.10 ms /   102 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@RCalasich @hermanntertsch Basically they are telling you that men harass you with their compliments, with their family protection or their machismo just because of what they have between their legs, but feminism can walk its clam, toto, chumino wherever it wants damn \"with your\" 20,000,000,000.\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.97 ms /    16 runs   (    0.56 ms per token,  1783.52 tokens per second)\n",
            "llama_print_timings: prompt eval time =     248.60 ms /    44 tokens (    5.65 ms per token,   176.99 tokens per second)\n",
            "llama_print_timings:        eval time =    1575.06 ms /    15 runs   (  105.00 ms per token,     9.52 tokens per second)\n",
            "llama_print_timings:       total time =    1987.47 ms /    59 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Pay attention to your children, so that they do not grow up believing that wearing a skirt “removes” machismo. https://t.co/04I6uEQEsw\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.62 ms /    16 runs   (    0.60 ms per token,  1663.72 tokens per second)\n",
            "llama_print_timings: prompt eval time =     249.50 ms /    60 tokens (    4.16 ms per token,   240.48 tokens per second)\n",
            "llama_print_timings:        eval time =    1588.20 ms /    15 runs   (  105.88 ms per token,     9.44 tokens per second)\n",
            "llama_print_timings:       total time =    2032.05 ms /    75 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@patovt Thanks Pato, in fact we tried to bring Barmaids Map to Spain at the beginning of this year but we found little receptivity to these and other topics, the scene was super fragmented and a lot of machismo even among women.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.90 ms /    16 runs   (    0.62 ms per token,  1616.32 tokens per second)\n",
            "llama_print_timings: prompt eval time =     307.76 ms /    92 tokens (    3.35 ms per token,   298.94 tokens per second)\n",
            "llama_print_timings:        eval time =    1652.00 ms /    15 runs   (  110.13 ms per token,     9.08 tokens per second)\n",
            "llama_print_timings:       total time =    2379.91 ms /   107 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@chanuwu22 @salmiaux @heartlessmedusa @Gise1393 @lightupmmylife that's why whenever a (feminist) woman says something stupid, she's going to say that it's \"mansplaining\" and that anyone who contradicts them is a fool and that's it, they stay so cool without needing to support their stupidity.\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.44 ms /    16 runs   (    0.53 ms per token,  1896.86 tokens per second)\n",
            "llama_print_timings: prompt eval time =     254.77 ms /    41 tokens (    6.21 ms per token,   160.93 tokens per second)\n",
            "llama_print_timings:        eval time =    1470.82 ms /    15 runs   (   98.05 ms per token,    10.20 tokens per second)\n",
            "llama_print_timings:       total time =    1878.13 ms /    56 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Uber is mansplaining me about life because I told him I studied Law and he told me that he knew more than me because he studied \"Criminal Justice\"\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.88 ms /    16 runs   (    0.56 ms per token,  1800.79 tokens per second)\n",
            "llama_print_timings: prompt eval time =     603.15 ms /    24 tokens (   25.13 ms per token,    39.79 tokens per second)\n",
            "llama_print_timings:        eval time =    1614.44 ms /    15 runs   (  107.63 ms per token,     9.29 tokens per second)\n",
            "llama_print_timings:       total time =    2340.08 ms /    39 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Today I discovered that straight men mansplaining among themselves HAHA how I hate them\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.19 ms /    16 runs   (    0.57 ms per token,  1741.59 tokens per second)\n",
            "llama_print_timings: prompt eval time =     239.54 ms /    37 tokens (    6.47 ms per token,   154.46 tokens per second)\n",
            "llama_print_timings:        eval time =    1670.02 ms /    15 runs   (  111.33 ms per token,     8.98 tokens per second)\n",
            "llama_print_timings:       total time =    2063.98 ms /    52 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "I'm sorry for all the mansplaining from an inge at my work, I'm already very warm for the metrorrey session today\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.91 ms /    16 runs   (    0.56 ms per token,  1796.54 tokens per second)\n",
            "llama_print_timings: prompt eval time =     694.04 ms /    26 tokens (   26.69 ms per token,    37.46 tokens per second)\n",
            "llama_print_timings:        eval time =    1578.19 ms /    15 runs   (  105.21 ms per token,     9.50 tokens per second)\n",
            "llama_print_timings:       total time =    2396.93 ms /    41 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Do men never get tired of mansplaining about absolutely everything? Well, how lazy some people are\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.84 ms /    16 runs   (    0.61 ms per token,  1626.84 tokens per second)\n",
            "llama_print_timings: prompt eval time =     298.22 ms /   106 tokens (    2.81 ms per token,   355.45 tokens per second)\n",
            "llama_print_timings:        eval time =    1627.53 ms /    15 runs   (  108.50 ms per token,     9.22 tokens per second)\n",
            "llama_print_timings:       total time =    2218.92 ms /   121 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@tefahernandez16 @ChefDSanmartin @charovargas_ How many times has our proofreader changed the words and because we were in a hurry we have not realized it or we have simply made a mistake!? In your case, it not only corrects you but also demonstrates how to do it: \"Mansplaining\"! He didn't give his opinion on the abortion, he questioned your spelling...🤦🏻‍♀️\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.30 ms /    16 runs   (    0.58 ms per token,  1720.25 tokens per second)\n",
            "llama_print_timings: prompt eval time =     781.28 ms /    29 tokens (   26.94 ms per token,    37.12 tokens per second)\n",
            "llama_print_timings:        eval time =    1497.41 ms /    15 runs   (   99.83 ms per token,    10.02 tokens per second)\n",
            "llama_print_timings:       total time =    2410.13 ms /    44 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Sit next to a manspreading man so that he does not occupy two places with his legs, check\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.54 ms /    16 runs   (    0.66 ms per token,  1517.74 tokens per second)\n",
            "llama_print_timings: prompt eval time =     251.86 ms /    35 tokens (    7.20 ms per token,   138.97 tokens per second)\n",
            "llama_print_timings:        eval time =    1768.28 ms /    15 runs   (  117.89 ms per token,     8.48 tokens per second)\n",
            "llama_print_timings:       total time =    2241.56 ms /    50 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Since I saw the tiktok of the girl spreading her legs also when someone next to her was manspreading I have taken on that personality\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.36 ms /    16 runs   (    0.58 ms per token,  1710.13 tokens per second)\n",
            "llama_print_timings: prompt eval time =     253.70 ms /    54 tokens (    4.70 ms per token,   212.85 tokens per second)\n",
            "llama_print_timings:        eval time =    1564.07 ms /    15 runs   (  104.27 ms per token,     9.59 tokens per second)\n",
            "llama_print_timings:       total time =    1998.95 ms /    69 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "THIS IS FEMINISM. I encourage feminists who are complaining about 'manspreading' in Spain to go to Iran to support those who are really fighting. https://t.co/oJ8UTCVtOS\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.69 ms /    16 runs   (    0.54 ms per token,  1842.26 tokens per second)\n",
            "llama_print_timings: prompt eval time =     251.50 ms /    33 tokens (    7.62 ms per token,   131.21 tokens per second)\n",
            "llama_print_timings:        eval time =    1511.49 ms /    15 runs   (  100.77 ms per token,     9.92 tokens per second)\n",
            "llama_print_timings:       total time =    1901.00 ms /    48 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Sorry but you are not manspreading. It has been deconstructed https://t.co/byPL72PNMB\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.27 ms /    16 runs   (    0.52 ms per token,  1934.70 tokens per second)\n",
            "llama_print_timings: prompt eval time =     589.77 ms /    23 tokens (   25.64 ms per token,    39.00 tokens per second)\n",
            "llama_print_timings:        eval time =    1555.86 ms /    15 runs   (  103.72 ms per token,     9.64 tokens per second)\n",
            "llama_print_timings:       total time =    2259.13 ms /    38 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "I was thinking about the pants torn by the bike, silently fighting the manspreading\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.29 ms /    16 runs   (    0.52 ms per token,  1929.80 tokens per second)\n",
            "llama_print_timings: prompt eval time =     907.90 ms /    29 tokens (   31.31 ms per token,    31.94 tokens per second)\n",
            "llama_print_timings:        eval time =    1492.46 ms /    15 runs   (   99.50 ms per token,    10.05 tokens per second)\n",
            "llama_print_timings:       total time =    2564.80 ms /    44 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "I'm actually in favor of men doing manspreading https://t.co/PNHuc7DOgn\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.51 ms /    16 runs   (    0.59 ms per token,  1681.91 tokens per second)\n",
            "llama_print_timings: prompt eval time =     259.64 ms /    61 tokens (    4.26 ms per token,   234.94 tokens per second)\n",
            "llama_print_timings:        eval time =    1462.44 ms /    15 runs   (   97.50 ms per token,    10.26 tokens per second)\n",
            "llama_print_timings:       total time =    1915.76 ms /    76 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Legend has it that Porfirio Díaz boasted that he governed Mexico as one would govern a madhouse. From the author of “Marimacho Mexico”! ($250) https://t.co/08scBDHRMU\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.34 ms /    16 runs   (    0.52 ms per token,  1918.70 tokens per second)\n",
            "llama_print_timings: prompt eval time =     632.08 ms /    22 tokens (   28.73 ms per token,    34.81 tokens per second)\n",
            "llama_print_timings:        eval time =    1543.35 ms /    15 runs   (  102.89 ms per token,     9.72 tokens per second)\n",
            "llama_print_timings:       total time =    2287.98 ms /    37 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "I can't be a sexy woman with this cold over and tomboy always...\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.46 ms /    16 runs   (    0.72 ms per token,  1395.55 tokens per second)\n",
            "llama_print_timings: prompt eval time =     244.30 ms /    49 tokens (    4.99 ms per token,   200.57 tokens per second)\n",
            "llama_print_timings:        eval time =    1804.13 ms /    15 runs   (  120.28 ms per token,     8.31 tokens per second)\n",
            "llama_print_timings:       total time =    2247.11 ms /    64 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "My dad calls me a tomboy, my colachon (with the tone of a dazed dad) and I look at him like that😍 https://t.co/KUx3g8AdSI\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       7.59 ms /    16 runs   (    0.47 ms per token,  2107.76 tokens per second)\n",
            "llama_print_timings: prompt eval time =     268.83 ms /    64 tokens (    4.20 ms per token,   238.07 tokens per second)\n",
            "llama_print_timings:        eval time =    1550.01 ms /    15 runs   (  103.33 ms per token,     9.68 tokens per second)\n",
            "llama_print_timings:       total time =    2017.42 ms /    79 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@EnClavePolitik @LassoGuillermo @CarinaVanceEC @OrlandoPerezEC @teleSURtv Isn't this tomboy the one who bought overpriced ambulances that had ashtrays for medical instruments? 🤔\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.06 ms /    16 runs   (    0.57 ms per token,  1765.42 tokens per second)\n",
            "llama_print_timings: prompt eval time =     244.34 ms /    46 tokens (    5.31 ms per token,   188.26 tokens per second)\n",
            "llama_print_timings:        eval time =    1538.65 ms /    15 runs   (  102.58 ms per token,     9.75 tokens per second)\n",
            "llama_print_timings:       total time =    1952.28 ms /    61 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "What a stupid daughter of a thousand whores, she only broke up with Thiago when it was convenient for her, I hope you get cancer, you fucking tomboy, I like you like hell.\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      11.74 ms /    16 runs   (    0.73 ms per token,  1362.63 tokens per second)\n",
            "llama_print_timings: prompt eval time =     295.47 ms /    79 tokens (    3.74 ms per token,   267.37 tokens per second)\n",
            "llama_print_timings:        eval time =    1844.02 ms /    15 runs   (  122.93 ms per token,     8.13 tokens per second)\n",
            "llama_print_timings:       total time =    2530.99 ms /    94 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Jo from Little Women. The original tomboy. Always with burns on her dresses because she stands near the fireplace. Justified fratricidal tendencies. She cuts her hair so she doesn't ask for money from her horrible aunt. Disaster in general. This speech:https://t.co/ZFWEgYJymc\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       8.62 ms /    16 runs   (    0.54 ms per token,  1855.07 tokens per second)\n",
            "llama_print_timings: prompt eval time =     251.49 ms /    35 tokens (    7.19 ms per token,   139.17 tokens per second)\n",
            "llama_print_timings:        eval time =    1527.27 ms /    15 runs   (  101.82 ms per token,     9.82 tokens per second)\n",
            "llama_print_timings:       total time =    1920.74 ms /    50 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Masculinism is urgently needed to fight against feminism. https://t.co/5s4jHOM1iT\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.28 ms /    16 runs   (    0.58 ms per token,  1724.14 tokens per second)\n",
            "llama_print_timings: prompt eval time =     247.37 ms /    45 tokens (    5.50 ms per token,   181.91 tokens per second)\n",
            "llama_print_timings:        eval time =    1599.82 ms /    15 runs   (  106.65 ms per token,     9.38 tokens per second)\n",
            "llama_print_timings:       total time =    2012.20 ms /    60 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@plopezperalvo @MasculinismoLi1 @jhon_lawrence1 @Alpaca_espon An account called liberal masculinismo siendl serie?\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.11 ms /    16 runs   (    0.57 ms per token,  1755.93 tokens per second)\n",
            "llama_print_timings: prompt eval time =     714.98 ms /    28 tokens (   25.53 ms per token,    39.16 tokens per second)\n",
            "llama_print_timings:        eval time =    1548.97 ms /    15 runs   (  103.26 ms per token,     9.68 tokens per second)\n",
            "llama_print_timings:       total time =    2388.21 ms /    43 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "I just saw the thing about liberal masculinism or whatever it's called, oh my god the red flags\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.90 ms /    16 runs   (    0.68 ms per token,  1468.29 tokens per second)\n",
            "llama_print_timings: prompt eval time =     291.98 ms /    85 tokens (    3.44 ms per token,   291.12 tokens per second)\n",
            "llama_print_timings:        eval time =    1712.86 ms /    15 runs   (  114.19 ms per token,     8.76 tokens per second)\n",
            "llama_print_timings:       total time =    2430.67 ms /   100 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@Bot_del_Rechazo @BrunoBellenger @luzliv25 @MaresCuarentona Machismo is not the counterpart of feminism, for machismo it is \"feminism\" and for feminism it is masculinism, the first two terms are patriarchal, that is, they resort to violence to solve problems.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.49 ms /    16 runs   (    0.59 ms per token,  1685.99 tokens per second)\n",
            "llama_print_timings: prompt eval time =     295.18 ms /    88 tokens (    3.35 ms per token,   298.12 tokens per second)\n",
            "llama_print_timings:        eval time =    1516.91 ms /    15 runs   (  101.13 ms per token,     9.89 tokens per second)\n",
            "llama_print_timings:       total time =    2065.35 ms /   103 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@klaster_fx @Patri79gg @Rita_Maestre In other words, if a man gets a girl pregnant and doesn't want to take charge, he has every right in the world to leave her behind. Let her worry about what she does. He doesn't have to pay anything...Today's radical feminism is giving way to the new masculinism.\n",
            "[/INST]\n",
            "YES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.13 ms /    16 runs   (    0.57 ms per token,  1751.89 tokens per second)\n",
            "llama_print_timings: prompt eval time =     240.76 ms /    48 tokens (    5.02 ms per token,   199.37 tokens per second)\n",
            "llama_print_timings:        eval time =    1541.52 ms /    15 runs   (  102.77 ms per token,     9.73 tokens per second)\n",
            "llama_print_timings:       total time =    1951.13 ms /    63 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "@neurorebelde @IsaMellen I think you are referring to hembrism/machismo. And it would be very wrong too. Feminism/masculinism seeks equality.\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.23 ms /    16 runs   (    0.58 ms per token,  1732.91 tokens per second)\n",
            "llama_print_timings: prompt eval time =     259.76 ms /    60 tokens (    4.33 ms per token,   230.99 tokens per second)\n",
            "llama_print_timings:        eval time =    1580.98 ms /    15 runs   (  105.40 ms per token,     9.49 tokens per second)\n",
            "llama_print_timings:       total time =    2039.06 ms /    75 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "I became obsessed with ONEPIECE and The Forced Marriage #Japanbooks #draw #Japancomicshttps://t.co/fcfIbvCdOq https://t.co/kbY5bIgBrn\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.27 ms /    16 runs   (    0.58 ms per token,  1725.81 tokens per second)\n",
            "llama_print_timings: prompt eval time =     263.06 ms /    61 tokens (    4.31 ms per token,   231.89 tokens per second)\n",
            "llama_print_timings:        eval time =    1582.23 ms /    15 runs   (  105.48 ms per token,     9.48 tokens per second)\n",
            "llama_print_timings:       total time =    2045.21 ms /    76 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "AntMan and The Forced Marriage are the best comics I've ever read #slayers #ink #Japanbookshttps://t.co/QUmjakJTwe https://t.co/qyPMEl93V6\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.05 ms /    16 runs   (    0.57 ms per token,  1768.74 tokens per second)\n",
            "llama_print_timings: prompt eval time =     254.86 ms /    39 tokens (    6.53 ms per token,   153.02 tokens per second)\n",
            "llama_print_timings:        eval time =    1524.48 ms /    15 runs   (  101.63 ms per token,     9.84 tokens per second)\n",
            "llama_print_timings:       total time =    1932.15 ms /    54 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "These people pull you into the alliance without breaking you. It seems more like a forced marriage. https://t.co/kkO0gPZ1g5\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.23 ms /    16 runs   (    0.58 ms per token,  1733.85 tokens per second)\n",
            "llama_print_timings: prompt eval time =     286.23 ms /    70 tokens (    4.09 ms per token,   244.56 tokens per second)\n",
            "llama_print_timings:        eval time =    1550.67 ms /    15 runs   (  103.38 ms per token,     9.67 tokens per second)\n",
            "llama_print_timings:       total time =    2051.33 ms /    85 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "I love the drawing style in \"The Forced Marriage\"! Is beautiful! And the character design is incredible. I highly recommend it! #artist #Summer #animationdevhttps://t.co/gid3CBmWeI https://t.co/XGE064d9ET\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.22 ms /    16 runs   (    0.58 ms per token,  1734.79 tokens per second)\n",
            "llama_print_timings: prompt eval time =     246.77 ms /    60 tokens (    4.11 ms per token,   243.15 tokens per second)\n",
            "llama_print_timings:        eval time =    1662.73 ms /    15 runs   (  110.85 ms per token,     9.02 tokens per second)\n",
            "llama_print_timings:       total time =    2109.92 ms /    75 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "I became obsessed with ONEPIECE and The Forced Marriage #plzsupport #conceptart #animememehttps://t.co/ZcAetm2Uvg https://t.co/3Ptun7tQzX\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =       9.32 ms /    16 runs   (    0.58 ms per token,  1717.11 tokens per second)\n",
            "llama_print_timings: prompt eval time =     275.73 ms /    70 tokens (    3.94 ms per token,   253.88 tokens per second)\n",
            "llama_print_timings:        eval time =    1498.95 ms /    15 runs   (   99.93 ms per token,    10.01 tokens per second)\n",
            "llama_print_timings:       total time =    1992.62 ms /    85 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "Discover more at Bilibili Comics - Search for \"The Forced Marriage\" and add it to your favorites! #originalcharacter #imagecomics #Japanbookshttps://t.co/zsFOEtdfiW https://t.co/bR6g3XrGvX\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =    1322.57 ms\n",
            "llama_print_timings:      sample time =      10.64 ms /    16 runs   (    0.66 ms per token,  1504.18 tokens per second)\n",
            "llama_print_timings: prompt eval time =     269.26 ms /    41 tokens (    6.57 ms per token,   152.27 tokens per second)\n",
            "llama_print_timings:        eval time =    1885.72 ms /    15 runs   (  125.71 ms per token,     7.95 tokens per second)\n",
            "llama_print_timings:       total time =    2411.80 ms /    56 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED: [INST]\n",
            "What deceptive weather, I came out in balls because it was hot and on the way back, it was a bit of a surprise for me. I caught pneumonia\n",
            "[/INST]\n",
            "NO\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r exist2024_badrock.zip task1_hard_badrock_1.json task1_hard_badrock_2.json"
      ],
      "metadata": {
        "id": "JAUcpxAdivmY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('exist2024_badrock.zip')"
      ],
      "metadata": {
        "id": "dia3xJw7TwSL"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b681ea880f56420eacb3fc0366dc65b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_da972865bee547b6998fcc38e88165dc",
              "IPY_MODEL_5b19be7f8ae645c6a264d794091d6940",
              "IPY_MODEL_2f04869e637542018dee1995a3fca139"
            ],
            "layout": "IPY_MODEL_858936563e4442b0a0bc168a9b30d3dc"
          }
        },
        "da972865bee547b6998fcc38e88165dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7de4cf1cfff847c39b30876b4ef2d1e4",
            "placeholder": "​",
            "style": "IPY_MODEL_800e8c46c9ae4a118168b9e0ed9bd453",
            "value": "mistral-7b-instruct-v0.2.Q6_K.gguf: 100%"
          }
        },
        "5b19be7f8ae645c6a264d794091d6940": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ea0a151eec96406281bfcfa3a70245bf",
            "max": 5942065440,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cec3fa17191843d089bf40785a6de01b",
            "value": 5942065440
          }
        },
        "2f04869e637542018dee1995a3fca139": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a7dbe5f4d8614b1992e8a1bf66783ef3",
            "placeholder": "​",
            "style": "IPY_MODEL_0e0454888c0647f4a0ecf54b19488707",
            "value": " 5.94G/5.94G [00:35&lt;00:00, 241MB/s]"
          }
        },
        "858936563e4442b0a0bc168a9b30d3dc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7de4cf1cfff847c39b30876b4ef2d1e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "800e8c46c9ae4a118168b9e0ed9bd453": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ea0a151eec96406281bfcfa3a70245bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cec3fa17191843d089bf40785a6de01b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a7dbe5f4d8614b1992e8a1bf66783ef3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0e0454888c0647f4a0ecf54b19488707": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}